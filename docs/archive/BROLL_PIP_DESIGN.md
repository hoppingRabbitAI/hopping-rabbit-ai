# B-Roll PiP å¢å¼ºåŠŸèƒ½è®¾è®¡æ–‡æ¡£

## æ¦‚è¿°

æœ¬æ–‡æ¡£æè¿° B-Roll åŠŸèƒ½çš„å¢å¼ºç‰ˆæœ¬ï¼Œæ–°å¢ä»¥ä¸‹æ ¸å¿ƒèƒ½åŠ›ï¼š

1. **B-Roll å¼€å…³é…ç½®** - ç”¨æˆ·å¯é€‰æ‹©æ˜¯å¦å¼€å¯ B-Roll
2. **B-Roll ç±»å‹é€‰æ‹©** - æ”¯æŒå…¨å±ï¼ˆFullscreenï¼‰ã€PiPï¼ˆç”»ä¸­ç”»ï¼‰ã€æ··åˆæ¨¡å¼
3. **äººè„¸æ£€æµ‹ä¸é¿è®©** - PiP B-Roll è‡ªåŠ¨é¿å¼€äººè„¸åŒºåŸŸ

---

## ä¸€ã€B-Roll é…ç½®é€‰é¡¹è®¾è®¡

### 1.1 é…ç½®æ•°æ®ç»“æ„

```typescript
// å‰ç«¯ç±»å‹å®šä¹‰
interface BRollConfig {
  // æ˜¯å¦å¯ç”¨ B-Roll
  enabled: boolean;
  
  // B-Roll æ˜¾ç¤ºæ¨¡å¼
  // - fullscreen: å…¨å±è¦†ç›–ï¼ˆé»˜è®¤ï¼‰
  // - pip: ç”»ä¸­ç”»ï¼ˆå°çª—å£å åŠ åœ¨äººåƒä¸Šï¼‰
  // - mixed: æ··åˆæ¨¡å¼ï¼ˆAI è‡ªåŠ¨é€‰æ‹©ï¼‰
  displayMode: 'fullscreen' | 'pip' | 'mixed';
  
  // PiP æ¨¡å¼ä¸“å±é…ç½®
  pipConfig?: {
    // PiP çª—å£å¤§å°ï¼ˆç›¸å¯¹äºç”»é¢çš„ç™¾åˆ†æ¯”ï¼‰
    size: 'small' | 'medium' | 'large'; // 20% | 30% | 40%
    
    // é»˜è®¤ä½ç½®ï¼ˆå½“æœªæ£€æµ‹åˆ°äººè„¸æ—¶ä½¿ç”¨ï¼‰
    defaultPosition: 'top-left' | 'top-right' | 'bottom-left' | 'bottom-right';
    
    // æ˜¯å¦å¯ç”¨äººè„¸é¿è®©
    faceAvoidance: boolean;
    
    // è¾¹è·ï¼ˆè·ç¦»ç”»é¢è¾¹ç¼˜çš„åƒç´ ï¼‰
    margin: number; // é»˜è®¤ 20px
    
    // åœ†è§’åŠå¾„
    borderRadius: number; // é»˜è®¤ 12px
  };
  
  // æ··åˆæ¨¡å¼é…ç½®
  mixedConfig?: {
    // å…¨å± B-Roll çš„æœ€å°æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰
    fullscreenMinDuration: number; // é»˜è®¤ 3000ms
    
    // PiP B-Roll çš„æœ€å°æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰
    pipMinDuration: number; // é»˜è®¤ 1500ms
    
    // ä½¿ç”¨ PiP çš„æ¯”ä¾‹ï¼ˆ0-1ï¼‰
    pipRatio: number; // é»˜è®¤ 0.4ï¼Œå³ 40% ç”¨ PiP
  };
}
```

### 1.2 åç«¯é…ç½®æ¨¡å‹

```python
# backend/app/schemas/broll_config.py

from enum import Enum
from pydantic import BaseModel, Field
from typing import Optional


class BRollDisplayMode(str, Enum):
    """B-Roll æ˜¾ç¤ºæ¨¡å¼"""
    FULLSCREEN = "fullscreen"  # å…¨å±è¦†ç›–
    PIP = "pip"                # ç”»ä¸­ç”»
    MIXED = "mixed"            # æ··åˆæ¨¡å¼


class PipSize(str, Enum):
    """PiP çª—å£å¤§å°"""
    SMALL = "small"    # 20% of screen
    MEDIUM = "medium"  # 30% of screen
    LARGE = "large"    # 40% of screen


class PipPosition(str, Enum):
    """PiP é»˜è®¤ä½ç½®"""
    TOP_LEFT = "top-left"
    TOP_RIGHT = "top-right"
    BOTTOM_LEFT = "bottom-left"
    BOTTOM_RIGHT = "bottom-right"


class PipConfig(BaseModel):
    """PiP æ¨¡å¼é…ç½®"""
    size: PipSize = PipSize.MEDIUM
    default_position: PipPosition = PipPosition.BOTTOM_RIGHT
    face_avoidance: bool = True
    margin: int = Field(default=20, ge=0, le=100)
    border_radius: int = Field(default=12, ge=0, le=50)


class MixedConfig(BaseModel):
    """æ··åˆæ¨¡å¼é…ç½®"""
    fullscreen_min_duration: int = Field(default=3000, ge=1000)
    pip_min_duration: int = Field(default=1500, ge=500)
    pip_ratio: float = Field(default=0.4, ge=0.0, le=1.0)


class BRollConfigRequest(BaseModel):
    """B-Roll é…ç½®è¯·æ±‚"""
    enabled: bool = True
    display_mode: BRollDisplayMode = BRollDisplayMode.FULLSCREEN
    pip_config: Optional[PipConfig] = None
    mixed_config: Optional[MixedConfig] = None
```

---

## äºŒã€äººè„¸æ£€æµ‹ä¸é¿è®©è®¾è®¡

### 2.1 æŠ€æœ¯æ–¹æ¡ˆ

ä½¿ç”¨ **MediaPipe Face Detection** è¿›è¡Œè½»é‡çº§äººè„¸æ£€æµ‹ï¼š
- é€Ÿåº¦å¿«ï¼šå•å¸§ < 20ms
- å‡†ç¡®ç‡é«˜ï¼š99%+ åœ¨æ­£è„¸åœºæ™¯
- æ”¯æŒå¤šäººè„¸æ£€æµ‹
- è¿”å›è¾¹ç•Œæ¡† + å…³é”®ç‚¹

### 2.2 äººè„¸æ£€æµ‹æœåŠ¡

```python
# backend/app/services/face_detector.py

import mediapipe as mp
import cv2
import numpy as np
from dataclasses import dataclass
from typing import List, Optional, Tuple
import logging

logger = logging.getLogger(__name__)


@dataclass
class FaceRegion:
    """äººè„¸åŒºåŸŸ"""
    x: float          # å·¦ä¸Šè§’ Xï¼ˆ0-1 å½’ä¸€åŒ–ï¼‰
    y: float          # å·¦ä¸Šè§’ Yï¼ˆ0-1 å½’ä¸€åŒ–ï¼‰
    width: float      # å®½åº¦ï¼ˆ0-1 å½’ä¸€åŒ–ï¼‰
    height: float     # é«˜åº¦ï¼ˆ0-1 å½’ä¸€åŒ–ï¼‰
    confidence: float # ç½®ä¿¡åº¦


@dataclass
class FaceDetectionResult:
    """äººè„¸æ£€æµ‹ç»“æœ"""
    faces: List[FaceRegion]
    frame_width: int
    frame_height: int
    timestamp_ms: int


class FaceDetector:
    """äººè„¸æ£€æµ‹å™¨"""
    
    def __init__(self, min_confidence: float = 0.7):
        """
        åˆå§‹åŒ–äººè„¸æ£€æµ‹å™¨
        
        Args:
            min_confidence: æœ€å°ç½®ä¿¡åº¦é˜ˆå€¼
        """
        self.min_confidence = min_confidence
        self.mp_face_detection = mp.solutions.face_detection
        self.detector = self.mp_face_detection.FaceDetection(
            model_selection=0,  # 0=è¿‘è·ç¦»ï¼ˆ2ç±³å†…ï¼‰1=è¿œè·ç¦»ï¼ˆ5ç±³å†…ï¼‰
            min_detection_confidence=min_confidence,
        )
    
    def detect_from_frame(
        self, 
        frame: np.ndarray,
        timestamp_ms: int = 0
    ) -> FaceDetectionResult:
        """
        ä»å•å¸§å›¾åƒæ£€æµ‹äººè„¸
        
        Args:
            frame: BGR æ ¼å¼çš„å›¾åƒï¼ˆOpenCV æ ¼å¼ï¼‰
            timestamp_ms: å¸§æ—¶é—´æˆ³
            
        Returns:
            FaceDetectionResult: æ£€æµ‹ç»“æœ
        """
        height, width = frame.shape[:2]
        
        # è½¬æ¢ä¸º RGB
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        
        # æ£€æµ‹
        results = self.detector.process(rgb_frame)
        
        faces = []
        if results.detections:
            for detection in results.detections:
                bbox = detection.location_data.relative_bounding_box
                faces.append(FaceRegion(
                    x=max(0, bbox.xmin),
                    y=max(0, bbox.ymin),
                    width=min(1 - bbox.xmin, bbox.width),
                    height=min(1 - bbox.ymin, bbox.height),
                    confidence=detection.score[0],
                ))
        
        return FaceDetectionResult(
            faces=faces,
            frame_width=width,
            frame_height=height,
            timestamp_ms=timestamp_ms,
        )
    
    def detect_from_video(
        self,
        video_path: str,
        sample_interval_ms: int = 1000,
        max_samples: int = 30,
    ) -> List[FaceDetectionResult]:
        """
        ä»è§†é¢‘ä¸­é‡‡æ ·æ£€æµ‹äººè„¸
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            sample_interval_ms: é‡‡æ ·é—´éš”ï¼ˆæ¯«ç§’ï¼‰
            max_samples: æœ€å¤§é‡‡æ ·æ•°
            
        Returns:
            List[FaceDetectionResult]: å„å¸§æ£€æµ‹ç»“æœ
        """
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            logger.error(f"æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")
            return []
        
        fps = cap.get(cv2.CAP_PROP_FPS)
        frame_interval = int(fps * sample_interval_ms / 1000)
        
        results = []
        frame_idx = 0
        sample_count = 0
        
        while cap.isOpened() and sample_count < max_samples:
            ret, frame = cap.read()
            if not ret:
                break
            
            if frame_idx % frame_interval == 0:
                timestamp_ms = int(frame_idx / fps * 1000)
                result = self.detect_from_frame(frame, timestamp_ms)
                results.append(result)
                sample_count += 1
            
            frame_idx += 1
        
        cap.release()
        return results
    
    def get_safe_pip_region(
        self,
        faces: List[FaceRegion],
        pip_size: float = 0.3,
        margin: float = 0.02,
        preferred_position: str = "bottom-right",
    ) -> Tuple[float, float]:
        """
        è®¡ç®— PiP çª—å£çš„å®‰å…¨ä½ç½®ï¼ˆé¿å¼€äººè„¸ï¼‰
        
        Args:
            faces: æ£€æµ‹åˆ°çš„äººè„¸åˆ—è¡¨
            pip_size: PiP çª—å£å¤§å°ï¼ˆç›¸å¯¹äºç”»é¢å®½åº¦çš„æ¯”ä¾‹ï¼‰
            margin: è¾¹è·ï¼ˆç›¸å¯¹äºç”»é¢çš„æ¯”ä¾‹ï¼‰
            preferred_position: é¦–é€‰ä½ç½®
            
        Returns:
            Tuple[x, y]: PiP å·¦ä¸Šè§’ä½ç½®ï¼ˆ0-1 å½’ä¸€åŒ–ï¼‰
        """
        # å®šä¹‰å››ä¸ªè§’è½çš„å€™é€‰ä½ç½®
        positions = {
            "top-left": (margin, margin),
            "top-right": (1 - pip_size - margin, margin),
            "bottom-left": (margin, 1 - pip_size - margin),
            "bottom-right": (1 - pip_size - margin, 1 - pip_size - margin),
        }
        
        # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°äººè„¸ï¼Œè¿”å›é¦–é€‰ä½ç½®
        if not faces:
            return positions.get(preferred_position, positions["bottom-right"])
        
        # è®¡ç®—æ¯ä¸ªä½ç½®ä¸äººè„¸åŒºåŸŸçš„é‡å åº¦
        def calc_overlap(pos: Tuple[float, float]) -> float:
            pip_x, pip_y = pos
            pip_rect = (pip_x, pip_y, pip_x + pip_size, pip_y + pip_size)
            
            total_overlap = 0
            for face in faces:
                face_rect = (
                    face.x,
                    face.y,
                    face.x + face.width,
                    face.y + face.height,
                )
                # è®¡ç®—äº¤é›†é¢ç§¯
                inter_x1 = max(pip_rect[0], face_rect[0])
                inter_y1 = max(pip_rect[1], face_rect[1])
                inter_x2 = min(pip_rect[2], face_rect[2])
                inter_y2 = min(pip_rect[3], face_rect[3])
                
                if inter_x2 > inter_x1 and inter_y2 > inter_y1:
                    total_overlap += (inter_x2 - inter_x1) * (inter_y2 - inter_y1)
            
            return total_overlap
        
        # æŒ‰é‡å åº¦æ’åºï¼Œé€‰æ‹©é‡å æœ€å°‘çš„ä½ç½®
        position_scores = [
            (name, pos, calc_overlap(pos))
            for name, pos in positions.items()
        ]
        position_scores.sort(key=lambda x: x[2])
        
        # ä¼˜å…ˆé€‰æ‹©é‡å ä¸º 0 çš„ä½ç½®ä¸­ï¼Œä¸é¦–é€‰ä½ç½®æœ€è¿‘çš„
        zero_overlap = [p for p in position_scores if p[2] == 0]
        if zero_overlap:
            # å¦‚æœé¦–é€‰ä½ç½®æ— é‡å ï¼Œä½¿ç”¨é¦–é€‰ä½ç½®
            for name, pos, _ in zero_overlap:
                if name == preferred_position:
                    return pos
            # å¦åˆ™è¿”å›ç¬¬ä¸€ä¸ªæ— é‡å ä½ç½®
            return zero_overlap[0][1]
        
        # å¦‚æœæ‰€æœ‰ä½ç½®éƒ½æœ‰é‡å ï¼Œè¿”å›é‡å æœ€å°‘çš„
        return position_scores[0][1]
    
    def close(self):
        """é‡Šæ”¾èµ„æº"""
        self.detector.close()
```

### 2.3 äººè„¸åŒºåŸŸç¼“å­˜

ä¸ºé¿å…é‡å¤æ£€æµ‹ï¼Œä½¿ç”¨ Redis ç¼“å­˜äººè„¸æ£€æµ‹ç»“æœï¼š

```python
# backend/app/services/face_detection_cache.py

import json
import hashlib
from typing import Optional, List
from app.services.face_detector import FaceDetectionResult, FaceRegion
from app.config import redis_client

CACHE_PREFIX = "face_detection:"
CACHE_TTL = 86400 * 7  # 7 å¤©


def get_cache_key(video_path: str) -> str:
    """ç”Ÿæˆç¼“å­˜é”®"""
    path_hash = hashlib.md5(video_path.encode()).hexdigest()
    return f"{CACHE_PREFIX}{path_hash}"


def cache_detection_results(
    video_path: str,
    results: List[FaceDetectionResult],
):
    """ç¼“å­˜æ£€æµ‹ç»“æœ"""
    key = get_cache_key(video_path)
    data = [
        {
            "faces": [
                {
                    "x": f.x, "y": f.y,
                    "width": f.width, "height": f.height,
                    "confidence": f.confidence,
                }
                for f in r.faces
            ],
            "frame_width": r.frame_width,
            "frame_height": r.frame_height,
            "timestamp_ms": r.timestamp_ms,
        }
        for r in results
    ]
    redis_client.setex(key, CACHE_TTL, json.dumps(data))


def get_cached_results(video_path: str) -> Optional[List[FaceDetectionResult]]:
    """è·å–ç¼“å­˜çš„æ£€æµ‹ç»“æœ"""
    key = get_cache_key(video_path)
    data = redis_client.get(key)
    if not data:
        return None
    
    results = []
    for item in json.loads(data):
        faces = [
            FaceRegion(
                x=f["x"], y=f["y"],
                width=f["width"], height=f["height"],
                confidence=f["confidence"],
            )
            for f in item["faces"]
        ]
        results.append(FaceDetectionResult(
            faces=faces,
            frame_width=item["frame_width"],
            frame_height=item["frame_height"],
            timestamp_ms=item["timestamp_ms"],
        ))
    return results
```

---

## ä¸‰ã€API æ¥å£è®¾è®¡

### 3.1 ä¿å­˜ B-Roll é…ç½®

```python
# æ‰©å±•ç°æœ‰ WorkflowConfigRequest

class WorkflowConfigRequest(BaseModel):
    """å·¥ä½œæµé…ç½®è¯·æ±‚"""
    # ç°æœ‰å­—æ®µ
    pip_enabled: bool = False
    pip_position: Optional[str] = "bottom-right"
    pip_size: Optional[str] = "medium"
    
    # â˜… æ–°å¢ B-Roll é…ç½®
    broll_enabled: bool = False
    broll_display_mode: str = "fullscreen"  # fullscreen | pip | mixed
    broll_pip_config: Optional[dict] = None  # PiP ä¸“å±é…ç½®
    broll_mixed_config: Optional[dict] = None  # æ··åˆæ¨¡å¼é…ç½®
    
    background_preset: Optional[str] = None
```

### 3.2 è·å–äººè„¸æ£€æµ‹ç»“æœ

```
POST /api/workspace/sessions/{session_id}/detect-faces
```

**è¯·æ±‚**ï¼š
```json
{
  "asset_id": "uuid",
  "sample_interval_ms": 1000,
  "max_samples": 20
}
```

**å“åº”**ï¼š
```json
{
  "status": "ok",
  "faces": [
    {
      "timestamp_ms": 0,
      "faces": [
        {
          "x": 0.2,
          "y": 0.1,
          "width": 0.3,
          "height": 0.4,
          "confidence": 0.98
        }
      ]
    }
  ],
  "dominant_region": {
    "x": 0.25,
    "y": 0.15,
    "width": 0.35,
    "height": 0.45
  },
  "safe_pip_positions": ["top-left", "bottom-right"]
}
```

### 3.3 ç”Ÿæˆ B-Roll Clipsï¼ˆå¢å¼ºç‰ˆï¼‰

æ›´æ–°ç°æœ‰ APIï¼Œæ”¯æŒ `display_mode` é€‰æ‹©ï¼š

```
POST /api/workspace/sessions/{session_id}/generate-broll-clips
```

**è¯·æ±‚**ï¼š
```json
{
  "display_mode": "mixed",
  "pip_config": {
    "size": "medium",
    "default_position": "bottom-right",
    "face_avoidance": true
  }
}
```

---

## å››ã€å‰ç«¯ UI è®¾è®¡

### 4.1 B-Roll é…ç½®é¢æ¿

åœ¨ `WorkflowModal` çš„ config æ­¥éª¤ä¸­æ–°å¢ B-Roll é…ç½®åŒºï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ¬ B-Roll è®¾ç½®                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  [ ] å¯ç”¨ B-Roll è‡ªåŠ¨æ’å…¥                                    â”‚
â”‚                                                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                             â”‚
â”‚  æ˜¾ç¤ºæ¨¡å¼ï¼š                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚  ğŸ“º å…¨å±     â”‚  â”‚  ğŸ–¼ï¸ ç”»ä¸­ç”»   â”‚  â”‚  ğŸ”€ æ™ºèƒ½æ··åˆ  â”‚       â”‚
â”‚  â”‚  Fullscreen  â”‚  â”‚    PiP       â”‚  â”‚    Mixed     â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                             â”‚
â”‚  ğŸ–¼ï¸ ç”»ä¸­ç”»è®¾ç½®ï¼ˆä»… PiP/Mixed æ¨¡å¼ï¼‰                           â”‚
â”‚                                                             â”‚
â”‚  çª—å£å¤§å°ï¼š  [å°] [ä¸­] [å¤§]                                   â”‚
â”‚  é»˜è®¤ä½ç½®ï¼š  [å·¦ä¸Š] [å³ä¸Š] [å·¦ä¸‹] [å³ä¸‹]                       â”‚
â”‚  [âœ“] è‡ªåŠ¨é¿å¼€äººè„¸                                            â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 å®æ—¶é¢„è§ˆ

æä¾›å¯è§†åŒ–é¢„è§ˆï¼Œå±•ç¤º PiP çª—å£ä½ç½®ä¸äººè„¸åŒºåŸŸçš„å…³ç³»ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    é¢„è§ˆç”»é¢                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚                                                   â”‚      â”‚
â”‚  â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”                           â”‚      â”‚
â”‚  â”‚              â”‚  ğŸ‘¤   â”‚  â† äººè„¸åŒºåŸŸï¼ˆè™šçº¿æ ‡æ³¨ï¼‰     â”‚      â”‚
â”‚  â”‚              â”‚       â”‚                           â”‚      â”‚
â”‚  â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚      â”‚
â”‚  â”‚                                                   â”‚      â”‚
â”‚  â”‚                                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚      â”‚
â”‚  â”‚                                   â”‚ B-Roll  â”‚    â”‚      â”‚
â”‚  â”‚                                   â”‚  PiP    â”‚    â”‚      â”‚
â”‚  â”‚                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                             â”‚
â”‚  âœ… æ— é®æŒ¡å†²çª                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## äº”ã€Remotion æ¸²æŸ“é€‚é…

### 5.1 PiP B-Roll ç»„ä»¶é…ç½®

```typescript
interface PipBRollConfig {
  // åŸºç¡€ä¿¡æ¯
  id: string;
  type: 'broll';
  start_ms: number;
  end_ms: number;
  
  // PiP ä¸“å±
  display_mode: 'pip';
  pip_position: {
    x: number;  // 0-1 å½’ä¸€åŒ–
    y: number;  // 0-1 å½’ä¸€åŒ–
  };
  pip_size: number;  // ç›¸å¯¹äºç”»é¢å®½åº¦çš„æ¯”ä¾‹
  border_radius: number;
  
  // äººè„¸é¿è®©ä¿¡æ¯
  face_regions?: Array<{
    x: number;
    y: number;
    width: number;
    height: number;
  }>;
  
  // èµ„æº
  asset_url: string;
  asset_id: string;
  
  // è¿‡æ¸¡åŠ¨ç”»
  transition_in: 'fade' | 'slide' | 'scale';
  transition_out: 'fade' | 'slide' | 'scale';
}
```

### 5.2 å‰ç«¯æ¸²æŸ“ç»„ä»¶

```tsx
// frontend/src/remotion/components/PipBRoll.tsx

import { AbsoluteFill, Img, Video, interpolate, useCurrentFrame } from 'remotion';

interface PipBRollProps {
  config: PipBRollConfig;
  canvasWidth: number;
  canvasHeight: number;
}

export function PipBRoll({ config, canvasWidth, canvasHeight }: PipBRollProps) {
  const frame = useCurrentFrame();
  
  // è®¡ç®—å®é™…åƒç´ ä½ç½®
  const pipWidth = canvasWidth * config.pip_size;
  const pipHeight = pipWidth * 9 / 16; // ä¿æŒ 16:9 æ¯”ä¾‹
  const pipX = config.pip_position.x * canvasWidth;
  const pipY = config.pip_position.y * canvasHeight;
  
  // å…¥åœºåŠ¨ç”»
  const opacity = interpolate(
    frame,
    [0, 15],
    [0, 1],
    { extrapolateRight: 'clamp' }
  );
  
  const scale = interpolate(
    frame,
    [0, 15],
    [0.8, 1],
    { extrapolateRight: 'clamp' }
  );
  
  return (
    <div
      style={{
        position: 'absolute',
        left: pipX,
        top: pipY,
        width: pipWidth,
        height: pipHeight,
        borderRadius: config.border_radius,
        overflow: 'hidden',
        opacity,
        transform: `scale(${scale})`,
        boxShadow: '0 4px 20px rgba(0,0,0,0.3)',
      }}
    >
      <Video
        src={config.asset_url}
        style={{
          width: '100%',
          height: '100%',
          objectFit: 'cover',
        }}
      />
    </div>
  );
}
```

---

## å…­ã€å®ç°è®¡åˆ’

### Phase 1: åŸºç¡€é…ç½®ï¼ˆ1-2 å¤©ï¼‰

1. [ ] åç«¯ï¼šæ–°å¢ `BRollDisplayMode` æšä¸¾å’Œé…ç½®æ¨¡å‹
2. [ ] åç«¯ï¼šæ‰©å±• `WorkflowConfigRequest` æ”¯æŒæ–°é…ç½®
3. [ ] å‰ç«¯ï¼šWorkflowModal æ–°å¢ B-Roll é…ç½® UI
4. [ ] å‰ç«¯ï¼šé…ç½®çŠ¶æ€æŒä¹…åŒ–

### Phase 2: äººè„¸æ£€æµ‹ï¼ˆ2-3 å¤©ï¼‰

1. [ ] åç«¯ï¼šå®ç° `FaceDetector` æœåŠ¡
2. [ ] åç«¯ï¼šæ·»åŠ  Redis ç¼“å­˜å±‚
3. [ ] åç«¯ï¼šæ–°å¢ `/detect-faces` API
4. [ ] å‰ç«¯ï¼šé›†æˆäººè„¸æ£€æµ‹ç»“æœæ˜¾ç¤º

### Phase 3: PiP ä½ç½®è®¡ç®—ï¼ˆ1-2 å¤©ï¼‰

1. [ ] åç«¯ï¼šå®ç° `get_safe_pip_region()` ç®—æ³•
2. [ ] åç«¯ï¼šæ›´æ–° B-Roll clip ç”Ÿæˆé€»è¾‘
3. [ ] å‰ç«¯ï¼šé¢„è§ˆç”»é¢æ˜¾ç¤ºäººè„¸åŒºåŸŸå’Œ PiP ä½ç½®

### Phase 4: Remotion é€‚é…ï¼ˆ2-3 å¤©ï¼‰

1. [ ] å‰ç«¯ï¼šå®ç° `PipBRoll` æ¸²æŸ“ç»„ä»¶
2. [ ] å‰ç«¯ï¼šæ”¯æŒå…¥åœº/é€€åœºåŠ¨ç”»
3. [ ] åç«¯ï¼šæ›´æ–° Remotion é…ç½®ç”Ÿæˆå™¨
4. [ ] æµ‹è¯•ï¼šE2E æ¸²æŸ“æµ‹è¯•

### Phase 5: æ··åˆæ¨¡å¼ï¼ˆ1-2 å¤©ï¼‰

1. [ ] åç«¯ï¼šå®ç°æ··åˆæ¨¡å¼å†³ç­–é€»è¾‘
2. [ ] åç«¯ï¼šæ ¹æ®å†…å®¹ç±»å‹è‡ªåŠ¨é€‰æ‹© fullscreen/pip
3. [ ] å‰ç«¯ï¼šæ··åˆæ¨¡å¼é…ç½® UI

---

## ä¸ƒã€ä¾èµ–é¡¹

### Python åŒ…

```txt
# requirements_ai.txt æ–°å¢
mediapipe>=0.10.0
```

### å‰ç«¯æ— æ–°å¢ä¾èµ–

---

## å…«ã€æµ‹è¯•ç”¨ä¾‹

### 8.1 äººè„¸æ£€æµ‹æµ‹è¯•

```python
def test_face_detection():
    detector = FaceDetector()
    
    # æµ‹è¯•å•å¸§æ£€æµ‹
    frame = cv2.imread("test_face.jpg")
    result = detector.detect_from_frame(frame)
    assert len(result.faces) >= 1
    assert result.faces[0].confidence > 0.7

def test_pip_position_avoidance():
    detector = FaceDetector()
    
    # æ¨¡æ‹Ÿäººè„¸åœ¨å³ä¸‹è§’
    faces = [FaceRegion(x=0.6, y=0.6, width=0.3, height=0.3, confidence=0.9)]
    
    # æœŸæœ› PiP é¿å¼€å³ä¸‹è§’
    pos = detector.get_safe_pip_region(faces, pip_size=0.3, preferred_position="bottom-right")
    
    # åº”è¯¥è¿”å›å…¶ä»–è§’è½
    assert pos != (0.68, 0.68)  # ä¸åº”è¯¥åœ¨å³ä¸‹è§’
```

### 8.2 é…ç½®æŒä¹…åŒ–æµ‹è¯•

```python
def test_broll_config_save_and_load():
    # ä¿å­˜é…ç½®
    config = {
        "broll_enabled": True,
        "broll_display_mode": "pip",
        "broll_pip_config": {
            "size": "medium",
            "default_position": "top-left",
            "face_avoidance": True,
        }
    }
    
    response = client.post(
        f"/api/workspace/sessions/{session_id}/workflow-config",
        json=config
    )
    assert response.status_code == 200
    
    # è¯»å–é…ç½®
    response = client.get(f"/api/workspace/sessions/{session_id}/workflow-config")
    data = response.json()
    assert data["broll_display_mode"] == "pip"
    assert data["broll_pip_config"]["face_avoidance"] == True
```

---

## ä¹ã€FAQ

### Q: ä¸ºä»€ä¹ˆé€‰æ‹© MediaPipe è€Œä¸æ˜¯å…¶ä»–äººè„¸æ£€æµ‹æ–¹æ¡ˆï¼Ÿ

A: MediaPipe ä¼˜åŠ¿ï¼š
- è½»é‡çº§ï¼šæ— éœ€ GPUï¼ŒCPU å³å¯é«˜æ•ˆè¿è¡Œ
- ç²¾åº¦é«˜ï¼šGoogle æŒç»­ä¼˜åŒ–
- è·¨å¹³å°ï¼šæ”¯æŒ Python/JS/Mobile
- å…è´¹å¼€æºï¼šæ— è®¸å¯è´¹ç”¨

### Q: PiP çª—å£å¤§å°å¦‚ä½•ç¡®å®šï¼Ÿ

A: åŸºäºç”¨æˆ·ä½“éªŒç ”ç©¶ï¼š
- Small (20%): é€‚åˆè¾…åŠ©æ€§å†…å®¹ï¼Œä¸å–§å®¾å¤ºä¸»
- Medium (30%): å¹³è¡¡å±•ç¤ºæ•ˆæœå’Œä¸»å†…å®¹
- Large (40%): å¼ºè°ƒ B-Roll å†…å®¹ï¼Œé€‚åˆäº§å“å±•ç¤º

### Q: å¦‚æœå››ä¸ªè§’è½éƒ½ä¸äººè„¸é‡å æ€ä¹ˆåŠï¼Ÿ

A: ç®—æ³•ä¼šï¼š
1. è®¡ç®—æ¯ä¸ªè§’è½ä¸äººè„¸çš„é‡å é¢ç§¯
2. é€‰æ‹©é‡å é¢ç§¯æœ€å°çš„ä½ç½®
3. å¦‚æœé‡å è¿‡å¤§ï¼ˆ>50%ï¼‰ï¼Œå¯è€ƒè™‘åˆ‡æ¢åˆ° fullscreen æ¨¡å¼
