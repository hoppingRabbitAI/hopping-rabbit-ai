#!/usr/bin/env python3
"""
æµ‹è¯• LangChain LLM æœåŠ¡
"""
import asyncio
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.services.llm import llm_service


async def test_basic_call():
    """æµ‹è¯•åŸºç¡€ API è°ƒç”¨"""
    print("=" * 50)
    print("ğŸ§ª æµ‹è¯• 1: åŸºç¡€ API è°ƒç”¨")
    print("=" * 50)
    
    if not llm_service.is_configured():
        print("âŒ LLM API æœªé…ç½®")
        return False
    
    print("âœ… API Key å·²é…ç½®")
    
    # ç®€å•æµ‹è¯•
    response = await llm_service.call(
        prompt="è¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚",
        system_prompt="ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„AIåŠ©æ‰‹ã€‚",
    )
    
    if response:
        print(f"âœ… API è°ƒç”¨æˆåŠŸ!")
        print(f"ğŸ“ å“åº”: {response[:200]}...")
        return True
    else:
        print("âŒ API è°ƒç”¨å¤±è´¥")
        return False


async def test_emotion_analysis():
    """æµ‹è¯•æƒ…ç»ªåˆ†æåŠŸèƒ½"""
    print("\n" + "=" * 50)
    print("ğŸ§ª æµ‹è¯• 2: æƒ…ç»ªåˆ†æåŠŸèƒ½")
    print("=" * 50)
    
    test_segments = [
        {"id": "seg_001", "text": "å¤§å®¶å¥½ï¼Œæ¬¢è¿æ¥åˆ°æˆ‘çš„é¢‘é“ï¼"},
        {"id": "seg_002", "text": "ä»Šå¤©æˆ‘è¦ç»™å¤§å®¶åˆ†äº«ä¸€ä¸ªéå¸¸é‡è¦çš„æŠ€å·§ï¼"},
        {"id": "seg_003", "text": "è¿™ä¸ªæ–¹æ³•çœŸçš„å¤ªå‰å®³äº†ï¼Œå½»åº•æ”¹å˜äº†æˆ‘çš„å·¥ä½œæµï¼"},
        {"id": "seg_004", "text": "å¥½çš„ï¼Œé‚£æˆ‘ä»¬ä¸‹æœŸå†è§ã€‚"},
    ]
    
    print(f"ğŸ“¤ å‘é€ {len(test_segments)} ä¸ªæµ‹è¯•ç‰‡æ®µ...")
    
    result = await llm_service.analyze_emotions(test_segments)
    
    if result and result.results:
        print("âœ… æƒ…ç»ªåˆ†ææˆåŠŸ!")
        for item in result.results:
            print(f"  [{item.id}] emotion={item.emotion.value}, importance={item.importance.value}, keywords={item.keywords}")
        return True
    else:
        print("âŒ æƒ…ç»ªåˆ†æè¿”å›ç©ºç»“æœ")
        return False


async def test_script_generation():
    """æµ‹è¯•è„šæœ¬ç”ŸæˆåŠŸèƒ½"""
    print("\n" + "=" * 50)
    print("ğŸ§ª æµ‹è¯• 3: è„šæœ¬ç”ŸæˆåŠŸèƒ½")
    print("=" * 50)
    
    script = await llm_service.generate_script(
        topic="å¦‚ä½•æé«˜å·¥ä½œæ•ˆç‡",
        style="professional",
        duration=30,
    )
    
    if script and script.segments:
        print("âœ… è„šæœ¬ç”ŸæˆæˆåŠŸ!")
        print(f"ğŸ“Œ æ ‡é¢˜: {script.title}")
        print(f"ğŸ“Œ ç‰‡æ®µæ•°: {len(script.segments)}")
        for i, seg in enumerate(script.segments[:3]):
            print(f"  [{i+1}] {seg.text[:50]}...")
        return True
    else:
        print("âŒ è„šæœ¬ç”Ÿæˆè¿”å›ç©ºç»“æœ")
        return False


async def main():
    print("\nğŸš€ LangChain LLM æœåŠ¡æµ‹è¯•")
    print("=" * 50)
    
    # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
    from app.config import get_settings
    settings = get_settings()
    print(f"ğŸ“Œ Provider: {llm_service.provider}")
    print(f"ğŸ“Œ Model: {settings.doubao_model_endpoint}")
    print(f"ğŸ“Œ Configured: {llm_service.is_configured()}")
    
    # æ‰§è¡Œæµ‹è¯•
    test1_passed = await test_basic_call()
    test2_passed = await test_emotion_analysis()
    test3_passed = await test_script_generation()
    
    # æ€»ç»“
    print("\n" + "=" * 50)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 50)
    print(f"  åŸºç¡€è°ƒç”¨:   {'âœ… PASS' if test1_passed else 'âŒ FAIL'}")
    print(f"  æƒ…ç»ªåˆ†æ:   {'âœ… PASS' if test2_passed else 'âŒ FAIL'}")
    print(f"  è„šæœ¬ç”Ÿæˆ:   {'âœ… PASS' if test3_passed else 'âŒ FAIL'}")
    
    if test1_passed and test2_passed and test3_passed:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼LLM æœåŠ¡å·²å°±ç»ªã€‚")
    else:
        print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®ã€‚")


if __name__ == "__main__":
    asyncio.run(main())
