"""
åˆ†é•œ API è·¯ç”±
æä¾›åˆ†é•œç­–ç•¥ç›¸å…³çš„ REST API

è®¾è®¡åŸåˆ™ï¼š
- åˆ†é•œç»“æœç›´æ¥å­˜å…¥ clips è¡¨ï¼ˆå¤ç”¨é¡¹ç›®å·²æœ‰ç»“æ„ï¼‰
- é€šè¿‡ parent_clip_id æ”¯æŒé€’å½’åˆ†é•œ
- æ—¶é—´å•ä½ç»Ÿä¸€ä½¿ç”¨æ¯«ç§’ (ms)
"""

import logging
from datetime import datetime
from typing import Optional, List, Dict, Any
from uuid import uuid4

from fastapi import APIRouter, HTTPException, Query, BackgroundTasks, Depends
from pydantic import BaseModel, Field

from app.config import get_settings
from app.services.supabase_client import get_supabase, get_file_url
from app.api.auth import get_current_user_id
from app.features.shot_segmentation import (
    SegmentationStrategy,
    SegmentationRequest,
    SegmentationClip,
    get_shot_segmentation_agent,
)

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/shot-segmentation", tags=["Shot Segmentation"])


def _convert_thumbnail_path_to_url(path: Optional[str]) -> Optional[str]:
    """
    å°†æœ¬åœ°ç¼©ç•¥å›¾è·¯å¾„è½¬æ¢ä¸ºå¯è®¿é—®çš„å®Œæ•´ URL
    
    ä¾‹å¦‚: /tmp/lepus_cache/xxx/clip.jpg -> http://localhost:8000/cache/xxx/clip.jpg
    å‰ç«¯ç›´æ¥ä½¿ç”¨ï¼Œæ— éœ€å†å¤„ç†
    """
    if not path:
        return None
    
    # å¦‚æœå·²ç»æ˜¯å®Œæ•´ URLï¼Œç›´æ¥è¿”å›
    if path.startswith("http"):
        return path
    
    settings = get_settings()
    cache_dir = settings.cache_dir or "/tmp/lepus_cache"
    backend_url = settings.backend_url or "http://localhost:8000"
    
    # å¦‚æœè·¯å¾„ä»¥ cache_dir å¼€å¤´ï¼Œè½¬æ¢ä¸ºå®Œæ•´ URL
    if path.startswith(cache_dir):
        relative_path = path[len(cache_dir):]
        # ç¡®ä¿ä»¥ / å¼€å¤´
        if not relative_path.startswith("/"):
            relative_path = "/" + relative_path
        return f"{backend_url}/cache{relative_path}"
    
    # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ /cache/...ï¼Œè¡¥å…¨ä¸ºå®Œæ•´ URL
    if path.startswith("/cache"):
        return f"{backend_url}{path}"
    
    # å…¶ä»–æƒ…å†µç›´æ¥è¿”å›
    return path


async def _extract_and_upload_audio_for_asr(video_path: str, asset_id: str, supabase) -> str:
    """
    ä»æœ¬åœ°è§†é¢‘æ–‡ä»¶æå–éŸ³é¢‘ï¼Œä¸Šä¼ åˆ° Supabase Storageï¼Œè¿”å›ç­¾å URL
    
    Args:
        video_path: æœ¬åœ°è§†é¢‘æ–‡ä»¶è·¯å¾„
        asset_id: èµ„äº§ IDï¼ˆç”¨äºå­˜å‚¨è·¯å¾„ï¼‰
        supabase: Supabase å®¢æˆ·ç«¯
        
    Returns:
        éŸ³é¢‘æ–‡ä»¶çš„ç­¾å URL
    """
    import tempfile
    import asyncio
    import os
    
    audio_storage_path = f"asr_audio/{asset_id}.mp3"
    
    # ç¼“å­˜æ£€æŸ¥ï¼šå¦‚æœéŸ³é¢‘å·²å­˜åœ¨ï¼Œç›´æ¥è¿”å›
    try:
        result = supabase.storage.from_("clips").create_signed_url(audio_storage_path, 3600)
        cached_url = result.get("signedURL") or result.get("signedUrl") or result.get("signed_url")
        if cached_url:
            logger.info(f"[ASR] âœ… ä½¿ç”¨ç¼“å­˜éŸ³é¢‘: {audio_storage_path}")
            return cached_url
    except Exception:
        pass  # ç¼“å­˜ä¸å­˜åœ¨ï¼Œç»§ç»­æå–
    
    logger.info(f"[ASR] ğŸµ å¼€å§‹ä»æœ¬åœ°è§†é¢‘æå–éŸ³é¢‘...")
    
    # æå–éŸ³é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶
    audio_path = os.path.join(tempfile.gettempdir(), f"asr_{asset_id}.mp3")
    
    try:
        cmd = [
            "ffmpeg", "-y",
            "-i", video_path,
            "-vn",                # ä¸è¦è§†é¢‘
            "-ar", "16000",       # 16kHz é‡‡æ ·ç‡ï¼ˆè¯­éŸ³è¯†åˆ«è¶³å¤Ÿï¼‰
            "-ac", "1",           # å•å£°é“
            "-b:a", "64k",        # 64kbps ç ç‡
            "-f", "mp3",
            audio_path
        ]
        
        process = await asyncio.create_subprocess_exec(
            *cmd,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )
        
        stdout, stderr = await process.communicate()
        
        if process.returncode != 0:
            raise ValueError(f"FFmpeg æå–éŸ³é¢‘å¤±è´¥: {stderr.decode()[:200]}")
        
        logger.info(f"[ASR] âœ… éŸ³é¢‘æå–å®Œæˆ: {audio_path}")
        
        # ä¸Šä¼ åˆ° Supabase Storage
        with open(audio_path, "rb") as f:
            audio_data = f.read()
        
        logger.info(f"[ASR] â˜ï¸ ä¸Šä¼ éŸ³é¢‘åˆ° Supabase ({len(audio_data) / 1024:.1f} KB)...")
        
        supabase.storage.from_("clips").upload(
            audio_storage_path,
            audio_data,
            {"content-type": "audio/mpeg", "upsert": "true"}
        )
        
        # è·å–ç­¾å URL
        result = supabase.storage.from_("clips").create_signed_url(audio_storage_path, 3600)
        signed_url = result.get("signedURL") or result.get("signedUrl") or result.get("signed_url")
        
        if not signed_url:
            raise ValueError("æ— æ³•è·å–éŸ³é¢‘ç­¾å URL")
        
        logger.info(f"[ASR] âœ… éŸ³é¢‘ä¸Šä¼ æˆåŠŸ")
        return signed_url
        
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if os.path.exists(audio_path):
            os.remove(audio_path)


async def _probe_video_duration_sec(video_url: str) -> Optional[float]:
    """ä½¿ç”¨ ffprobe æ¢æµ‹è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰ã€‚"""
    import asyncio

    cmd = [
        "ffprobe",
        "-v", "error",
        "-show_entries", "format=duration",
        "-of", "default=noprint_wrappers=1:nokey=1",
        video_url,
    ]

    process = await asyncio.create_subprocess_exec(
        *cmd,
        stdout=asyncio.subprocess.PIPE,
        stderr=asyncio.subprocess.PIPE,
    )
    stdout, _stderr = await process.communicate()
    raw = (stdout or b"").decode(errors="ignore").strip()
    if not raw or raw.upper() == "N/A":
        return None
    try:
        value = float(raw)
        return value if value > 0 else None
    except ValueError:
        return None


async def _extract_single_frame(video_url: str, timestamp_sec: float, output_path: str) -> None:
    """ä½¿ç”¨ ffmpeg åœ¨æŒ‡å®šæ—¶é—´ç‚¹æŠ½å–ä¸€å¸§ã€‚"""
    import asyncio

    seek = max(float(timestamp_sec), 0.0)
    cmd = [
        "ffmpeg",
        "-hide_banner",
        "-y",
        "-ss", f"{seek:.3f}",
        "-i", video_url,
        "-frames:v", "1",
        "-q:v", "2",
        output_path,
    ]

    process = await asyncio.create_subprocess_exec(
        *cmd,
        stdout=asyncio.subprocess.PIPE,
        stderr=asyncio.subprocess.PIPE,
    )
    _stdout, stderr = await process.communicate()
    if process.returncode != 0:
        raise RuntimeError(f"ffmpeg extract failed: {(stderr or b'').decode(errors='ignore')[:240]}")


def _resolve_clip_video_context_for_extract(supabase, clip_id: str, user_id: str) -> Dict[str, Any]:
    """è§£æ clip æŠ½å¸§æ‰€éœ€çš„è§†é¢‘ä¸Šä¸‹æ–‡ï¼Œå¹¶æ ¡éªŒé¡¹ç›®è®¿é—®æƒé™ã€‚"""

    clip = (
        supabase.table("clips")
        .select("id,track_id,asset_id,video_url,cached_url,source_start,source_end,start_time,end_time")
        .eq("id", clip_id)
        .single()
        .execute()
        .data
    )
    if not clip:
        raise HTTPException(status_code=404, detail=f"Clip not found: {clip_id}")

    track_id = clip.get("track_id")
    track = (
        supabase.table("tracks")
        .select("id,project_id")
        .eq("id", track_id)
        .single()
        .execute()
        .data
    )
    if not track:
        raise HTTPException(status_code=400, detail=f"Clip {clip_id} ç¼ºå°‘æœ‰æ•ˆ track")

    project_id = track.get("project_id")
    if project_id:
        project = (
            supabase.table("projects")
            .select("id,user_id")
            .eq("id", project_id)
            .single()
            .execute()
            .data
        )
        if not project:
            raise HTTPException(status_code=404, detail=f"Project not found: {project_id}")
        owner_id = str(project.get("user_id") or "")
        if owner_id and owner_id != str(user_id):
            raise HTTPException(status_code=403, detail="æ— æƒè®¿é—®è¯¥ clip")

    video_url = clip.get("video_url") or clip.get("cached_url")
    if video_url and isinstance(video_url, str) and not video_url.startswith("http"):
        # å…¼å®¹å­˜å‚¨è·¯å¾„å½¢å¼
        video_url = get_file_url("clips", video_url, expires_in=3600)

    if not video_url:
        asset_id = clip.get("asset_id")
        if not asset_id:
            raise HTTPException(status_code=400, detail=f"Clip {clip_id} ç¼ºå°‘å¯ç”¨è§†é¢‘æ¥æº")
        asset = (
            supabase.table("assets")
            .select("storage_path")
            .eq("id", asset_id)
            .single()
            .execute()
            .data
        )
        if not asset or not asset.get("storage_path"):
            raise HTTPException(status_code=400, detail=f"Clip {clip_id} æ— æ³•è§£æèµ„äº§è·¯å¾„")
        video_url = get_file_url("clips", asset.get("storage_path"), expires_in=3600)

    source_start_ms = clip.get("source_start") or 0
    source_end_ms = clip.get("source_end")
    start_time_ms = clip.get("start_time") or 0
    end_time_ms = clip.get("end_time") or start_time_ms
    clip_duration_sec = max((end_time_ms - start_time_ms) / 1000.0, 0.0)

    source_start_sec = max(source_start_ms / 1000.0, 0.0)
    source_end_sec = source_end_ms / 1000.0 if source_end_ms is not None else None
    if source_end_sec is None and clip_duration_sec > 0:
        source_end_sec = source_start_sec + clip_duration_sec

    return {
        "clip": clip,
        "project_id": project_id,
        "video_url": video_url,
        "source_start_sec": source_start_sec,
        "source_end_sec": source_end_sec,
        "clip_duration_sec": clip_duration_sec if clip_duration_sec > 0 else None,
    }


# ==========================================
# è¯·æ±‚/å“åº”æ¨¡å‹
# ==========================================

class StartSegmentationRequest(BaseModel):
    """å¯åŠ¨åˆ†é•œè¯·æ±‚"""
    strategy: str  # scene | sentence | paragraph
    
    # ============ é€’å½’åˆ†é•œæ”¯æŒ ============
    parent_clip_id: Optional[str] = Field(default=None, description="çˆ¶ Clip IDï¼Œç”¨äºé€’å½’åˆ†é•œ")
    source_start_ms: Optional[int] = Field(default=None, description="åˆ†é•œèŒƒå›´èµ·å§‹ï¼ˆæ¯«ç§’ï¼‰")
    source_end_ms: Optional[int] = Field(default=None, description="åˆ†é•œèŒƒå›´ç»“æŸï¼ˆæ¯«ç§’ï¼‰")
    
    # ============ åœºæ™¯åˆ†é•œå‚æ•° ============
    scene_threshold: float = 27.0
    scene_min_length_ms: int = 500
    
    # ============ åˆ†å¥åˆ†é•œå‚æ•° ============
    min_sentence_duration_ms: int = 1500
    max_sentence_duration_ms: int = 30000
    merge_short_sentences: bool = True
    
    # ============ æ®µè½åˆ†é•œå‚æ•° ============
    target_paragraph_count: Optional[int] = None
    min_paragraph_duration_ms: int = 10000


class StartSegmentationResponse(BaseModel):
    """å¯åŠ¨åˆ†é•œå“åº”"""
    task_id: str
    status: str = "pending"
    message: str = "åˆ†é•œä»»åŠ¡å·²åˆ›å»º"
    is_recursive: bool = False  # æ˜¯å¦ä¸ºé€’å½’åˆ†é•œ


class ClipItem(BaseModel):
    """å•ä¸ªåˆ†é•œ Clip"""
    id: str
    asset_id: str
    clip_type: str = "video"
    start_time: int      # æ—¶é—´è½´ä½ç½®ï¼ˆæ¯«ç§’ï¼‰
    end_time: int
    source_start: int    # æºç´ æä½ç½®ï¼ˆæ¯«ç§’ï¼‰
    source_end: int
    parent_clip_id: Optional[str] = None
    thumbnail_url: Optional[str] = None
    transcript: Optional[str] = None
    name: Optional[str] = None
    video_url: Optional[str] = None  # â˜… æ›¿æ¢åçš„è§†é¢‘ URL
    canvas_position: Optional[dict] = None  # â˜… ç”»å¸ƒä¸Šçš„ä½ç½®ï¼ˆåˆ·æ–°åæ¢å¤ï¼‰
    
    @property
    def duration(self) -> int:
        return self.end_time - self.start_time


class FreeNodeResponse(BaseModel):
    """è‡ªç”±èŠ‚ç‚¹å“åº”æ•°æ®"""
    id: str
    asset_id: str
    media_type: str
    thumbnail_url: Optional[str] = None
    video_url: Optional[str] = None
    duration_ms: int = 5000
    canvas_position: dict = {}
    aspect_ratio: Optional[str] = None
    generating_task_id: Optional[str] = None
    generating_capability: Optional[str] = None


class CanvasEdgeResponse(BaseModel):
    """ç”»å¸ƒè¿çº¿å“åº”æ•°æ®"""
    id: str
    source: str
    target: str


class GetClipsResponse(BaseModel):
    """è·å–åˆ†é•œç»“æœå“åº”"""
    session_id: str
    strategy: Optional[str] = None
    status: str  # pending | analyzing | completed | error
    clips: List[ClipItem] = []
    total_duration_ms: int = 0
    error_message: Optional[str] = None
    # â˜… è‡ªç”±èŠ‚ç‚¹ & ç”»å¸ƒè¿çº¿
    free_nodes: List[FreeNodeResponse] = []
    canvas_edges: List[CanvasEdgeResponse] = []


class ExtractClipFramesRequest(BaseModel):
    """è§†é¢‘èŠ‚ç‚¹æŠ½å¸§è¯·æ±‚"""
    frame_count: int = Field(6, ge=1, le=24, description="æŠ½å¸§æ•°é‡")
    start_offset_ms: int = Field(0, ge=0, le=30000, description="ç›¸å¯¹ç‰‡æ®µèµ·ç‚¹åç§»")
    end_offset_ms: int = Field(0, ge=0, le=30000, description="ç›¸å¯¹ç‰‡æ®µç»ˆç‚¹åç§»")


class ExtractedFrameItem(BaseModel):
    index: int
    timestamp_sec: float
    image_url: str
    asset_id: str
    storage_path: str


# ==========================================
# API è·¯ç”±
# ==========================================

@router.post("/sessions/{session_id}/segment", response_model=StartSegmentationResponse)
async def start_segmentation(
    session_id: str,
    request: StartSegmentationRequest,
    background_tasks: BackgroundTasks,
):
    """
    å¯åŠ¨åˆ†é•œä»»åŠ¡ï¼ˆå¹‚ç­‰ï¼‰
    
    æ”¯æŒä¸¤ç§åœºæ™¯:
    1. é¦–æ¬¡åˆ†é•œ: å¯¹æ•´ä¸ª asset è¿›è¡Œåˆ†é•œ
    2. é€’å½’åˆ†é•œ: å¯¹å·²æœ‰çš„ clip è¿›è¡ŒäºŒæ¬¡åˆ†é•œï¼ˆé€šè¿‡ parent_clip_id æŒ‡å®šï¼‰
    
    ç­–ç•¥:
    - scene: åœºæ™¯åˆ†é•œ (åŸºäºè§†è§‰å˜åŒ–)
    - sentence: åˆ†å¥åˆ†é•œ (éœ€è¦ ASR ç»“æœ)
    - paragraph: æ®µè½åˆ†é•œ (éœ€è¦ ASR ç»“æœ + LLM)
    
    å¹‚ç­‰æ€§:
    - å¦‚æœåˆ†é•œæ­£åœ¨è¿›è¡Œä¸­ï¼Œç›´æ¥è¿”å› "analyzing" çŠ¶æ€
    - å¦‚æœåˆ†é•œå·²å®Œæˆä¸”ç­–ç•¥åŒ¹é…ï¼Œè¿”å› "completed" çŠ¶æ€
    """
    
    supabase = get_supabase()
    
    # 1. è·å– Session ä¿¡æ¯ï¼ˆåŒ…æ‹¬ workflow_step ç”¨äºå¹‚ç­‰æ€§æ£€æŸ¥ï¼‰
    session_result = supabase.table("workspace_sessions").select(
        "id, user_id, uploaded_asset_id, uploaded_asset_ids, status, workflow_step, project_id"
    ).eq("id", session_id).single().execute()
    
    if not session_result.data:
        raise HTTPException(status_code=404, detail="Session not found")
    
    session = session_result.data
    workflow_step = session.get("workflow_step", "")
    
    # â˜… å¹‚ç­‰æ€§æ£€æŸ¥ 1: å¦‚æœåˆ†é•œæ­£åœ¨è¿›è¡Œä¸­ï¼Œç›´æ¥è¿”å›
    if workflow_step == "shot_segmentation":
        logger.info(f"[åˆ†é•œ] å¹‚ç­‰æ€§æ£€æŸ¥: session {session_id} åˆ†é•œæ­£åœ¨è¿›è¡Œä¸­ï¼Œè·³è¿‡å¯åŠ¨")
        return StartSegmentationResponse(
            task_id="",  # æ— éœ€æ–°ä»»åŠ¡ ID
            status="analyzing",
            message=f"åˆ†é•œæ­£åœ¨è¿›è¡Œä¸­ï¼Œè¯·ç­‰å¾…å®Œæˆ",
            is_recursive=request.parent_clip_id is not None,
        )
    
    # â˜… å¹‚ç­‰æ€§æ£€æŸ¥ 2: ç›´æ¥æŸ¥è¯¢æ˜¯å¦å·²æœ‰ç›¸åŒç­–ç•¥çš„ clipsï¼ˆä¸ä¾èµ– workflow_stepï¼‰
    # è¿™æ ·å³ä½¿ workflow_step çŠ¶æ€å¼‚å¸¸ï¼Œåªè¦æœ‰å¯¹åº”ç­–ç•¥çš„ clips å°±ä¸ä¼šé‡å¤åˆ†é•œ
    project_id = session.get("project_id")
    if project_id:
        # è·å–ç°æœ‰ clips çš„ç­–ç•¥
        track_result = supabase.table("tracks").select("id").eq("project_id", project_id).execute()
        track_ids = [t["id"] for t in (track_result.data or [])]
        if track_ids:
            clip_result = supabase.table("clips").select("id, metadata").in_("track_id", track_ids).limit(1).execute()
            if clip_result.data and len(clip_result.data) > 0:
                existing_strategy = (clip_result.data[0].get("metadata") or {}).get("strategy")
                if existing_strategy == request.strategy:
                    logger.info(f"[åˆ†é•œ] å¹‚ç­‰æ€§æ£€æŸ¥: session {session_id} ç­–ç•¥ {request.strategy} å·²æœ‰ clipsï¼Œè·³è¿‡å¯åŠ¨")
                    # â˜… ä¿®å¤ workflow_step çŠ¶æ€ï¼ˆå¦‚æœä¸ä¸€è‡´ï¼‰
                    if workflow_step != "shot_completed":
                        logger.info(f"[åˆ†é•œ] ä¿®å¤ workflow_step: {workflow_step} -> shot_completed")
                        supabase.table("workspace_sessions").update({
                            "workflow_step": "shot_completed",
                        }).eq("id", session_id).execute()
                    return StartSegmentationResponse(
                        task_id="",
                        status="completed",
                        message=f"ä½¿ç”¨ {request.strategy} ç­–ç•¥çš„åˆ†é•œå·²å®Œæˆ",
                        is_recursive=request.parent_clip_id is not None,
                    )
                else:
                    logger.info(f"[åˆ†é•œ] ç­–ç•¥å˜æ›´: {existing_strategy} -> {request.strategy}ï¼Œéœ€è¦é‡æ–°åˆ†é•œ")
    
    # 3. è·å– Asset ID
    asset_id = session.get("uploaded_asset_id")
    if not asset_id:
        asset_ids = session.get("uploaded_asset_ids", [])
        if asset_ids:
            asset_id = asset_ids[0]
    
    if not asset_id:
        raise HTTPException(status_code=400, detail="Session ä¸­æ²¡æœ‰å…³è”çš„è§†é¢‘èµ„æº")
    
    # 3. éªŒè¯ç­–ç•¥
    try:
        strategy = SegmentationStrategy(request.strategy)
    except ValueError:
        raise HTTPException(
            status_code=400,
            detail=f"ä¸æ”¯æŒçš„åˆ†é•œç­–ç•¥: {request.strategy}ï¼Œå¯é€‰: scene, sentence, paragraph"
        )
    
    # 4. å¦‚æœæ˜¯é€’å½’åˆ†é•œï¼ŒéªŒè¯çˆ¶ Clip
    is_recursive = request.parent_clip_id is not None
    if is_recursive:
        clip_result = supabase.table("clips").select(
            "id, source_start, source_end, asset_id"
        ).eq("id", request.parent_clip_id).single().execute()
        
        if not clip_result.data:
            raise HTTPException(status_code=404, detail="Parent clip not found")
        
        parent_clip = clip_result.data
        
        # ä½¿ç”¨çˆ¶ clip çš„èŒƒå›´ï¼ˆå¦‚æœè¯·æ±‚ä¸­æ²¡æœ‰æŒ‡å®šï¼‰
        if request.source_start_ms is None:
            request.source_start_ms = parent_clip.get("source_start", 0)
        if request.source_end_ms is None:
            request.source_end_ms = parent_clip.get("source_end", 0)
    
    # 5. åˆ›å»ºä»»åŠ¡
    task_id = str(uuid4())
    
    # æ›´æ–° Session çŠ¶æ€ï¼ˆç­–ç•¥æ˜¯ actionï¼Œä¸æ˜¯ stateï¼Œä¸å­˜åˆ° sessionï¼‰
    supabase.table("workspace_sessions").update({
        "workflow_step": "shot_segmentation",
    }).eq("id", session_id).execute()
    
    # 6. åœ¨åå°æ‰§è¡Œåˆ†é•œ
    background_tasks.add_task(
        run_segmentation_task,
        task_id=task_id,
        session_id=session_id,
        asset_id=asset_id,
        strategy=strategy,
        params=request,
    )
    
    return StartSegmentationResponse(
        task_id=task_id,
        status="pending",
        message=f"æ­£åœ¨ä½¿ç”¨ {strategy.value} ç­–ç•¥è¿›è¡Œ{'é€’å½’' if is_recursive else ''}åˆ†é•œ",
        is_recursive=is_recursive,
    )



# ==========================================
# æŸ¥è¯¢æ¥å£
# ==========================================

@router.get("/sessions/{session_id}/clips")
async def get_session_clips(
    session_id: str,
    parent_clip_id: Optional[str] = Query(None, description="ç­›é€‰ç‰¹å®šçˆ¶ Clip çš„å­åˆ†é•œ"),
):
    """
    è·å– Session çš„åˆ†é•œ Clips
    
    æ•°æ®æ¨¡å‹å…³ç³»: session â†’ project â†’ tracks â†’ clips
    """
    
    supabase = get_supabase()
    
    # 1. è·å– Session ä¿¡æ¯ï¼ˆåŒ…å« project_idï¼‰
    session_result = supabase.table("workspace_sessions").select(
        "id, project_id, user_id, workflow_step, error_message"
    ).eq("id", session_id).single().execute()
    
    if not session_result.data:
        raise HTTPException(status_code=404, detail="Session not found")
    
    session = session_result.data
    project_id = session.get("project_id")
    session_user_id = session.get("user_id")
    
    if not project_id:
        return GetClipsResponse(
            session_id=session_id,
            strategy=None,
            status="pending",
            clips=[],
            total_duration_ms=0,
        )
    
    # 2. â˜… ä¼˜å…ˆä» canvas_nodes è¡¨è¯»å–ï¼ˆé‡æ„åçš„æ–°è·¯å¾„ï¼‰
    nodes_result = supabase.table("canvas_nodes").select("*").eq(
        "project_id", project_id
    ).order("order_index").execute()
    
    all_nodes = nodes_result.data or []
    
    # â˜… é™çº§: canvas_nodes ä¸ºç©ºæ—¶å›é€€åˆ° clips è¡¨
    if not all_nodes:
        track_result = supabase.table("tracks").select("id").eq(
            "project_id", project_id
        ).execute()
        track_ids = [t["id"] for t in (track_result.data or [])]
        
        if not track_ids:
            return GetClipsResponse(
                session_id=session_id, strategy=None, status="pending",
                clips=[], total_duration_ms=0,
            )
        
        query = supabase.table("clips").select(
            "id, asset_id, clip_type, start_time, end_time, source_start, source_end, "
            "parent_clip_id, name, metadata, video_url"
        ).in_("track_id", track_ids).in_("clip_type", ["video", "image"])
        if parent_clip_id:
            query = query.eq("parent_clip_id", parent_clip_id)
        clips_result = query.order("start_time").execute()
        
        all_clips_data = clips_result.data or []
        clips_data = []
        free_nodes_data = []
        for clip in all_clips_data:
            metadata = clip.get("metadata", {}) or {}
            if metadata.get("canvas_mode") == "free":
                free_nodes_data.append(clip)
            else:
                clips_data.append(clip)
    else:
        # â˜… ä» canvas_nodes æ„å»ºå…¼å®¹çš„ clips_data / free_nodes_data
        clips_data = []
        free_nodes_data = []
        for node in all_nodes:
            # è½¬æ¢ canvas_node ä¸º clip å…¼å®¹æ ¼å¼
            meta = node.get("metadata") or {}
            compat = {
                "id": node.get("id"),
                "asset_id": node.get("asset_id"),
                "clip_type": node.get("media_type", "video"),
                "start_time": int((node.get("start_time") or 0) * 1000),
                "end_time": int((node.get("end_time") or 0) * 1000),
                "source_start": node.get("source_start", 0),
                "source_end": node.get("source_end", 0),
                "parent_clip_id": None,
                "name": meta.get("name"),
                "metadata": {
                    **meta,
                    "thumbnail_url": node.get("thumbnail_url") or meta.get("thumbnail_url"),
                    "canvas_position": node.get("canvas_position"),
                },
                "video_url": node.get("video_url"),
            }
            if node.get("node_type") == "free":
                compat["metadata"]["canvas_mode"] = "free"
                free_nodes_data.append(compat)
            else:
                clips_data.append(compat)
    
    # 5. åˆ¤æ–­çŠ¶æ€
    workflow_step = session.get("workflow_step", "")
    
    if workflow_step == "shot_segmentation":
        status = "analyzing"
    elif len(clips_data) > 0:
        status = "completed"
    else:
        status = "pending"
    
    # 5. è½¬æ¢æ ¼å¼
    clips = []
    total_duration_ms = 0
    
    for clip in clips_data:
        metadata = clip.get("metadata", {}) or {}
        # å°†æœ¬åœ°ç¼©ç•¥å›¾è·¯å¾„è½¬æ¢ä¸ºå¯è®¿é—®çš„ URL
        thumbnail_url = _convert_thumbnail_path_to_url(metadata.get("thumbnail_url"))
        # â˜… å›¾ç‰‡ç±»å‹ï¼šä¼˜å…ˆç”¨ç´ ææœ¬èº«çš„ç­¾å URLï¼ˆé¿å…è¿‡æœŸé—®é¢˜ï¼‰
        if clip.get("clip_type") == "image" and clip.get("asset_id"):
            try:
                asset_result = supabase.table("assets").select("storage_path").eq("id", clip["asset_id"]).single().execute()
                if asset_result.data and asset_result.data.get("storage_path"):
                    thumbnail_url = get_file_url("clips", asset_result.data["storage_path"])
            except Exception as e:
                logger.warning(f"[Segmentation] âš ï¸ è·å– clip {clip.get('id', '?')} ç¼©ç•¥å›¾å¤±è´¥: {e}")
        clips.append(ClipItem(
            id=clip.get("id", ""),
            asset_id=clip.get("asset_id", ""),
            clip_type=clip.get("clip_type", "video"),
            start_time=clip.get("start_time", 0),
            end_time=clip.get("end_time", 0),
            source_start=clip.get("source_start", 0),
            source_end=clip.get("source_end", 0),
            parent_clip_id=clip.get("parent_clip_id"),
            thumbnail_url=thumbnail_url,
            transcript=metadata.get("transcript"),
            name=clip.get("name"),
            video_url=clip.get("video_url"),  # â˜… æ›¿æ¢åçš„è§†é¢‘ URL
            canvas_position=metadata.get("canvas_position"),  # â˜… ç”»å¸ƒä½ç½®
        ))
        total_duration_ms = max(total_duration_ms, clip.get("end_time", 0))
    
    # ä»ç¬¬ä¸€ä¸ª clip çš„ metadata è·å–ç­–ç•¥ï¼ˆæ¯ä¸ª clip å¯èƒ½ä¸åŒï¼‰
    first_clip_strategy = None
    if clips_data:
        first_metadata = clips_data[0].get("metadata", {}) or {}
        first_clip_strategy = first_metadata.get("strategy")
    
    # â˜… è½¬æ¢è‡ªç”±èŠ‚ç‚¹
    free_nodes_response = []
    for fn_clip in free_nodes_data:
        fn_meta = fn_clip.get("metadata", {}) or {}
        fn_asset_id = fn_clip.get("asset_id")

        # æ²»æœ¬ï¼šå†å²è„æ•°æ®ä¿®å¤ â€”â€” ç”»å¸ƒèŠ‚ç‚¹è‹¥ç¼ºå°‘ asset_idï¼Œè‡ªåŠ¨è¡¥å»º asset å¹¶å›å†™ clip
        if not fn_asset_id:
            is_image_node = fn_clip.get("clip_type") == "image"
            fallback_ext = "jpg" if is_image_node else "mp4"
            fallback_mime = "image/jpeg" if is_image_node else "video/mp4"
            generated_asset_id = str(uuid4())
            fallback_url = fn_meta.get("thumbnail_url") if is_image_node else (fn_clip.get("video_url") or fn_meta.get("thumbnail_url"))
            asset_payload = {
                "id": generated_asset_id,
                "project_id": project_id,
                "user_id": session_user_id,
                "name": f"canvas-node-{fn_clip.get('id', '')[:8]}",
                "original_filename": f"canvas-node-{fn_clip.get('id', '')[:8]}.{fallback_ext}",
                "file_type": "image" if is_image_node else "video",
                "mime_type": fallback_mime,
                "file_size": 0,
                "storage_path": f"virtual/free-nodes/{session_id}/{fn_clip.get('id', '')}.{fallback_ext}",
                "duration": max(0.0, float(max(0, fn_clip.get("end_time", 0) - fn_clip.get("start_time", 0))) / 1000.0),
                "status": "ready",
                "metadata": {
                    "is_virtual": True,
                    "source": "canvas_free_node_backfill",
                    "external_url": fallback_url,
                },
                "created_at": datetime.utcnow().isoformat(),
                "updated_at": datetime.utcnow().isoformat(),
            }
            try:
                supabase.table("assets").insert(asset_payload).execute()
                supabase.table("clips").update({"asset_id": generated_asset_id}).eq("id", fn_clip.get("id", "")).execute()
                fn_asset_id = generated_asset_id
                fn_clip["asset_id"] = generated_asset_id
                logger.info("[GetClips] å·²ä¸ºè‡ªç”±èŠ‚ç‚¹è¡¥å»º asset_id: clip=%s asset=%s", fn_clip.get("id"), generated_asset_id)
            except Exception as backfill_err:
                logger.warning("[GetClips] è‡ªç”±èŠ‚ç‚¹è¡¥å»º asset å¤±è´¥ clip=%s err=%s", fn_clip.get("id"), backfill_err)

        fn_thumbnail = _convert_thumbnail_path_to_url(fn_meta.get("thumbnail_url"))
        # â˜… å›¾ç‰‡ç±»å‹ï¼šä¼˜å…ˆç”¨ç´ ææœ¬èº«çš„ç­¾å URLï¼ˆé¿å…è¿‡æœŸé—®é¢˜ï¼‰
        if fn_clip.get("clip_type") == "image" and fn_asset_id:
            try:
                asset_res = supabase.table("assets").select("storage_path").eq("id", fn_asset_id).single().execute()
                if asset_res.data and asset_res.data.get("storage_path"):
                    fn_thumbnail = get_file_url("clips", asset_res.data["storage_path"])
            except Exception as e:
                logger.warning(f"[Segmentation] âš ï¸ è·å–è‡ªç”±èŠ‚ç‚¹ç¼©ç•¥å›¾å¤±è´¥: {e}")
        free_nodes_response.append(FreeNodeResponse(
            id=fn_clip.get("id", ""),
            asset_id=fn_asset_id or "",
            media_type=fn_clip.get("clip_type", "video"),
            thumbnail_url=fn_thumbnail,
            video_url=fn_clip.get("video_url"),
            duration_ms=max(0, fn_clip.get("end_time", 0) - fn_clip.get("start_time", 0)),
            canvas_position=fn_meta.get("canvas_position", {"x": 200, "y": 200}),
            aspect_ratio=fn_meta.get("aspect_ratio"),
            generating_task_id=fn_meta.get("generating_task_id"),
            generating_capability=fn_meta.get("generating_capability"),
        ))
    
    # â˜… è·å–ç”»å¸ƒè¿çº¿ï¼ˆä¼˜å…ˆä» canvas_edges è¡¨ï¼Œé™çº§åˆ° session metadataï¼‰
    canvas_edges_response = []
    try:
        edges_result = supabase.table("canvas_edges").select("*").eq(
            "project_id", project_id
        ).execute()
        if edges_result.data:
            for edge_data in edges_result.data:
                canvas_edges_response.append(CanvasEdgeResponse(
                    id=edge_data.get("id", ""),
                    source=edge_data.get("source_node_id", ""),
                    target=edge_data.get("target_node_id", ""),
                ))
        else:
            # é™çº§: ä» session metadata è¯»å–
            session_meta = session.get("metadata") or {}
            if not session_meta:
                sess_meta_result = supabase.table("workspace_sessions").select("metadata").eq("id", session_id).single().execute()
                if sess_meta_result.data:
                    session_meta = sess_meta_result.data.get("metadata") or {}
            for edge_data in session_meta.get("canvas_edges", []):
                canvas_edges_response.append(CanvasEdgeResponse(
                    id=edge_data.get("id", ""),
                    source=edge_data.get("source", ""),
                    target=edge_data.get("target", ""),
                ))
    except Exception as e:
        logger.warning(f"[GetClips] è·å–ç”»å¸ƒè¿çº¿å¤±è´¥: {e}")
    
    return GetClipsResponse(
        session_id=session_id,
        strategy=first_clip_strategy,
        status=status,
        clips=clips,
        total_duration_ms=total_duration_ms,
        error_message=session.get("error_message"),
        free_nodes=free_nodes_response,
        canvas_edges=canvas_edges_response,
    )


# ==========================================
# æ‰¹é‡åˆ›å»º Clipsï¼ˆä»ç´ æåº“æ·»åŠ ï¼‰
# ==========================================

class BatchClipItem(BaseModel):
    """æ‰¹é‡åˆ›å»ºçš„å•ä¸ª Clip æ•°æ®"""
    id: str  # å‰ç«¯ç”Ÿæˆçš„ UUID
    asset_id: str
    start_time: int  # æ¯«ç§’
    end_time: int  # æ¯«ç§’
    source_start: Optional[int] = None
    source_end: Optional[int] = None
    thumbnail_url: Optional[str] = None
    video_url: Optional[str] = None  # â˜… ç´ æè§†é¢‘ URL
    clip_type: str = "video"  # â˜… æ”¯æŒ image / video


class BatchCreateClipsRequest(BaseModel):
    """æ‰¹é‡åˆ›å»º Clips è¯·æ±‚"""
    after_clip_id: str  # åœ¨æ­¤ clip ä¹‹åæ’å…¥
    clips: List[BatchClipItem]


@router.post("/sessions/{session_id}/clips/batch")
async def batch_create_clips(session_id: str, request: BatchCreateClipsRequest):
    """
    æ‰¹é‡åˆ›å»º Clipsï¼ˆä»ç´ æåº“æ·»åŠ åˆ°æ—¶é—´è½´ï¼‰
    
    1. è·å– session çš„ project å’Œ track
    2. åœ¨æŒ‡å®šä½ç½®æ’å…¥æ–°çš„ clips
    3. æ›´æ–°åç»­ clips çš„æ—¶é—´ä½ç½®
    """
    import uuid
    
    supabase = get_supabase()
    
    # 1. è·å– Session ä¿¡æ¯
    session_result = supabase.table("workspace_sessions").select(
        "id, project_id"
    ).eq("id", session_id).single().execute()
    
    if not session_result.data:
        raise HTTPException(status_code=404, detail="Session not found")
    
    project_id = session_result.data.get("project_id")
    if not project_id:
        raise HTTPException(status_code=400, detail="Session has no project")
    
    # 2. è·å– Trackï¼ˆä½¿ç”¨ç¬¬ä¸€ä¸ª trackï¼ŒæŒ‰ order_index æ’åºï¼‰
    # æ³¨æ„ï¼štracks è¡¨æ²¡æœ‰ type å­—æ®µï¼Œå®ƒæ˜¯é€šç”¨å®¹å™¨
    track_result = supabase.table("tracks").select("id").eq(
        "project_id", project_id
    ).order("order_index").limit(1).execute()
    
    if not track_result.data:
        raise HTTPException(status_code=400, detail="No track found for this project")
    
    track_id = track_result.data[0]["id"]
    
    # 3. è·å– after_clip çš„ä½ç½®ä¿¡æ¯
    after_clip_result = supabase.table("clips").select(
        "id, start_time, end_time, track_id"
    ).eq("id", request.after_clip_id).single().execute()
    
    if not after_clip_result.data:
        raise HTTPException(status_code=404, detail="After clip not found")
    
    after_clip = after_clip_result.data
    # â˜… ä½¿ç”¨ after_clip æ‰€åœ¨çš„ trackï¼Œè€Œä¸æ˜¯ç¬¬ä¸€ä¸ª track
    track_id = after_clip.get("track_id") or track_id
    insert_time = after_clip["end_time"]  # æ–° clips ä»è¿™ä¸ªæ—¶é—´å¼€å§‹
    
    # 4. è®¡ç®—éœ€è¦ç§»åŠ¨çš„æ—¶é—´é‡ï¼ˆæ‰€æœ‰æ–° clips çš„æ€»æ—¶é•¿ï¼‰
    total_new_duration = sum(c.end_time - c.start_time for c in request.clips)
    
    # 5. æ›´æ–°åç»­ clips çš„æ—¶é—´ï¼ˆéœ€è¦åç§»ï¼‰
    # è·å–æ‰€æœ‰åœ¨ after_clip ä¹‹åçš„ clips
    later_clips_result = supabase.table("clips").select("id, start_time, end_time").eq(
        "track_id", track_id
    ).gt("start_time", after_clip["end_time"]).execute()
    
    # æ‰¹é‡æ›´æ–°æ—¶é—´
    for later_clip in (later_clips_result.data or []):
        supabase.table("clips").update({
            "start_time": later_clip["start_time"] + total_new_duration,
            "end_time": later_clip["end_time"] + total_new_duration,
        }).eq("id", later_clip["id"]).execute()
    
    # 6. åˆ›å»ºæ–°çš„ clips
    created_clips = []
    current_time = insert_time
    
    for clip_data in request.clips:
        duration = clip_data.end_time - clip_data.start_time
        
        # â˜… éªŒè¯æˆ–ç”Ÿæˆæœ‰æ•ˆçš„ UUID
        try:
            clip_id = str(uuid.UUID(clip_data.id))  # éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆ UUID
        except (ValueError, AttributeError):
            clip_id = str(uuid.uuid4())  # å¦‚æœæ— æ•ˆï¼Œè‡ªåŠ¨ç”Ÿæˆ
        
        new_clip = {
            "id": clip_id,
            "track_id": track_id,
            "asset_id": clip_data.asset_id,
            "clip_type": clip_data.clip_type,  # â˜… ä½¿ç”¨å‰ç«¯ä¼ å…¥çš„ç±»å‹ï¼ˆimage/videoï¼‰
            "start_time": current_time,
            "end_time": current_time + duration,
            "source_start": clip_data.source_start or 0,
            "source_end": clip_data.source_end or duration,
            "video_url": clip_data.video_url,  # â˜… ä¿å­˜ç´ æè§†é¢‘ URL
            "metadata": {
                "thumbnail_url": clip_data.thumbnail_url,
                "added_from": "material_picker",
            },
        }
        
        supabase.table("clips").insert(new_clip).execute()
        created_clips.append(new_clip)
        current_time += duration
    
    logger.info(f"[BatchCreateClips] âœ… åˆ›å»º {len(created_clips)} ä¸ª clipsï¼Œæ’å…¥ä½ç½®: {request.after_clip_id}")
    
    # â˜… åŒæ­¥å†™å…¥ canvas_nodes è¡¨ï¼ˆVisual Editor ä¸“ç”¨ï¼‰
    try:
        from datetime import datetime as dt
        now_cn = dt.utcnow().isoformat()
        # è·å–å½“å‰æœ€å¤§ order_index
        existing_nodes = supabase.table("canvas_nodes").select("order_index").eq(
            "project_id", project_id
        ).order("order_index", desc=True).limit(1).execute()
        max_order = (existing_nodes.data[0]["order_index"] + 1) if existing_nodes.data else 0
        
        canvas_rows = []
        for idx, clip in enumerate(created_clips):
            duration_ms = clip["end_time"] - clip["start_time"]
            canvas_rows.append({
                "id": str(uuid.uuid4()),
                "project_id": project_id,
                "asset_id": clip["asset_id"],
                "node_type": "sequence",
                "media_type": clip.get("clip_type", "video"),
                "order_index": max_order + idx,
                "start_time": clip["start_time"] / 1000.0,
                "end_time": clip["end_time"] / 1000.0,
                "duration": duration_ms / 1000.0,
                "source_start": clip.get("source_start", 0),
                "source_end": clip.get("source_end", duration_ms),
                "canvas_position": {"x": 0, "y": 0},
                "video_url": clip.get("video_url"),
                "thumbnail_url": (clip.get("metadata") or {}).get("thumbnail_url"),
                "metadata": {"added_from": "material_picker"},
                "clip_id": clip["id"],
                "created_at": now_cn,
                "updated_at": now_cn,
            })
        if canvas_rows:
            supabase.table("canvas_nodes").insert(canvas_rows).execute()
            logger.info(f"[BatchCreateClips] âœ… åŒæ­¥åˆ›å»º {len(canvas_rows)} ä¸ª canvas_nodes")
    except Exception as e:
        logger.warning(f"[BatchCreateClips] âš ï¸ canvas_nodes å†™å…¥å¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {e}")
    
    return {
        "success": True,
        "session_id": session_id,
        "created_count": len(created_clips),
        "clips": [{"id": c["id"], "start_time": c["start_time"], "end_time": c["end_time"]} for c in created_clips],
    }


@router.post("/clips/{clip_id}/extract-frames")
async def extract_clip_frames(
    clip_id: str,
    request: ExtractClipFramesRequest,
    user_id: str = Depends(get_current_user_id),
):
    """
    å¯¹å•ä¸ªè§†é¢‘èŠ‚ç‚¹æ‰§è¡Œå‡åŒ€æŠ½å¸§ï¼Œè¿”å›å¯ç›´æ¥ç”¨äºåˆ›å»ºè‡ªç”±å›¾ç‰‡èŠ‚ç‚¹çš„æ•°æ®ã€‚
    """
    import os
    import tempfile

    supabase = get_supabase()
    context = _resolve_clip_video_context_for_extract(supabase, clip_id, user_id)

    if not context.get("video_url"):
        raise HTTPException(status_code=400, detail="æœªæ‰¾åˆ°å¯ç”¨è§†é¢‘ URL")

    # æ¢æµ‹æ—¶é•¿ï¼›è‹¥æ— æ³•æ¢æµ‹åˆ™ç”± clip å…ƒæ•°æ®å…œåº•
    probed_duration = await _probe_video_duration_sec(context["video_url"])

    if probed_duration and probed_duration > 0:
        duration_sec = float(probed_duration)
    elif context.get("source_end_sec"):
        duration_sec = float(context["source_end_sec"])
    elif context.get("clip_duration_sec"):
        duration_sec = float(context.get("source_start_sec") or 0.0) + float(context["clip_duration_sec"])
    else:
        raise HTTPException(status_code=400, detail="æ— æ³•ç¡®å®šè§†é¢‘æ—¶é•¿ï¼Œæ— æ³•æŠ½å¸§")

    source_start_sec = float(context.get("source_start_sec") or 0.0)
    source_end_sec = context.get("source_end_sec")
    clip_duration_sec = context.get("clip_duration_sec")

    if source_end_sec is None:
        if clip_duration_sec:
            source_end_sec = source_start_sec + float(clip_duration_sec)
        else:
            source_end_sec = duration_sec

    source_end_sec = max(source_start_sec, min(float(source_end_sec), duration_sec))

    start_offset_sec = max(request.start_offset_ms / 1000.0, 0.0)
    end_offset_sec = max(request.end_offset_ms / 1000.0, 0.0)

    window_start = min(source_start_sec + start_offset_sec, source_end_sec)
    window_end = max(window_start, source_end_sec - end_offset_sec)

    # ç•™ä¸€ç‚¹å®‰å…¨è¾¹ç•Œï¼Œé¿å…è´´è¾¹æŠ½å¸§åœ¨æŸäº›ç¼–ç ä¸‹å–ä¸åˆ°å…³é”®å¸§
    safe_margin = 0.02
    if window_end - window_start > safe_margin * 2:
        window_start += safe_margin
        window_end -= safe_margin

    if window_end <= window_start:
        raise HTTPException(status_code=400, detail="æŠ½å¸§çª—å£æ— æ•ˆï¼Œè¯·å‡å°‘èµ·æ­¢åç§»")

    if request.frame_count == 1:
        timestamps = [(window_start + window_end) / 2.0]
    else:
        step = (window_end - window_start) / (request.frame_count - 1)
        timestamps = [window_start + (step * i) for i in range(request.frame_count)]

    project_id = context.get("project_id")
    frames: List[Dict[str, Any]] = []

    try:
        with tempfile.TemporaryDirectory(prefix="clip-extract-frames-") as tmp_dir:
            for idx, ts in enumerate(timestamps):
                local_frame_path = os.path.join(tmp_dir, f"frame-{idx+1:02d}.jpg")
                await _extract_single_frame(context["video_url"], ts, local_frame_path)

                with open(local_frame_path, "rb") as f:
                    frame_bytes = f.read()

                frame_asset_id = str(uuid4())
                storage_path = f"extracted-frames/{project_id or 'global'}/{clip_id}/{frame_asset_id}.jpg"

                supabase.storage.from_("clips").upload(
                    storage_path,
                    frame_bytes,
                    {"content-type": "image/jpeg", "upsert": "true"},
                )

                asset_record = {
                    "id": frame_asset_id,
                    "project_id": project_id,
                    "user_id": user_id,
                    "name": f"clip-{clip_id}-frame-{idx+1:02d}",
                    "original_filename": f"clip-{clip_id}-frame-{idx+1:02d}.jpg",
                    "file_type": "image",
                    "mime_type": "image/jpeg",
                    "file_size": len(frame_bytes),
                    "storage_path": storage_path,
                    "status": "ready",
                }
                supabase.table("assets").insert(asset_record).execute()

                frame_url = get_file_url("clips", storage_path, expires_in=3600)
                frames.append({
                    "index": idx,
                    "timestamp_sec": round(ts, 3),
                    "image_url": frame_url,
                    "asset_id": frame_asset_id,
                    "storage_path": storage_path,
                })
    except HTTPException:
        raise
    except Exception as exc:
        logger.error("[ExtractFrames] æŠ½å¸§å¤±è´¥ clip=%s error=%s", clip_id, exc)
        raise HTTPException(status_code=400, detail=f"æŠ½å¸§å¤±è´¥: {exc}")

    return {
        "success": True,
        "clip_id": clip_id,
        "frame_count": len(frames),
        "window_start_sec": round(window_start, 3),
        "window_end_sec": round(window_end, 3),
        "frames": frames,
    }


class ClipUpdateRequest(BaseModel):
    """æ›´æ–° Clip è¯·æ±‚"""
    source_start: Optional[int] = None
    source_end: Optional[int] = None
    name: Optional[str] = None
    video_url: Optional[str] = None
    thumbnail_url: Optional[str] = None  # â˜… ç¼©ç•¥å›¾ URL


@router.patch("/clips/{clip_id}")
async def update_clip(clip_id: str, request: ClipUpdateRequest):
    """
    æ›´æ–°åˆ†é•œï¼ˆåŒ…æ‹¬æ›¿æ¢è§†é¢‘å’Œç¼©ç•¥å›¾ï¼‰
    """
    supabase = get_supabase()
    
    # è·å–å½“å‰ Clip
    clip_result = supabase.table("clips").select("*").eq("id", clip_id).single().execute()
    if not clip_result.data:
        raise HTTPException(status_code=404, detail="Clip not found")
    
    # æ„å»ºæ›´æ–°æ•°æ®
    update_data = {}
    if request.source_start is not None:
        update_data["source_start"] = request.source_start
    if request.source_end is not None:
        update_data["source_end"] = request.source_end
    if request.name is not None:
        update_data["name"] = request.name
    if request.video_url is not None:
        update_data["video_url"] = request.video_url
    
    # â˜… æ›´æ–°ç¼©ç•¥å›¾ï¼šå­˜å‚¨åœ¨ metadata.thumbnail_url
    if request.thumbnail_url is not None:
        current_metadata = clip_result.data.get("metadata") or {}
        current_metadata["thumbnail_url"] = request.thumbnail_url
        update_data["metadata"] = current_metadata
    
    if not update_data:
        return {"success": True, "clip_id": clip_id, "message": "No changes"}
    
    supabase.table("clips").update(update_data).eq("id", clip_id).execute()
    
    return {"success": True, "clip_id": clip_id, "updated": update_data}



@router.delete("/clips/{clip_id}")
async def delete_clip(clip_id: str):
    """
    åˆ é™¤å•ä¸ª Clip
    
    1. è·å– clip ä¿¡æ¯ç”¨äºæ—¶é—´è°ƒæ•´
    2. åˆ é™¤ clip
    3. è°ƒæ•´åç»­ clips çš„æ—¶é—´
    """
    supabase = get_supabase()
    
    # 1. è·å–è¦åˆ é™¤çš„ clip ä¿¡æ¯
    clip_result = supabase.table("clips").select(
        "id, track_id, start_time, end_time"
    ).eq("id", clip_id).single().execute()
    
    if not clip_result.data:
        raise HTTPException(status_code=404, detail="Clip not found")
    
    clip = clip_result.data
    track_id = clip["track_id"]
    deleted_duration = clip["end_time"] - clip["start_time"]
    deleted_end_time = clip["end_time"]
    
    # 2. åˆ é™¤ clip
    supabase.table("clips").delete().eq("id", clip_id).execute()
    
    # 3. è°ƒæ•´åç»­ clips çš„æ—¶é—´ï¼ˆå‰ç§»ï¼‰
    later_clips_result = supabase.table("clips").select(
        "id, start_time, end_time"
    ).eq("track_id", track_id).gt("start_time", deleted_end_time).execute()
    
    for later_clip in (later_clips_result.data or []):
        supabase.table("clips").update({
            "start_time": later_clip["start_time"] - deleted_duration,
            "end_time": later_clip["end_time"] - deleted_duration,
        }).eq("id", later_clip["id"]).execute()
    
    logger.info(f"[DeleteClip] âœ… åˆ é™¤ clip: {clip_id}, è°ƒæ•´ {len(later_clips_result.data or [])} ä¸ªåç»­ clips")
    
    return {"success": True, "clip_id": clip_id}


class UploadThumbnailRequest(BaseModel):
    """ä¸Šä¼ ç¼©ç•¥å›¾è¯·æ±‚"""
    clip_id: str
    base64_data: str  # data:image/jpeg;base64,... æˆ–çº¯ base64


@router.post("/clips/{clip_id}/upload-thumbnail")
async def upload_clip_thumbnail(clip_id: str, request: UploadThumbnailRequest):
    """
    ä¸Šä¼  Clip ç¼©ç•¥å›¾åˆ° Supabase Storage
    
    æ¥æ”¶å‰ç«¯æˆªå–çš„ base64 å›¾ç‰‡ï¼Œä¸Šä¼ åˆ°äº‘å­˜å‚¨ï¼Œè¿”å› URL
    """
    import base64
    import tempfile
    import os
    
    supabase = get_supabase()
    
    # æ£€æŸ¥ clip æ˜¯å¦å­˜åœ¨
    clip_result = supabase.table("clips").select("id").eq("id", clip_id).single().execute()
    if not clip_result.data:
        raise HTTPException(status_code=404, detail="Clip not found")
    
    try:
        # è§£æ base64 æ•°æ®
        base64_str = request.base64_data
        if base64_str.startswith("data:"):
            # ç§»é™¤ data:image/jpeg;base64, å‰ç¼€
            base64_str = base64_str.split(",", 1)[1]
        
        # è§£ç 
        image_data = base64.b64decode(base64_str)
        
        # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(suffix=".jpg", delete=False) as tmp:
            tmp.write(image_data)
            tmp_path = tmp.name
        
        try:
            # ä¸Šä¼ åˆ° Supabase Storageï¼ˆä½¿ç”¨ä¸ç°æœ‰ç¼©ç•¥å›¾ç›¸åŒçš„ bucketï¼‰
            STORAGE_BUCKET = "ai-creations"
            storage_path = f"thumbnails/{clip_id}_replaced.jpg"
            
            # å…ˆå°è¯•åˆ é™¤å·²å­˜åœ¨çš„æ–‡ä»¶
            try:
                supabase.storage.from_(STORAGE_BUCKET).remove([storage_path])
            except:
                pass
            
            # ä¸Šä¼ 
            supabase.storage.from_(STORAGE_BUCKET).upload(
                storage_path,
                image_data,
                {"content-type": "image/jpeg"}
            )
            
            # è·å–å…¬å¼€ URL
            public_url = supabase.storage.from_(STORAGE_BUCKET).get_public_url(storage_path)
            
            # æ›´æ–° clip çš„ metadata.thumbnail_url
            clip_data = supabase.table("clips").select("metadata").eq("id", clip_id).single().execute()
            current_metadata = clip_data.data.get("metadata") or {} if clip_data.data else {}
            current_metadata["thumbnail_url"] = public_url
            supabase.table("clips").update({"metadata": current_metadata}).eq("id", clip_id).execute()
            
            logger.info(f"[UploadThumbnail] âœ… ä¸Šä¼ æˆåŠŸ: {clip_id} -> {public_url[:60]}...")
            
            return {"success": True, "clip_id": clip_id, "thumbnail_url": public_url}
            
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            os.unlink(tmp_path)
            
    except Exception as e:
        logger.error(f"[UploadThumbnail] âŒ ä¸Šä¼ å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ==========================================
# åå°ä»»åŠ¡
# ==========================================

async def run_segmentation_task(
    task_id: str,
    session_id: str,
    asset_id: str,
    strategy: SegmentationStrategy,
    params: StartSegmentationRequest,
):
    """
    åå°æ‰§è¡Œåˆ†é•œä»»åŠ¡
    
    åˆ†é•œç»“æœç›´æ¥å­˜å…¥ clips è¡¨
    """
    import os
    from app.config import get_settings
    
    settings = get_settings()
    supabase = get_supabase()
    
    try:
        is_recursive = params.parent_clip_id is not None
        logger.info(
            f"å¼€å§‹åˆ†é•œä»»åŠ¡: session={session_id}, strategy={strategy.value}, "
            f"recursive={is_recursive}"
        )
        
        # 1. è·å– Asset ä¿¡æ¯
        asset_result = supabase.table("assets").select(
            "id, storage_path, metadata, duration"
        ).eq("id", asset_id).single().execute()
        
        if not asset_result.data:
            raise ValueError("Asset not found")
        
        asset = asset_result.data
        
        # 2. æ„å»ºè§†é¢‘è·¯å¾„
        # PySceneDetect/OpenCV éœ€è¦ç›´æ¥å¯è¯»å–çš„æœ¬åœ°è§†é¢‘æ–‡ä»¶
        # éœ€è¦æŠŠè¿œç¨‹è§†é¢‘ä¸‹è½½åˆ°æœ¬åœ°ä¸´æ—¶æ–‡ä»¶
        storage_path = asset.get("storage_path", "")
        temp_video_path = None  # ç”¨äºè¿½è¸ªéœ€è¦æ¸…ç†çš„ä¸´æ—¶æ–‡ä»¶
        
        import tempfile
        import subprocess
        import hashlib
        
        temp_dir = settings.cache_dir or tempfile.gettempdir()
        
        if storage_path.startswith("cloudflare:"):
            # Cloudflare Stream è§†é¢‘
            video_uid = storage_path.replace("cloudflare:", "")
            hls_url = f"https://videodelivery.net/{video_uid}/manifest/video.m3u8"
            temp_video_path = os.path.join(temp_dir, f"shot_seg_{video_uid}.mp4")
            
            logger.info(f"ä¸‹è½½ Cloudflare HLS åˆ°ä¸´æ—¶æ–‡ä»¶: {hls_url}")
            download_url = hls_url
            
        elif storage_path.startswith("http"):
            # å·²ç»æ˜¯ HTTP URL
            download_url = storage_path
            path_hash = hashlib.md5(storage_path.encode()).hexdigest()[:12]
            temp_video_path = os.path.join(temp_dir, f"shot_seg_{path_hash}.mp4")
            
        else:
            # Supabase Storage è·¯å¾„ï¼ˆå¦‚ uploads/xxx/xxx.mp4ï¼‰
            from app.services.supabase_client import get_file_url
            download_url = get_file_url("clips", storage_path, expires_in=3600)
            
            if not download_url:
                raise ValueError(f"æ— æ³•è·å–è§†é¢‘ URL: {storage_path}")
            
            path_hash = hashlib.md5(storage_path.encode()).hexdigest()[:12]
            temp_video_path = os.path.join(temp_dir, f"shot_seg_{path_hash}.mp4")
            
            logger.info(f"è·å– Supabase ç­¾å URL: {download_url[:80]}...")
        
        # ä¸‹è½½è§†é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶ï¼ˆä½¿ç”¨å¼‚æ­¥æ–¹å¼ï¼Œé¿å…é˜»å¡äº‹ä»¶å¾ªç¯ï¼‰
        import asyncio
        
        if not os.path.exists(temp_video_path):
            logger.info(f"ä¸‹è½½è§†é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶: {temp_video_path}")
            
            try:
                # â˜… ä½¿ç”¨å¼‚æ­¥ subprocessï¼Œé¿å…é˜»å¡äº‹ä»¶å¾ªç¯å¯¼è‡´è¿æ¥æ–­å¼€
                process = await asyncio.create_subprocess_exec(
                    "ffmpeg", "-y",
                    "-i", download_url,
                    "-c", "copy",  # ç›´æ¥å¤åˆ¶ï¼Œä¸é‡æ–°ç¼–ç 
                    "-movflags", "+faststart",
                    temp_video_path,
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE
                )
                
                # ç­‰å¾…å®Œæˆï¼Œè®¾ç½®è¶…æ—¶
                try:
                    stdout, stderr = await asyncio.wait_for(
                        process.communicate(),
                        timeout=300  # 5 åˆ†é’Ÿè¶…æ—¶
                    )
                except asyncio.TimeoutError:
                    process.kill()
                    await process.wait()
                    raise ValueError("è§†é¢‘ä¸‹è½½è¶…æ—¶ï¼ˆ>5åˆ†é’Ÿï¼‰")
                
                if process.returncode != 0:
                    error_msg = stderr.decode() if stderr else "æœªçŸ¥é”™è¯¯"
                    logger.error(f"FFmpeg ä¸‹è½½å¤±è´¥: {error_msg}")
                    raise ValueError(f"æ— æ³•ä¸‹è½½è§†é¢‘: {error_msg[:200]}")
                
                logger.info(f"è§†é¢‘ä¸‹è½½å®Œæˆ: {temp_video_path}")
                
            except FileNotFoundError:
                raise ValueError("FFmpeg æœªå®‰è£…ï¼Œæ— æ³•å¤„ç†è§†é¢‘")
        else:
            logger.info(f"ä½¿ç”¨ç¼“å­˜çš„ä¸´æ—¶æ–‡ä»¶: {temp_video_path}")
        
        video_path = temp_video_path
        
        if not video_path or not os.path.exists(video_path):
            raise ValueError(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
        
        # 3. è·å– ASR ç»“æœ (å¦‚æœæœ‰)
        metadata = asset.get("metadata", {}) or {}
        transcript_segments = metadata.get("transcript_segments", [])
        
        logger.info(f"[åˆ†é•œä»»åŠ¡] ğŸ“‹ ASR transcript_segments æ¥è‡ª metadata: {len(transcript_segments)} æ¡")
        if transcript_segments:
            # æ‰“å°å‰3ä¸ª segments çš„ç»“æ„
            for i, seg in enumerate(transcript_segments[:3]):
                logger.info(f"[åˆ†é•œä»»åŠ¡]   ASRæ ·æœ¬[{i}]: {seg}")
            if len(transcript_segments) > 3:
                logger.info(f"[åˆ†é•œä»»åŠ¡]   ... è¿˜æœ‰ {len(transcript_segments) - 3} æ¡")
        
        # 3.5 å¦‚æœç­–ç•¥éœ€è¦ ASR ä½†æ²¡æœ‰ç»“æœï¼Œè‡ªåŠ¨æ‰§è¡Œ ASR
        if strategy in [SegmentationStrategy.SENTENCE, SegmentationStrategy.PARAGRAPH]:
            if not transcript_segments or len(transcript_segments) == 0:
                logger.info(f"ç­–ç•¥ {strategy.value} éœ€è¦ ASRï¼Œå¼€å§‹è‡ªåŠ¨è½¬å†™...")
                
                # ä½¿ç”¨å·²ä¸‹è½½çš„æœ¬åœ°è§†é¢‘æ–‡ä»¶æå–éŸ³é¢‘ï¼Œä¸Šä¼ åˆ° Supabase è·å–å…¬å¼€ URL
                asr_audio_url = await _extract_and_upload_audio_for_asr(
                    video_path=video_path,
                    asset_id=asset_id,
                    supabase=supabase,
                )
                
                logger.info(f"ASR éŸ³é¢‘ URL: {asr_audio_url[:80]}...")
                
                # æ‰§è¡Œ ASR è½¬å†™
                from app.tasks.transcribe import transcribe_audio
                
                asr_result = await transcribe_audio(
                    audio_url=asr_audio_url,
                    language="zh",
                    audio_format="mp3",
                    enable_word_timestamps=True,
                    enable_ddc=True,  # è¯­ä¹‰é¡ºæ»‘
                )
                
                transcript_segments = asr_result.get("segments", [])
                logger.info(f"[åˆ†é•œä»»åŠ¡] ğŸ¤ ASR è½¬å†™å®Œæˆ: {len(transcript_segments)} ä¸ªåˆ†å¥")
                
                # æ‰“å° ASR ç»“æœè¯¦æƒ…
                for i, seg in enumerate(transcript_segments):
                    start = seg.get('start', seg.get('start_ms', 0))
                    end = seg.get('end', seg.get('end_ms', 0))
                    text = seg.get('text', seg.get('transcript', ''))[:50]
                    logger.info(f"[åˆ†é•œä»»åŠ¡]   ASR[{i+1}]: [{start}-{end}] {text}...")
                
                # å°† ASR ç»“æœä¿å­˜åˆ° asset metadata
                new_metadata = {**metadata, "transcript_segments": transcript_segments}
                supabase.table("assets").update({
                    "metadata": new_metadata
                }).eq("id", asset_id).execute()
                logger.info("[åˆ†é•œä»»åŠ¡] ğŸ’¾ ASR ç»“æœå·²ä¿å­˜åˆ° asset metadata")
        
        # 4. åˆ›å»ºåˆ†é•œè¯·æ±‚
        seg_request = SegmentationRequest(
            session_id=session_id,
            asset_id=asset_id,
            strategy=strategy,
            parent_clip_id=params.parent_clip_id,
            source_start_ms=params.source_start_ms,
            source_end_ms=params.source_end_ms,
            scene_threshold=params.scene_threshold,
            scene_min_length_ms=params.scene_min_length_ms,
            min_sentence_duration_ms=params.min_sentence_duration_ms,
            max_sentence_duration_ms=params.max_sentence_duration_ms,
            merge_short_sentences=params.merge_short_sentences,
            target_paragraph_count=params.target_paragraph_count,
            min_paragraph_duration_ms=params.min_paragraph_duration_ms,
        )
        
        # 5. æ‰§è¡Œåˆ†é•œ
        logger.info(f"[åˆ†é•œä»»åŠ¡] ğŸš€ å¼€å§‹æ‰§è¡Œåˆ†é•œ: strategy={strategy.value}, transcript_segments={len(transcript_segments)}æ¡")
        logger.info(f"[åˆ†é•œä»»åŠ¡]   å‚æ•°: min_sentence={seg_request.min_sentence_duration_ms}ms, max_sentence={seg_request.max_sentence_duration_ms}ms, merge={seg_request.merge_short_sentences}")
        
        agent = get_shot_segmentation_agent()
        result = await agent.segment(
            request=seg_request,
            video_path=video_path,
            transcript_segments=transcript_segments,
            extract_thumbnails_flag=True,
        )
        
        logger.info(f"[åˆ†é•œä»»åŠ¡] âœ… åˆ†é•œå®Œæˆ: ç”Ÿæˆ {len(result.clips)} ä¸ª clips")
        
        # 6. è·å–æˆ–åˆ›å»º Track
        track_id = await _get_or_create_track(supabase, session_id, asset_id)
        
        # 7. åˆ é™¤æ—§çš„ Clips
        if is_recursive:
            # é€’å½’åˆ†é•œï¼šåˆ é™¤æŒ‡å®šçˆ¶ clip çš„å­ clips
            supabase.table("clips").delete().eq(
                "parent_clip_id", params.parent_clip_id
            ).execute()
            logger.info(f"å·²åˆ é™¤ parent_clip_id={params.parent_clip_id} çš„å­åˆ†é•œ")
        else:
            # éé€’å½’åˆ†é•œï¼šåˆ é™¤è¯¥ track ä¸‹æ‰€æœ‰æ— çˆ¶èŠ‚ç‚¹çš„ clipsï¼ˆä¿ç•™æœ‰ parent_clip_id çš„å­åˆ†é•œï¼‰
            supabase.table("clips").delete().eq(
                "track_id", track_id
            ).is_("parent_clip_id", "null").execute()
            logger.info(f"å·²åˆ é™¤ track_id={track_id} çš„é¡¶å±‚åˆ†é•œ")
        
        # 8. ä¿å­˜ Clips åˆ°æ•°æ®åº“
        clips_to_insert = []
        for clip in result.clips:
            clip_data = {
                "id": clip.id,
                "track_id": track_id,
                "asset_id": clip.asset_id,
                "clip_type": "video",
                "start_time": clip.start_time,
                "end_time": clip.end_time,
                "source_start": clip.source_start,
                "source_end": clip.source_end,
                "parent_clip_id": clip.parent_clip_id,
                "name": clip.name,
                "metadata": {
                    "strategy": strategy.value,
                    "transcript": clip.transcript,
                    "thumbnail_url": clip.thumbnail_url,
                    **clip.metadata,
                },
            }
            clips_to_insert.append(clip_data)
        
        if clips_to_insert:
            supabase.table("clips").insert(clips_to_insert).execute()
        
        # 9. æ›´æ–° Session çŠ¶æ€
        # æ³¨ï¼šç­–ç•¥ä¿¡æ¯å­˜åœ¨æ¯ä¸ª clip.metadata.strategy ä¸­
        # æ”¯æŒåŒä¸€ session ç”¨ä¸åŒç­–ç•¥åˆ‡åˆ†ä¸åŒ clip
        supabase.table("workspace_sessions").update({
            "workflow_step": "shot_completed",
        }).eq("id", session_id).execute()
        
        logger.info(f"åˆ†é•œå®Œæˆ: {len(result.clips)} ä¸ªåˆ†é•œå·²ä¿å­˜åˆ° clips è¡¨")
        
    except Exception as e:
        logger.error(f"åˆ†é•œä»»åŠ¡å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        
        supabase.table("workspace_sessions").update({
            "workflow_step": "shot_error",
            "error_message": str(e),
        }).eq("id", session_id).execute()
    
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if temp_video_path and os.path.exists(temp_video_path):
            try:
                os.remove(temp_video_path)
                logger.info(f"å·²æ¸…ç†ä¸´æ—¶è§†é¢‘æ–‡ä»¶: {temp_video_path}")
            except Exception as cleanup_err:
                logger.warning(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {cleanup_err}")


async def _get_or_create_track(supabase, session_id: str, asset_id: str) -> str:
    """
    è·å–æˆ–åˆ›å»º Project çš„ä¸»è§†é¢‘è½¨é“
    
    æ•°æ®æ¨¡å‹: session â†’ project â†’ tracks
    """
    
    # 1. è·å– session çš„ project_id
    session_result = supabase.table("workspace_sessions").select(
        "project_id"
    ).eq("id", session_id).single().execute()
    
    if not session_result.data or not session_result.data.get("project_id"):
        raise ValueError(f"Session {session_id} æ²¡æœ‰å…³è”çš„ project")
    
    project_id = session_result.data["project_id"]
    
    # 2. æŸ¥æ‰¾ç°æœ‰è½¨é“
    track_result = supabase.table("tracks").select("id").eq(
        "project_id", project_id
    ).eq("name", "è§†é¢‘è½¨é“").execute()
    
    if track_result.data and len(track_result.data) > 0:
        return track_result.data[0]["id"]
    
    # 3. åˆ›å»ºæ–°è½¨é“
    new_track = {
        "id": str(uuid4()),
        "project_id": project_id,
        "name": "è§†é¢‘è½¨é“",
        "order_index": 0,
    }
    
    supabase.table("tracks").insert(new_track).execute()
    
    return new_track["id"]


# ==========================================
# â˜… è‡ªç”±èŠ‚ç‚¹ APIï¼ˆç”»å¸ƒä¸Šç‹¬ç«‹äºæ—¶é—´è½´çš„ç´ æï¼‰
# ==========================================

class FreeNodeItem(BaseModel):
    """è‡ªç”±èŠ‚ç‚¹æ•°æ®"""
    id: str
    asset_id: Optional[str] = None
    media_type: str = "video"
    thumbnail_url: Optional[str] = None
    video_url: Optional[str] = None
    duration_ms: int = 0
    canvas_position: dict = Field(default_factory=lambda: {"x": 200, "y": 200})
    aspect_ratio: Optional[str] = None
    generating_task_id: Optional[str] = None
    generating_capability: Optional[str] = None


class BatchCreateFreeNodesRequest(BaseModel):
    """æ‰¹é‡åˆ›å»ºè‡ªç”±èŠ‚ç‚¹"""
    nodes: List[FreeNodeItem]


@router.post("/sessions/{session_id}/free-nodes/batch")
async def batch_create_free_nodes(session_id: str, request: BatchCreateFreeNodesRequest):
    """
    æ‰¹é‡åˆ›å»ºè‡ªç”±èŠ‚ç‚¹ï¼ˆå­˜å‚¨åœ¨ clips è¡¨ï¼Œmetadata.canvas_mode='free'ï¼‰
    """
    import uuid
    supabase = get_supabase()

    session_result = supabase.table("workspace_sessions").select("id, project_id, user_id").eq("id", session_id).single().execute()
    if not session_result.data:
        raise HTTPException(status_code=404, detail="Session not found")

    session_project_id = session_result.data.get("project_id")
    session_user_id = session_result.data.get("user_id")
    now = datetime.utcnow().isoformat()
    
    # è·å– track_idï¼ˆå–ç¬¬ä¸€ä¸ªèŠ‚ç‚¹çš„ asset_id ä½œä¸ºå‚è€ƒï¼‰
    first_asset_id = request.nodes[0].asset_id if request.nodes else ""
    track_id = await _get_or_create_track(supabase, session_id, first_asset_id)
    
    created = []
    for node in request.nodes:
        # â˜… clip_id å¿…é¡»æ˜¯åˆæ³• UUIDï¼ˆclips.id åˆ—æ˜¯ UUID ç±»å‹ï¼‰
        raw_clip_id = node.id
        try:
            clip_id = str(uuid.UUID(raw_clip_id))
        except (ValueError, AttributeError):
            # gen-xxx æˆ–å…¶ä»–é UUID æ ¼å¼ â†’ ç”Ÿæˆæ–° UUIDï¼Œå°†åŸå§‹ ID å­˜å…¥ metadata
            logger.warning("[FreeNodes] clip_id=%s ä¸æ˜¯åˆæ³• UUIDï¼Œè‡ªåŠ¨ç”Ÿæˆæ–° UUID", raw_clip_id)
            clip_id = str(uuid.uuid4())
        
        metadata = {
            "canvas_mode": "free",
            "canvas_position": node.canvas_position,
            "thumbnail_url": node.thumbnail_url,
            "aspect_ratio": node.aspect_ratio,
            "added_from": "canvas_free_add",
        }
        # â˜… æŒä¹…åŒ– AI ç”ŸæˆçŠ¶æ€ï¼ˆå ä½èŠ‚ç‚¹åˆ·æ–°åæ¢å¤ï¼‰
        if node.generating_task_id:
            metadata["generating_task_id"] = node.generating_task_id
        if node.generating_capability:
            metadata["generating_capability"] = node.generating_capability
        
        normalized_asset_id = (node.asset_id or '').strip() or None
        if normalized_asset_id:
            try:
                normalized_asset_id = str(uuid.UUID(normalized_asset_id))
            except ValueError:
                raise HTTPException(status_code=400, detail=f"free-node[{clip_id}] çš„ asset_id ä¸æ˜¯åˆæ³• UUID")
        else:
            normalized_asset_id = str(uuid.uuid4())

        # æ²»æœ¬ï¼šæ¯ä¸ªèŠ‚ç‚¹éƒ½ç¡®ä¿æœ‰å¯¹åº” asset è®°å½•ï¼ˆè‹¥ä¸å­˜åœ¨åˆ™è‡ªåŠ¨è¡¥å»ºï¼‰
        asset_exists = False
        try:
            existing_assets = supabase.table("assets").select("id").eq("id", normalized_asset_id).limit(1).execute().data or []
            asset_exists = len(existing_assets) > 0
        except Exception:
            asset_exists = False

        if not asset_exists:
            is_image = node.media_type == "image"
            fallback_ext = "jpg" if is_image else "mp4"
            fallback_mime = "image/jpeg" if is_image else "video/mp4"
            source_url = node.thumbnail_url if is_image else (node.video_url or node.thumbnail_url)

            asset_payload = {
                "id": normalized_asset_id,
                "project_id": session_project_id,
                "user_id": session_user_id,
                "name": f"canvas-node-{clip_id[:8]}",
                "original_filename": f"canvas-node-{clip_id[:8]}.{fallback_ext}",
                "file_type": "image" if is_image else "video",
                "mime_type": fallback_mime,
                "file_size": 0,
                "storage_path": f"virtual/free-nodes/{session_id}/{clip_id}.{fallback_ext}",
                "duration": max(0.0, float(node.duration_ms) / 1000.0),
                "status": "processing" if node.generating_task_id else "ready",
                "metadata": {
                    "is_virtual": True,
                    "source": "canvas_free_node",
                    "external_url": source_url,
                    "generating_task_id": node.generating_task_id,
                },
                "created_at": now,
                "updated_at": now,
            }
            try:
                supabase.table("assets").insert(asset_payload).execute()
            except Exception as asset_insert_err:
                logger.warning("[FreeNodes] è‡ªåŠ¨è¡¥å»º asset å¤±è´¥ asset_id=%s clip_id=%s err=%s", normalized_asset_id, clip_id, asset_insert_err)

        new_clip = {
            "id": clip_id,
            "track_id": track_id,
            "asset_id": normalized_asset_id,
            "clip_type": node.media_type,
            "start_time": -1,  # â˜… è‡ªç”±èŠ‚ç‚¹ç”¨ -1 æ ‡è®°
            "end_time": -1 + max(node.duration_ms, 1),
            "source_start": 0,
            "source_end": max(node.duration_ms, 1),  # â˜… è‡³å°‘ä¸º 1ï¼Œæ»¡è¶³ valid_source_range çº¦æŸ (source_end > source_start)
            "metadata": metadata,
            "video_url": node.video_url,
        }
        
        supabase.table("clips").insert(new_clip).execute()
        created.append(new_clip)
    
    # â˜… åŒæ­¥å†™å…¥ canvas_nodes è¡¨ï¼ˆVisual Editor ä¸“ç”¨ï¼‰
    try:
        canvas_rows = []
        for clip in created:
            meta = clip.get("metadata") or {}
            duration_ms = max(clip.get("source_end", 1) - clip.get("source_start", 0), 1)
            canvas_rows.append({
                "id": str(uuid.uuid4()),
                "project_id": session_project_id,
                "asset_id": clip["asset_id"],
                "node_type": "free",
                "media_type": clip.get("clip_type", "video"),
                "order_index": 0,
                "start_time": 0,
                "end_time": duration_ms / 1000.0,
                "duration": duration_ms / 1000.0,
                "source_start": clip.get("source_start", 0),
                "source_end": clip.get("source_end", duration_ms),
                "canvas_position": meta.get("canvas_position", {"x": 200, "y": 200}),
                "video_url": clip.get("video_url"),
                "thumbnail_url": meta.get("thumbnail_url"),
                "metadata": {
                    "generating_task_id": meta.get("generating_task_id"),
                    "generating_capability": meta.get("generating_capability"),
                    "aspect_ratio": meta.get("aspect_ratio"),
                },
                "clip_id": clip["id"],
                "created_at": now,
                "updated_at": now,
            })
        if canvas_rows:
            supabase.table("canvas_nodes").insert(canvas_rows).execute()
            logger.info(f"[FreeNodes] âœ… åŒæ­¥åˆ›å»º {len(canvas_rows)} ä¸ª canvas_nodes")
    except Exception as e:
        logger.warning(f"[FreeNodes] âš ï¸ canvas_nodes å†™å…¥å¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {e}")
    
    logger.info(f"[FreeNodes] âœ… åˆ›å»º {len(created)} ä¸ªè‡ªç”±èŠ‚ç‚¹")
    return {"success": True, "created_count": len(created)}


@router.delete("/free-nodes/{node_id}")
async def delete_free_node(node_id: str):
    """åˆ é™¤è‡ªç”±èŠ‚ç‚¹"""
    import uuid as uuid_mod
    try:
        str(uuid_mod.UUID(node_id))
    except (ValueError, AttributeError):
        logger.warning("[FreeNodes] delete_free_node: node_id=%s ä¸æ˜¯åˆæ³• UUIDï¼Œè·³è¿‡", node_id)
        return {"success": False, "reason": "invalid_uuid"}
    supabase = get_supabase()
    supabase.table("clips").delete().eq("id", node_id).execute()
    
    # â˜… åŒæ­¥åˆ é™¤ canvas_nodes
    try:
        # å…ˆåˆ å…³è”çš„ canvas_edges
        supabase.table("canvas_edges").delete().or_(
            f"source_node_id.eq.{node_id},target_node_id.eq.{node_id}"
        ).execute()
        # åˆ é™¤èŠ‚ç‚¹ï¼ˆé€šè¿‡ clip_id å…³è”ï¼‰
        supabase.table("canvas_nodes").delete().eq("clip_id", node_id).execute()
        # ä¹Ÿå°è¯•é€šè¿‡ id ç›´æ¥åˆ é™¤
        supabase.table("canvas_nodes").delete().eq("id", node_id).execute()
    except Exception as e:
        logger.warning(f"[FreeNodes] âš ï¸ canvas_nodes åˆ é™¤åŒæ­¥å¤±è´¥: {e}")
    
    return {"success": True}


class UpdateFreeNodeRequest(BaseModel):
    """æ›´æ–°è‡ªç”±èŠ‚ç‚¹æ•°æ®ï¼ˆä»»åŠ¡å®Œæˆåæ›´æ–° videoUrlã€metadata ç­‰ï¼‰"""
    video_url: Optional[str] = None
    metadata: Optional[dict] = None


@router.patch("/free-nodes/{node_id}/update")
async def update_free_node(node_id: str, request: UpdateFreeNodeRequest):
    """æ›´æ–°è‡ªç”±èŠ‚ç‚¹çš„è§†é¢‘ URL å’Œ metadataï¼ˆä»»åŠ¡å®Œæˆåè°ƒç”¨ï¼‰"""
    import uuid as uuid_mod
    try:
        str(uuid_mod.UUID(node_id))
    except (ValueError, AttributeError):
        logger.warning("[FreeNodes] update_free_node: node_id=%s ä¸æ˜¯åˆæ³• UUIDï¼Œè·³è¿‡", node_id)
        return {"success": False, "reason": "invalid_uuid"}
    supabase = get_supabase()
    
    clip_result = supabase.table("clips").select("metadata, video_url").eq("id", node_id).single().execute()
    if not clip_result.data:
        raise HTTPException(status_code=404, detail="Node not found")
    
    updates = {}
    if request.video_url is not None:
        updates["video_url"] = request.video_url
    
    if request.metadata is not None:
        existing_metadata = clip_result.data.get("metadata") or {}
        existing_metadata.update(request.metadata)
        updates["metadata"] = existing_metadata
    
    if updates:
        supabase.table("clips").update(updates).eq("id", node_id).execute()
        
        # â˜… åŒæ­¥æ›´æ–° canvas_nodes
        try:
            cn_updates = {"updated_at": datetime.utcnow().isoformat()}
            if request.video_url is not None:
                cn_updates["video_url"] = request.video_url
            if request.metadata is not None:
                # åˆå¹¶ metadata å¹¶æå– thumbnail_url
                cn_updates["metadata"] = updates.get("metadata", {})
                thumb = (updates.get("metadata") or {}).get("thumbnail_url")
                if thumb:
                    cn_updates["thumbnail_url"] = thumb
            
            supabase.table("canvas_nodes").update(cn_updates).eq("clip_id", node_id).execute()
        except Exception as e:
            logger.warning(f"[FreeNodes] âš ï¸ canvas_nodes æ›´æ–°åŒæ­¥å¤±è´¥: {e}")
    
    return {"success": True}


class UpdatePositionRequest(BaseModel):
    canvas_position: dict


@router.patch("/free-nodes/{node_id}/position")
async def update_free_node_position(node_id: str, request: UpdatePositionRequest):
    """æ›´æ–°è‡ªç”±èŠ‚ç‚¹çš„ç”»å¸ƒä½ç½®"""
    import uuid as uuid_mod
    try:
        str(uuid_mod.UUID(node_id))
    except (ValueError, AttributeError):
        logger.warning("[FreeNodes] update_position: node_id=%s ä¸æ˜¯åˆæ³• UUIDï¼Œè·³è¿‡", node_id)
        return {"success": False, "reason": "invalid_uuid"}
    supabase = get_supabase()
    
    # è·å–å½“å‰ metadata å¹¶åˆå¹¶
    clip_result = supabase.table("clips").select("metadata").eq("id", node_id).single().execute()
    if not clip_result.data:
        raise HTTPException(status_code=404, detail="Node not found")
    
    metadata = clip_result.data.get("metadata") or {}
    metadata["canvas_position"] = request.canvas_position
    
    supabase.table("clips").update({"metadata": metadata}).eq("id", node_id).execute()
    
    # â˜… åŒæ­¥æ›´æ–° canvas_nodes è¡¨
    try:
        # å…ˆå°è¯•é€šè¿‡ clip_id å…³è”æ›´æ–°
        cn_result = supabase.table("canvas_nodes").select("id").eq("clip_id", node_id).limit(1).execute()
        if cn_result.data:
            supabase.table("canvas_nodes").update({
                "canvas_position": request.canvas_position,
                "updated_at": datetime.utcnow().isoformat(),
            }).eq("clip_id", node_id).execute()
        else:
            # é™çº§: é€šè¿‡ id ç›´æ¥åŒ¹é…
            supabase.table("canvas_nodes").update({
                "canvas_position": request.canvas_position,
                "updated_at": datetime.utcnow().isoformat(),
            }).eq("id", node_id).execute()
    except Exception as e:
        logger.warning(f"[FreeNodes] âš ï¸ canvas_nodes position åŒæ­¥å¤±è´¥: {e}")
    
    return {"success": True}


# ==========================================
# â˜… ç”»å¸ƒè¿çº¿ APIï¼ˆå­˜å‚¨åœ¨ session metadataï¼‰
# ==========================================

class CanvasEdgesRequest(BaseModel):
    edges: List[dict]


@router.put("/sessions/{session_id}/canvas-edges")
async def save_canvas_edges(session_id: str, request: CanvasEdgesRequest):
    """ä¿å­˜ç”»å¸ƒè¿çº¿åˆ° session metadata + canvas_edges è¡¨"""
    supabase = get_supabase()
    
    session_result = supabase.table("workspace_sessions").select("metadata, project_id").eq("id", session_id).single().execute()
    if not session_result.data:
        raise HTTPException(status_code=404, detail="Session not found")
    
    metadata = session_result.data.get("metadata") or {}
    metadata["canvas_edges"] = request.edges
    
    supabase.table("workspace_sessions").update({"metadata": metadata}).eq("id", session_id).execute()
    
    # â˜… åŒæ­¥å†™å…¥ canvas_edges è¡¨
    project_id = session_result.data.get("project_id")
    if project_id:
        try:
            # æ¸…ç©ºæ—§è¿çº¿
            supabase.table("canvas_edges").delete().eq("project_id", project_id).execute()
            # å†™å…¥æ–°è¿çº¿
            if request.edges:
                from datetime import datetime as dt
                now = dt.utcnow().isoformat()
                rows = []
                for edge in request.edges:
                    if isinstance(edge, dict) and edge.get("source") and edge.get("target"):
                        rows.append({
                            "id": edge.get("id") or str(uuid4()),
                            "project_id": project_id,
                            "source_node_id": edge["source"],
                            "target_node_id": edge["target"],
                            "source_handle": edge.get("sourceHandle"),
                            "target_handle": edge.get("targetHandle"),
                            "created_at": now,
                        })
                if rows:
                    supabase.table("canvas_edges").insert(rows).execute()
                    logger.info(f"[CanvasEdges] âœ… åŒæ­¥ {len(rows)} æ¡è¿çº¿åˆ° canvas_edges è¡¨")
        except Exception as e:
            logger.warning(f"[CanvasEdges] âš ï¸ canvas_edges è¡¨åŒæ­¥å¤±è´¥: {e}")
    
    return {"success": True}


@router.get("/sessions/{session_id}/canvas-edges")
async def get_canvas_edges(session_id: str):
    """è·å–ç”»å¸ƒè¿çº¿"""
    supabase = get_supabase()
    
    session_result = supabase.table("workspace_sessions").select("metadata").eq("id", session_id).single().execute()
    if not session_result.data:
        raise HTTPException(status_code=404, detail="Session not found")
    
    metadata = session_result.data.get("metadata") or {}
    return {"edges": metadata.get("canvas_edges", [])}
