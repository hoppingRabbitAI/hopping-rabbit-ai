"""
HoppingRabbit AI - æ™ºèƒ½åŠŸèƒ½ API (Phase 6)
é™éŸ³æ£€æµ‹ã€å¡«å……è¯æ£€æµ‹ã€è¯´è¯äººåˆ†ç¦»ã€éŸ³è½¨åˆ†ç¦»ã€å­—å¹•çƒ§å½•
"""
import bisect
import logging
from fastapi import APIRouter, HTTPException, BackgroundTasks, Query
from fastapi.responses import Response
from typing import Optional, List, Dict, Any, Tuple
from datetime import datetime
from uuid import uuid4
from pydantic import BaseModel
import json

from ..services.supabase_client import supabase
from ..services.smart_analyzer import normalize_classification

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/ai", tags=["Smart Features"])


# ============================================
# è¯·æ±‚æ¨¡å‹
# ============================================

class SilenceDetectionRequest(BaseModel):
    """é™éŸ³æ£€æµ‹è¯·æ±‚"""
    project_id: str
    audio_url: str
    method: str = "energy"  # energy, silero, ffmpeg
    silence_threshold_db: float = -35
    min_silence_duration: float = 0.5
    min_speech_duration: float = 0.3
    padding: float = 0.1

class FillerDetectionRequest(BaseModel):
    """å¡«å……è¯æ£€æµ‹è¯·æ±‚"""
    project_id: str
    transcript: Dict[str, Any]
    custom_words: Optional[List[str]] = None
    min_confidence: float = 0.7
    languages: Optional[List[str]] = None

class DiarizeRequest(BaseModel):
    """è¯´è¯äººåˆ†ç¦»è¯·æ±‚"""
    project_id: str
    audio_url: str
    num_speakers: Optional[int] = None
    transcript: Optional[Dict[str, Any]] = None

class StemSeparateRequest(BaseModel):
    """éŸ³è½¨åˆ†ç¦»è¯·æ±‚"""
    project_id: str
    audio_url: str
    model: str = "htdemucs"
    two_stems: bool = True
    stems: Optional[List[str]] = None

class SubtitleBurnRequest(BaseModel):
    """å­—å¹•çƒ§å½•è¯·æ±‚"""
    project_id: str
    video_url: str
    subtitles: List[Dict[str, Any]]
    style: Dict[str, Any]


# ============================================
# é™éŸ³æ£€æµ‹
# ============================================

@router.post("/detect-silence")
async def detect_silence(request: SilenceDetectionRequest, background_tasks: BackgroundTasks):
    """
    æ£€æµ‹éŸ³é¢‘ä¸­çš„é™éŸ³ç‰‡æ®µ
    
    æ”¯æŒä¸‰ç§æ£€æµ‹æ–¹æ³•:
    - energy: åŸºäºèƒ½é‡é˜ˆå€¼ï¼ˆå¿«é€Ÿï¼‰
    - silero: åŸºäº Silero VAD æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ˆå‡†ç¡®ï¼‰
    - ffmpeg: ä½¿ç”¨ FFmpeg å†…ç½®æ£€æµ‹ï¼ˆæ— ä¾èµ–ï¼‰
    """
    try:
        task_id = str(uuid4())
        now = datetime.utcnow().isoformat()
        
        task_data = {
            "id": task_id,
            "type": "silence_detection",
            "project_id": request.project_id,
            "status": "pending",
            "progress": 0,
            "params": request.model_dump(),
            "created_at": now,
            "updated_at": now
        }
        
        supabase.table("tasks").insert(task_data).execute()
        
        # å¼‚æ­¥æ‰§è¡Œ
        background_tasks.add_task(
            execute_silence_detection,
            task_id,
            request.project_id,
            request.audio_url,
            request.method,
            request.silence_threshold_db,
            request.min_silence_duration,
            request.min_speech_duration,
            request.padding
        )
        
        return {"task_id": task_id, "status": "pending"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# å¡«å……è¯æ£€æµ‹
# ============================================

@router.post("/detect-fillers")
async def detect_fillers(request: FillerDetectionRequest):
    """
    æ£€æµ‹è½¬å½•æ–‡æœ¬ä¸­çš„å¡«å……è¯ï¼ˆå£å¤´ç¦…ã€è¯­æ°”è¯ï¼‰
    
    è‡ªåŠ¨è¯†åˆ«ï¼š
    - ä¸­æ–‡ï¼šå—¯ã€å•Šã€é‚£ä¸ªã€ç„¶åã€å°±æ˜¯...
    - è‹±æ–‡ï¼šum, uh, like, you know, basically...
    - æ”¯æŒè‡ªå®šä¹‰è¯åº“
    """
    try:
        task_id = str(uuid4())
        now = datetime.utcnow().isoformat()
        
        # åŒæ­¥æ‰§è¡Œï¼ˆå¡«å……è¯æ£€æµ‹å¾ˆå¿«ï¼‰
        from ..tasks.filler_detection import detect_fillers as detect_filler_words
        result = detect_filler_words(
            transcript=request.transcript,
            custom_words=request.custom_words,
            min_confidence=request.min_confidence,
            languages=request.languages
        )
        
        # è®°å½•ä»»åŠ¡
        supabase.table("tasks").insert({
            "id": task_id,
            "type": "filler_detection",
            "project_id": request.project_id,
            "status": "completed",
            "progress": 100,
            "result": result,
            "created_at": now,
            "updated_at": now
        }).execute()
        
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# è¯´è¯äººåˆ†ç¦»
# ============================================

@router.post("/diarize")
async def diarize_audio(request: DiarizeRequest, background_tasks: BackgroundTasks):
    """
    è¯´è¯äººåˆ†ç¦» - è¯†åˆ«éŸ³é¢‘ä¸­çš„ä¸åŒè¯´è¯äºº
    
    åŠŸèƒ½ï¼š
    - è‡ªåŠ¨æ£€æµ‹è¯´è¯äººæ•°é‡ï¼ˆ2-10äººï¼‰
    - å¯æ‰‹åŠ¨æŒ‡å®šè¯´è¯äººæ•°é‡
    - ä¸è½¬å½•æ–‡æœ¬åˆå¹¶ï¼Œæ ‡æ³¨æ¯æ®µè¯çš„è¯´è¯äºº
    """
    try:
        task_id = str(uuid4())
        now = datetime.utcnow().isoformat()
        
        task_data = {
            "id": task_id,
            "type": "diarization",
            "project_id": request.project_id,
            "status": "pending",
            "progress": 0,
            "params": {
                "num_speakers": request.num_speakers,
                "has_transcript": bool(request.transcript)
            },
            "created_at": now,
            "updated_at": now
        }
        
        supabase.table("tasks").insert(task_data).execute()
        
        # å¼‚æ­¥æ‰§è¡Œ
        background_tasks.add_task(
            execute_diarization,
            task_id,
            request.project_id,
            request.audio_url,
            request.num_speakers,
            request.transcript
        )
        
        return {"task_id": task_id, "status": "pending"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# éŸ³è½¨åˆ†ç¦»
# ============================================

@router.post("/separate-stems")
async def separate_stems(request: StemSeparateRequest, background_tasks: BackgroundTasks):
    """
    éŸ³è½¨åˆ†ç¦» - å°†éŸ³é¢‘åˆ†ç¦»ä¸ºäººå£°ã€ä¼´å¥ç­‰ç‹¬ç«‹è½¨é“
    
    æ”¯æŒæ¨¡å‹ï¼š
    - htdemucs: é»˜è®¤ï¼Œå¹³è¡¡è´¨é‡å’Œé€Ÿåº¦
    - htdemucs_ft: Fine-tuned ç‰ˆæœ¬ï¼Œè´¨é‡æ›´é«˜
    - mdx_extra: MDX æ¨¡å‹
    
    è¾“å‡ºï¼š
    - two_stems=True: äººå£° + ä¼´å¥
    - two_stems=False: äººå£° + é¼“ç‚¹ + è´æ–¯ + å…¶ä»–
    """
    try:
        task_id = str(uuid4())
        now = datetime.utcnow().isoformat()
        
        task_data = {
            "id": task_id,
            "type": "stem_separation",
            "project_id": request.project_id,
            "status": "pending",
            "progress": 0,
            "params": request.model_dump(),
            "created_at": now,
            "updated_at": now
        }
        
        supabase.table("tasks").insert(task_data).execute()
        
        # ä½¿ç”¨ Celery å¼‚æ­¥æ‰§è¡Œï¼ˆè€—æ—¶ä»»åŠ¡ï¼‰
        try:
            from ..tasks.stem_separation import separate_stems_task
            separate_stems_task.delay(
                task_id,
                request.project_id,
                request.audio_url,
                request.model,
                request.two_stems,
                request.stems
            )
        except:
            # Celery ä¸å¯ç”¨ï¼Œè¿”å›æç¤º
            return {
                "task_id": task_id, 
                "status": "error",
                "message": "éŸ³è½¨åˆ†ç¦»éœ€è¦ Celery åå°ä»»åŠ¡æ”¯æŒï¼Œè¯·ç¡®ä¿å·²å¯åŠ¨ Celery Worker"
            }
        
        return {"task_id": task_id, "status": "pending"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# å­—å¹•çƒ§å½•
# ============================================

@router.post("/burn-subtitles")
async def burn_subtitles(request: SubtitleBurnRequest, background_tasks: BackgroundTasks):
    """
    å­—å¹•çƒ§å½• - å°†å­—å¹•ç¡¬ç¼–ç åˆ°è§†é¢‘ä¸­
    
    æ”¯æŒæ ·å¼ï¼š
    - å­—ä½“ã€å¤§å°ã€é¢œè‰²
    - æè¾¹ã€é˜´å½±
    - ä½ç½®ã€åŠ¨ç”»æ•ˆæœ
    """
    try:
        task_id = str(uuid4())
        now = datetime.utcnow().isoformat()
        
        task_data = {
            "id": task_id,
            "type": "subtitle_burn",
            "project_id": request.project_id,
            "status": "pending",
            "progress": 0,
            "params": {
                "subtitle_count": len(request.subtitles),
                "style": request.style
            },
            "created_at": now,
            "updated_at": now
        }
        
        supabase.table("tasks").insert(task_data).execute()
        
        background_tasks.add_task(
            execute_subtitle_burn,
            task_id,
            request.project_id,
            request.video_url,
            request.subtitles,
            request.style
        )
        
        return {"task_id": task_id, "status": "pending"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# å­—å¹•å¯¼å‡º
# ============================================

@router.get("/export-subtitles/{project_id}")
async def export_subtitles(
    project_id: str,
    format: str = Query("srt", enum=["srt", "vtt", "ass"]),
    subtitles: Optional[str] = None  # JSON å­—ç¬¦ä¸²
):
    """
    å¯¼å‡ºå­—å¹•æ–‡ä»¶
    
    æ”¯æŒæ ¼å¼ï¼š
    - srt: SubRip æ ¼å¼
    - vtt: WebVTT æ ¼å¼
    - ass: ASS/SSA æ ¼å¼ï¼ˆæ”¯æŒæ ·å¼ï¼‰
    """
    try:
        from ..tasks.subtitle_burn import export_srt, export_vtt, export_ass
        
        # è§£æå­—å¹•æ•°æ®
        if subtitles:
            subtitle_list = json.loads(subtitles)
        else:
            # ä»é¡¹ç›®è·å–å­—å¹•
            project = supabase.table("projects").select("subtitles").eq("id", project_id).single().execute()
            subtitle_list = project.data.get("subtitles", []) if project.data else []
        
        if not subtitle_list:
            raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°å­—å¹•æ•°æ®")
        
        if format == "srt":
            content = export_srt(subtitle_list)
            media_type = "text/plain"
            filename = f"{project_id}.srt"
        elif format == "vtt":
            content = export_vtt(subtitle_list)
            media_type = "text/vtt"
            filename = f"{project_id}.vtt"
        else:  # ass
            style = {}
            content = export_ass(subtitle_list, style)
            media_type = "text/plain"
            filename = f"{project_id}.ass"
        
        return Response(
            content=content,
            media_type=media_type,
            headers={"Content-Disposition": f"attachment; filename={filename}"}
        )
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# ä»»åŠ¡æ‰§è¡Œå‡½æ•°
# ============================================

async def execute_silence_detection(
    task_id: str,
    project_id: str,
    audio_url: str,
    method: str,
    silence_threshold_db: float,
    min_silence_duration: float,
    min_speech_duration: float,
    padding: float
):
    """æ‰§è¡Œé™éŸ³æ£€æµ‹"""
    import tempfile
    import httpx
    import os
    
    try:
        supabase.table("tasks").update({
            "status": "running",
            "progress": 10,
            "updated_at": datetime.utcnow().isoformat()
        }).eq("id", task_id).execute()
        
        with tempfile.TemporaryDirectory() as tmpdir:
            audio_path = os.path.join(tmpdir, "audio.wav")
            
            # ä¸‹è½½éŸ³é¢‘
            async with httpx.AsyncClient(timeout=300) as client:
                response = await client.get(audio_url, follow_redirects=True)
                response.raise_for_status()
                with open(audio_path, "wb") as f:
                    f.write(response.content)
            
            # æ£€æµ‹
            from ..tasks.vad import VADDetector, detect_silence_ffmpeg
            
            if method == "ffmpeg":
                result = detect_silence_ffmpeg(
                    audio_path,
                    silence_threshold_db,
                    min_silence_duration
                )
            else:
                detector = VADDetector(
                    method=method,
                    silence_threshold_db=silence_threshold_db,
                    min_silence_duration=min_silence_duration,
                    min_speech_duration=min_speech_duration,
                    padding=padding
                )
                result = detector.detect(audio_path)
            
            supabase.table("tasks").update({
                "status": "completed",
                "progress": 100,
                "result": result,
                "updated_at": datetime.utcnow().isoformat()
            }).eq("id", task_id).execute()
            
    except Exception as e:
        supabase.table("tasks").update({
            "status": "failed",
            "error": str(e),
            "updated_at": datetime.utcnow().isoformat()
        }).eq("id", task_id).execute()


async def execute_diarization(
    task_id: str,
    project_id: str,
    audio_url: str,
    num_speakers: Optional[int],
    transcript: Optional[Dict]
):
    """æ‰§è¡Œè¯´è¯äººåˆ†ç¦»"""
    import tempfile
    import httpx
    import os
    
    try:
        supabase.table("tasks").update({
            "status": "running",
            "progress": 10,
            "updated_at": datetime.utcnow().isoformat()
        }).eq("id", task_id).execute()
        
        with tempfile.TemporaryDirectory() as tmpdir:
            audio_path = os.path.join(tmpdir, "audio.wav")
            
            async with httpx.AsyncClient(timeout=300) as client:
                response = await client.get(audio_url, follow_redirects=True)
                response.raise_for_status()
                with open(audio_path, "wb") as f:
                    f.write(response.content)
            
            from ..tasks.diarization import diarize_audio
            result = await diarize_audio(
                audio_path=audio_path,
                num_speakers=num_speakers,
                transcript=transcript
            )
            
            supabase.table("tasks").update({
                "status": "completed",
                "progress": 100,
                "result": result,
                "updated_at": datetime.utcnow().isoformat()
            }).eq("id", task_id).execute()
            
    except Exception as e:
        supabase.table("tasks").update({
            "status": "failed",
            "error": str(e),
            "updated_at": datetime.utcnow().isoformat()
        }).eq("id", task_id).execute()


async def execute_subtitle_burn(
    task_id: str,
    project_id: str,
    video_url: str,
    subtitles: List[Dict],
    style: Dict
):
    """æ‰§è¡Œå­—å¹•çƒ§å½•"""
    import tempfile
    import httpx
    import os
    
    try:
        supabase.table("tasks").update({
            "status": "running",
            "progress": 10,
            "updated_at": datetime.utcnow().isoformat()
        }).eq("id", task_id).execute()
        
        with tempfile.TemporaryDirectory() as tmpdir:
            video_path = os.path.join(tmpdir, "input.mp4")
            output_path = os.path.join(tmpdir, "output.mp4")
            
            async with httpx.AsyncClient(timeout=600) as client:
                response = await client.get(video_url, follow_redirects=True)
                response.raise_for_status()
                with open(video_path, "wb") as f:
                    f.write(response.content)
            
            from ..tasks.subtitle_burn import burn_subtitles
            result_path = await burn_subtitles(
                video_path=video_path,
                subtitles=subtitles,
                style=style,
                output_path=output_path
            )
            
            # ä¸Šä¼ ç»“æœ
            storage_path = f"exports/{project_id}/subtitled_{task_id}.mp4"
            
            with open(result_path, "rb") as f:
                supabase.storage.from_("videos").upload(
                    storage_path,
                    f.read(),
                    {"content-type": "video/mp4"}
                )
            
            from ..services.supabase_client import get_file_url
            result_url = get_file_url("videos", storage_path)
            
            supabase.table("tasks").update({
                "status": "completed",
                "progress": 100,
                "result": {"url": result_url, "subtitle_count": len(subtitles)},
                "updated_at": datetime.utcnow().isoformat()
            }).eq("id", task_id).execute()
            
    except Exception as e:
        supabase.table("tasks").update({
            "status": "failed",
            "error": str(e),
            "updated_at": datetime.utcnow().isoformat()
        }).eq("id", task_id).execute()


# ============================================
# ä¸€é”® AI æˆç‰‡
# ============================================

class AIVideoCreateRequest(BaseModel):
    """ä¸€é”®æˆç‰‡è¯·æ±‚"""
    project_id: str
    video_path: str  # æœ¬åœ°è§†é¢‘è·¯å¾„
    audio_url: str   # éŸ³é¢‘å…¬ç½‘ URL (ç”¨äº ASR)
    options: Optional[Dict[str, Any]] = None  # å¯é€‰é…ç½®


class AIVideoCreateResponse(BaseModel):
    """ä¸€é”®æˆç‰‡å“åº”"""
    task_id: str
    status: str
    message: str


@router.post("/ai-create", response_model=AIVideoCreateResponse)
async def ai_video_create(request: AIVideoCreateRequest, background_tasks: BackgroundTasks):
    """
    ä¸€é”® AI æˆç‰‡
    
    è‡ªåŠ¨å®Œæˆ:
    1. è¯­éŸ³è¯†åˆ« (ASR) åˆ‡ç‰‡
    2. äººè„¸æ£€æµ‹ (MediaPipe) å®šä½ç„¦ç‚¹
    3. æ™ºèƒ½è¿é•œ (Zoom/Pan) ç”Ÿæˆ
    4. å­—å¹•ç”Ÿæˆ
    
    å¯é€‰ (éœ€é…ç½® LLM API):
    5. æƒ…ç»ªåˆ†æå¢å¼ºè¿é•œæ•ˆæœ
    """
    try:
        task_id = str(uuid4())
        now = datetime.utcnow().isoformat()
        
        task_data = {
            "id": task_id,
            "type": "ai_video_create",
            "project_id": request.project_id,
            "status": "pending",
            "progress": 0,
            "params": request.model_dump(),
            "created_at": now,
            "updated_at": now
        }
        
        supabase.table("tasks").insert(task_data).execute()
        
        # å¼‚æ­¥æ‰§è¡Œ
        background_tasks.add_task(
            execute_ai_video_create,
            task_id,
            request.project_id,
            request.video_path,
            request.audio_url,
            request.options or {}
        )
        
        return AIVideoCreateResponse(
            task_id=task_id,
            status="pending",
            message="AI æˆç‰‡ä»»åŠ¡å·²æäº¤ï¼Œæ­£åœ¨å¤„ç†ä¸­..."
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


async def execute_ai_video_create(
    task_id: str,
    project_id: str,
    video_path: str,
    audio_url: str,
    options: Dict
):
    """æ‰§è¡Œä¸€é”®æˆç‰‡ä»»åŠ¡"""
    import asyncio
    
    try:
        # æ›´æ–°çŠ¶æ€
        supabase.table("tasks").update({
            "status": "processing",
            "progress": 5,
            "updated_at": datetime.utcnow().isoformat()
        }).eq("id", task_id).execute()
        
        from ..services.ai_video_creator import ai_video_creator
        
        # æ‰§è¡Œ AI å¤„ç†
        result = await ai_video_creator.process(
            video_path=video_path,
            audio_url=audio_url,
            options=options
        )
        
        # æ›´æ–°è¿›åº¦
        supabase.table("tasks").update({
            "status": "processing",
            "progress": 80,
            "updated_at": datetime.utcnow().isoformat()
        }).eq("id", task_id).execute()
        
        # å°†ç»“æœè½¬æ¢ä¸º Clips å’Œ Tracks å¹¶å­˜å…¥æ•°æ®åº“
        clips_data = await _save_ai_result_to_project(project_id, result)
        
        # å®Œæˆ
        supabase.table("tasks").update({
            "status": "completed",
            "progress": 100,
            "result": {
                "clips_count": result.clips_count,
                "total_duration": result.total_duration,
                "speech_duration": result.speech_duration,
                "subtitles_count": len(result.subtitles)
            },
            "updated_at": datetime.utcnow().isoformat()
        }).eq("id", task_id).execute()
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        
        supabase.table("tasks").update({
            "status": "failed",
            "error": str(e),
            "updated_at": datetime.utcnow().isoformat()
        }).eq("id", task_id).execute()


async def _save_ai_result_to_project(project_id: str, result) -> List[Dict]:
    """
    å°† AI å¤„ç†ç»“æœä¿å­˜ä¸º Project çš„ Clips å’Œ Tracks
    
    è¦†ç›–ç­–ç•¥ï¼š
    - æŸ¥æ‰¾è¯¥é¡¹ç›®å·²æœ‰çš„ AI è§†é¢‘è½¨é“å’Œå­—å¹•è½¨é“
    - å¦‚æœå­˜åœ¨ï¼Œåˆ é™¤æ—§ clips å¹¶å¤ç”¨è½¨é“
    - å¦‚æœä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°è½¨é“
    """
    from ..services.ai_video_creator import AIEditingResult, SmartSegment
    from .workspace import _split_segments_by_punctuation
    
    now = datetime.utcnow().isoformat()
    
    # æŸ¥æ‰¾å·²æœ‰çš„ AI è½¨é“
    existing_tracks = supabase.table("tracks").select("id, name").eq("project_id", project_id).execute()
    existing_data = existing_tracks.data or []
    
    video_track_id = None
    subtitle_track_id = None
    
    for track in existing_data:
        if track.get("name") == "AI Video Track" or track.get("name") == "AI è§†é¢‘è½¨é“":
            video_track_id = track["id"]
        elif track.get("name") == "AI Subtitles" or track.get("name") == "AI å­—å¹•è½¨é“":
            subtitle_track_id = track["id"]
    
    # å¦‚æœæœ‰æ—§è½¨é“ï¼Œåˆ é™¤å…¶ä¸‹çš„æ‰€æœ‰ clips
    if video_track_id:
        supabase.table("clips").delete().eq("track_id", video_track_id).execute()
        logger.debug(f"åˆ é™¤æ—§è§†é¢‘è½¨é“ clips, track_id={video_track_id}")
    
    if subtitle_track_id:
        supabase.table("clips").delete().eq("track_id", subtitle_track_id).execute()
        logger.debug(f"åˆ é™¤æ—§å­—å¹•è½¨é“ clips, track_id={subtitle_track_id}")
    
    # å¦‚æœæ²¡æœ‰æ—§è½¨é“ï¼Œåˆ›å»ºæ–°çš„
    if not video_track_id:
        video_track_id = str(uuid4())
        video_track = {
            "id": video_track_id,
            "project_id": project_id,
            "name": "AI è§†é¢‘è½¨é“",
            "order_index": 0,
            "is_visible": True,
            "is_locked": False,
            "is_muted": False,
            "created_at": now,
            "updated_at": now
        }
        supabase.table("tracks").insert(video_track).execute()
        logger.debug(f"åˆ›å»ºæ–°è§†é¢‘è½¨é“, track_id={video_track_id}")
    
    if not subtitle_track_id:
        subtitle_track_id = str(uuid4())
        subtitle_track = {
            "id": subtitle_track_id,
            "project_id": project_id,
            "name": "AI å­—å¹•è½¨é“",
            "order_index": 1,
            "is_visible": True,
            "is_locked": False,
            "is_muted": False,
            "created_at": now,
            "updated_at": now
        }
        supabase.table("tracks").insert(subtitle_track).execute()
        logger.debug(f"åˆ›å»ºæ–°å­—å¹•è½¨é“, track_id={subtitle_track_id}")
    
    # 3. åˆ›å»ºè§†é¢‘ Clips (å¸¦ transform å’Œé™éŸ³åˆ†çº§)
    video_clips = []
    subtitle_clips = []
    
    timeline_position = 0
    speech_count = 0
    breath_count = 0
    
    for seg_idx, seg in enumerate(result.segments):
        clip_duration = int(seg.end - seg.start)
        
        # åˆ¤æ–­æ˜¯å¦ä¸ºæ¢æ°”/é™éŸ³ç‰‡æ®µ
        is_breath = seg.is_breath if hasattr(seg, "is_breath") else False
        is_silence = seg.is_silence if hasattr(seg, "is_silence") else False
        
        # å‘½å
        if is_breath:
            clip_name = "æ¢æ°”"
            breath_count += 1
        elif is_silence:
            clip_name = "é™éŸ³"
        else:
            speech_count += 1
            clip_name = f"ç‰‡æ®µ {speech_count}"
        
        # è§†é¢‘ clip IDï¼Œç”¨äºå­—å¹•å…³è”
        video_clip_id = str(uuid4())
        
        video_clip = {
            "id": video_clip_id,
            "track_id": video_track_id,
            "clip_type": "video",
            "name": clip_name,
            "start_time": timeline_position,
            "end_time": timeline_position + clip_duration,
            "source_start": int(seg.start),
            "source_end": int(seg.end),
            "volume": 1.0,
            "is_muted": False,
            "transform": seg.transform if hasattr(seg, "transform") else None,
            "speed": 1.0,
            "created_at": now,
            "updated_at": now
        }
        
        # ä¿ç•™å…ƒæ•°æ®
        if hasattr(seg, "metadata") and seg.metadata:
            video_clip["metadata"] = seg.metadata
        
        video_clips.append(video_clip)
        
        # 4. åˆ›å»ºå­—å¹• Clips (æŒ‰æ ‡ç‚¹åˆ‡åˆ†ï¼Œåªæœ‰è¯­éŸ³ç‰‡æ®µ)
        if seg.text and not is_breath and not is_silence:
            seg_dict = {
                "id": seg.id,
                "text": seg.text,
                "start": int(seg.start),
                "end": int(seg.end),
            }
            
            # æŒ‰æ ‡ç‚¹åˆ‡åˆ†
            fine_subs = _split_segments_by_punctuation([seg_dict])
            
            for sub_idx, sub_seg in enumerate(fine_subs):
                sub_start = sub_seg.get("start", seg.start)
                sub_end = sub_seg.get("end", seg.end)
                sub_text = sub_seg.get("text", "").strip()
                sub_duration = sub_end - sub_start
                
                if sub_duration <= 0 or not sub_text:
                    continue
                
                subtitle_timeline_start = timeline_position + (sub_start - int(seg.start))
                
                subtitle_clip = {
                    "id": str(uuid4()),
                    "track_id": subtitle_track_id,
                    "clip_type": "subtitle",
                    "parent_clip_id": video_clip_id,  # å…³è”è§†é¢‘ clip
                    "start_time": subtitle_timeline_start,
                    "end_time": subtitle_timeline_start + sub_duration,
                    "content_text": sub_text,
                    "text_style": {
                        "fontSize": 15,
                        "fontColor": "#FFFFFF",
                        "backgroundColor": "transparent",
                        "alignment": "center",
                        "maxWidth": "85%",  # å­—å¹•æœ€å¤§å®½åº¦ 85% ç”»å¸ƒå®½åº¦
                    },
                    "transform": {
                        "x": 0,
                        "y": 150,
                        "scale": 1,
                    },
                    "metadata": {
                        "segment_id": seg.id,
                        "order_index": seg_idx * 100 + sub_idx,
                    },
                    "created_at": now,
                    "updated_at": now
                }
                subtitle_clips.append(subtitle_clip)
        
        timeline_position += clip_duration
    
    logger.info(f"AI Create ç»Ÿè®¡: è¯­éŸ³ç‰‡æ®µ {speech_count}, æ¢æ°”ä¿ç•™ {breath_count}")
    
    # â˜…â˜…â˜… éªŒè¯ï¼šç¡®ä¿æ‰€æœ‰ clip éƒ½æœ‰å¿…éœ€çš„å­—æ®µ â˜…â˜…â˜…
    required_fields = ["id", "track_id", "clip_type", "start_time", "end_time"]
    for clip in video_clips + subtitle_clips:
        for field in required_fields:
            if clip.get(field) is None:
                logger.error(f"âŒ AI Create clip {clip.get('id', 'unknown')[:8]} ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
                raise ValueError(f"Clip ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
    
    # æ‰¹é‡æ’å…¥
    if video_clips:
        supabase.table("clips").insert(video_clips).execute()
        logger.info(f"\nğŸ¬ [AI Create] åˆ›å»º {len(video_clips)} ä¸ªè§†é¢‘ Clip:")
        for i, clip in enumerate(video_clips[:10]):  # æœ€å¤šæ‰“å°å‰ 10 ä¸ª
            transform_info = ""
            if clip.get("transform"):
                t = clip["transform"]
                if isinstance(t, dict) and t.get("scaleX") is not None:
                    transform_info = f", transform.scaleX={t.get('scaleX', 1):.2f}"
            logger.info(f"   [{i}] id={clip['id'][:8]}, start={clip['start_time']}, end={clip['end_time']}, source={clip.get('source_start')}-{clip.get('source_end')}{transform_info}")
        if len(video_clips) > 10:
            logger.info(f"   ... è¿˜æœ‰ {len(video_clips) - 10} ä¸ª clips")
    
    if subtitle_clips:
        supabase.table("clips").insert(subtitle_clips).execute()
        logger.info(f"\nğŸ“ [AI Create] åˆ›å»º {len(subtitle_clips)} ä¸ªå­—å¹• Clip:")
        for i, clip in enumerate(subtitle_clips[:10]):  # æœ€å¤šæ‰“å°å‰ 10 ä¸ª
            text = clip.get('content_text', '')[:20] + '...' if len(clip.get('content_text', '')) > 20 else clip.get('content_text', '')
            logger.info(f"   [{i}] id={clip['id'][:8]}, parent={clip.get('parent_clip_id', '')[:8] if clip.get('parent_clip_id') else 'N/A'}, start={clip['start_time']}, text='{text}'")
        if len(subtitle_clips) > 10:
            logger.info(f"   ... è¿˜æœ‰ {len(subtitle_clips) - 10} ä¸ªå­—å¹•")
    
    return video_clips + subtitle_clips


# ============================================
# åŸºäºå­—å¹• Clips é‡æ–°åˆ†æ (Phase 1: å­—å¹•çº§æƒ…ç»ªåˆ†æ)
# ============================================

# å¸¸é‡
SUBTITLE_TIME_TOLERANCE_MS = 100  # å­—å¹•æ—¶é—´åŒ¹é…å®¹å·®ï¼ˆæ¯«ç§’ï¼‰


class ReanalyzeFromClipsRequest(BaseModel):
    """åŸºäºå­—å¹• clips é‡æ–°è¿è¡Œ AI åˆ†æ"""
    project_id: str
    video_clip_id: Optional[str] = None  # å¯é€‰ï¼šæŒ‡å®šè§†é¢‘ clipï¼Œä¸æŒ‡å®šåˆ™åˆ†æé¡¹ç›®æ‰€æœ‰å­—å¹•
    enable_llm: bool = True


class ReanalyzeAllSubtitlesRequest(BaseModel):
    """é‡æ–°åˆ†æé¡¹ç›®æ‰€æœ‰å­—å¹•çš„æƒ…ç»ª"""
    project_id: str
    enable_llm: bool = True


async def _get_video_clip(video_clip_id: str) -> dict:
    """è·å–è§†é¢‘ clip ä¿¡æ¯"""
    result = supabase.table("clips").select("*").eq("id", video_clip_id).single().execute()
    if not result.data:
        raise HTTPException(status_code=404, detail="è§†é¢‘ clip ä¸å­˜åœ¨")
    return result.data


async def _find_subtitle_clips(video_clip: dict, video_clip_id: str) -> List[dict]:
    """æŸ¥æ‰¾è§†é¢‘æ—¶é—´èŒƒå›´å†…çš„å­—å¹• clips"""
    video_start = video_clip.get("start_time", 0)
    video_end = video_clip.get("end_time", 0)
    
    # å…ˆæŒ‰æ—¶é—´èŒƒå›´æŸ¥æ‰¾
    result = supabase.table("clips").select("*").eq(
        "clip_type", "subtitle"
    ).gte("start_time", video_start - SUBTITLE_TIME_TOLERANCE_MS
    ).lte("end_time", video_end + SUBTITLE_TIME_TOLERANCE_MS
    ).order("start_time").execute()
    
    subtitle_clips = result.data or []
    
    # å¤‡é€‰ï¼šç”¨ parent_clip_id æŸ¥æ‰¾
    if not subtitle_clips:
        result = supabase.table("clips").select("*").eq(
            "parent_clip_id", video_clip_id
        ).eq("clip_type", "subtitle").order("start_time").execute()
        subtitle_clips = result.data or []
    
    return subtitle_clips


def _convert_to_segments(subtitle_clips: List[dict]) -> List[dict]:
    """å°†å­—å¹• clips è½¬æ¢ä¸ºåˆ†æç”¨çš„ segments æ ¼å¼"""
    segments = []
    for clip in subtitle_clips:
        text = clip.get("content_text", "").strip()
        if not text:
            continue
        segments.append({
            "id": clip["id"],
            "start": clip.get("start_time", 0),
            "end": clip.get("end_time", 0),
            "text": text,
            "clip_id": clip["id"],
        })
    return segments


def _create_keyframes_from_segments(
    smart_segments: List,
    video_clip_id: str,
    video_start: int,
    video_duration: int,
) -> List[dict]:
    """
    æ ¹æ®åˆ†æç»“æœåˆ›å»ºå…³é”®å¸§ï¼ˆä½¿ç”¨å½’ä¸€åŒ– offset 0-1ï¼‰
    
    æ­¤å‡½æ•°ç°åœ¨ä½¿ç”¨ TransformParams.get_keyframes_for_db() æ–¹æ³•ï¼Œ
    è¿™æ˜¯ç”Ÿæˆå…³é”®å¸§çš„æ ‡å‡†æ–¹å¼ï¼ŒåŒ…å«å®Œæ•´çš„é€»è¾‘ï¼š
    - STATIC ç­–ç•¥ï¼šä¸ç”Ÿæˆå…³é”®å¸§
    - INSTANT ç­–ç•¥ï¼šåªæœ‰åœ¨æœ‰å®é™…å˜æ¢æ—¶æ‰ç”Ÿæˆé¦–å°¾å¸§ï¼ˆç›¸åŒå€¼ï¼‰
    - KEYFRAME ç­–ç•¥ï¼šåªæœ‰åœ¨æœ‰å®é™…åŠ¨ç”»æ—¶æ‰ç”Ÿæˆé¦–å°¾å¸§ï¼ˆä¸åŒå€¼ï¼‰
    
    Args:
        smart_segments: SmartSegment åˆ—è¡¨ï¼ˆå¿…é¡»åŒ…å« transform_params å­—æ®µï¼‰
        video_clip_id: è§†é¢‘ clip ID
        video_start: è§†é¢‘èµ·å§‹æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
        video_duration: è§†é¢‘æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰
    
    Returns:
        å…³é”®å¸§è®°å½•åˆ—è¡¨
    """
    all_keyframes = []
    segments_with_keyframes = 0
    segments_skipped = 0
    
    for seg in smart_segments:
        # ä¼˜å…ˆä½¿ç”¨ transform_paramsï¼ˆTransformParams å¯¹è±¡ï¼‰
        params = getattr(seg, 'transform_params', None)
        
        if params is None:
            # å‘åå…¼å®¹ï¼šå¦‚æœæ²¡æœ‰ transform_paramsï¼Œå°è¯•ä» transform dict é‡å»º
            transform = getattr(seg, 'transform', None) or {}
            strategy = transform.get('_strategy', 'static')
            
            if 'static' in strategy or 'no_change' in strategy:
                segments_skipped += 1
                continue
            
            # æ— æ³•é‡å»º TransformParamsï¼Œè·³è¿‡
            logger.warning(f"[Keyframes] segment {seg.id[:8]} æ²¡æœ‰ transform_paramsï¼Œè·³è¿‡")
            segments_skipped += 1
            continue
        
        # ä½¿ç”¨ TransformParams.get_keyframes_for_db() ç”Ÿæˆå…³é”®å¸§
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬éœ€è¦å¤„ç† segment ç›¸å¯¹äºæ•´ä¸ªè§†é¢‘çš„æ—¶é—´åç§»
        segment_duration = seg.end - seg.start

        strategy_label = params.strategy.value if hasattr(params.strategy, "value") else str(params.strategy)
        logger.info(
            f"[Keyframes] segment {seg.id[:8]} range={seg.start}-{seg.end}ms "
            f"duration={segment_duration:.0f}ms strategy={strategy_label} "
            f"start_scale={params.start_scale:.3f} end_scale={params.end_scale:.3f} "
            f"pos=({params.position_x:.3f},{params.position_y:.3f}) rot={params.rotation:.3f} "
            f"rule={params.rule_applied}"
        )
        
        # ç”Ÿæˆæ­¤ segment çš„å…³é”®å¸§
        segment_keyframes = params.get_keyframes_for_db(
            clip_id=video_clip_id,
            duration_ms=segment_duration
        )
        
        if not segment_keyframes:
            segments_skipped += 1
            logger.debug(f"[Keyframes] è·³è¿‡ segment {seg.id[:8]}: TransformParams è¿”å›ç©ºå…³é”®å¸§")
            continue
        
        # è°ƒæ•´å…³é”®å¸§çš„ offset ä»¥åæ˜  segment åœ¨è§†é¢‘ä¸­çš„ä½ç½®
        seg_start_in_clip = max(0, seg.start - video_start)
        seg_end_in_clip = min(video_duration, seg.end - video_start)
        
        if seg_end_in_clip <= seg_start_in_clip:
            segments_skipped += 1
            continue
        
        # è®¡ç®— segment åœ¨æ•´ä¸ªè§†é¢‘ä¸­çš„ç›¸å¯¹ä½ç½®
        clip_start_offset = seg_start_in_clip / video_duration if video_duration > 0 else 0
        clip_end_offset = seg_end_in_clip / video_duration if video_duration > 0 else 1
        segment_span = clip_end_offset - clip_start_offset
        
        # è°ƒæ•´æ¯ä¸ªå…³é”®å¸§çš„ offset
        for kf in segment_keyframes:
            # å°† segment å†…çš„ offset (0-1) æ˜ å°„åˆ°è§†é¢‘ clip çš„ offset
            original_offset = kf['offset']
            kf['offset'] = clip_start_offset + original_offset * segment_span
        
        all_keyframes.extend(segment_keyframes)
        segments_with_keyframes += 1
        
        logger.info(
            f"[Keyframes] segment {seg.id[:8]}: "
            f"åˆ›å»º {len(segment_keyframes)} ä¸ªå…³é”®å¸§, "
            f"offset {clip_start_offset:.2f}-{clip_end_offset:.2f}"
        )
    
    logger.info(
        f"[Keyframes] æ€»è®¡: {segments_with_keyframes} ä¸ª segment ç”Ÿæˆå…³é”®å¸§, "
        f"{segments_skipped} ä¸ªè·³è¿‡, å…± {len(all_keyframes)} ä¸ªå…³é”®å¸§"
    )
    
    return all_keyframes


def _collect_statistics(smart_segments: List) -> Tuple[Dict[str, int], Dict[str, int], Dict[str, int]]:
    """æ”¶é›†åˆ†æç»Ÿè®¡ä¿¡æ¯
    
    Returns:
        Tuple of (emotion_distribution, importance_distribution, transform_distribution)
    """
    emotion_dist = {}
    importance_dist = {}
    transform_dist = {}
    
    for seg in smart_segments:
        emotion_dist[seg.emotion] = emotion_dist.get(seg.emotion, 0) + 1
        importance_dist[seg.importance] = importance_dist.get(seg.importance, 0) + 1
        transform_dist[seg.transform_type] = transform_dist.get(seg.transform_type, 0) + 1
    
    return emotion_dist, importance_dist, transform_dist


async def _get_project_subtitle_clips(project_id: str) -> List[dict]:
    """è·å–é¡¹ç›®æ‰€æœ‰å­—å¹• clips"""
    # å…ˆè·å–é¡¹ç›®çš„æ‰€æœ‰è½¨é“
    tracks_result = supabase.table("tracks").select("id").eq("project_id", project_id).execute()
    if not tracks_result.data:
        return []
    
    track_ids = [t["id"] for t in tracks_result.data]
    
    # è·å–è¿™äº›è½¨é“ä¸Šçš„æ‰€æœ‰å­—å¹• clips
    result = supabase.table("clips").select("*").eq(
        "clip_type", "subtitle"
    ).in_("track_id", track_ids).order("start_time").execute()
    
    return result.data or []


def _update_subtitle_clips_metadata(smart_segments: List, subtitle_clips: List[dict]) -> int:
    """å°†æƒ…ç»ªåˆ†æç»“æœæ›´æ–°åˆ°å­—å¹• clips çš„ metadata ä¸­
    
    ä¼˜åŒ–ï¼šä½¿ç”¨æ‰¹é‡æ›´æ–°å‡å°‘æ•°æ®åº“è¯·æ±‚æ¬¡æ•°
    
    Returns:
        æ›´æ–°çš„å­—å¹•æ•°é‡
    """
    now = datetime.utcnow().isoformat()
    
    # åˆ›å»º segment id -> analysis result çš„æ˜ å°„
    analysis_map = {}
    for seg in smart_segments:
        analysis_map[seg.id] = {
            "emotion": seg.emotion.value if hasattr(seg.emotion, 'value') else str(seg.emotion),
            "importance": seg.importance.value if hasattr(seg.importance, 'value') else str(seg.importance),
            "keywords": seg.keywords if hasattr(seg, 'keywords') else [],
            "transform_type": seg.transform_type if hasattr(seg, 'transform_type') else "static",
            "scale_start": seg.scale_start if hasattr(seg, 'scale_start') else None,
            "scale_end": seg.scale_end if hasattr(seg, 'scale_end') else None,
            "analyzed_at": now,
        }
    
    # æ”¶é›†éœ€è¦æ›´æ–°çš„ clips å’Œå¯¹åº”çš„ metadata
    updates_by_metadata = {}  # metadata JSON string -> list of clip_ids
    
    failed_updates = []  # æ”¶é›†å¤±è´¥çš„æ›´æ–°
    for clip in subtitle_clips:
        clip_id = clip["id"]
        if clip_id not in analysis_map:
            continue
        
        # åˆå¹¶ç°æœ‰ metadata å’Œæ–°çš„åˆ†æç»“æœ
        existing_metadata = clip.get("metadata") or {}
        new_metadata = {
            **existing_metadata,
            "ai_analysis": analysis_map[clip_id],
        }
        
        # ç”±äºæ¯ä¸ª clip çš„ metadata å¯èƒ½ä¸åŒï¼Œéœ€è¦å•ç‹¬æ›´æ–°
        # ä½†å¯ä»¥ä½¿ç”¨ upsert æˆ–äº‹åŠ¡æ¥ä¼˜åŒ–
        try:
            supabase.table("clips").update({
                "metadata": new_metadata,
                "updated_at": now,
            }).eq("id", clip_id).execute()
        except Exception as e:
            failed_updates.append((clip_id, str(e)))
    
    # å¦‚æœæœ‰å¤±è´¥çš„æ›´æ–°ï¼ŒæŠ›å‡ºé”™è¯¯
    if failed_updates:
        error_msg = f"æ›´æ–°å­—å¹• metadata å¤±è´¥: {len(failed_updates)} ä¸ªå¤±è´¥"
        for clip_id, err in failed_updates[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
            error_msg += f"\n  - {clip_id[:8]}: {err}"
        raise RuntimeError(error_msg)
    
    return len([c for c in subtitle_clips if c["id"] in analysis_map])


@router.post("/reanalyze-from-clips")
async def reanalyze_from_clips(request: ReanalyzeFromClipsRequest):
    """
    åŸºäºå­—å¹•ç‰‡æ®µé‡æ–°è¿è¡Œ AI æƒ…ç»ªåˆ†æ (Phase 1: å­—å¹•çº§æƒ…ç»ªåˆ†æ)
    
    æµç¨‹ï¼š
    1. è·å–å­—å¹• clipsï¼ˆæŒ‡å®šè§†é¢‘ clip èŒƒå›´å†…çš„ï¼Œæˆ–é¡¹ç›®å…¨éƒ¨ï¼‰
    2. å¯¹æ¯ä¸ªå­—å¹•ç‹¬ç«‹è¿è¡Œ LLM æƒ…ç»ªåˆ†æ
    3. å°†åˆ†æç»“æœå­˜åˆ°å­—å¹• clip çš„ metadata.ai_analysis ä¸­
    4. ç”Ÿæˆè¿é•œå†³ç­–
    5. åˆ›å»ºå…³é”®å¸§ï¼ˆå¦‚æœæŒ‡å®šäº†è§†é¢‘ clipï¼‰
    
    æ–°å¢åŠŸèƒ½ï¼š
    - ä¸æŒ‡å®š video_clip_id æ—¶ï¼Œåˆ†æé¡¹ç›®æ‰€æœ‰å­—å¹•
    - æƒ…ç»ªåˆ†æç»“æœæŒä¹…åŒ–åˆ°å­—å¹• clip çš„ metadata ä¸­
    """
    try:
        from ..services.ai_video_creator import ai_video_creator, SmartSegment
        
        video_clip_id = request.video_clip_id
        video_clip = None
        video_start = 0
        video_duration = 0
        
        # 1. è·å–å­—å¹• clips
        if video_clip_id:
            # æŒ‡å®šè§†é¢‘ clipï¼šè·å–å…¶æ—¶é—´èŒƒå›´å†…çš„å­—å¹•
            logger.info(f"Reanalyze: åˆ†æè§†é¢‘ Clip èŒƒå›´å†…çš„å­—å¹• - project={request.project_id}, clip={video_clip_id}")
            video_clip = await _get_video_clip(video_clip_id)
            video_start = video_clip.get("start_time", 0)
            video_end = video_clip.get("end_time", 0)
            video_duration = video_end - video_start
            subtitle_clips = await _find_subtitle_clips(video_clip, video_clip_id)
        else:
            # æœªæŒ‡å®šï¼šè·å–é¡¹ç›®æ‰€æœ‰å­—å¹•
            logger.info(f"Reanalyze: åˆ†æé¡¹ç›®æ‰€æœ‰å­—å¹• - project={request.project_id}")
            subtitle_clips = await _get_project_subtitle_clips(request.project_id)
        
        if not subtitle_clips:
            raise HTTPException(status_code=400, detail="æ²¡æœ‰æ‰¾åˆ°å­—å¹•ç‰‡æ®µ")
        
        logger.info(f"Reanalyze: æ‰¾åˆ° {len(subtitle_clips)} ä¸ªå­—å¹•ç‰‡æ®µ")
        
        # 2. è½¬æ¢ä¸ºåˆ†ææ ¼å¼
        segments = _convert_to_segments(subtitle_clips)
        if not segments:
            raise HTTPException(status_code=400, detail="æ²¡æœ‰æœ‰æ•ˆçš„å­—å¹•æ–‡æœ¬")
        
        # 3. åˆ›å»º SmartSegment
        smart_segments = [
            SmartSegment(id=seg["id"], start=seg["start"], end=seg["end"], text=seg["text"])
            for seg in segments
        ]
        for seg, orig in zip(smart_segments, segments):
            seg.metadata = {"clip_id": orig["clip_id"]}
        
        # 4. LLM æƒ…ç»ªåˆ†æï¼ˆå­—å¹•çº§ï¼‰
        if request.enable_llm and smart_segments:
            logger.info(f"Reanalyze: å¯¹ {len(smart_segments)} ä¸ªå­—å¹•è¿è¡Œ LLM æƒ…ç»ªåˆ†æ")
            smart_segments = await ai_video_creator._step3_llm_analysis(smart_segments)
        
        # 5. ç”Ÿæˆè¿é•œå†³ç­–
        logger.debug("Reanalyze: ç”Ÿæˆè¿é•œå†³ç­–")
        smart_segments = ai_video_creator._step4_generate_transform(smart_segments)
        
        # 6. ã€æ–°å¢ã€‘å°†åˆ†æç»“æœæ›´æ–°åˆ°å­—å¹• clips çš„ metadata
        updated_count = _update_subtitle_clips_metadata(smart_segments, subtitle_clips)
        logger.info(f"Reanalyze: æ›´æ–° {updated_count} ä¸ªå­—å¹•çš„ metadata")
        
        # 7. å¦‚æœæŒ‡å®šäº†è§†é¢‘ clipï¼Œåˆ›å»ºå…³é”®å¸§
        keyframes = []
        if video_clip_id and video_clip:
            supabase.table("keyframes").delete().eq("clip_id", video_clip_id).execute()
            keyframes = _create_keyframes_from_segments(
                smart_segments, video_clip_id, video_start, video_duration
            )
            if keyframes:
                supabase.table("keyframes").insert(keyframes).execute()
                logger.info(f"Reanalyze: åˆ›å»º {len(keyframes)} ä¸ªå…³é”®å¸§")
        
        # 8. æ”¶é›†ç»Ÿè®¡
        emotion_dist, importance_dist, transform_dist = _collect_statistics(smart_segments)
        logger.info(f"Reanalyze å®Œæˆ: å­—å¹•={len(smart_segments)}, æƒ…ç»ª={emotion_dist}")
        
        return {
            "success": True,
            "video_clip_id": video_clip_id,
            "subtitles_analyzed": len(smart_segments),
            "subtitles_updated": updated_count,
            "keyframes_created": len(keyframes),
            "emotion_distribution": emotion_dist,
            "importance_distribution": importance_dist,
            "transform_distribution": transform_dist,
            "details": [
                {
                    "subtitle_id": seg.id,
                    "text": seg.text[:50] + "..." if len(seg.text) > 50 else seg.text,
                    "emotion": seg.emotion.value if hasattr(seg.emotion, 'value') else str(seg.emotion),
                    "importance": seg.importance.value if hasattr(seg.importance, 'value') else str(seg.importance),
                    "transform": seg.transform_type if hasattr(seg, 'transform_type') else "static",
                    "scale": f"{seg.scale_start:.2f}â†’{seg.scale_end:.2f}" if hasattr(seg, 'scale_start') and seg.scale_start else "static",
                }
                for seg in smart_segments
            ]
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.exception(f"Reanalyze å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# Phase 2: æ™ºèƒ½åˆ‡ç‰‡å†³ç­–å¼•æ“
# ============================================

class SmartSliceRequest(BaseModel):
    """æ™ºèƒ½åˆ‡ç‰‡è¯·æ±‚"""
    project_id: str
    enable_llm: bool = True  # æ˜¯å¦å…ˆè¿è¡Œæƒ…ç»ªåˆ†æ


# åˆ‡ç‰‡å†³ç­–è§„åˆ™
SLICE_RULES = {
    # å¿…é¡»ç‹¬ç«‹æˆç‰‡çš„æƒ…ç»ªç»„åˆ
    "must_isolate": [
        ("excited", "high"),    # æ¿€åŠ¨ + é«˜é‡è¦æ€§ â†’ ç‹¬ç«‹
        ("excited", "medium"),  # æ¿€åŠ¨ + ä¸­é‡è¦æ€§ â†’ ç‹¬ç«‹
        ("serious", "high"),    # ä¸¥è‚ƒ + é«˜é‡è¦æ€§ â†’ ç‹¬ç«‹
    ],
    # å¯ä»¥åˆå¹¶çš„æƒ…ç»ªç»„åˆ
    "can_merge": [
        ("neutral", "low"),     # å¹³æ·¡ + ä½é‡è¦æ€§ â†’ å¯åˆå¹¶
        ("neutral", "medium"),  # å¹³æ·¡ + ä¸­é‡è¦æ€§ â†’ å¯åˆå¹¶
        ("happy", "low"),       # å¼€å¿ƒ + ä½é‡è¦æ€§ â†’ å¯åˆå¹¶
    ],
    # æœ€å¤§åˆå¹¶æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰
    "max_merge_duration": 5000,
    # æœ€å°ç‹¬ç«‹ç‰‡æ®µæ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰
    "min_isolated_duration": 500,
}


def _should_isolate(emotion: str, importance: str) -> bool:
    """åˆ¤æ–­æ˜¯å¦åº”è¯¥ç‹¬ç«‹æˆç‰‡"""
    return (emotion, importance) in SLICE_RULES["must_isolate"]


def _can_merge(emotion: str, importance: str) -> bool:
    """åˆ¤æ–­æ˜¯å¦å¯ä»¥åˆå¹¶"""
    return (emotion, importance) in SLICE_RULES["can_merge"]


def _decide_video_slices(subtitle_clips: List[dict]) -> List[dict]:
    """
    æ™ºèƒ½åˆ‡ç‰‡å†³ç­–ï¼šæ ¹æ®å­—å¹•æƒ…ç»ªåˆ†æç»“æœå†³å®šè§†é¢‘ç‰‡æ®µåˆ’åˆ†
    
    è§„åˆ™ï¼š
    1. excited + high/medium â†’ å¿…é¡»ç‹¬ç«‹æˆç‰‡
    2. neutral + low â†’ å¯ä»¥å’Œç›¸é‚»çš„åˆå¹¶
    3. å…¶ä»–æƒ…å†µ â†’ é»˜è®¤ç‹¬ç«‹
    
    Returns:
        List of video slice definitions:
        [
            {
                "slice_id": "slice_1",
                "subtitle_ids": ["sub_1", "sub_2"],  # åŒ…å«çš„å­—å¹• ID
                "start_time": 0,
                "end_time": 3000,
                "reason": "merged:neutral+low",  # åˆ‡ç‰‡åŸå› 
                "emotions": ["neutral", "neutral"],
                "transform_hint": "static",  # å»ºè®®çš„è¿é•œæ•ˆæœ
            }
        ]
    """
    if not subtitle_clips:
        return []
    
    slices = []
    current_slice = None
    
    for clip in subtitle_clips:
        ai_analysis = (clip.get("metadata") or {}).get("ai_analysis", {})
        emotion = ai_analysis.get("emotion", "neutral")
        importance = ai_analysis.get("importance", "medium")
        transform_type = ai_analysis.get("transform_type", "static")
        
        clip_info = {
            "id": clip["id"],
            "text": clip.get("content_text", ""),
            "start": clip.get("start_time", 0),
            "end": clip.get("end_time", 0),
            "emotion": emotion,
            "importance": importance,
            "transform": transform_type,
        }
        
        # å†³ç­–ï¼šæ˜¯å¦ç‹¬ç«‹æˆç‰‡
        if _should_isolate(emotion, importance):
            # å…ˆç»“æŸå½“å‰åˆå¹¶ä¸­çš„ slice
            if current_slice:
                slices.append(current_slice)
                current_slice = None
            
            # åˆ›å»ºç‹¬ç«‹ slice
            slices.append({
                "slice_id": f"slice_{len(slices) + 1}",
                "subtitle_ids": [clip_info["id"]],
                "start_time": clip_info["start"],
                "end_time": clip_info["end"],
                "reason": f"isolated:{emotion}+{importance}",
                "emotions": [emotion],
                "transform_hint": transform_type,
                "is_highlight": True,  # æ ‡è®°ä¸ºé«˜å…‰ç‰‡æ®µ
            })
        
        elif _can_merge(emotion, importance):
            # å¯ä»¥åˆå¹¶
            if current_slice:
                # æ£€æŸ¥åˆå¹¶åæ˜¯å¦è¶…è¿‡æœ€å¤§æ—¶é•¿
                merged_duration = clip_info["end"] - current_slice["start_time"]
                if merged_duration <= SLICE_RULES["max_merge_duration"]:
                    # åˆå¹¶åˆ°å½“å‰ slice
                    current_slice["subtitle_ids"].append(clip_info["id"])
                    current_slice["end_time"] = clip_info["end"]
                    current_slice["emotions"].append(emotion)
                else:
                    # è¶…æ—¶é•¿ï¼Œç»“æŸå½“å‰ sliceï¼Œå¼€å§‹æ–°çš„
                    slices.append(current_slice)
                    current_slice = {
                        "slice_id": f"slice_{len(slices) + 1}",
                        "subtitle_ids": [clip_info["id"]],
                        "start_time": clip_info["start"],
                        "end_time": clip_info["end"],
                        "reason": f"merged:{emotion}+{importance}",
                        "emotions": [emotion],
                        "transform_hint": "static",
                        "is_highlight": False,
                    }
            else:
                # å¼€å§‹æ–°çš„åˆå¹¶ slice
                current_slice = {
                    "slice_id": f"slice_{len(slices) + 1}",
                    "subtitle_ids": [clip_info["id"]],
                    "start_time": clip_info["start"],
                    "end_time": clip_info["end"],
                    "reason": f"merged:{emotion}+{importance}",
                    "emotions": [emotion],
                    "transform_hint": "static",
                    "is_highlight": False,
                }
        
        else:
            # é»˜è®¤ï¼šç‹¬ç«‹æˆç‰‡
            if current_slice:
                slices.append(current_slice)
                current_slice = None
            
            slices.append({
                "slice_id": f"slice_{len(slices) + 1}",
                "subtitle_ids": [clip_info["id"]],
                "start_time": clip_info["start"],
                "end_time": clip_info["end"],
                "reason": f"default:{emotion}+{importance}",
                "emotions": [emotion],
                "transform_hint": transform_type,
                "is_highlight": importance == "high",
            })
    
    # åˆ«å¿˜äº†æœ€åä¸€ä¸ª slice
    if current_slice:
        slices.append(current_slice)
    
    return slices


@router.post("/smart-slice")
async def smart_slice(request: SmartSliceRequest):
    """
    æ™ºèƒ½åˆ‡ç‰‡å†³ç­– API (Phase 2)
    
    æ ¹æ®å­—å¹•çš„æƒ…ç»ªåˆ†æç»“æœï¼Œæ™ºèƒ½å†³å®šè§†é¢‘ç‰‡æ®µçš„åˆ’åˆ†ï¼š
    - excited + high â†’ "ä½†æ˜¯ï¼" è¿™æ ·çš„ç‰‡æ®µç‹¬ç«‹æˆç‰‡ï¼Œå±•ç¤ºæ”¾å¤§æ•ˆæœ
    - neutral + low â†’ å¹³æ·¡ç‰‡æ®µå¯ä»¥åˆå¹¶ï¼Œå‡å°‘ç¢ç‰‡åŒ–
    
    æµç¨‹ï¼š
    1. è·å–é¡¹ç›®æ‰€æœ‰å­—å¹•ï¼ˆå¸¦ ai_analysis metadataï¼‰
    2. å¦‚æœæ²¡æœ‰åˆ†æç»“æœï¼Œå…ˆè¿è¡Œæƒ…ç»ªåˆ†æ
    3. åº”ç”¨åˆ‡ç‰‡å†³ç­–è§„åˆ™
    4. è¿”å›å»ºè®®çš„è§†é¢‘ç‰‡æ®µåˆ’åˆ†
    
    æ³¨æ„ï¼šæ­¤ API ä»…è¿”å›åˆ‡ç‰‡å»ºè®®ï¼Œä¸å®é™…ä¿®æ”¹æ•°æ®åº“
    """
    try:
        from ..services.ai_video_creator import ai_video_creator, SmartSegment
        
        logger.info(f"SmartSlice: æ™ºèƒ½åˆ‡ç‰‡å†³ç­– - project={request.project_id}")
        
        # 1. è·å–é¡¹ç›®æ‰€æœ‰å­—å¹•
        subtitle_clips = await _get_project_subtitle_clips(request.project_id)
        if not subtitle_clips:
            raise HTTPException(status_code=400, detail="æ²¡æœ‰æ‰¾åˆ°å­—å¹•ç‰‡æ®µ")
        
        logger.info(f"SmartSlice: æ‰¾åˆ° {len(subtitle_clips)} ä¸ªå­—å¹•")
        
        # 2. æ£€æŸ¥æ˜¯å¦å·²æœ‰æƒ…ç»ªåˆ†æç»“æœ
        analyzed_count = sum(
            1 for c in subtitle_clips 
            if (c.get("metadata") or {}).get("ai_analysis")
        )
        
        # å¦‚æœå¤§éƒ¨åˆ†å­—å¹•æ²¡æœ‰åˆ†æç»“æœï¼Œå…ˆè¿è¡Œåˆ†æ
        if analyzed_count < len(subtitle_clips) * 0.5 and request.enable_llm:
            logger.info(f"SmartSlice: {analyzed_count}/{len(subtitle_clips)} å·²åˆ†æï¼Œå…ˆè¿è¡Œæƒ…ç»ªåˆ†æ")
            
            # å¤ç”¨ reanalyze é€»è¾‘
            segments = _convert_to_segments(subtitle_clips)
            smart_segments = [
                SmartSegment(id=seg["id"], start=seg["start"], end=seg["end"], text=seg["text"])
                for seg in segments
            ]
            
            smart_segments = await ai_video_creator._step3_llm_analysis(smart_segments)
            smart_segments = ai_video_creator._step4_generate_transform(smart_segments)
            
            _update_subtitle_clips_metadata(smart_segments, subtitle_clips)
            
            # é‡æ–°è·å–æ›´æ–°åçš„å­—å¹•
            subtitle_clips = await _get_project_subtitle_clips(request.project_id)
        
        # 3. åº”ç”¨åˆ‡ç‰‡å†³ç­–è§„åˆ™
        slices = _decide_video_slices(subtitle_clips)
        
        # 4. ç»Ÿè®¡
        isolated_count = sum(1 for s in slices if "isolated" in s.get("reason", ""))
        merged_count = sum(1 for s in slices if "merged" in s.get("reason", ""))
        highlight_count = sum(1 for s in slices if s.get("is_highlight"))
        
        logger.info(f"SmartSlice å®Œæˆ: æ€»ç‰‡æ®µ={len(slices)}, ç‹¬ç«‹={isolated_count}, åˆå¹¶={merged_count}, é«˜å…‰={highlight_count}")
        
        return {
            "success": True,
            "project_id": request.project_id,
            "total_subtitles": len(subtitle_clips),
            "total_slices": len(slices),
            "statistics": {
                "isolated_slices": isolated_count,
                "merged_slices": merged_count,
                "highlight_slices": highlight_count,
            },
            "slices": slices,
            "rules_applied": SLICE_RULES,
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.exception(f"SmartSlice å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/apply-smart-slice")
async def apply_smart_slice(request: SmartSliceRequest):
    """
    åº”ç”¨æ™ºèƒ½åˆ‡ç‰‡ï¼šæ ¹æ®å†³ç­–ç»“æœé‡æ–°ç”Ÿæˆè§†é¢‘ç‰‡æ®µ
    
    æµç¨‹ï¼š
    1. è¿è¡Œ smart-slice è·å–åˆ‡ç‰‡å†³ç­–
    2. åˆ é™¤ç°æœ‰è§†é¢‘ clips
    3. æ ¹æ®åˆ‡ç‰‡å†³ç­–åˆ›å»ºæ–°çš„è§†é¢‘ clips
    4. ä¸ºæ¯ä¸ªè§†é¢‘ clip åˆ›å»ºå¯¹åº”çš„å…³é”®å¸§
    
    âš ï¸ æ­¤ API ä¼šä¿®æ”¹æ•°æ®åº“ï¼Œè¯·è°¨æ…ä½¿ç”¨
    """
    try:
        logger.info(f"ApplySmartSlice: åº”ç”¨æ™ºèƒ½åˆ‡ç‰‡ - project={request.project_id}")
        
        # 1. è·å–åˆ‡ç‰‡å†³ç­–
        slice_result = await smart_slice(request)
        slices = slice_result.get("slices", [])
        
        if not slices:
            raise HTTPException(status_code=400, detail="æ²¡æœ‰ç”Ÿæˆåˆ‡ç‰‡å†³ç­–")
        
        # 2. è·å–é¡¹ç›®çš„è§†é¢‘è½¨é“
        tracks_result = supabase.table("tracks").select("*").eq(
            "project_id", request.project_id
        ).execute()
        
        video_track = None
        for track in (tracks_result.data or []):
            # æ‰¾åˆ°åŒ…å«è§†é¢‘ clip çš„è½¨é“
            clips_check = supabase.table("clips").select("id").eq(
                "track_id", track["id"]
            ).eq("clip_type", "video").limit(1).execute()
            if clips_check.data:
                video_track = track
                break
        
        if not video_track:
            raise HTTPException(status_code=400, detail="æ²¡æœ‰æ‰¾åˆ°è§†é¢‘è½¨é“")
        
        video_track_id = video_track["id"]
        
        # 3. è·å–åŸå§‹è§†é¢‘ asset ä¿¡æ¯ï¼ˆç”¨äº source_start/source_endï¼‰
        old_clips = supabase.table("clips").select("*").eq(
            "track_id", video_track_id
        ).eq("clip_type", "video").order("start_time").execute()
        
        # è·å–ç¬¬ä¸€ä¸ª clip çš„ asset_id ä½œä¸ºå‚è€ƒ
        asset_id = None
        if old_clips.data:
            asset_id = old_clips.data[0].get("asset_id")
        
        # 4. åˆ é™¤æ—§çš„è§†é¢‘ clips å’Œå…³é”®å¸§ï¼ˆä¼˜åŒ–ï¼šæ‰¹é‡åˆ é™¤ï¼‰
        old_clip_ids = [c["id"] for c in (old_clips.data or [])]
        if old_clip_ids:
            supabase.table("keyframes").delete().in_("clip_id", old_clip_ids).execute()
            supabase.table("clips").delete().in_("id", old_clip_ids).execute()
            logger.info(f"ApplySmartSlice: åˆ é™¤ {len(old_clip_ids)} ä¸ªæ—§è§†é¢‘ clips")
        
        # 5. åˆ›å»ºæ–°çš„è§†é¢‘ clips
        now = datetime.utcnow().isoformat()
        new_clips = []
        all_keyframes = []
        
        for idx, slice_info in enumerate(slices):
            clip_id = str(uuid4())
            start_time = slice_info["start_time"]
            end_time = slice_info["end_time"]
            duration = end_time - start_time
            
            # ç¡®å®šè¿é•œæ•ˆæœ
            is_highlight = slice_info.get("is_highlight", False)
            transform_hint = slice_info.get("transform_hint", "static")
            
            # åˆ›å»ºè§†é¢‘ clip
            new_clip = {
                "id": clip_id,
                "track_id": video_track_id,
                "asset_id": asset_id,
                "clip_type": "video",
                "name": f"ç‰‡æ®µ {idx + 1}" + (" â­" if is_highlight else ""),
                "start_time": start_time,
                "end_time": end_time,
                "source_start": start_time,  # å‡è®¾æºæ—¶é—´ = æ—¶é—´çº¿æ—¶é—´
                "source_end": end_time,
                "volume": 1.0,
                "is_muted": False,
                "speed": 1.0,
                "metadata": {
                    "smart_slice": {
                        "reason": slice_info.get("reason"),
                        "emotions": slice_info.get("emotions"),
                        "subtitle_ids": slice_info.get("subtitle_ids"),
                        "is_highlight": is_highlight,
                    }
                },
                "created_at": now,
                "updated_at": now,
            }
            new_clips.append(new_clip)
            
            # 6. ä¸ºé«˜å…‰ç‰‡æ®µåˆ›å»ºå…³é”®å¸§
            if is_highlight and transform_hint != "static":
                # åˆ›å»º zoom in å…³é”®å¸§ï¼ˆä½¿ç”¨å½’ä¸€åŒ– offset 0-1ï¼‰
                scale_start = 1.0
                scale_end = 1.25 if "excited" in str(slice_info.get("emotions", [])) else 1.15
                
                for prop in ["scaleX", "scaleY"]:
                    # å¼€å§‹å…³é”®å¸§ (offset = 0)
                    all_keyframes.append({
                        "id": str(uuid4()),
                        "clip_id": clip_id,
                        "property": prop,
                        "offset": 0.0,  # å½’ä¸€åŒ– offset (0-1)
                        "value": scale_start,
                        "easing": "easeInOut",
                        "created_at": now,
                        "updated_at": now,
                    })
                    # ç»“æŸå…³é”®å¸§ (offset = 1)
                    all_keyframes.append({
                        "id": str(uuid4()),
                        "clip_id": clip_id,
                        "property": prop,
                        "offset": 1.0,  # å½’ä¸€åŒ– offset (0-1)
                        "value": scale_end,
                        "easing": "easeInOut",
                        "created_at": now,
                        "updated_at": now,
                    })
        
        # â˜…â˜…â˜… éªŒè¯ï¼šç¡®ä¿æ‰€æœ‰ clip éƒ½æœ‰å¿…éœ€çš„å­—æ®µ â˜…â˜…â˜…
        required_fields = ["id", "track_id", "clip_type", "start_time", "end_time"]
        for clip in new_clips:
            for field in required_fields:
                if clip.get(field) is None:
                    logger.error(f"âŒ ApplySmartSlice clip {clip.get('id', 'unknown')[:8]} ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
                    raise ValueError(f"Clip ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
        
        # 7. æ‰¹é‡æ’å…¥
        if new_clips:
            supabase.table("clips").insert(new_clips).execute()
            logger.info(f"ApplySmartSlice: åˆ›å»º {len(new_clips)} ä¸ªæ–°è§†é¢‘ clips")
        
        if all_keyframes:
            supabase.table("keyframes").insert(all_keyframes).execute()
            logger.info(f"ApplySmartSlice: åˆ›å»º {len(all_keyframes)} ä¸ªå…³é”®å¸§")
        
        return {
            "success": True,
            "project_id": request.project_id,
            "clips_created": len(new_clips),
            "keyframes_created": len(all_keyframes),
            "slices": slices,
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.exception(f"ApplySmartSlice å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# æ™ºèƒ½ä¸€é”®æˆç‰‡ V2 API
# ============================================

class ContentAnalysisRequest(BaseModel):
    """æ™ºèƒ½å†…å®¹åˆ†æè¯·æ±‚"""
    project_id: str
    script: Optional[str] = None  # ç”¨æˆ·è„šæœ¬ï¼ˆå¯é€‰ï¼‰
    transcript_id: Optional[str] = None  # ASR ç»“æœ IDï¼ˆå¦‚æœå·²æœ‰ï¼‰
    options: Optional[Dict[str, Any]] = None  # åˆ†æé€‰é¡¹


class ContentAnalysisResponse(BaseModel):
    """æ™ºèƒ½å†…å®¹åˆ†æå“åº”"""
    analysis_id: str
    status: str
    message: str


class SegmentSelection(BaseModel):
    """ç‰‡æ®µé€‰æ‹©"""
    segment_id: str
    action: str  # 'keep' | 'delete'
    selected_from_group: Optional[str] = None


class SelectionConfirmRequest(BaseModel):
    """ç¡®è®¤é€‰æ‹©è¯·æ±‚"""
    analysis_id: str
    selections: List[SegmentSelection]
    apply_zoom_recommendations: bool = True


@router.post("/v2/analyze-content", response_model=ContentAnalysisResponse)
async def analyze_content_v2(
    request: ContentAnalysisRequest,
    background_tasks: BackgroundTasks
):
    """
    æ™ºèƒ½ä¸€é”®æˆç‰‡ V2 - å†…å®¹åˆ†æ
    
    æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
    1. æœ‰è„šæœ¬æ¨¡å¼ï¼šå¯¹æ¯”è„šæœ¬å’Œ ASR ç»“æœ
    2. æ— è„šæœ¬æ¨¡å¼ï¼šæ™ºèƒ½è¯†åˆ«åºŸè¯å’Œæœ‰æ•ˆå†…å®¹
    
    å¼‚æ­¥æ‰§è¡Œï¼Œè¿”å› analysis_id ç”¨äºè½®è¯¢è¿›åº¦
    """
    from ..services.smart_analyzer import (
        create_content_analysis,
        ProcessingStage
    )
    
    try:
        # è·å–é¡¹ç›®ä¿¡æ¯
        project_result = supabase.table("projects").select("*").eq("id", request.project_id).single().execute()
        if not project_result.data:
            raise HTTPException(status_code=404, detail="é¡¹ç›®ä¸å­˜åœ¨")
        
        project = project_result.data
        user_id = project.get("user_id", "unknown")
        
        # åˆ›å»ºåˆ†æè®°å½•
        analysis_id = await create_content_analysis(
            project_id=request.project_id,
            user_id=user_id,
            script=request.script
        )
        
        # å¼‚æ­¥æ‰§è¡Œåˆ†æ
        background_tasks.add_task(
            execute_smart_analysis,
            analysis_id,
            request.project_id,
            request.script,
            request.options or {}
        )
        
        return ContentAnalysisResponse(
            analysis_id=analysis_id,
            status="pending",
            message="åˆ†æä»»åŠ¡å·²åˆ›å»ºï¼Œè¯·è½®è¯¢ /v2/analysis/{id}/progress è·å–è¿›åº¦"
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.exception(f"åˆ›å»ºåˆ†æä»»åŠ¡å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/v2/analysis/{analysis_id}/progress")
async def get_analysis_progress_v2(analysis_id: str):
    """
    è·å–åˆ†æè¿›åº¦
    
    è¿”å›å½“å‰å¤„ç†é˜¶æ®µå’Œè¿›åº¦ç™¾åˆ†æ¯”
    """
    from ..services.smart_analyzer import get_analysis_progress
    
    progress = await get_analysis_progress(analysis_id)
    if not progress:
        raise HTTPException(status_code=404, detail="åˆ†æä»»åŠ¡ä¸å­˜åœ¨")
    
    return progress


@router.get("/v2/analysis/{analysis_id}/result")
async def get_analysis_result_v2(analysis_id: str):
    """
    è·å–åˆ†æç»“æœ
    
    åˆ†æå®Œæˆåè°ƒç”¨ï¼Œè¿”å›å®Œæ•´çš„åˆ†æç»“æœ
    """
    try:
        result = supabase.table("content_analyses").select("*").eq("id", analysis_id).single().execute()
        
        if not result.data:
            raise HTTPException(status_code=404, detail="åˆ†æä»»åŠ¡ä¸å­˜åœ¨")
        
        data = result.data
        
        if data["status"] not in ["completed", "confirmed"]:
            raise HTTPException(
                status_code=400, 
                detail=f"åˆ†æå°šæœªå®Œæˆï¼Œå½“å‰çŠ¶æ€: {data['status']}"
            )
        
        # â˜… æ ‡å‡†åŒ– segments ä¸­çš„ classificationï¼ˆä¸­æ–‡ -> è‹±æ–‡ï¼‰
        segments = data.get("segments") or []
        for seg in segments:
            if isinstance(seg, dict) and "classification" in seg:
                seg["classification"] = normalize_classification(seg["classification"])
        
        return {
            "id": data["id"],
            "project_id": data["project_id"],
            "mode": data["mode"],
            "segments": segments,
            "repeat_groups": data["repeat_groups"],
            "style_analysis": data["style_analysis"],
            "summary": data["summary"],
            "status": data["status"]
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.exception(f"è·å–åˆ†æç»“æœå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/v2/project/{project_id}/latest-analysis")
async def get_latest_analysis_by_project(project_id: str):
    """
    æ ¹æ®é¡¹ç›® ID è·å–æœ€æ–°çš„åˆ†æç»“æœ
    
    ç”¨äºå¼¹çª—æ‰“å¼€æ—¶æ²¡æœ‰ analysis_id çš„åœºæ™¯
    """
    try:
        # æŸ¥è¯¢è¯¥é¡¹ç›®æœ€æ–°çš„å·²å®Œæˆåˆ†æ
        result = supabase.table("content_analyses") \
            .select("*") \
            .eq("project_id", project_id) \
            .in_("status", ["completed", "confirmed"]) \
            .order("created_at", desc=True) \
            .limit(1) \
            .execute()
        
        if not result.data or len(result.data) == 0:
            # è¿”å›ç©ºç»“æœè€Œä¸æ˜¯404ï¼Œè¡¨ç¤ºé¡¹ç›®æ²¡æœ‰åˆ†æè®°å½•
            return {
                "has_analysis": False,
                "analysis": None
            }
        
        data = result.data[0]
        
        # â˜… æ ‡å‡†åŒ– segments ä¸­çš„ classificationï¼ˆä¸­æ–‡ -> è‹±æ–‡ï¼‰
        segments = data.get("segments") or []
        for seg in segments:
            if isinstance(seg, dict) and "classification" in seg:
                seg["classification"] = normalize_classification(seg["classification"])
        
        return {
            "has_analysis": True,
            "analysis": {
                "id": data["id"],
                "project_id": data["project_id"],
                "mode": data["mode"],
                "segments": segments,
                "repeat_groups": data["repeat_groups"],
                "style_analysis": data["style_analysis"],
                "summary": data["summary"],
                "status": data["status"]
            }
        }
        
    except Exception as e:
        logger.exception(f"è·å–é¡¹ç›®æœ€æ–°åˆ†æç»“æœå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/v2/confirm-selection")
async def confirm_selection_v2(request: SelectionConfirmRequest):
    """
    ç¡®è®¤ç”¨æˆ·çš„é€‰æ‹©ï¼Œç”Ÿæˆæœ€ç»ˆçš„ clips
    
    ç”¨æˆ·åœ¨å®¡æ ¸ç•Œé¢å®Œæˆé€‰æ‹©åè°ƒç”¨
    """
    try:
        logger.info(f"ğŸ¬ [confirm-selection] å¼€å§‹å¤„ç†ç¡®è®¤è¯·æ±‚")
        logger.info(f"   analysis_id: {request.analysis_id}")
        logger.info(f"   selections æ•°é‡: {len(request.selections)}")
        logger.info(f"   apply_zoom: {request.apply_zoom_recommendations}")
        
        # è¯¦ç»†è®°å½•æ¯ä¸ª selection
        for i, sel in enumerate(request.selections):
            logger.debug(f"   selection[{i}]: segment_id={sel.segment_id[:8] if sel.segment_id else 'N/A'}, action={sel.action}")
        
        # è·å–åˆ†æç»“æœ
        analysis_result = supabase.table("content_analyses").select("*").eq("id", request.analysis_id).single().execute()
        
        if not analysis_result.data:
            logger.error(f"   âŒ åˆ†æä»»åŠ¡ä¸å­˜åœ¨: {request.analysis_id}")
            raise HTTPException(status_code=404, detail="åˆ†æä»»åŠ¡ä¸å­˜åœ¨")
        
        analysis = analysis_result.data
        logger.info(f"   åˆ†æä»»åŠ¡çŠ¶æ€: {analysis['status']}")
        logger.info(f"   project_id: {analysis.get('project_id')}")
        logger.info(f"   segments æ•°é‡: {len(analysis.get('segments', []))}")
        
        # â˜…â˜…â˜… ä¿®å¤ï¼šå…è®¸ completed å’Œ confirmed çŠ¶æ€éƒ½èƒ½ç¡®è®¤é€‰æ‹© â˜…â˜…â˜…
        # confirmed çŠ¶æ€è¯´æ˜ç”¨æˆ·ä¹‹å‰ç¡®è®¤è¿‡ï¼Œç°åœ¨é‡æ–°ç¡®è®¤ï¼ˆå¹‚ç­‰æ“ä½œï¼‰
        if analysis["status"] not in ["completed", "confirmed"]:
            logger.error(f"   âŒ åˆ†æçŠ¶æ€ä¸æ­£ç¡®: {analysis['status']}")
            raise HTTPException(
                status_code=400,
                detail=f"åˆ†æçŠ¶æ€ä¸æ­£ç¡®: {analysis['status']}ï¼Œéœ€è¦ completed æˆ– confirmed"
            )
        
        # ä¿å­˜ç”¨æˆ·é€‰æ‹©
        selection_id = str(uuid4())
        selection_data = {
            "id": selection_id,
            "analysis_id": request.analysis_id,
            "user_id": analysis["user_id"],
            "selections": [s.model_dump() for s in request.selections],
            "apply_zoom_recommendations": request.apply_zoom_recommendations,
            "created_at": datetime.utcnow().isoformat()
        }
        
        supabase.table("content_selections").insert(selection_data).execute()
        logger.info(f"   âœ“ ç”¨æˆ·é€‰æ‹©å·²ä¿å­˜: selection_id={selection_id}")
        
        # æ›´æ–°åˆ†æçŠ¶æ€ä¸ºå·²ç¡®è®¤
        supabase.table("content_analyses").update({
            "status": "confirmed",
            "updated_at": datetime.utcnow().isoformat()
        }).eq("id", request.analysis_id).execute()
        logger.info(f"   âœ“ åˆ†æçŠ¶æ€å·²æ›´æ–°ä¸º confirmed")
        
        # ç”Ÿæˆ clipsï¼ˆåŸºäºé€‰æ‹©ç»“æœï¼‰
        logger.info(f"   â³ å¼€å§‹ç”Ÿæˆ clips...")
        clips_count = await generate_clips_from_selection(
            analysis=analysis,
            selections=request.selections,
            apply_zoom=request.apply_zoom_recommendations
        )
        logger.info(f"   âœ“ clips ç”Ÿæˆå®Œæˆ: {clips_count} ä¸ª")
        
        # æ›´æ–°ç”Ÿæˆçš„ clips æ•°é‡
        supabase.table("content_selections").update({
            "generated_clips_count": clips_count
        }).eq("id", selection_id).execute()
        
        # â˜…â˜…â˜… æ·»åŠ è¯¦ç»†æ—¥å¿—ï¼šæŸ¥è¯¢æœ€ç»ˆä¿ç•™çš„ clips å’Œ keyframes â˜…â˜…â˜…
        project_id = analysis.get('project_id')
        if project_id:
            # è·å–è§†é¢‘è½¨é“
            track_result = supabase.table("tracks").select("id").eq(
                "project_id", project_id
            ).order("order_index").limit(1).execute()
            
            if track_result.data:
                track_id = track_result.data[0]["id"]
                
                # è·å–ä¿ç•™çš„è§†é¢‘ clips
                final_clips = supabase.table("clips").select(
                    "id, start_time, end_time, source_start, source_end, asset_id"
                ).eq("track_id", track_id).eq("clip_type", "video").order("start_time").execute()
                
                clips_data = final_clips.data or []
                logger.info(f"\nğŸ¬ [confirm-selection] æœ€ç»ˆä¿ç•™çš„è§†é¢‘ clips: {len(clips_data)} ä¸ª")
                for i, c in enumerate(clips_data[:10]):
                    logger.info(f"   [{i}] id={c['id'][:8]}, timeline={c['start_time']}-{c['end_time']}, source={c['source_start']}-{c['source_end']}")
                if len(clips_data) > 10:
                    logger.info(f"   ... è¿˜æœ‰ {len(clips_data) - 10} ä¸ª clips")
                
                # è·å–ä¿ç•™çš„å­—å¹•
                clip_ids = [c['id'] for c in clips_data]
                if clip_ids:
                    subtitles = supabase.table("clips").select(
                        "id, parent_clip_id, start_time, content_text"
                    ).in_("parent_clip_id", clip_ids).order("start_time").execute()
                    
                    sub_data = subtitles.data or []
                    logger.info(f"\nğŸ“ [confirm-selection] ä¿ç•™çš„å­—å¹•: {len(sub_data)} æ¡")
                
                # è·å–ä¿ç•™çš„å…³é”®å¸§
                if clip_ids:
                    keyframes = supabase.table("keyframes").select(
                        "id, clip_id, property, offset, value"
                    ).in_("clip_id", clip_ids).order("clip_id, offset").execute()
                    
                    kf_data = keyframes.data or []
                    logger.info(f"\nğŸ¯ [confirm-selection] ä¿ç•™çš„å…³é”®å¸§: {len(kf_data)} ä¸ª")
                    for i, kf in enumerate(kf_data[:20]):
                        logger.info(f"   [{i}] clip={kf['clip_id'][:8]}, prop={kf['property']}, offset={kf['offset']:.2f}, value={kf['value']}")
                    if len(kf_data) > 20:
                        logger.info(f"   ... è¿˜æœ‰ {len(kf_data) - 20} ä¸ªå…³é”®å¸§")
        
        logger.info(f"\nğŸ¬ [confirm-selection] å®Œæˆ! clips_created={clips_count}")
        
        return {
            "success": True,
            "selection_id": selection_id,
            "clips_created": clips_count,
            "message": "é€‰æ‹©å·²ç¡®è®¤ï¼Œclips å·²ç”Ÿæˆ"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.exception(f"âŒ [confirm-selection] ç¡®è®¤é€‰æ‹©å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# è„šæœ¬ç®¡ç† API
# ============================================

class ScriptUploadRequest(BaseModel):
    """è„šæœ¬ä¸Šä¼ è¯·æ±‚"""
    project_id: str
    content: str
    title: Optional[str] = None


@router.post("/v2/scripts")
async def upload_script(request: ScriptUploadRequest):
    """ä¸Šä¼ é¡¹ç›®è„šæœ¬"""
    try:
        # è·å–é¡¹ç›®
        project_result = supabase.table("projects").select("user_id").eq("id", request.project_id).single().execute()
        if not project_result.data:
            raise HTTPException(status_code=404, detail="é¡¹ç›®ä¸å­˜åœ¨")
        
        user_id = project_result.data["user_id"]
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰è„šæœ¬
        existing = supabase.table("project_scripts").select("id").eq("project_id", request.project_id).execute()
        
        script_id = str(uuid4())
        now = datetime.utcnow().isoformat()
        word_count = len(request.content)
        
        if existing.data:
            # æ›´æ–°å·²æœ‰è„šæœ¬
            script_id = existing.data[0]["id"]
            supabase.table("project_scripts").update({
                "content": request.content,
                "title": request.title,
                "word_count": word_count,
                "updated_at": now
            }).eq("id", script_id).execute()
        else:
            # åˆ›å»ºæ–°è„šæœ¬
            supabase.table("project_scripts").insert({
                "id": script_id,
                "project_id": request.project_id,
                "user_id": user_id,
                "content": request.content,
                "title": request.title,
                "word_count": word_count,
                "created_at": now,
                "updated_at": now
            }).execute()
        
        return {
            "id": script_id,
            "project_id": request.project_id,
            "word_count": word_count,
            "message": "è„šæœ¬ä¸Šä¼ æˆåŠŸ"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.exception(f"ä¸Šä¼ è„šæœ¬å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/v2/scripts/{project_id}")
async def get_script(project_id: str):
    """è·å–é¡¹ç›®è„šæœ¬"""
    try:
        result = supabase.table("project_scripts").select("*").eq("project_id", project_id).single().execute()
        
        if not result.data:
            raise HTTPException(status_code=404, detail="è„šæœ¬ä¸å­˜åœ¨")
        
        return result.data
        
    except HTTPException:
        raise
    except Exception as e:
        if "No rows" in str(e):
            raise HTTPException(status_code=404, detail="è„šæœ¬ä¸å­˜åœ¨")
        logger.exception(f"è·å–è„šæœ¬å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# åå°æ‰§è¡Œå‡½æ•°
# ============================================

async def _get_transcription_results(
    project_id: str,
    max_wait_time: int = 60
) -> Tuple[List[Dict], float]:
    """
    è·å–é¡¹ç›®æ‰€æœ‰è§†é¢‘ç´ æçš„å·²æœ‰è½¬å†™ç»“æœ
    
    â˜…â˜…â˜… åªè¯»å–ï¼Œä¸è§¦å‘ï¼ASR å·²åœ¨ workspace æµç¨‹ä¸­å®Œæˆ â˜…â˜…â˜…
    
    Args:
        project_id: é¡¹ç›® ID
        max_wait_time: æœ€å¤§ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰- ç­‰å¾… workspace æµç¨‹å®Œæˆ ASR
    
    Returns:
        (merged_segments, total_duration): åˆå¹¶åçš„è½¬å†™ç‰‡æ®µå’Œæ€»æ—¶é•¿
    """
    import asyncio
    
    poll_interval = 3  # ç§’
    waited_time = 0
    
    # 1. è·å–é¡¹ç›®ä¸­æ‰€æœ‰è§†é¢‘ç´ æï¼ˆæŒ‰åˆ›å»ºæ—¶é—´æ’åºï¼‰
    assets_result = supabase.table("assets").select(
        "id, status, storage_path, duration, created_at"
    ).eq("project_id", project_id).eq("file_type", "video").order(
        "created_at"
    ).execute()
    
    if not assets_result.data:
        logger.warning(f"âš ï¸ é¡¹ç›® {project_id} æ²¡æœ‰è§†é¢‘ç´ æ")
        return [], 0
    
    asset_ids = [a["id"] for a in assets_result.data]
    logger.info(f"ğŸ“‹ é¡¹ç›®æœ‰ {len(asset_ids)} ä¸ªè§†é¢‘ç´ æï¼Œç­‰å¾…è½¬å†™ç»“æœ...")
    
    # 2. ç­‰å¾…æ‰€æœ‰ç´ æçš„è½¬å†™å®Œæˆï¼ˆworkspace æµç¨‹å·²è§¦å‘ï¼‰
    while waited_time < max_wait_time:
        # æŸ¥è¯¢æ‰€æœ‰ç´ æçš„è½¬å†™ä»»åŠ¡
        tasks_result = supabase.table("tasks").select(
            "id, asset_id, status, result"
        ).in_("asset_id", asset_ids).eq("task_type", "transcribe").execute()
        
        # æ„å»º asset_id -> task æ˜ å°„ï¼ˆä¼˜å…ˆä½¿ç”¨å·²å®Œæˆçš„ï¼‰
        task_map = {}
        for task in (tasks_result.data or []):
            asset_id = task.get("asset_id")
            if asset_id not in task_map or task.get("status") == "completed":
                task_map[asset_id] = task
        
        # æ£€æŸ¥æ‰€æœ‰ç´ ææ˜¯å¦éƒ½æœ‰å·²å®Œæˆçš„è½¬å†™
        completed_results = {}
        pending_count = 0
        
        for asset_id in asset_ids:
            task = task_map.get(asset_id)
            if task and task.get("status") == "completed" and task.get("result"):
                result = task["result"]
                segments = result.get("segments", []) if isinstance(result, dict) else result
                completed_results[asset_id] = segments
            elif task and task.get("status") in ("pending", "running"):
                pending_count += 1
            # å¦‚æœæ²¡æœ‰ä»»åŠ¡ï¼Œè¯´æ˜ workspace æµç¨‹è¿˜æ²¡åˆ° ASR æ­¥éª¤
            elif not task:
                pending_count += 1
        
        # æ‰€æœ‰ç´ æéƒ½æœ‰è½¬å†™ç»“æœ
        if len(completed_results) == len(asset_ids):
            logger.info(f"âœ… æ‰€æœ‰ {len(asset_ids)} ä¸ªç´ æçš„è½¬å†™ç»“æœå·²å°±ç»ª")
            break
        
        # è¿˜æœ‰æœªå®Œæˆçš„
        if waited_time < max_wait_time:
            logger.info(f"â³ ç­‰å¾…è½¬å†™å®Œæˆ... ({len(completed_results)}/{len(asset_ids)} å·²å®Œæˆ, {pending_count} è¿›è¡Œä¸­, å·²ç­‰å¾… {waited_time}s)")
            await asyncio.sleep(poll_interval)
            waited_time += poll_interval
    
    if waited_time >= max_wait_time and len(completed_results) < len(asset_ids):
        logger.warning(f"âš ï¸ ç­‰å¾…è½¬å†™ç»“æœè¶…æ—¶ï¼Œåªè·å–åˆ° {len(completed_results)}/{len(asset_ids)} ä¸ª")
    
    # 3. åˆå¹¶æ‰€æœ‰ç´ æçš„è½¬å†™ç»“æœï¼ˆæŒ‰ç´ æåˆ›å»ºæ—¶é—´é¡ºåºï¼‰
    merged_segments = []
    total_duration = 0
    time_offset_ms = 0  # æ—¶é—´åç§»é‡ï¼ˆæ¯«ç§’ï¼‰
    
    for asset in assets_result.data:
        asset_id = asset["id"]
        asset_duration = asset.get("duration") or 0  # ç§’
        asset_duration_ms = int(asset_duration * 1000)  # è½¬æ¯«ç§’
        
        segments = completed_results.get(asset_id, [])
        if segments:
            # ä¸ºæ¯ä¸ªç‰‡æ®µæ·»åŠ æ—¶é—´åç§»å’Œç´ ææ ‡è¯†
            for seg in segments:
                adjusted_seg = seg.copy()
                adjusted_seg["start"] = seg.get("start", 0) + time_offset_ms
                adjusted_seg["end"] = seg.get("end", 0) + time_offset_ms
                adjusted_seg["_asset_id"] = asset_id
                merged_segments.append(adjusted_seg)
            logger.info(f"   âœ“ ç´ æ {asset_id[:8]}: {len(segments)} ä¸ªç‰‡æ®µ")
        else:
            logger.warning(f"   âœ— ç´ æ {asset_id[:8]}: æ— è½¬å†™ç»“æœ")
        
        time_offset_ms += asset_duration_ms
        total_duration += asset_duration
    
    logger.info(f"ğŸ“Š åˆå¹¶ç»“æœ: {len(merged_segments)} ä¸ªç‰‡æ®µï¼Œæ€»æ—¶é•¿ {total_duration:.1f}s")
    return merged_segments, total_duration


async def execute_smart_analysis(
    analysis_id: str,
    project_id: str,
    script: Optional[str],
    options: Dict[str, Any]
):
    """åå°æ‰§è¡Œæ™ºèƒ½åˆ†æï¼ˆæ”¯æŒå¤šç´ æï¼‰"""
    from ..services.smart_analyzer import (
        smart_analyzer,
        ProcessingStage,
        update_analysis_progress,
        save_analysis_result,
        AnalysisResult,
        AnalysisSummary
    )
    import asyncio
    
    try:
        logger.info(f"ğŸš€ å¼€å§‹æ™ºèƒ½åˆ†æ: analysis_id={analysis_id}, project_id={project_id}")
        
        # é˜¶æ®µ1: è·å–è½¬å†™ç»“æœï¼ˆASR å·²åœ¨ workspace æµç¨‹ä¸­å®Œæˆï¼‰
        await update_analysis_progress(analysis_id, ProcessingStage.TRANSCRIBING)
        
        # â˜…â˜…â˜… åªè¯»å–å·²æœ‰çš„è½¬å†™ç»“æœï¼Œä¸è§¦å‘æ–°çš„ ASR â˜…â˜…â˜…
        transcript_segments, video_duration = await _get_transcription_results(
            project_id=project_id,
            max_wait_time=60  # æœ€å¤šç­‰å¾… 60 ç§’ï¼ˆworkspace åº”è¯¥å·²å®Œæˆï¼‰
        )
        
        # å¦‚æœæ²¡æœ‰è½¬å†™ç»“æœ
        if not transcript_segments:
            logger.warning(f"âš ï¸ é¡¹ç›® {project_id} æ— è½¬å†™ç»“æœï¼Œè¿”å›ç©ºåˆ†æç»“æœ")
            
            empty_result = AnalysisResult(
                segments=[],
                repeat_groups=[],
                style_analysis=None,
                summary=AnalysisSummary(
                    total_segments=0,
                    keep_count=0,
                    delete_count=0,
                    choose_count=0,
                    repeat_groups_count=0,
                    estimated_duration_after=0.0,
                    reduction_percent=0.0,
                    script_coverage=None
                )
            )
            await save_analysis_result(analysis_id, empty_result)
            await update_analysis_progress(analysis_id, ProcessingStage.COMPLETED)
            logger.info(f"âœ… æ™ºèƒ½åˆ†æå®Œæˆï¼ˆæ— è½¬å†™å†…å®¹ï¼‰: {analysis_id}")
            return
        
        logger.info(f"âœ… è·å–åˆ° {len(transcript_segments)} ä¸ªè½¬å†™ç‰‡æ®µï¼Œç»§ç»­åˆ†æ...")
        logger.info(f"ğŸ“‹ è§†é¢‘æ€»æ—¶é•¿: {video_duration:.1f}s")
        
        # é˜¶æ®µ2: LLM æ™ºèƒ½åˆ†æ
        await update_analysis_progress(analysis_id, ProcessingStage.ANALYZING)
        
        result = await smart_analyzer.analyze(
            transcript_segments=transcript_segments,
            script=script,
            audio_features=None,  # TODO: æå–éŸ³é¢‘ç‰¹å¾
            video_duration=video_duration
        )
        
        # é˜¶æ®µ3: ç”Ÿæˆæ¨è
        await update_analysis_progress(analysis_id, ProcessingStage.GENERATING)
        
        # ä¿å­˜ç»“æœ
        await save_analysis_result(analysis_id, result)
        
        # å®Œæˆ
        await update_analysis_progress(analysis_id, ProcessingStage.COMPLETED)
        
        logger.info(f"âœ… æ™ºèƒ½åˆ†æå®Œæˆ: {analysis_id}")
        
    except Exception as e:
        logger.exception(f"âŒ æ™ºèƒ½åˆ†æå¤±è´¥: {e}")
        
        # æ›´æ–°å¤±è´¥çŠ¶æ€
        supabase.table("content_analyses").update({
            "status": "failed",
            "processing_stage": "failed",
            "error_message": str(e),
            "updated_at": datetime.utcnow().isoformat()
        }).eq("id", analysis_id).execute()


async def generate_clips_from_selection(
    analysis: Dict,
    selections: List[SegmentSelection],
    apply_zoom: bool
) -> int:
    """æ ¹æ®ç”¨æˆ·é€‰æ‹©ç­›é€‰ clips
    
    â˜…â˜…â˜… é‡æ„ï¼šä¸å†é‡å»º clipsï¼Œè€Œæ˜¯å¤ç”¨ä¸€é”®æˆç‰‡å·²åˆ›å»ºçš„ clips â˜…â˜…â˜…
    
    é€»è¾‘ï¼š
    1. æ ¹æ® segment æ—¶é—´èŒƒå›´åŒ¹é…ç°æœ‰ clips
    2. åˆ é™¤ä¸ action=delete segments é‡å çš„ clipsï¼ˆåŠå…¶å…³è”çš„å­—å¹•å’Œå…³é”®å¸§ï¼‰
    3. ç´§å‡‘æ—¶é—´çº¿ - æ›´æ–°ä¿ç•™ clips çš„ start_time
    
    â˜… å…³é”®å¸§å·²åœ¨ä¸€é”®æˆç‰‡æ—¶åˆ›å»ºï¼Œè¿™é‡Œä¸éœ€è¦å†ç”Ÿæˆ
    """
    project_id = analysis["project_id"]
    segments = analysis.get("segments", [])
    
    logger.info(f"ğŸ“¦ generate_clips_from_selection (ç®€åŒ–ç‰ˆ): project_id={project_id}")
    logger.info(f"   segments æ•°é‡: {len(segments)}")
    logger.info(f"   selections æ•°é‡: {len(selections)}")
    
    # ç»Ÿè®¡é€‰æ‹©
    keep_count = sum(1 for s in selections if s.action == "keep")
    delete_count = sum(1 for s in selections if s.action == "delete")
    logger.info(f"   selections ç»Ÿè®¡: keep={keep_count}, delete={delete_count}")
    
    # æ„å»ºé€‰æ‹©æ˜ å°„ï¼šsegment_id -> action
    selection_map = {s.segment_id: s.action for s in selections}
    
    # â˜… æ”¶é›†è¦åˆ é™¤çš„æ—¶é—´èŒƒå›´ï¼ˆç§’ -> æ¯«ç§’ï¼‰
    delete_time_ranges = []  # [(start_ms, end_ms)]
    for seg in segments:
        seg_id = seg.get("id", "")
        action = selection_map.get(seg_id)
        
        # æ²¡æœ‰æ˜ç¡®é€‰æ‹©çš„ï¼ŒæŒ‰æ¨èæ¥
        if not action:
            should_delete = seg.get("action") == "delete" or not seg.get("is_recommended", True)
        else:
            should_delete = action == "delete"
        
        if should_delete:
            # LLM è¾“å‡ºçš„æ—¶é—´æ˜¯ç§’ï¼Œè½¬æ¢ä¸ºæ¯«ç§’
            start_ms = int(seg.get("start", 0) * 1000)
            end_ms = int(seg.get("end", 0) * 1000)
            delete_time_ranges.append((start_ms, end_ms))
            logger.info(f"   âŒ è¦åˆ é™¤: {seg_id} ({start_ms}-{end_ms}ms)")
    
    logger.info(f"ğŸ“‹ è¦åˆ é™¤çš„æ—¶é—´èŒƒå›´: {len(delete_time_ranges)} ä¸ª")
    
    # â˜… è·å–è§†é¢‘è½¨é“
    track_result = supabase.table("tracks").select("id").eq(
        "project_id", project_id
    ).order("order_index").limit(1).execute()
    
    if not track_result.data:
        logger.warning(f"é¡¹ç›® {project_id} æ²¡æœ‰è½¨é“")
        return 0
    
    track_id = track_result.data[0]["id"]
    logger.info(f"   è§†é¢‘è½¨é“: {track_id}")
    
    # â˜… è·å–ç°æœ‰è§†é¢‘ clips
    clips_result = supabase.table("clips").select(
        "id, start_time, end_time, source_start, source_end, asset_id"
    ).eq("track_id", track_id).eq("clip_type", "video").order("start_time").execute()
    
    existing_clips = clips_result.data or []
    logger.info(f"   ç°æœ‰è§†é¢‘ clips: {len(existing_clips)} ä¸ª")
    
    if not existing_clips:
        logger.warning(f"é¡¹ç›® {project_id} æ²¡æœ‰è§†é¢‘ clips")
        return 0
    
    # â˜… åˆ¤æ–­æ¯ä¸ª clip æ˜¯å¦ä¸åˆ é™¤èŒƒå›´é‡å 
    clips_to_delete = []
    clips_to_keep = []
    
    for clip in existing_clips:
        clip_start = clip["source_start"]  # ä½¿ç”¨ source æ—¶é—´åŒ¹é…ï¼ˆä¸åŸè§†é¢‘å¯¹åº”ï¼‰
        clip_end = clip["source_end"]
        
        # æ£€æŸ¥æ˜¯å¦ä¸ä»»ä½•åˆ é™¤èŒƒå›´é‡å 
        should_delete = False
        for del_start, del_end in delete_time_ranges:
            # é‡å æ¡ä»¶ï¼šä¸æ˜¯å®Œå…¨åˆ†ç¦»
            if not (clip_end <= del_start or clip_start >= del_end):
                should_delete = True
                logger.info(f"   clip {clip['id'][:8]} ({clip_start}-{clip_end}ms) ä¸åˆ é™¤èŒƒå›´ ({del_start}-{del_end}ms) é‡å ")
                break
        
        if should_delete:
            clips_to_delete.append(clip)
        else:
            clips_to_keep.append(clip)
    
    logger.info(f"ğŸ“Š ç­›é€‰ç»“æœ: ä¿ç•™ {len(clips_to_keep)} ä¸ª, åˆ é™¤ {len(clips_to_delete)} ä¸ª")
    
    # â˜…â˜…â˜… è¯¦ç»†æ—¥å¿—ï¼šåˆ—å‡ºä¿ç•™å’Œåˆ é™¤çš„ clips â˜…â˜…â˜…
    if clips_to_keep:
        logger.info(f"\nâœ… ä¿ç•™çš„ clips ({len(clips_to_keep)} ä¸ª):")
        for i, c in enumerate(clips_to_keep[:10]):
            logger.info(f"   [{i}] id={c['id'][:8]}, source={c['source_start']}-{c['source_end']}ms")
        if len(clips_to_keep) > 10:
            logger.info(f"   ... è¿˜æœ‰ {len(clips_to_keep) - 10} ä¸ª")
    
    if clips_to_delete:
        logger.info(f"\nâŒ è¦åˆ é™¤çš„ clips ({len(clips_to_delete)} ä¸ª):")
        for i, c in enumerate(clips_to_delete[:10]):
            logger.info(f"   [{i}] id={c['id'][:8]}, source={c['source_start']}-{c['source_end']}ms")
        if len(clips_to_delete) > 10:
            logger.info(f"   ... è¿˜æœ‰ {len(clips_to_delete) - 10} ä¸ª")
    
    # â˜…â˜…â˜… æ€§èƒ½ä¼˜åŒ–ï¼šå¦‚æœæ²¡æœ‰åˆ é™¤ä»»ä½• clipï¼Œç›´æ¥è¿”å› â˜…â˜…â˜…
    if not clips_to_delete:
        logger.info(f"âœ… æ— éœ€åˆ é™¤ä»»ä½• clipï¼Œä¿æŒåŸæ ·")
        return len(clips_to_keep)
    
    # â˜… åˆ é™¤ clips åŠå…¶å…³è”æ•°æ®ï¼ˆå…³é”®å¸§ã€å­—å¹•ï¼‰
    delete_ids = [c["id"] for c in clips_to_delete]
    
    # å…ˆæŸ¥è¯¢è¦åˆ é™¤çš„å…³é”®å¸§æ•°é‡
    kf_to_delete = supabase.table("keyframes").select("id, clip_id, property").in_("clip_id", delete_ids).execute()
    kf_count = len(kf_to_delete.data or [])
    logger.info(f"\nğŸ—‘ï¸ åˆ é™¤å…³è”æ•°æ®:")
    logger.info(f"   å…³é”®å¸§: {kf_count} ä¸ª")
    
    # æŸ¥è¯¢è¦åˆ é™¤çš„å­—å¹•æ•°é‡
    sub_to_delete = supabase.table("clips").select("id").in_("parent_clip_id", delete_ids).execute()
    sub_count = len(sub_to_delete.data or [])
    logger.info(f"   å­—å¹•: {sub_count} æ¡")
    
    # åˆ é™¤å…³è”çš„å…³é”®å¸§
    supabase.table("keyframes").delete().in_("clip_id", delete_ids).execute()
    
    # åˆ é™¤å…³è”çš„å­—å¹•ï¼ˆparent_clip_id æŒ‡å‘è¢«åˆ é™¤çš„ clipï¼‰
    supabase.table("clips").delete().in_("parent_clip_id", delete_ids).execute()
    
    # åˆ é™¤è§†é¢‘ clips
    supabase.table("clips").delete().in_("id", delete_ids).execute()
    logger.info(f"   è§†é¢‘ clips: {len(delete_ids)} ä¸ª")
    logger.info(f"   å·²åˆ é™¤ {len(delete_ids)} ä¸ªè§†é¢‘ clips")
    
    # â˜… ç´§å‡‘æ—¶é—´çº¿ - æŒ‰ start_time é¡ºåºé‡æ–°æ’åˆ—ï¼ˆæ‰¹é‡ä¼˜åŒ–ç‰ˆï¼‰
    now = datetime.utcnow().isoformat()
    timeline_position = 0
    
    # æŒ‰åŸå§‹ start_time æ’åºï¼ˆä¿æŒé¡ºåºï¼‰
    clips_to_keep.sort(key=lambda c: c["start_time"])
    
    # â˜…â˜…â˜… æ€§èƒ½ä¼˜åŒ–ï¼šå…ˆè®¡ç®—æ‰€æœ‰å˜æ›´ï¼Œæœ€åæ‰¹é‡æ‰§è¡Œ â˜…â˜…â˜…
    clip_updates = []  # [(clip_id, new_start, new_end, offset)]
    
    for clip in clips_to_keep:
        clip_duration = clip["end_time"] - clip["start_time"]
        new_start = timeline_position
        new_end = timeline_position + clip_duration
        
        # åªæœ‰ä½ç½®å˜åŒ–æ—¶æ‰è®°å½•
        if clip["start_time"] != new_start:
            offset = new_start - clip["start_time"]
            clip_updates.append((clip["id"], new_start, new_end, offset))
            logger.debug(f"   clip {clip['id'][:8]}: {clip['start_time']}->{new_start}ms")
        
        timeline_position = new_end
    
    logger.info(f"   éœ€è¦æ›´æ–°çš„ clips: {len(clip_updates)} ä¸ª")
    
    # â˜…â˜…â˜… æ‰¹é‡æ›´æ–° clipsï¼ˆä¸€æ¬¡æŸ¥è¯¢è·å–æ‰€æœ‰å­—å¹•ï¼Œé¿å… N+1 é—®é¢˜ï¼‰â˜…â˜…â˜…
    if clip_updates:
        clip_ids_to_update = [u[0] for u in clip_updates]
        
        # ä¸€æ¬¡æ€§è·å–æ‰€æœ‰éœ€è¦æ›´æ–°çš„ clips çš„å­—å¹•
        all_subtitles_result = supabase.table("clips").select(
            "id, parent_clip_id, start_time, end_time"
        ).in_("parent_clip_id", clip_ids_to_update).execute()
        
        # æ„å»º parent_clip_id -> subtitles æ˜ å°„
        subtitles_by_parent = {}
        for sub in (all_subtitles_result.data or []):
            parent_id = sub["parent_clip_id"]
            if parent_id not in subtitles_by_parent:
                subtitles_by_parent[parent_id] = []
            subtitles_by_parent[parent_id].append(sub)
        
        logger.info(f"   å…³è”å­—å¹•æ€»æ•°: {len(all_subtitles_result.data or [])} æ¡")
        
        # é€ä¸ªæ›´æ–° clipï¼ˆSupabase ä¸æ”¯æŒçœŸæ­£çš„æ‰¹é‡ upsert with different valuesï¼‰
        # ä½†è‡³å°‘é¿å…äº† N+1 æŸ¥è¯¢é—®é¢˜
        for clip_id, new_start, new_end, offset in clip_updates:
            supabase.table("clips").update({
                "start_time": new_start,
                "end_time": new_end,
                "updated_at": now
            }).eq("id", clip_id).execute()
            
            # æ›´æ–°è¯¥ clip çš„å­—å¹•
            for sub in subtitles_by_parent.get(clip_id, []):
                supabase.table("clips").update({
                    "start_time": sub["start_time"] + offset,
                    "end_time": sub["end_time"] + offset,
                    "updated_at": now
                }).eq("id", sub["id"]).execute()
    
    logger.info(f"âœ… æ—¶é—´çº¿ç´§å‡‘å®Œæˆï¼Œæ€»æ—¶é•¿: {timeline_position}ms")
