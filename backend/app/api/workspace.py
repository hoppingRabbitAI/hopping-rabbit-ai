"""
HoppingRabbit AI - å·¥ä½œå° API
å¤„ç†ä»ä¸Šä¼ åˆ°è¿›å…¥ç¼–è¾‘å™¨çš„å®Œæ•´æµç¨‹
é€‚é…æ–°è¡¨ç»“æ„ (2026-01-07)
"""
import os
import logging
from fastapi import APIRouter, HTTPException, BackgroundTasks, Depends
from pydantic import BaseModel
from typing import Optional, Literal, List, Dict, Any
from datetime import datetime
from uuid import uuid4
from enum import Enum

from ..services.supabase_client import supabase, get_file_url, create_signed_upload_url
from ..services.transform_rules import SegmentContext, transform_engine, sequence_processor, EmotionType, ImportanceLevel, TransformParams, ZoomStrategy
from .auth import get_current_user

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/workspace", tags=["Workspace"])


# ============================================
# æ•°æ®æ¨¡å‹
# ============================================

class TaskType(str, Enum):
    AI_CLIPS = "clips"      # AI æ™ºèƒ½åˆ‡ç‰‡
    SUMMARY = "summary"     # å†…å®¹æ€»ç»“
    AI_CREATE = "ai-create" # â˜… ä¸€é”®æˆç‰‡
    VOICE_EXTRACT = "voice-extract" # â˜… ä»…æå–å­—å¹•/éŸ³é¢‘


class SourceType(str, Enum):
    LOCAL = "local"         # æœ¬åœ°ä¸Šä¼ 
    YOUTUBE = "youtube"     # YouTube é“¾æ¥
    URL = "url"             # å…¶ä»– URL


# â˜… ProcessingStepsConfig å·²åˆ é™¤
# ä¸€é”®æˆç‰‡ç”± task_type == 'ai-create' å†³å®šï¼ŒASR é»˜è®¤å¼€å¯


class FileInfo(BaseModel):
    """å•ä¸ªæ–‡ä»¶ä¿¡æ¯ï¼ˆå¤šæ–‡ä»¶ä¸Šä¼ ï¼‰"""
    name: str
    size: int
    content_type: str
    duration: Optional[float] = None  # è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
    order_index: int = 0


class CreateSessionRequest(BaseModel):
    """åˆ›å»ºå¤„ç†ä¼šè¯è¯·æ±‚"""
    source_type: SourceType
    task_type: TaskType = TaskType.AI_CLIPS
    # â˜… å¼ºåˆ¶è§†é¢‘æ¯”ä¾‹ï¼šä»…å…è®¸ 9:16 æˆ– 16:9
    aspect_ratio: Optional[str] = None  # "9:16" æˆ– "16:9"
    
    # === å•æ–‡ä»¶ä¸Šä¼ ï¼ˆå‘åå…¼å®¹ï¼‰===
    file_name: Optional[str] = None
    file_size: Optional[int] = None
    content_type: Optional[str] = None
    duration: Optional[float] = None  # è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œå‰ç«¯æœ¬åœ°æå–
    
    # === å¤šæ–‡ä»¶ä¸Šä¼ ï¼ˆæ–°å¢ï¼‰===
    files: Optional[List[FileInfo]] = None  # å¤šä¸ªæ–‡ä»¶ä¿¡æ¯
    
    # é“¾æ¥è§£æç›¸å…³
    source_url: Optional[str] = None
    # â˜… processing_steps å·²åˆ é™¤ï¼Œç”± task_type å†³å®šå¤„ç†æµç¨‹


class AssetUploadInfo(BaseModel):
    """å•ä¸ªèµ„æºçš„ä¸Šä¼ ä¿¡æ¯"""
    asset_id: str
    upload_url: str
    storage_path: str
    order_index: int  # ä¿æŒä¸å‰ç«¯ä¸€è‡´
    file_name: str


class CreateSessionResponse(BaseModel):
    """åˆ›å»ºä¼šè¯å“åº”"""
    session_id: str
    project_id: str
    # â˜… ç»Ÿä¸€ç”¨ assets æ•°ç»„ï¼ˆå³ä½¿å•æ–‡ä»¶ä¹Ÿæ˜¯ä¸€ä¸ªå…ƒç´ çš„æ•°ç»„ï¼‰
    assets: Optional[List[AssetUploadInfo]] = None


class SessionStatus(BaseModel):
    """ä¼šè¯çŠ¶æ€"""
    session_id: str
    project_id: str
    status: Literal["uploading", "processing", "completed", "failed", "cancelled", "expired"]
    current_step: Optional[str] = None
    progress: int = 0
    steps: List[dict] = []  # å¤„ç†æ­¥éª¤åˆ—è¡¨
    error: Optional[str] = None
    transcript_segments: Optional[int] = None
    marked_clips: Optional[int] = None
    
    # === è§†é¢‘èµ„æº IDï¼ˆç”¨äºé¢„è§ˆï¼‰===
    uploaded_asset_id: Optional[str] = None
    uploaded_asset_ids: Optional[List[str]] = None
    
    # === å¤šæ–‡ä»¶ä¸Šä¼ è¿›åº¦ï¼ˆæ–°å¢ï¼‰===
    upload_progress: Optional[dict] = None  # {total_files, completed_files, ...}


# â˜… æ­¥éª¤å®šä¹‰å·²ç§»è‡³å‰ç«¯ ProcessingView.tsx
# åç«¯åªè¿”å› current_stepï¼Œå‰ç«¯æœ¬åœ°ç”Ÿæˆæ­¥éª¤åˆ—è¡¨
# è¿™æ ·é¿å…å‰åç«¯ç»´æŠ¤ä¸¤å¥—é‡å¤çš„æ­¥éª¤å®šä¹‰


def _get_file_type(content_type: str) -> str:
    """æ ¹æ® MIME ç±»å‹åˆ¤æ–­æ–‡ä»¶ç±»å‹"""
    if not content_type:
        return "video"
    if content_type.startswith("video/"):
        return "video"
    elif content_type.startswith("audio/"):
        return "audio"
    elif content_type.startswith("image/"):
        return "image"
    else:
        return "video"


# ============================================
# API ç«¯ç‚¹
# ============================================

@router.post("/sessions", response_model=CreateSessionResponse)
async def create_session(
    request: CreateSessionRequest,
    current_user: dict = Depends(get_current_user)
):
    """
    åˆ›å»ºå¤„ç†ä¼šè¯ (æ­¥éª¤1: ä»…ä¸Šä¼ ï¼Œä¸æ‰£ç§¯åˆ†)
    
    â˜… æ¸è¿›å¼ä¸¤æ­¥æµç¨‹:
    1. create_session - åˆ›å»ºä¼šè¯ + ä¸Šä¼ è§†é¢‘ (æœ¬æ¥å£ï¼Œä¸æ‰£ç§¯åˆ†)
    2. start-ai-processing - ç”¨æˆ·ç¡®è®¤é…ç½®åå¯åŠ¨ AI å¤„ç† (æ‰£ç§¯åˆ†)
    """
    try:
        user_id = current_user["user_id"]
        
        # â˜… ç§»é™¤ç§¯åˆ†æ£€æŸ¥ï¼ç§¯åˆ†æ£€æŸ¥ç§»åˆ° start-ai-processing æ¥å£
        # è¿™æ ·ç”¨æˆ·å¯ä»¥å…ˆä¸Šä¼ è§†é¢‘ï¼Œå†å†³å®šæ˜¯å¦ä½¿ç”¨ AI åŠŸèƒ½
        
        session_id = str(uuid4())
        project_id = str(uuid4())
        now = datetime.utcnow().isoformat()
        
        logger.info(f"[Session] å¼€å§‹åˆ›å»ºä¼šè¯, user_id={user_id}, source_type={request.source_type.value}")
        
        # â˜… å¼ºåˆ¶æ ¡éªŒæ¯”ä¾‹ï¼ˆåªå…è®¸ 9:16 / 16:9ï¼‰
        if request.aspect_ratio not in ("9:16", "16:9"):
            raise HTTPException(status_code=400, detail="è¯·å…ˆé€‰æ‹©è§†é¢‘æ¯”ä¾‹ï¼ˆä»…æ”¯æŒ 9:16 æˆ– 16:9ï¼‰")

        # 1. åˆ›å»ºé¡¹ç›®
        project_name = _generate_project_name(request)
        # æ ¹æ®æ¯”ä¾‹è®¾ç½®é¡¹ç›®åˆ†è¾¨ç‡
        if request.aspect_ratio == "9:16":
            resolution = {"width": 1080, "height": 1920}
        else:
            resolution = {"width": 1920, "height": 1080}

        project_data = {
            "id": project_id,
            "user_id": user_id,
            "name": project_name,
            "status": "processing",
            "resolution": resolution,
            "fps": 30,
            "created_at": now,
            "updated_at": now,
        }
        supabase.table("projects").insert(project_data).execute()
        logger.info(f"[Session] âœ… åˆ›å»ºé¡¹ç›®æˆåŠŸ, project_id={project_id}, name={project_name}")
        
        # 2. åˆ›å»ºä¼šè¯è®°å½•
        session_data = {
            "id": session_id,
            "user_id": user_id,
            "project_id": project_id,
            "status": "uploading",
            "upload_source": request.source_type.value,
            "source_url": request.source_url,
            "selected_tasks": [request.task_type.value],
            "processing_steps": {"aspect_ratio": request.aspect_ratio},
            "progress": 0,
            "created_at": now,
            "updated_at": now,
        }
        supabase.table("workspace_sessions").insert(session_data).execute()
        logger.info(f"[Session] âœ… åˆ›å»ºä¼šè¯æˆåŠŸ, session_id={session_id}, task_type={request.task_type.value}")
        
        response = CreateSessionResponse(
            session_id=session_id,
            project_id=project_id,
        )
        
        # 3. æ ¹æ®æ¥æºç±»å‹å¤„ç†
        if request.source_type == SourceType.LOCAL:
            # === åˆ¤æ–­æ˜¯å¤šæ–‡ä»¶è¿˜æ˜¯å•æ–‡ä»¶ä¸Šä¼  ===
            logger.info(f"[Session] ğŸ“‚ æ£€æŸ¥ä¸Šä¼ æ¨¡å¼:")
            logger.info(f"[Session]    request.files: {request.files}")
            logger.info(f"[Session]    request.file_name: {request.file_name}")
            logger.info(f"[Session]    files æ˜¯å¦æœ‰å€¼: {bool(request.files)}")
            logger.info(f"[Session]    files é•¿åº¦: {len(request.files) if request.files else 0}")
            
            if request.files and len(request.files) > 0:
                logger.info(f"[Session] âœ… è¿›å…¥å¤šæ–‡ä»¶ä¸Šä¼ æ¨¡å¼")
                # â˜… å¤šæ–‡ä»¶ä¸Šä¼ æ¨¡å¼
                assets_info = []
                asset_ids = []
                total_bytes = sum(f.size for f in request.files)
                
                for file_info in request.files:
                    asset_id = str(uuid4())
                    asset_ids.append(asset_id)
                    file_ext = file_info.name.split(".")[-1] if "." in file_info.name else "mp4"
                    storage_path = f"uploads/{project_id}/{asset_id}.{file_ext}"
                    
                    # ç”Ÿæˆé¢„ç­¾åä¸Šä¼  URLï¼ˆå¯ç”¨ upsert é¿å…é‡è¯•å¤±è´¥ï¼‰
                    presign_result = create_signed_upload_url("clips", storage_path, upsert=True)
                    upload_url = presign_result.get("signedURL") or presign_result.get("signed_url", "")
                    
                    # åˆ›å»º asset è®°å½•
                    asset_data = {
                        "id": asset_id,
                        "project_id": project_id,
                        "user_id": user_id,
                        "name": file_info.name,
                        "original_filename": file_info.name,
                        "file_type": _get_file_type(file_info.content_type),
                        "mime_type": file_info.content_type or "video/mp4",
                        "file_size": file_info.size,
                        "storage_path": storage_path,
                        "duration": file_info.duration,
                        "status": "uploading",  # ç­‰å¾…ä¸Šä¼ ï¼ˆçº¦æŸåªå…è®¸ uploading/processing/ready/errorï¼‰
                        "order_index": file_info.order_index,  # ç´ æé¡ºåº
                        "upload_progress": {
                            "bytes_uploaded": 0,
                            "total_bytes": file_info.size,
                            "percentage": 0,
                        },
                        "created_at": now,
                        "updated_at": now,
                    }
                    supabase.table("assets").insert(asset_data).execute()
                    
                    assets_info.append(AssetUploadInfo(
                        asset_id=asset_id,
                        upload_url=upload_url,
                        storage_path=storage_path,
                        order_index=file_info.order_index,
                        file_name=file_info.name,
                    ))
                
                # æ›´æ–°ä¼šè¯è®°å½•
                supabase.table("workspace_sessions").update({
                    "uploaded_asset_id": asset_ids[0] if asset_ids else None,  # â˜… å…¼å®¹æ—§é€»è¾‘
                    "uploaded_asset_ids": asset_ids,  # JSON æ•°ç»„
                    "upload_progress": {
                        "total_files": len(request.files),
                        "completed_files": 0,
                        "failed_files": 0,
                        "pending_files": len(request.files),
                        "total_bytes": total_bytes,
                        "uploaded_bytes": 0,
                    },
                    "status": "uploading",
                }).eq("id", session_id).execute()
                
                response.assets = assets_info
                logger.info(f"[Session] âœ… å¤šæ–‡ä»¶ä¸Šä¼ æ¨¡å¼ï¼Œåˆ›å»º {len(assets_info)} ä¸ªèµ„æº")
                logger.info(f"[Session]    response.assets æ•°é‡: {len(response.assets)}")
                for i, a in enumerate(response.assets):
                    logger.info(f"[Session]    asset[{i}]: {a.asset_id}, order={a.order_index}")
                
            else:
                # â˜… å•æ–‡ä»¶ä¸Šä¼ æ¨¡å¼ï¼ˆå‘åå…¼å®¹ï¼‰
                asset_id = str(uuid4())
                file_ext = request.file_name.split(".")[-1] if request.file_name and "." in request.file_name else "mp4"
                storage_path = f"uploads/{project_id}/{asset_id}.{file_ext}"
                
                logger.info(f"[Session] æ­£åœ¨ç”Ÿæˆé¢„ç­¾åä¸Šä¼ URL, storage_path={storage_path}")
                logger.debug(f"[Session] æ”¶åˆ°çš„ duration: {request.duration}")
                presign_result = create_signed_upload_url("clips", storage_path, upsert=True)
                upload_url = presign_result.get("signedURL") or presign_result.get("signed_url", "")
                logger.info(f"[Session] âœ… é¢„ç­¾åURLç”ŸæˆæˆåŠŸ, url_length={len(upload_url)}")
                
                asset_data = {
                    "id": asset_id,
                    "project_id": project_id,
                    "user_id": user_id,
                    "name": request.file_name or "æœªå‘½å",
                    "original_filename": request.file_name,
                    "file_type": _get_file_type(request.content_type),
                    "mime_type": request.content_type or "video/mp4",
                    "file_size": request.file_size,
                    "storage_path": storage_path,
                    "duration": request.duration,
                    "status": "uploading",
                    "order_index": 0,
                    "created_at": now,
                    "updated_at": now,
                }
                supabase.table("assets").insert(asset_data).execute()
                logger.info(f"[Session] âœ… åˆ›å»ºèµ„æºæˆåŠŸ, asset_id={asset_id}, file_name={request.file_name}")
                
                supabase.table("workspace_sessions").update({
                    "uploaded_asset_id": asset_id,
                    "uploaded_asset_ids": [asset_id],  # åŒæ—¶æ›´æ–°æ•°ç»„å­—æ®µ
                    "status": "uploading",
                }).eq("id", session_id).execute()
                logger.info(f"[Session] âœ… æ›´æ–°ä¼šè¯å…³è”èµ„æºæˆåŠŸ")
                
                # â˜… å•æ–‡ä»¶ä¹Ÿç»Ÿä¸€æ”¾å…¥ assets æ•°ç»„
                response.assets = [AssetUploadInfo(
                    asset_id=asset_id,
                    upload_url=upload_url,
                    storage_path=storage_path,
                    order_index=0,
                    file_name=request.file_name,
                )]
            
        elif request.source_type in (SourceType.YOUTUBE, SourceType.URL):
            supabase.table("workspace_sessions").update({
                "status": "processing",
                "current_step": "fetch",
            }).eq("id", session_id).execute()
            logger.info(f"[Session] âœ… URLç±»å‹ä¼šè¯å¼€å§‹å¤„ç†, source_url={request.source_url}")
        
        logger.info(f"[Session] âœ… ä¼šè¯åˆ›å»ºå®Œæˆ, session_id={session_id}, project_id={project_id}")
        return response
        
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        logger.error(f"[Session] âŒ åˆ›å»ºä¼šè¯å¤±è´¥: {e}")
        logger.error(f"[Session] âŒ å®Œæ•´å †æ ˆ:\n{traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/sessions/{session_id}/asset/{asset_id}/uploaded")
async def notify_asset_uploaded(session_id: str, asset_id: str):
    """
    é€šçŸ¥å•ä¸ªæ–‡ä»¶ä¸Šä¼ å®Œæˆï¼ˆå¤šæ–‡ä»¶ä¸Šä¼ æ¨¡å¼ï¼‰
    å‰ç«¯æ¯ä¸Šä¼ å®Œä¸€ä¸ªæ–‡ä»¶å°±è°ƒç”¨ä¸€æ¬¡
    """
    logger.info(f"[Upload] ğŸ“¤ æ”¶åˆ°èµ„æºä¸Šä¼ å®Œæˆé€šçŸ¥: session={session_id}, asset={asset_id}")
    try:
        now = datetime.utcnow().isoformat()
        
        # æ›´æ–°è¯¥ asset çŠ¶æ€
        logger.info(f"[Upload]    æ›´æ–° asset {asset_id} çŠ¶æ€ä¸º uploaded")
        supabase.table("assets").update({
            "status": "uploaded",
            "upload_progress": {
                "percentage": 100,
                "completed": True,
            },
            "updated_at": now,
        }).eq("id", asset_id).execute()
        
        # è·å– session ä¿¡æ¯
        session = supabase.table("workspace_sessions").select("*").eq("id", session_id).single().execute()
        if not session.data:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
        
        session_data = session.data
        asset_ids = session_data.get("uploaded_asset_ids", [])
        
        # ç»Ÿè®¡ä¸Šä¼ è¿›åº¦
        assets_result = supabase.table("assets").select("id, status, file_size").in_("id", asset_ids).execute()
        assets = assets_result.data or []
        
        completed = sum(1 for a in assets if a.get("status") == "uploaded")
        failed = sum(1 for a in assets if a.get("status") == "error")
        pending = len(assets) - completed - failed
        uploaded_bytes = sum(a.get("file_size", 0) for a in assets if a.get("status") == "uploaded")
        total_bytes = sum(a.get("file_size", 0) for a in assets)
        
        # æ›´æ–° session è¿›åº¦
        supabase.table("workspace_sessions").update({
            "upload_progress": {
                "total_files": len(assets),
                "completed_files": completed,
                "failed_files": failed,
                "pending_files": pending,
                "total_bytes": total_bytes,
                "uploaded_bytes": uploaded_bytes,
            },
            "updated_at": now,
        }).eq("id", session_id).execute()
        
        logger.info(f"[Session] ğŸ“¤ Asset {asset_id} ä¸Šä¼ å®Œæˆ, è¿›åº¦: {completed}/{len(assets)}")
        
        return {
            "status": "ok",
            "progress": {
                "completed": completed,
                "total": len(assets),
                "all_completed": completed == len(assets),
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[Session] âŒ é€šçŸ¥ä¸Šä¼ å®Œæˆå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# â˜… ä¸Šä¼ å®Œæˆååˆ›å»ºåŸºç¡€é¡¹ç›®ç»“æ„ (æ–°å¢)
# ============================================

class FinalizeUploadResponse(BaseModel):
    """å®Œæˆä¸Šä¼ å“åº”"""
    status: str
    project_id: str
    tracks: list  # åˆ›å»ºçš„è½¨é“ä¿¡æ¯
    clips: list   # åˆ›å»ºçš„ clip ä¿¡æ¯
    message: str


@router.post("/sessions/{session_id}/finalize-upload", response_model=FinalizeUploadResponse)
async def finalize_upload(
    session_id: str,
    current_user: dict = Depends(get_current_user)
):
    """
    å®Œæˆä¸Šä¼ ï¼Œåˆ›å»ºåŸºç¡€é¡¹ç›®ç»“æ„ (track + video clip)
    
    â˜… æ¸è¿›å¼æµç¨‹çš„å…³é”®æ­¥éª¤:
    1. ç”¨æˆ·ä¸Šä¼ è§†é¢‘åè°ƒç”¨æ­¤æ¥å£
    2. åˆ›å»ºåŸºç¡€çš„è§†é¢‘è½¨é“å’Œå­—å¹•è½¨é“
    3. å°†ä¸Šä¼ çš„è§†é¢‘æ”¾åˆ°æ—¶é—´è½´ä¸Šï¼ˆåˆ›å»º video clipï¼‰
    4. æ­¤æ—¶ç”¨æˆ·å¯ä»¥åœ¨ç¼–è¾‘å™¨ä¸­é¢„è§ˆå’Œç¼–è¾‘
    5. åç»­ AI å¤„ç†æ˜¯å¯é€‰çš„å¢å€¼åŠŸèƒ½
    """
    try:
        user_id = current_user["user_id"]
        now = datetime.utcnow().isoformat()
        
        # 1. è·å–ä¼šè¯ä¿¡æ¯
        session = supabase.table("workspace_sessions").select("*").eq("id", session_id).single().execute()
        if not session.data:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
        
        session_data = session.data
        project_id = session_data.get("project_id")
        
        # æ ¡éªŒä¼šè¯å½’å±
        if session_data.get("user_id") != user_id:
            raise HTTPException(status_code=403, detail="æ— æƒæ“ä½œæ­¤ä¼šè¯")
        
        # 2. è·å–æ‰€æœ‰å…³è”çš„ assets
        asset_ids = session_data.get("uploaded_asset_ids", [])
        if not asset_ids:
            single_asset_id = session_data.get("uploaded_asset_id")
            if single_asset_id:
                asset_ids = [single_asset_id]
        
        if not asset_ids:
            raise HTTPException(status_code=400, detail="ä¼šè¯æœªå…³è”ä»»ä½•èµ„æº")
        
        # æ£€æŸ¥æ‰€æœ‰æ–‡ä»¶æ˜¯å¦éƒ½ä¸Šä¼ å®Œæˆ
        assets_result = supabase.table("assets").select("*").in_("id", asset_ids).execute()
        assets = assets_result.data or []
        
        not_ready = [a for a in assets if a.get("status") not in ("uploaded", "ready")]
        if not_ready:
            pending_names = [a.get("name", a["id"]) for a in not_ready[:3]]
            raise HTTPException(
                status_code=400, 
                detail=f"éƒ¨åˆ†æ–‡ä»¶æœªä¸Šä¼ å®Œæˆ: {', '.join(pending_names)}"
            )
        
        # 3. æ£€æŸ¥æ˜¯å¦å·²åˆ›å»ºè¿‡ trackï¼ˆé¿å…é‡å¤åˆ›å»ºï¼‰
        existing_tracks = supabase.table("tracks").select("id").eq("project_id", project_id).execute()
        if existing_tracks.data and len(existing_tracks.data) > 0:
            logger.info(f"[Finalize] âš ï¸ é¡¹ç›® {project_id} å·²å­˜åœ¨è½¨é“ï¼Œè·³è¿‡åˆ›å»º")
            return FinalizeUploadResponse(
                status="ok",
                project_id=project_id,
                tracks=[{"id": t["id"]} for t in existing_tracks.data],
                clips=[],
                message="é¡¹ç›®ç»“æ„å·²å­˜åœ¨",
            )
        
        # 4. åˆ›å»ºåŸºç¡€è½¨é“
        video_track_id = str(uuid4())
        text_track_id = str(uuid4())
        
        # è§†é¢‘è½¨é“
        supabase.table("tracks").insert({
            "id": video_track_id,
            "project_id": project_id,
            "name": "è§†é¢‘è½¨é“",
            "order_index": 0,
            "is_muted": False,
            "is_locked": False,
            "is_visible": True,
            "created_at": now,
            "updated_at": now,
        }).execute()
        
        # å­—å¹•è½¨é“ (order_index 100+ ç¡®ä¿å§‹ç»ˆåœ¨æœ€ä¸Šå±‚)
        supabase.table("tracks").insert({
            "id": text_track_id,
            "project_id": project_id,
            "name": "å­—å¹•è½¨é“",
            "order_index": 100,  # â˜… å­—å¹•/æ–‡æœ¬è½¨é“å›ºå®šåœ¨ 100+ å±‚çº§
            "is_muted": False,
            "is_locked": False,
            "is_visible": True,
            "created_at": now,
            "updated_at": now,
        }).execute()
        
        logger.info(f"[Finalize] âœ… åˆ›å»ºåŸºç¡€è½¨é“: video={video_track_id}, text={text_track_id}")
        
        # 5. æŒ‰é¡ºåºæ’åˆ— assets å¹¶åˆ›å»º video clips
        sorted_assets = sorted(assets, key=lambda a: a.get("order_index", 0))
        
        created_clips = []
        timeline_position = 0  # æ—¶é—´è½´ä½ç½®ï¼ˆæ¯«ç§’ï¼‰
        
        for asset in sorted_assets:
            asset_id = asset["id"]
            duration_sec = asset.get("duration") or 0
            duration_ms = int(duration_sec * 1000)
            
            # å¦‚æœæ²¡æœ‰æ—¶é•¿ä¿¡æ¯ï¼Œä½¿ç”¨é»˜è®¤å€¼ï¼ˆåç»­å¯ä»¥é€šè¿‡ ffprobe è·å–ï¼‰
            if duration_ms <= 0:
                duration_ms = 10000  # é»˜è®¤ 10 ç§’
                logger.warning(f"[Finalize] âš ï¸ Asset {asset_id} æ— æ—¶é•¿ä¿¡æ¯ï¼Œä½¿ç”¨é»˜è®¤ 10s")
            
            clip_id = str(uuid4())
            
            # åˆ›å»º video clip
            clip_data = {
                "id": clip_id,
                "track_id": video_track_id,
                "asset_id": asset_id,
                "clip_type": "video",
                "name": asset.get("name", "è§†é¢‘"),
                "start_time": timeline_position,
                "end_time": timeline_position + duration_ms,
                "source_start": 0,
                "source_end": duration_ms,
                "volume": 1.0,
                "is_muted": False,
                "transform": {
                    "x": 0, "y": 0,
                    "scaleX": 1, "scaleY": 1,
                    "rotation": 0,
                    "opacity": 1,
                },
                "speed": 1.0,
                "created_at": now,
                "updated_at": now,
            }
            
            supabase.table("clips").insert(clip_data).execute()
            
            created_clips.append({
                "id": clip_id,
                "asset_id": asset_id,
                "start_time": timeline_position,
                "end_time": timeline_position + duration_ms,
            })
            
            logger.info(f"[Finalize] âœ… åˆ›å»º clip: {clip_id}, asset={asset_id}, duration={duration_ms}ms")
            
            # æ›´æ–°æ—¶é—´è½´ä½ç½®ï¼ˆä¸‹ä¸€ä¸ª clip ç´§è·Ÿç€ï¼‰
            timeline_position += duration_ms
        
        # 6. æ›´æ–°æ‰€æœ‰ assets çŠ¶æ€ä¸º ready
        for asset in assets:
            supabase.table("assets").update({
                "status": "ready",
                "updated_at": now,
            }).eq("id", asset["id"]).execute()
        
        # 7. æ›´æ–°é¡¹ç›®çŠ¶æ€ä¸º ready (æ•°æ®åº“çº¦æŸ: draft/processing/ready/exported/archived)
        supabase.table("projects").update({
            "status": "ready",
            "updated_at": now,
        }).eq("id", project_id).execute()
        
        # 8. æ›´æ–°ä¼šè¯çŠ¶æ€å’Œ workflow_step
        #    status: completed è¡¨ç¤ºä¸Šä¼ å®Œæˆ
        #    workflow_step: config è¡¨ç¤ºä¸‹ä¸€æ­¥æ˜¯"åˆ†æé…ç½®"
        #    â˜… åŒæ—¶ç¡®ä¿ uploaded_asset_id å’Œ uploaded_asset_ids éƒ½æœ‰å€¼
        session_update = {
            "status": "completed",
            "workflow_step": "config",  # â˜… ä¸Šä¼ å®Œæˆåè¿›å…¥é…ç½®æ­¥éª¤
            "uploaded_asset_ids": asset_ids,  # ç¡®ä¿æ•°ç»„å­—æ®µæœ‰å€¼
            "updated_at": now,
        }
        # å¦‚æœæœ‰ assetsï¼Œè®¾ç½®ç¬¬ä¸€ä¸ªä¸º uploaded_asset_idï¼ˆå…¼å®¹æ—§é€»è¾‘ï¼‰
        if asset_ids:
            session_update["uploaded_asset_id"] = asset_ids[0]
        
        supabase.table("workspace_sessions").update(session_update).eq("id", session_id).execute()
        
        logger.info(f"[Finalize] âœ… å®Œæˆä¸Šä¼ ï¼Œé¡¹ç›® {project_id} å¯ä»¥ç¼–è¾‘äº†")
        logger.info(f"[Finalize]    åˆ›å»ºäº† {len(created_clips)} ä¸ª clips, workflow_step -> config")
        
        return FinalizeUploadResponse(
            status="ok",
            project_id=project_id,
            tracks=[
                {"id": video_track_id, "name": "è§†é¢‘è½¨é“", "order_index": 0},
                {"id": text_track_id, "name": "å­—å¹•è½¨é“", "order_index": 100},  # â˜… å­—å¹•å§‹ç»ˆåœ¨æœ€ä¸Šå±‚
            ],
            clips=created_clips,
            message=f"åŸºç¡€é¡¹ç›®ç»“æ„åˆ›å»ºæˆåŠŸï¼ŒåŒ…å« {len(created_clips)} ä¸ªè§†é¢‘ç‰‡æ®µ",
        )
        
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        logger.error(f"[Finalize] âŒ å®Œæˆä¸Šä¼ å¤±è´¥: {e}")
        logger.error(f"[Finalize] âŒ å®Œæ•´å †æ ˆ:\n{traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/sessions/{session_id}/confirm-upload")
async def confirm_upload(session_id: str, background_tasks: BackgroundTasks):
    """
    ç¡®è®¤æ‰€æœ‰æ–‡ä»¶ä¸Šä¼ å®Œæˆï¼Œå¼€å§‹å¤„ç†
    æ”¯æŒå¤šæ–‡ä»¶å’Œå•æ–‡ä»¶æ¨¡å¼
    """
    try:
        session = supabase.table("workspace_sessions").select("*").eq("id", session_id).single().execute()
        if not session.data:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
        
        session_data = session.data
        project_id = session_data.get("project_id")
        now = datetime.utcnow().isoformat()
        
        # â˜… é˜²æ­¢é‡å¤è§¦å‘ï¼šå¦‚æœå·²ç»åœ¨å¤„ç†ä¸­ï¼Œç›´æ¥è¿”å›
        current_status = session_data.get("status")
        if current_status == "processing":
            logger.info(f"[Session] âš ï¸ ä¼šè¯ {session_id} å·²åœ¨å¤„ç†ä¸­ï¼Œè·³è¿‡é‡å¤è¯·æ±‚")
            return {
                "status": "processing",
                "message": "ä»»åŠ¡å·²åœ¨å¤„ç†ä¸­ï¼Œè¯·å‹¿é‡å¤æäº¤",
                "asset_count": len(session_data.get("uploaded_asset_ids", [])),
            }
        
        # === è·å–æ‰€æœ‰å…³è”çš„ assets ===
        asset_ids = session_data.get("uploaded_asset_ids", [])
        
        # å…¼å®¹æ—§çš„å•æ–‡ä»¶æ¨¡å¼
        if not asset_ids:
            single_asset_id = session_data.get("uploaded_asset_id")
            if single_asset_id:
                asset_ids = [single_asset_id]
        
        if not asset_ids:
            raise HTTPException(status_code=400, detail="ä¼šè¯æœªå…³è”ä»»ä½•èµ„æº")
        
        # === æ£€æŸ¥æ‰€æœ‰æ–‡ä»¶æ˜¯å¦éƒ½ä¸Šä¼ å®Œæˆ ===
        assets_result = supabase.table("assets").select("*").in_("id", asset_ids).execute()
        assets = assets_result.data or []
        
        if len(assets) != len(asset_ids):
            raise HTTPException(status_code=400, detail="éƒ¨åˆ†èµ„æºè®°å½•ä¸å­˜åœ¨")
        
        # æ£€æŸ¥æœªå®Œæˆçš„ä¸Šä¼ 
        not_uploaded = [a for a in assets if a.get("status") not in ("uploaded", "uploading", "processing", "ready")]
        if not_uploaded:
            pending_names = [a.get("name", a["id"]) for a in not_uploaded[:3]]
            raise HTTPException(
                status_code=400, 
                detail=f"éƒ¨åˆ†æ–‡ä»¶æœªä¸Šä¼ å®Œæˆ: {', '.join(pending_names)}"
            )
        
        # === æ›´æ–°æ‰€æœ‰ assets çŠ¶æ€ä¸ºå¤„ç†ä¸­ ===
        for asset in assets:
            supabase.table("assets").update({
                "status": "processing",
                "updated_at": now,
            }).eq("id", asset["id"]).execute()
        
        # === æ›´æ–° session çŠ¶æ€ ===
        supabase.table("workspace_sessions").update({
            "status": "processing",
            "current_step": "fetch",
            "progress": 0,
            "updated_at": now,
        }).eq("id", session_id).execute()
        
        selected_tasks = session_data.get("selected_tasks", ["clips"])
        task_type = selected_tasks[0] if selected_tasks else "clips"
        
        # === æŒ‰é¡ºåºæ’åˆ— assets ===
        sorted_assets = sorted(assets, key=lambda a: a.get("order_index", 0))
        
        logger.info(f"[Session] ========================================")
        logger.info(f"[Session] ğŸš€ å‡†å¤‡å¯åŠ¨åå°å¤„ç†ä»»åŠ¡")
        logger.info(f"[Session]    session_id: {session_id}")
        logger.info(f"[Session]    project_id: {project_id}")
        logger.info(f"[Session]    task_type: {task_type}")
        logger.info(f"[Session]    sorted_assets count: {len(sorted_assets)}")
        for i, a in enumerate(sorted_assets):
            logger.info(f"[Session]    asset[{i}]: {a.get('name')} (order={a.get('order_index')})")
        logger.info(f"[Session] ========================================")
        
        # === å¯åŠ¨åå°å¤„ç†ä»»åŠ¡ ===
        background_tasks.add_task(
            _process_session_multi_assets,
            session_id=session_id,
            project_id=project_id,
            assets=sorted_assets,
            task_type=task_type,
        )
        
        logger.info(f"[Session] âœ… åå°ä»»åŠ¡å·²æ·»åŠ , å¼€å§‹å¤„ç† {len(assets)} ä¸ªç´ æ")
        
        return {
            "status": "processing", 
            "message": f"å¼€å§‹å¤„ç† {len(assets)} ä¸ªç´ æ",
            "asset_count": len(assets),
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[Session] âŒ ç¡®è®¤ä¸Šä¼ å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/sessions/{session_id}", response_model=SessionStatus)
async def get_session_status(session_id: str):
    """è·å–ä¼šè¯å¤„ç†çŠ¶æ€
    
    è¿”å›:
    - current_step: å½“å‰æ­¥éª¤ IDï¼ˆfetch/transcribe/segment/vision/transform/subtitle/prepareï¼‰
    - progress: 0-100 è¿›åº¦
    - status: pending/processing/completed/failed
    
    æ³¨æ„: steps å­—æ®µå·²åºŸå¼ƒï¼Œå‰ç«¯æœ¬åœ°ç”Ÿæˆæ­¥éª¤åˆ—è¡¨
    """
    try:
        session = supabase.table("workspace_sessions").select("*").eq("id", session_id).single().execute()
        if not session.data:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
        
        data = session.data
        
        return SessionStatus(
            session_id=data["id"],
            project_id=data["project_id"],
            status=data["status"],
            current_step=data.get("current_step"),
            progress=data.get("progress", 0),
            steps=[],  # â˜… åºŸå¼ƒï¼Œå‰ç«¯æœ¬åœ°ç”Ÿæˆ
            error=data.get("error_message"),
            uploaded_asset_id=data.get("uploaded_asset_id"),
            uploaded_asset_ids=data.get("uploaded_asset_ids"),
        )
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.delete("/sessions/{session_id}")
async def cancel_session(session_id: str):
    """å–æ¶ˆå¤„ç†ä¼šè¯"""
    try:
        supabase.table("workspace_sessions").update({
            "status": "cancelled",
            "updated_at": datetime.utcnow().isoformat(),
        }).eq("id", session_id).execute()
        
        return {"message": "ä¼šè¯å·²å–æ¶ˆ"}
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# â˜… å·¥ä½œæµæ­¥éª¤ç®¡ç† API
# ============================================

class UpdateWorkflowStepRequest(BaseModel):
    """æ›´æ–°å·¥ä½œæµæ­¥éª¤è¯·æ±‚"""
    workflow_step: str  # entry, upload, processing, defiller, broll_config
    entry_mode: Optional[str] = None  # ai-talk, refine
    enable_smart_clip: Optional[bool] = None  # æ™ºèƒ½å‰ªè¾‘å¼€å…³
    enable_broll: Optional[bool] = None  # B-Roll å¼€å…³
    shot_strategy: Optional[str] = None  # åˆ†é•œç­–ç•¥: scene, sentence, paragraph
    aspect_ratio: Optional[str] = None  # ä»…æ”¯æŒ 9:16 æˆ– 16:9


@router.put("/sessions/{session_id}/workflow-step")
async def update_workflow_step(
    session_id: str,
    request: UpdateWorkflowStepRequest,
    current_user: dict = Depends(get_current_user)
):
    """
    æ›´æ–°ä¼šè¯çš„å·¥ä½œæµæ­¥éª¤çŠ¶æ€
    
    ç”¨äºå‰ç«¯ä¿å­˜ç”¨æˆ·å½“å‰æ‰€åœ¨çš„å·¥ä½œæµæ­¥éª¤ï¼Œæ”¯æŒæ–­ç‚¹æ¢å¤ã€‚
    """
    try:
        user_id = current_user["user_id"]
        
        # éªŒè¯ä¼šè¯å½’å±
        session = supabase.table("workspace_sessions").select("user_id").eq("id", session_id).single().execute()
        if not session.data:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
        
        if session.data.get("user_id") != user_id:
            raise HTTPException(status_code=403, detail="æ— æƒæ“ä½œæ­¤ä¼šè¯")
        
        # æ›´æ–°å·¥ä½œæµæ­¥éª¤
        update_data = {
            "current_step": request.workflow_step,
            "updated_at": datetime.utcnow().isoformat(),
        }
        
        # å°†æ‰€æœ‰å·¥ä½œæµçŠ¶æ€å­˜å‚¨åˆ° processing_steps JSONB å­—æ®µ
        processing_steps_data = {
            "workflow_step": request.workflow_step,
        }
        if request.entry_mode is not None:
            processing_steps_data["entry_mode"] = request.entry_mode
        if request.enable_smart_clip is not None:
            processing_steps_data["enable_smart_clip"] = request.enable_smart_clip
        if request.enable_broll is not None:
            processing_steps_data["enable_broll"] = request.enable_broll
        if request.shot_strategy is not None:
            processing_steps_data["shot_strategy"] = request.shot_strategy
        if request.aspect_ratio is not None:
            if request.aspect_ratio not in ("9:16", "16:9"):
                raise HTTPException(status_code=400, detail="æ¯”ä¾‹ä¸åˆæ³•ï¼Œä»…æ”¯æŒ 9:16 æˆ– 16:9")
            processing_steps_data["aspect_ratio"] = request.aspect_ratio
        
        update_data["processing_steps"] = processing_steps_data
        
        supabase.table("workspace_sessions").update(update_data).eq("id", session_id).execute()
        
        logger.info(f"[Workflow] æ›´æ–°å·¥ä½œæµæ­¥éª¤: session={session_id}, step={request.workflow_step}, mode={request.entry_mode}, smart_clip={request.enable_smart_clip}, broll={request.enable_broll}, shot_strategy={request.shot_strategy}")
        
        return {"status": "ok", "workflow_step": request.workflow_step}
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[Workflow] æ›´æ–°å·¥ä½œæµæ­¥éª¤å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/sessions/{session_id}/workflow-step")
async def get_workflow_step(
    session_id: str,
    current_user: dict = Depends(get_current_user)
):
    """
    è·å–ä¼šè¯çš„å·¥ä½œæµæ­¥éª¤çŠ¶æ€
    
    ç”¨äºå‰ç«¯æ¢å¤åˆ°ç”¨æˆ·ä¸Šæ¬¡ç¦»å¼€çš„å·¥ä½œæµæ­¥éª¤ã€‚
    """
    try:
        user_id = current_user["user_id"]
        
        session = supabase.table("workspace_sessions").select("*").eq("id", session_id).single().execute()
        if not session.data:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
        
        if session.data.get("user_id") != user_id:
            raise HTTPException(status_code=403, detail="æ— æƒæ“ä½œæ­¤ä¼šè¯")
        
        data = session.data
        processing_steps = data.get("processing_steps") or {}
        
        # â˜… ä¼˜å…ˆä½¿ç”¨é¡¶å±‚ workflow_stepï¼ˆç”± B-Roll å®Œæˆæ—¶è®¾ç½®ï¼‰ï¼Œå…¶æ¬¡æ˜¯ processing_steps ä¸­çš„å€¼
        workflow_step = data.get("workflow_step") or processing_steps.get("workflow_step") or data.get("current_step") or "upload"
        
        return {
            "session_id": session_id,
            "project_id": data.get("project_id"),
            "workflow_step": workflow_step,
            "entry_mode": processing_steps.get("entry_mode") or "refine",
            "enable_smart_clip": processing_steps.get("enable_smart_clip"),
            "enable_broll": processing_steps.get("enable_broll"),
            "aspect_ratio": processing_steps.get("aspect_ratio"),
            "status": data.get("status"),
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[Workflow] è·å–å·¥ä½œæµæ­¥éª¤å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/sessions/by-project/{project_id}/workflow-step")
async def get_workflow_step_by_project(
    project_id: str,
    current_user: dict = Depends(get_current_user)
):
    """
    é€šè¿‡é¡¹ç›® ID è·å–ä¼šè¯çš„å·¥ä½œæµæ­¥éª¤çŠ¶æ€
    
    ç”¨äºä»é¡¹ç›®åˆ—è¡¨ç‚¹å‡»æ—¶æ£€æŸ¥æ˜¯å¦æœ‰æœªå®Œæˆçš„å·¥ä½œæµã€‚
    
    â˜…â˜…â˜… æ²»æœ¬é€»è¾‘ï¼šæ£€æŸ¥å¼¹çª—æ¯ä¸ªæ­¥éª¤çš„å®é™…å®ŒæˆçŠ¶æ€ â˜…â˜…â˜…
    
    refine æ¨¡å¼æ­¥éª¤å®Œæˆæ¡ä»¶ï¼š
    1. upload - æœ‰ assetsï¼ˆè§†é¢‘å·²ä¸Šä¼ ï¼‰
    2. config - è¿›å…¥è¿‡ processingï¼ˆæœ‰è½¬å†™ä»»åŠ¡æˆ–ç»“æœï¼‰
    3. processing - è½¬å†™å·²å®Œæˆï¼ˆassets æœ‰ transcriptï¼‰
    4. defiller - clips å·²åˆ›å»ºï¼ˆå£ç™–ä¿®å‰ªå·²åº”ç”¨æˆ–è·³è¿‡ï¼‰
    
    å¦‚æœæ‰€æœ‰æ­¥éª¤éƒ½å®Œæˆ â†’ è¿”å› completedï¼Œä¸å¼¹çª—
    """
    try:
        user_id = current_user["user_id"]
        
        # é€šè¿‡ project_id æŸ¥æ‰¾æœ€æ–°çš„ä¼šè¯
        session = supabase.table("workspace_sessions")\
            .select("*")\
            .eq("project_id", project_id)\
            .eq("user_id", user_id)\
            .order("created_at", desc=True)\
            .limit(1)\
            .execute()
        
        if not session.data or len(session.data) == 0:
            raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°ç›¸å…³ä¼šè¯")
        
        data = session.data[0]
        session_id = data.get("id")
        processing_steps = data.get("processing_steps") or {}
        entry_mode = processing_steps.get("entry_mode") or "refine"
        
        # â˜…â˜…â˜… æ£€æŸ¥æ¯ä¸ªæ­¥éª¤çš„å®é™…å®ŒæˆçŠ¶æ€ â˜…â˜…â˜…
        # ç®€åŒ–é€»è¾‘ï¼šåªæ£€æŸ¥ assets å’Œ clips æ˜¯å¦å­˜åœ¨
        
        # Step 1: upload - æ£€æŸ¥æ˜¯å¦æœ‰ assets
        assets_check = supabase.table("assets")\
            .select("id, status")\
            .eq("project_id", project_id)\
            .eq("file_type", "video")\
            .limit(1)\
            .execute()
        
        has_assets = assets_check.data and len(assets_check.data) > 0
        if not has_assets:
            # æ²¡æœ‰ä¸Šä¼ è§†é¢‘ï¼Œä» upload æ­¥éª¤å¼€å§‹
            logger.info(f"[Workflow] é¡¹ç›® {project_id} æœªä¸Šä¼ è§†é¢‘ï¼Œéœ€ä» upload å¼€å§‹")
            return {
                "session_id": session_id,
                "project_id": project_id,
                "workflow_step": "upload",
                "entry_mode": entry_mode,
                "enable_smart_clip": processing_steps.get("enable_smart_clip"),
                "enable_broll": processing_steps.get("enable_broll"),
                "aspect_ratio": processing_steps.get("aspect_ratio"),
                "status": data.get("status"),
            }
        
        # Step 2-4: æ£€æŸ¥æ˜¯å¦æœ‰ clipsï¼ˆclips å­˜åœ¨ = å£ç™–ä¿®å‰ªå·²å®Œæˆ = å·¥ä½œæµå·²å®Œæˆï¼‰
        # â˜… clips æ²¡æœ‰ project_idï¼Œéœ€è¦é€šè¿‡ tracks è¡¨å…³è”
        clips_check = supabase.table("clips")\
            .select("id, tracks!inner(project_id)")\
            .eq("tracks.project_id", project_id)\
            .limit(1)\
            .execute()
        
        has_clips = clips_check.data and len(clips_check.data) > 0
        if not has_clips:
            # æœ‰è§†é¢‘ä½†æ²¡ clipsï¼Œéœ€è¦æ£€æŸ¥å½“å‰æ­¥éª¤
            stored_step = data.get("workflow_step") or processing_steps.get("workflow_step") or "config"
            # å¦‚æœæ˜¯ processing/defiller/broll-configï¼Œä¿æŒåŸæ­¥éª¤ï¼›å¦åˆ™ä» config å¼€å§‹
            actual_step = stored_step if stored_step in ["processing", "defiller", "broll-config"] else "config"
            logger.info(f"[Workflow] é¡¹ç›® {project_id} æ—  clipsï¼Œéœ€ä» {actual_step} å¼€å§‹")
            return {
                "session_id": session_id,
                "project_id": project_id,
                "workflow_step": actual_step,
                "entry_mode": entry_mode,
                "enable_smart_clip": processing_steps.get("enable_smart_clip"),
                "enable_broll": processing_steps.get("enable_broll"),
                "aspect_ratio": processing_steps.get("aspect_ratio"),
                "status": data.get("status"),
            }
        
        # â˜… æ‰€æœ‰æ­¥éª¤éƒ½å®Œæˆäº†ï¼è¿”å› completedï¼Œä¸å¼¹çª—
        logger.info(f"[Workflow] é¡¹ç›® {project_id} æ‰€æœ‰æ­¥éª¤å·²å®Œæˆï¼Œç›´æ¥è¿›ç¼–è¾‘å™¨")
        return {
            "session_id": session_id,
            "project_id": project_id,
            "workflow_step": "completed",
            "entry_mode": entry_mode,
            "enable_smart_clip": processing_steps.get("enable_smart_clip"),
            "enable_broll": processing_steps.get("enable_broll"),
            "aspect_ratio": processing_steps.get("aspect_ratio"),
            "status": data.get("status"),
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[Workflow] é€šè¿‡é¡¹ç›®è·å–å·¥ä½œæµæ­¥éª¤å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# â˜… ä¿å­˜å·¥ä½œæµé…ç½®ï¼ˆB-Roll, PiP ç­‰ï¼‰
# ============================================

class WorkflowConfigRequest(BaseModel):
    """å·¥ä½œæµé…ç½®è¯·æ±‚"""
    pip_enabled: bool = False                   # æ˜¯å¦å¯ç”¨æŒ‚è§’äººåƒ
    pip_position: Optional[str] = "bottom-right"  # äººåƒä½ç½®: bottom-right, bottom-left, top-right, top-left
    pip_size: Optional[str] = "medium"          # äººåƒå¤§å°: small, medium, large
    broll_enabled: bool = False                 # æ˜¯å¦å¯ç”¨ B-Roll
    broll_selections: Optional[List[dict]] = None  # B-Roll é€‰æ‹© [{clip_id, selected_asset_id}]
    background_preset: Optional[str] = None     # èƒŒæ™¯é¢„è®¾ ID
    
    # â˜…â˜…â˜… B-Roll å¢å¼ºé…ç½®ï¼ˆPhase 2ï¼‰ â˜…â˜…â˜…
    broll_display_mode: Optional[str] = "fullscreen"  # fullscreen | pip | mixed
    broll_pip_config: Optional[dict] = None     # PiP ä¸“å±é…ç½®
    broll_mixed_config: Optional[dict] = None   # æ··åˆæ¨¡å¼é…ç½®
    broll_face_detection: Optional[dict] = None # äººè„¸æ£€æµ‹ç»“æœç¼“å­˜


@router.post("/sessions/{session_id}/workflow-config")
async def save_workflow_config(
    session_id: str,
    request: WorkflowConfigRequest,
    current_user: dict = Depends(get_current_user)
):
    """
    ä¿å­˜å·¥ä½œæµé…ç½®ï¼ˆB-Roll, PiP ç­‰ï¼‰
    
    â˜… è¿™äº›é…ç½®å°†åœ¨ç¼–è¾‘å™¨åŠ è½½æ—¶ä½¿ç”¨ï¼Œè‡ªåŠ¨åº”ç”¨åˆ°ç”»å¸ƒä¸Š
    """
    try:
        user_id = current_user["user_id"]
        
        # éªŒè¯ä¼šè¯å½’å±
        session = supabase.table("workspace_sessions").select("*").eq("id", session_id).single().execute()
        if not session.data:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
        
        if session.data.get("user_id") != user_id:
            raise HTTPException(status_code=403, detail="æ— æƒæ“ä½œæ­¤ä¼šè¯")
        
        # æ›´æ–° processing_steps JSONB å­—æ®µï¼Œä¿ç•™å·²æœ‰é…ç½®
        existing_steps = session.data.get("processing_steps") or {}
        existing_steps.update({
            "pip_enabled": request.pip_enabled,
            "pip_position": request.pip_position,
            "pip_size": request.pip_size,
            "broll_enabled": request.broll_enabled,
            "broll_selections": request.broll_selections or [],
            "background_preset": request.background_preset,
            # â˜…â˜…â˜… B-Roll å¢å¼ºé…ç½® â˜…â˜…â˜…
            "broll_display_mode": request.broll_display_mode or "fullscreen",
            "broll_pip_config": request.broll_pip_config,
            "broll_mixed_config": request.broll_mixed_config,
            "broll_face_detection": request.broll_face_detection,
            "config_saved_at": datetime.utcnow().isoformat(),
        })
        
        supabase.table("workspace_sessions").update({
            "processing_steps": existing_steps,
            "updated_at": datetime.utcnow().isoformat(),
        }).eq("id", session_id).execute()
        
        logger.info(f"[Workflow] ä¿å­˜å·¥ä½œæµé…ç½®: session={session_id}, pip={request.pip_enabled}, broll={request.broll_enabled}, mode={request.broll_display_mode}")
        
        return {
            "status": "ok",
            "message": "é…ç½®å·²ä¿å­˜",
            "config": {
                "pip_enabled": request.pip_enabled,
                "broll_enabled": request.broll_enabled,
                "broll_display_mode": request.broll_display_mode,
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[Workflow] ä¿å­˜å·¥ä½œæµé…ç½®å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/sessions/{session_id}/workflow-config")
async def get_workflow_config(
    session_id: str,
    current_user: dict = Depends(get_current_user)
):
    """
    è·å–å·¥ä½œæµé…ç½®
    
    â˜… ç¼–è¾‘å™¨åŠ è½½æ—¶è°ƒç”¨ï¼Œè¯»å– PiP å’Œ B-Roll é…ç½®
    """
    try:
        user_id = current_user["user_id"]
        
        session = supabase.table("workspace_sessions").select("*").eq("id", session_id).single().execute()
        if not session.data:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
        
        if session.data.get("user_id") != user_id:
            raise HTTPException(status_code=403, detail="æ— æƒæ“ä½œæ­¤ä¼šè¯")
        
        processing_steps = session.data.get("processing_steps") or {}
        
        return {
            "session_id": session_id,
            "project_id": session.data.get("project_id"),
            "pip_enabled": processing_steps.get("pip_enabled", False),
            "pip_position": processing_steps.get("pip_position", "bottom-right"),
            "pip_size": processing_steps.get("pip_size", "medium"),
            "broll_enabled": processing_steps.get("broll_enabled", False),
            "broll_selections": processing_steps.get("broll_selections", []),
            "background_preset": processing_steps.get("background_preset"),
            # â˜…â˜…â˜… B-Roll å¢å¼ºé…ç½® â˜…â˜…â˜…
            "broll_display_mode": processing_steps.get("broll_display_mode", "fullscreen"),
            "broll_pip_config": processing_steps.get("broll_pip_config"),
            "broll_mixed_config": processing_steps.get("broll_mixed_config"),
            "broll_face_detection": processing_steps.get("broll_face_detection"),
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[Workflow] è·å–å·¥ä½œæµé…ç½®å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# â˜…â˜…â˜… äººè„¸æ£€æµ‹ APIï¼ˆç”¨äº PiP B-Roll é¿è®©ï¼‰â˜…â˜…â˜…
# ============================================

class DetectFacesRequest(BaseModel):
    """äººè„¸æ£€æµ‹è¯·æ±‚"""
    asset_id: str
    sample_interval_ms: int = 1000  # é‡‡æ ·é—´éš”
    max_samples: int = 20           # æœ€å¤§é‡‡æ ·å¸§æ•°


@router.post("/sessions/{session_id}/detect-faces")
async def detect_faces(
    session_id: str,
    request: DetectFacesRequest,
    background_tasks: BackgroundTasks,
    current_user: dict = Depends(get_current_user)
):
    """
    æ£€æµ‹è§†é¢‘ä¸­çš„äººè„¸ä½ç½®
    
    ç”¨äº PiP B-Roll ä½ç½®è®¡ç®—ï¼Œé¿å…é®æŒ¡äººè„¸
    """
    try:
        user_id = current_user["user_id"]
        
        # éªŒè¯ä¼šè¯å½’å±
        session = supabase.table("workspace_sessions").select("*").eq("id", session_id).single().execute()
        if not session.data:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
        
        if session.data.get("user_id") != user_id:
            raise HTTPException(status_code=403, detail="æ— æƒæ“ä½œæ­¤ä¼šè¯")
        
        # è·å–èµ„æºä¿¡æ¯
        asset = supabase.table("assets").select("*").eq("id", request.asset_id).single().execute()
        if not asset.data:
            raise HTTPException(status_code=404, detail="èµ„æºä¸å­˜åœ¨")
        
        # è·å–è§†é¢‘æ–‡ä»¶è·¯å¾„
        video_url = asset.data.get("url") or asset.data.get("proxy_url")
        if not video_url:
            raise HTTPException(status_code=400, detail="èµ„æºæ— å¯ç”¨è§†é¢‘ URL")
        
        # å¯¼å…¥äººè„¸æ£€æµ‹å™¨
        try:
            from app.services.face_detector import get_face_detector, FaceRegion
        except ImportError as e:
            logger.error(f"[FaceDetection] æ— æ³•å¯¼å…¥äººè„¸æ£€æµ‹å™¨: {e}")
            # è¿”å›é»˜è®¤ç»“æœï¼ˆæ‰€æœ‰ä½ç½®éƒ½å®‰å…¨ï¼‰
            return {
                "status": "ok",
                "asset_id": request.asset_id,
                "frames": [],
                "dominant_region": None,
                "safe_pip_positions": ["top-left", "top-right", "bottom-left", "bottom-right"],
                "message": "äººè„¸æ£€æµ‹æ¨¡å—æœªå®‰è£…ï¼Œä½¿ç”¨é»˜è®¤é…ç½®",
            }
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æœ¬åœ°æ–‡ä»¶è¿˜æ˜¯è¿œç¨‹ URL
        import os
        from pathlib import Path
        
        # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œå°è¯•æ‰¾åˆ°æœ¬åœ°æ–‡ä»¶
        local_path = None
        if not video_url.startswith("http"):
            # å°è¯•å¤šä¸ªå¯èƒ½çš„è·¯å¾„
            possible_paths = [
                video_url,
                f"/app/data/{video_url}",
                f"./data/{video_url}",
            ]
            for p in possible_paths:
                if Path(p).exists():
                    local_path = p
                    break
        
        if local_path:
            # æœ¬åœ°æ–‡ä»¶ï¼Œç›´æ¥æ£€æµ‹
            detector = get_face_detector()
            result = detector.detect_from_video(
                local_path,
                sample_interval_ms=request.sample_interval_ms,
                max_samples=request.max_samples,
            )
            
            return {
                "status": "ok",
                "asset_id": request.asset_id,
                "frames": [
                    {
                        "timestamp_ms": f.timestamp_ms,
                        "faces": [face.to_dict() for face in f.faces],
                    }
                    for f in result.frames
                ],
                "dominant_region": result.dominant_region.to_dict() if result.dominant_region else None,
                "safe_pip_positions": result.safe_pip_positions,
            }
        else:
            # è¿œç¨‹ URLï¼Œéœ€è¦ä¸‹è½½åå¤„ç†ï¼ˆå¼‚æ­¥ä»»åŠ¡ï¼‰
            # æš‚æ—¶è¿”å›é»˜è®¤ç»“æœ
            logger.warning(f"[FaceDetection] è¿œç¨‹è§†é¢‘æš‚ä¸æ”¯æŒäººè„¸æ£€æµ‹: {video_url}")
            return {
                "status": "ok",
                "asset_id": request.asset_id,
                "frames": [],
                "dominant_region": None,
                "safe_pip_positions": ["top-left", "top-right", "bottom-left", "bottom-right"],
                "message": "è¿œç¨‹è§†é¢‘æš‚ä¸æ”¯æŒå®æ—¶äººè„¸æ£€æµ‹",
            }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[FaceDetection] äººè„¸æ£€æµ‹å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# â˜… æ¸è¿›å¼ä¸¤æ­¥æµç¨‹: å¯åŠ¨ AI å¤„ç† (æ­¥éª¤2)
# ============================================

class StartAIProcessingRequest(BaseModel):
    """å¯åŠ¨ AI å¤„ç†è¯·æ±‚"""
    task_type: TaskType = TaskType.AI_CREATE
    # AI é…ç½®é€‰é¡¹ (å¯é€‰)
    output_ratio: Optional[str] = None  # è¾“å‡ºæ¯”ä¾‹: "9:16" æˆ– "16:9"
    template_id: Optional[str] = None   # æ¨¡æ¿ ID
    options: Optional[dict] = None      # å…¶ä»– AI é€‰é¡¹


class StartAIProcessingResponse(BaseModel):
    """å¯åŠ¨ AI å¤„ç†å“åº”"""
    status: str
    message: str
    credits_consumed: int
    credits_remaining: int


@router.post("/sessions/{session_id}/start-ai-processing", response_model=StartAIProcessingResponse)
async def start_ai_processing(
    session_id: str,
    request: StartAIProcessingRequest,
    background_tasks: BackgroundTasks,
    current_user: dict = Depends(get_current_user)
):
    """
    å¯åŠ¨ AI å¤„ç† (æ­¥éª¤2: æ£€æŸ¥ç§¯åˆ† + æ‰£é™¤ç§¯åˆ† + å¼€å§‹å¤„ç†)
    
    â˜… æ¸è¿›å¼ä¸¤æ­¥æµç¨‹:
    1. create_session - åˆ›å»ºä¼šè¯ + ä¸Šä¼ è§†é¢‘ (ä¸æ‰£ç§¯åˆ†)
    2. start-ai-processing - ç”¨æˆ·ç¡®è®¤é…ç½®åå¯åŠ¨ AI å¤„ç† (æœ¬æ¥å£ï¼Œæ‰£ç§¯åˆ†)
    
    æµç¨‹:
    1. æ ¡éªŒä¼šè¯çŠ¶æ€ (å¿…é¡»æ˜¯ä¸Šä¼ å®ŒæˆçŠ¶æ€)
    2. æ£€æŸ¥ç§¯åˆ†ä½™é¢
    3. æ‰£é™¤ç§¯åˆ†
    4. å¯åŠ¨åå°å¤„ç†ä»»åŠ¡
    """
    try:
        user_id = current_user["user_id"]
        now = datetime.utcnow().isoformat()
        
        # 1. è·å–ä¼šè¯ä¿¡æ¯
        session = supabase.table("workspace_sessions").select("*").eq("id", session_id).single().execute()
        if not session.data:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
        
        session_data = session.data
        project_id = session_data.get("project_id")
        
        # æ ¡éªŒä¼šè¯å½’å±
        if session_data.get("user_id") != user_id:
            raise HTTPException(status_code=403, detail="æ— æƒæ“ä½œæ­¤ä¼šè¯")
        
        # æ ¡éªŒä¼šè¯çŠ¶æ€: å¿…é¡»æ˜¯ completedï¼ˆfinalize-upload åçš„çŠ¶æ€ï¼‰
        if session_data.get("status") != "completed":
            raise HTTPException(
                status_code=400, 
                detail=f"ä¼šè¯çŠ¶æ€ä¸æ­£ç¡®: {session_data.get('status')}ï¼Œé¢„æœŸä¸º completedï¼ˆè¯·å…ˆå®Œæˆä¸Šä¼ ï¼‰"
            )
        
        # 2. è·å–æ‰€æœ‰å…³è”çš„ assets
        asset_ids = session_data.get("uploaded_asset_ids", [])
        if not asset_ids:
            single_asset_id = session_data.get("uploaded_asset_id")
            if single_asset_id:
                asset_ids = [single_asset_id]

        # â˜… å¼ºåˆ¶é™åˆ¶è¾“å‡ºæ¯”ä¾‹
        if request.output_ratio is not None and request.output_ratio not in ("9:16", "16:9"):
            raise HTTPException(status_code=400, detail="è¾“å‡ºæ¯”ä¾‹ä¸åˆæ³•ï¼Œä»…æ”¯æŒ 9:16 æˆ– 16:9")
        
        if not asset_ids:
            raise HTTPException(status_code=400, detail="ä¼šè¯æœªå…³è”ä»»ä½•èµ„æºï¼Œè¯·å…ˆä¸Šä¼ è§†é¢‘")
        
        # æ£€æŸ¥æ‰€æœ‰æ–‡ä»¶æ˜¯å¦éƒ½ä¸Šä¼ å®Œæˆ
        assets_result = supabase.table("assets").select("*").in_("id", asset_ids).execute()
        assets = assets_result.data or []
        
        not_ready = [a for a in assets if a.get("status") not in ("uploaded", "ready", "processing")]
        if not_ready:
            pending_names = [a.get("name", a["id"]) for a in not_ready[:3]]
            raise HTTPException(
                status_code=400, 
                detail=f"éƒ¨åˆ†æ–‡ä»¶æœªä¸Šä¼ å®Œæˆ: {', '.join(pending_names)}"
            )
        
        # 3. æ£€æŸ¥å¹¶æ‰£é™¤ç§¯åˆ† (ä»… AI åŠŸèƒ½éœ€è¦)
        credits_consumed = 0
        credits_remaining = 0
        
        if request.task_type.value == 'ai-create':
            from app.services.credit_service import get_credit_service
            credit_service = get_credit_service()
            
            # ai_create å›ºå®š 100 ç§¯åˆ†
            credits_required = 100
            
            # æ£€æŸ¥ç§¯åˆ†
            check_result = await credit_service.quick_check_credits(user_id, credits_required)
            
            if not check_result.get("allowed"):
                logger.warning(f"[AI Processing] âŒ ç§¯åˆ†ä¸è¶³: user_id={user_id}, required={credits_required}, available={check_result.get('available')}")
                raise HTTPException(
                    status_code=402,
                    detail={
                        "error": "insufficient_credits",
                        "message": f"ç§¯åˆ†ä¸è¶³ï¼Œéœ€è¦ {credits_required} ç§¯åˆ†ï¼Œå½“å‰ä½™é¢ {check_result.get('available')}",
                        "required": credits_required,
                        "available": check_result.get("available"),
                    }
                )
            
            # â˜… æ‰£é™¤ç§¯åˆ†
            consume_result = await credit_service.consume_credits(
                user_id=user_id,
                model_key="ai_create",
                credits=credits_required,  # â˜… å¿…é¡»ä¼ å…¥æ¶ˆè€—çš„ç§¯åˆ†æ•°
                ai_task_id=session_id,  # ä½¿ç”¨ session_id ä½œä¸ºä»»åŠ¡ ID
                description=f"ä¸€é”® AI æˆç‰‡ - {session_data.get('project_id', 'unknown')[:8]}",
            )
            
            if not consume_result.get("success"):
                raise HTTPException(
                    status_code=500,
                    detail=f"ç§¯åˆ†æ‰£é™¤å¤±è´¥: {consume_result.get('error', 'æœªçŸ¥é”™è¯¯')}"
                )
            
            credits_consumed = consume_result.get("credits_consumed", credits_required)
            credits_remaining = consume_result.get("credits_after", 0)
            
            logger.info(f"[AI Processing] âœ… ç§¯åˆ†æ‰£é™¤æˆåŠŸ: user_id={user_id}, consumed={credits_consumed}, remaining={credits_remaining}")
        
        # 4. æ›´æ–°ä¼šè¯é…ç½®
        update_data = {
            "selected_tasks": [request.task_type.value],
            "status": "processing",
            "current_step": "fetch",
            "progress": 0,
            "updated_at": now,
        }
        
        # ä¿å­˜ AI é…ç½®é€‰é¡¹
        if request.output_ratio or request.template_id or request.options:
            update_data["ai_config"] = {
                "output_ratio": request.output_ratio,
                "template_id": request.template_id,
                "options": request.options or {},
            }
        
        supabase.table("workspace_sessions").update(update_data).eq("id", session_id).execute()
        
        # 5. æ›´æ–°æ‰€æœ‰ assets çŠ¶æ€ä¸ºå¤„ç†ä¸­
        for asset in assets:
            supabase.table("assets").update({
                "status": "processing",
                "updated_at": now,
            }).eq("id", asset["id"]).execute()
        
        # 6. æŒ‰é¡ºåºæ’åˆ— assets
        sorted_assets = sorted(assets, key=lambda a: a.get("order_index", 0))
        
        logger.info(f"[AI Processing] ========================================")
        logger.info(f"[AI Processing] ğŸš€ å¯åŠ¨ AI å¤„ç†ä»»åŠ¡")
        logger.info(f"[AI Processing]    session_id: {session_id}")
        logger.info(f"[AI Processing]    project_id: {project_id}")
        logger.info(f"[AI Processing]    task_type: {request.task_type.value}")
        logger.info(f"[AI Processing]    credits_consumed: {credits_consumed}")
        logger.info(f"[AI Processing]    ç´ ææ•°é‡: {len(sorted_assets)}")
        logger.info(f"[AI Processing] ========================================")
        
        # 7. å¯åŠ¨åå°å¤„ç†ä»»åŠ¡
        background_tasks.add_task(
            _process_session_multi_assets,
            session_id=session_id,
            project_id=project_id,
            assets=sorted_assets,
            task_type=request.task_type.value,
        )
        
        return StartAIProcessingResponse(
            status="processing",
            message=f"AI å¤„ç†å·²å¯åŠ¨ï¼Œæ­£åœ¨å¤„ç† {len(assets)} ä¸ªç´ æ",
            credits_consumed=credits_consumed,
            credits_remaining=credits_remaining,
        )
        
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        logger.error(f"[AI Processing] âŒ å¯åŠ¨å¤±è´¥: {e}")
        logger.error(f"[AI Processing] âŒ å®Œæ•´å †æ ˆ:\n{traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# â˜… å£æ’­è§†é¢‘ç²¾ä¿®: å£ç™–/åºŸè¯æ£€æµ‹ (Defiller) - V2
# ============================================

class FillerWord(BaseModel):
    """å£ç™–è¯æ±‡"""
    word: str                      # å£ç™–è¯æ±‡ï¼ˆå¦‚"å—¯..."ã€"é‚£ä¸ª"ï¼‰
    count: int                     # å‡ºç°æ¬¡æ•°
    total_duration_ms: int         # æ€»æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰
    occurrences: List[dict]        # å‡ºç°ä½ç½® [{"start": ms, "end": ms, "clip_id": str}]


class ClipInfo(BaseModel):
    """V2: Clip ä¿¡æ¯ï¼ˆæ™ºèƒ½åˆ†æé˜¶æ®µç›´æ¥åˆ›å»ºçš„ clipsï¼‰"""
    id: str                        # clip UUID
    text: str                      # æ–‡æœ¬å†…å®¹
    start_time: int                # æ—¶é—´è½´å¼€å§‹ä½ç½® (ms)
    end_time: int                  # æ—¶é—´è½´ç»“æŸä½ç½® (ms)
    source_start: int              # æºç´ æå¼€å§‹ä½ç½® (ms)
    source_end: int                # æºç´ æç»“æŸä½ç½® (ms)
    asset_id: str                  # å…³è”çš„ asset ID
    is_filler: bool = False        # æ˜¯å¦ä¸ºå£ç™–/å¾…åˆ é™¤ç‰‡æ®µ
    filler_type: Optional[str] = None   # å£ç™–ç±»å‹: breath/hesitation/repeat_word/filler_word
    filler_reason: Optional[str] = None # å£ç™–åŸå› 
    confidence: float = 1.0        # æ£€æµ‹ç½®ä¿¡åº¦


class DetectFillersRequest(BaseModel):
    """å£ç™–æ£€æµ‹è¯·æ±‚ - â˜…â˜…â˜… æ™ºèƒ½æ¸…ç†ä¸‰é€‰é¡¹ â˜…â˜…â˜…"""
    # â˜…â˜…â˜… æ–°ç‰ˆä¸‰é€‰é¡¹å‚æ•°ï¼ˆå‚è€ƒç«å“è®¾è®¡ï¼‰â˜…â˜…â˜…
    cut_silences: bool = True           # åˆ é™¤é™éŸ³ç‰‡æ®µï¼ˆæ¢æ°”/åœé¡¿/æ­»å¯‚ï¼‰
    cut_bad_takes: bool = True          # åˆ é™¤NG/é‡å¤ç‰‡æ®µï¼ˆå£åƒ/è¯´é”™ï¼‰
    remove_filler_words: bool = True    # åˆ é™¤å£ç™–è¯ï¼ˆå—¯/é‚£ä¸ª/å°±æ˜¯ï¼‰
    
    # â˜… å‘åå…¼å®¹æ—§å‚æ•°ï¼ˆä¼šè¢«è‡ªåŠ¨è½¬æ¢ï¼‰
    detect_fillers: Optional[bool] = None   # æ—§å‚æ•°ï¼šè¯†åˆ«å£ç™–
    detect_breaths: Optional[bool] = None   # æ—§å‚æ•°ï¼šè¯†åˆ«æ¢æ°”


class DetectFillersResponse(BaseModel):
    """å£ç™–æ£€æµ‹å“åº” - V2 æ”¯æŒç›´æ¥è¿”å› clips"""
    status: str
    session_id: str
    project_id: str
    filler_words: List[FillerWord]           # æ£€æµ‹åˆ°çš„å£ç™–è¯æ±‡
    silence_segments: List[dict]             # é™éŸ³ç‰‡æ®µåˆ—è¡¨ï¼ˆå« silence_infoï¼‰
    transcript_segments: List[dict]          # å®Œæ•´è½¬å†™ç»“æœï¼ˆå‘åå…¼å®¹ï¼‰
    total_filler_duration_ms: int            # åºŸè¯æ€»æ—¶é•¿
    original_duration_ms: int                # åŸè§†é¢‘æ—¶é•¿
    estimated_savings_percent: float         # é¢„è®¡èŠ‚çœç™¾åˆ†æ¯”
    # â˜… V2 æ–°å¢å­—æ®µ
    clips: Optional[List[ClipInfo]] = None   # æ™ºèƒ½åˆ†æé˜¶æ®µåˆ›å»ºçš„ clips
    clips_created: Optional[int] = None      # åˆ›å»ºçš„ clip æ•°é‡
    filler_clips_count: Optional[int] = None # å£ç™– clip æ•°é‡


@router.post("/sessions/{session_id}/detect-fillers", response_model=DetectFillersResponse)
async def detect_fillers(
    session_id: str,
    request: DetectFillersRequest = None,
    background_tasks: BackgroundTasks = None,
    current_user: dict = Depends(get_current_user)
):
    """
    å£ç™–/åºŸè¯æ£€æµ‹ (å£æ’­è§†é¢‘ç²¾ä¿®æ¨¡å¼)
    
    â˜… å¤ç”¨ç°æœ‰ ASR + é™éŸ³æ£€æµ‹é€»è¾‘ï¼Œä¸æ‰§è¡Œ keyframe åˆ†æ
    â˜… è¿”å›åºŸè¯ç‰‡æ®µä¾›å‰ç«¯ DefillerModal ä½¿ç”¨
    â˜… æ ¹æ®é…ç½®é€‰é¡¹æ§åˆ¶æ£€æµ‹å†…å®¹
    â˜… æ€§èƒ½ä¼˜åŒ–ï¼šå¤š asset å¹¶è¡Œ ASR
    
    æµç¨‹:
    1. è·å–ä¼šè¯å…³è”çš„è§†é¢‘èµ„æº
    2. æ‰§è¡Œ ASR è½¬å†™ï¼ˆå«é™éŸ³æ£€æµ‹ï¼‰- å¹¶è¡Œå¤„ç†å¤šä¸ª asset
    3. åˆ†æå£ç™–è¯æ±‡ï¼ˆå—¯ã€å•Šã€é‚£ä¸ªã€å°±æ˜¯ç­‰ï¼‰
    4. è¿”å›ç»“æ„åŒ–çš„åºŸè¯æ•°æ®
    """
    import asyncio
    import time
    
    start_time = time.time()
    
    try:
        user_id = current_user["user_id"]
        now = datetime.utcnow().isoformat()
        
        # â˜… è·å–é…ç½®é€‰é¡¹ï¼ˆå¦‚æœæ²¡æœ‰ä¼ å…¥ï¼Œä½¿ç”¨é»˜è®¤å€¼ï¼‰
        if request is None:
            request = DetectFillersRequest()
        
        # â˜…â˜…â˜… æ–°ç‰ˆä¸‰é€‰é¡¹å‚æ•°å¤„ç† â˜…â˜…â˜…
        # å‘åå…¼å®¹ï¼šå¦‚æœä½¿ç”¨æ—§å‚æ•°ï¼Œè½¬æ¢ä¸ºæ–°å‚æ•°
        if request.detect_fillers is not None or request.detect_breaths is not None:
            # æ—§ç‰ˆæœ¬è°ƒç”¨ï¼Œè½¬æ¢ä¸ºæ–°å‚æ•°
            cut_silences = request.detect_breaths if request.detect_breaths is not None else True
            cut_bad_takes = request.detect_fillers if request.detect_fillers is not None else True
            remove_filler_words = request.detect_fillers if request.detect_fillers is not None else True
        else:
            # æ–°ç‰ˆæœ¬è°ƒç”¨
            cut_silences = request.cut_silences
            cut_bad_takes = request.cut_bad_takes
            remove_filler_words = request.remove_filler_words
        
        # æ˜ å°„åˆ°å®é™…æ£€æµ‹å¼€å…³
        detect_silences_enabled = cut_silences               # é™éŸ³æ£€æµ‹ï¼ˆæ¢æ°”/åœé¡¿/æ­»å¯‚ï¼‰
        detect_semantics_enabled = cut_bad_takes or remove_filler_words  # LLM è¯­ä¹‰åˆ†æï¼ˆNG + å£ç™–è¯ï¼‰
        
        logger.info(f"[Defiller] â˜… ä¸‰é€‰é¡¹é…ç½®: cut_silences={cut_silences}, cut_bad_takes={cut_bad_takes}, remove_filler_words={remove_filler_words}")
        logger.info(f"[Defiller] â†’ æ£€æµ‹å¼€å…³: silences={detect_silences_enabled}, semantics={detect_semantics_enabled}")
        
        # 1. è·å–ä¼šè¯ä¿¡æ¯
        session = supabase.table("workspace_sessions").select("*").eq("id", session_id).single().execute()
        if not session.data:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
        
        session_data = session.data
        project_id = session_data.get("project_id")
        
        # æ ¡éªŒä¼šè¯å½’å±
        if session_data.get("user_id") != user_id:
            raise HTTPException(status_code=403, detail="æ— æƒæ“ä½œæ­¤ä¼šè¯")
        
        # 2. è·å–å…³è”çš„ assets
        asset_ids = session_data.get("uploaded_asset_ids", [])
        if not asset_ids:
            single_asset_id = session_data.get("uploaded_asset_id")
            if single_asset_id:
                asset_ids = [single_asset_id]
        
        if not asset_ids:
            raise HTTPException(status_code=400, detail="ä¼šè¯æœªå…³è”ä»»ä½•èµ„æº")
        
        assets_result = supabase.table("assets").select("*").in_("id", asset_ids).execute()
        assets = assets_result.data or []
        
        if not assets:
            raise HTTPException(status_code=400, detail="æœªæ‰¾åˆ°èµ„æºæ–‡ä»¶")
        
        # 3. æ‰§è¡Œ ASR è½¬å†™ï¼ˆå¤ç”¨ _run_asr å‡½æ•°ï¼Œæ­£ç¡®å¤„ç† Cloudflare HLSï¼‰
        # â˜…â˜…â˜… ä¼˜åŒ–ï¼šå¤š asset å¹¶è¡Œå¤„ç† â˜…â˜…â˜…
        from ..services.supabase_client import get_file_url
        
        all_segments = []
        total_duration_ms = 0
        
        # è¿›åº¦å›è°ƒï¼ˆdetect-fillers æ— éœ€å®æ—¶è¿›åº¦ï¼Œä½¿ç”¨ç©ºå‡½æ•°ï¼‰
        def dummy_progress(step: str, progress: int):
            logger.debug(f"[Defiller] Progress: {step} = {progress}%")
        
        async def process_single_asset(asset: dict) -> tuple:
            """å¤„ç†å•ä¸ª asset çš„ ASRï¼Œè¿”å› (asset_id, segments, duration_ms)"""
            # â˜… assets è¡¨ç”¨ storage_path å­˜å‚¨ç›¸å¯¹è·¯å¾„ï¼Œéœ€è¦ç”Ÿæˆç­¾å URL
            storage_path = asset.get("storage_path")
            if not storage_path:
                logger.warning(f"[Defiller] âš ï¸ Asset {asset['id']} æ²¡æœ‰ storage_pathï¼Œè·³è¿‡")
                return (asset["id"], [], 0)
            
            # ä½¿ç”¨ get_file_url è·å–ç­¾å URL (bucket æ˜¯ "clips")
            try:
                file_url = get_file_url("clips", storage_path, expires_in=3600)
                if not file_url:
                    logger.warning(f"[Defiller] âš ï¸ æ— æ³•è·å–ç­¾å URL: {storage_path}")
                    return (asset["id"], [], 0)
            except Exception as url_err:
                logger.warning(f"[Defiller] âš ï¸ è·å–ç­¾å URL å¤±è´¥: {url_err}")
                return (asset["id"], [], 0)
            
            asset_duration = float(asset.get("duration") or 0)
            duration_ms = int(asset_duration * 1000)
            
            logger.info(f"[Defiller] å¼€å§‹è½¬å†™ asset {asset['id'][:8]}: {file_url[:60]}...")
            
            # â˜…â˜…â˜… å¤ç”¨ _run_asr å‡½æ•°ï¼Œå…³é—­ DDC ä»¥ä¿ç•™è¯­æ°”è¯ â˜…â˜…â˜…
            # enable_ddc=False: ä¸å¯ç”¨è¯­ä¹‰é¡ºæ»‘ï¼Œä¿ç•™"å—¯"ã€"å•Š"ç­‰åŸå§‹è¯­æ°”è¯
            segments = await _run_asr(
                file_url=file_url,
                update_progress=dummy_progress,
                current_progress=0,
                step_progress=100,
                asset_id=asset["id"],
                video_duration_sec=asset_duration,
                enable_ddc=False  # â˜… å£ç™–æ£€æµ‹éœ€è¦ä¿ç•™åŸå§‹è¯­æ°”è¯
            )
            
            # ä¸ºæ¯ä¸ª segment æ·»åŠ  asset_id
            for seg in segments:
                seg["asset_id"] = asset["id"]
            
            logger.info(f"[Defiller] è½¬å†™å®Œæˆ asset {asset['id'][:8]}: {len(segments)} ä¸ªç‰‡æ®µ")
            return (asset["id"], segments, duration_ms)
        
        # â˜…â˜…â˜… å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰ asset çš„ ASR â˜…â˜…â˜…
        asr_start = time.time()
        logger.info(f"[Defiller] ğŸš€ å¼€å§‹å¹¶è¡Œ ASRï¼Œå…± {len(assets)} ä¸ª asset")
        
        tasks = [process_single_asset(asset) for asset in assets]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        asr_elapsed = time.time() - asr_start
        logger.info(f"[Defiller] â±ï¸ ASR å¹¶è¡Œå®Œæˆï¼Œè€—æ—¶ {asr_elapsed:.1f}s")
        
        # æ”¶é›†ç»“æœï¼ˆæŒ‰åŸå§‹é¡ºåºï¼‰
        asset_order = {asset["id"]: i for i, asset in enumerate(assets)}
        valid_results = []
        
        for result in results:
            if isinstance(result, Exception):
                logger.error(f"[Defiller] âŒ ASR å¼‚å¸¸: {result}")
                continue
            asset_id, segments, duration_ms = result
            valid_results.append((asset_id, segments, duration_ms))
        
        # æŒ‰åŸå§‹ asset é¡ºåºæ’åºå¹¶åˆå¹¶
        valid_results.sort(key=lambda x: asset_order.get(x[0], 999))
        
        for asset_id, segments, duration_ms in valid_results:
            all_segments.extend(segments)
            total_duration_ms += duration_ms
        
        # 4. â˜… ä½¿ç”¨æ™ºèƒ½å£ç™–æ£€æµ‹æœåŠ¡
        from ..services.filler_detector import detect_all_fillers, FillerType
        
        filler_words_map = {}  # word -> {count, total_duration_ms, occurrences}
        silence_segments = []
        
        logger.info(f"[Defiller] ğŸ¤– å¼€å§‹æ™ºèƒ½å£ç™–æ£€æµ‹: {len(all_segments)} ä¸ªç‰‡æ®µ")
        
        # ç›´æ¥ä½¿ç”¨ ASR ç»“æœï¼Œæ— éœ€é¢å¤–ä¸‹è½½
        # - é™éŸ³ç‰‡æ®µï¼šä» ASR ç»“æœçš„ silence_info æå–ï¼ˆtranscribe.py å·²åˆ†ç±»ï¼‰
        # - è¯­ä¹‰åˆ†æï¼šLLM åˆ†ææ–‡æœ¬
        # â˜…â˜…â˜… ä¼ é€’ä¸‰é€‰é¡¹å‚æ•°ç»™æ£€æµ‹æœåŠ¡ â˜…â˜…â˜…
        analysis_result = await detect_all_fillers(
            segments=all_segments,  # åŒ…å«é™éŸ³å’Œæ–‡æœ¬ç‰‡æ®µ
            detect_silences=detect_silences_enabled,    # é™éŸ³æ£€æµ‹
            detect_semantics=detect_semantics_enabled,   # LLM è¯­ä¹‰åˆ†æ
            cut_bad_takes=cut_bad_takes,                 # â˜… æ–°å¢ï¼šæ˜¯å¦æ£€æµ‹ NG ç‰‡æ®µ
            remove_filler_words=remove_filler_words,     # â˜… æ–°å¢ï¼šæ˜¯å¦æ£€æµ‹å£ç™–è¯
        )
        
        logger.info(f"[Defiller] ğŸ¤– æ£€æµ‹å®Œæˆ: {len(analysis_result.detections)} ä¸ªé—®é¢˜")
        logger.info(f"[Defiller] ğŸ¤– åˆ†ç±»: {analysis_result.filler_count_by_type}")
        
        # å°†æ£€æµ‹ç»“æœè½¬æ¢ä¸º filler_words_map æ ¼å¼
        for detection in analysis_result.detections:
            # æ ¹æ®ç±»å‹ç”Ÿæˆæ˜¾ç¤ºåç§°
            type_names = {
                FillerType.BREATH: "[æ¢æ°”]",
                FillerType.HESITATION: "[å¡é¡¿]",
                FillerType.DEAD_AIR: "[æ­»å¯‚]",
                FillerType.FILLER_WORD: detection.text or "[å£ç™–è¯]",
                FillerType.REPEAT_WORD: f"[é‡å¤] {detection.text}",
                FillerType.NG_TAKE: "[NGç‰‡æ®µ]",
            }
            filler_type = type_names.get(detection.filler_type, detection.text)
            
            duration_ms = detection.duration_ms
            
            if filler_type not in filler_words_map:
                filler_words_map[filler_type] = {"count": 0, "total_duration_ms": 0, "occurrences": []}
            
            filler_words_map[filler_type]["count"] += 1
            filler_words_map[filler_type]["total_duration_ms"] += duration_ms
            filler_words_map[filler_type]["occurrences"].append({
                "start": detection.start,
                "end": detection.end,
                "asset_id": detection.asset_id,
                "text": detection.text,
                "reason": detection.reason,
                "confidence": detection.confidence,
                "segment_id": detection.segment_id,
            })
            
            # å¦‚æœæ˜¯é™éŸ³ç±»å‹ï¼Œæ·»åŠ åˆ° silence_segments
            if detection.filler_type in (FillerType.BREATH, FillerType.HESITATION, FillerType.DEAD_AIR):
                silence_segments.append({
                    "id": detection.segment_id,
                    "text": "",
                    "start": detection.start,
                    "end": detection.end,
                    "asset_id": detection.asset_id,
                    "silence_info": {
                        "classification": detection.filler_type.value,
                        "duration_ms": duration_ms,
                        "reason": detection.reason,
                    }
                })
        
        # 5. æ„å»ºå“åº”
        filler_words = [
            FillerWord(
                word=word,
                count=data["count"],
                total_duration_ms=data["total_duration_ms"],
                occurrences=data["occurrences"]
            )
            for word, data in sorted(filler_words_map.items(), key=lambda x: -x[1]["count"])
        ]
        
        total_filler_duration = sum(f.total_duration_ms for f in filler_words)
        savings_percent = (total_filler_duration / total_duration_ms * 100) if total_duration_ms > 0 else 0
        
        logger.info(f"[Defiller] âœ… æ£€æµ‹å®Œæˆ: {len(filler_words)} ç±»å£ç™–, æ€»æ—¶é•¿ {total_filler_duration}ms")
        logger.info(f"[Defiller]    é¢„è®¡èŠ‚çœ {savings_percent:.1f}%")
        
        # â˜…â˜…â˜… V2: æ™ºèƒ½åˆ†æé˜¶æ®µç›´æ¥åˆ›å»º clips â˜…â˜…â˜…
        # æ„å»º filler æ£€æµ‹ç»“æœçš„å¿«é€ŸæŸ¥æ‰¾è¡¨ (segment_id -> detection_info)
        filler_lookup = {}
        for detection in analysis_result.detections:
            filler_lookup[detection.segment_id] = {
                "filler_type": detection.filler_type.value,
                "reason": detection.reason,
                "confidence": detection.confidence,
            }
        
        # è·å–æˆ–åˆ›å»ºè§†é¢‘è½¨é“
        tracks_result = supabase.table("tracks").select("id").eq("project_id", project_id).eq("order_index", 0).execute()
        if tracks_result.data:
            track_id = tracks_result.data[0]["id"]
            logger.info(f"[Defiller V2] ä½¿ç”¨å·²æœ‰è½¨é“: {track_id}")
        else:
            # åˆ›å»ºæ–°è½¨é“
            track_id = str(uuid4())
            supabase.table("tracks").insert({
                "id": track_id,
                "project_id": project_id,
                "name": "è§†é¢‘è½¨é“",
                "type": "video",
                "order_index": 0,
                "created_at": now,
                "updated_at": now,
            }).execute()
            logger.info(f"[Defiller V2] åˆ›å»ºæ–°è½¨é“: {track_id}")
        
        # â˜…â˜…â˜… è·å–æˆ–åˆ›å»ºå­—å¹•è½¨é“ â˜…â˜…â˜…
        # å­—å¹•è½¨é“åº”è¯¥åœ¨ 100+ å±‚çº§ï¼ˆå§‹ç»ˆåœ¨æœ€ä¸Šå±‚ï¼‰
        subtitle_tracks_result = supabase.table("tracks").select("id").eq("project_id", project_id).eq("name", "å­—å¹•").execute()
        if not subtitle_tracks_result.data:
            # ä¹Ÿæ£€æŸ¥æ—§çš„ order_index=1 çš„è½¨é“ï¼ˆå…¼å®¹æ—§æ•°æ®ï¼‰
            subtitle_tracks_result = supabase.table("tracks").select("id").eq("project_id", project_id).eq("order_index", 1).execute()
        
        if subtitle_tracks_result.data:
            subtitle_track_id = subtitle_tracks_result.data[0]["id"]
            # â˜… ç¡®ä¿å­—å¹•è½¨é“ order_index æ˜¯ 100+
            supabase.table("tracks").update({"order_index": 100}).eq("id", subtitle_track_id).execute()
            logger.info(f"[Defiller V2] ä½¿ç”¨å·²æœ‰å­—å¹•è½¨é“: {subtitle_track_id}, æ›´æ–° order_index=100")
        else:
            # åˆ›å»ºå­—å¹•è½¨é“
            subtitle_track_id = str(uuid4())
            supabase.table("tracks").insert({
                "id": subtitle_track_id,
                "project_id": project_id,
                "name": "å­—å¹•",
                "order_index": 100,  # â˜… å­—å¹•å§‹ç»ˆåœ¨æœ€ä¸Šå±‚
                "created_at": now,
                "updated_at": now,
            }).execute()
            logger.info(f"[Defiller V2] åˆ›å»ºå­—å¹•è½¨é“: {subtitle_track_id}, order_index=100")
        
        # åˆ é™¤å·²æœ‰çš„ clipsï¼ˆå¦‚æœé‡æ–°åˆ†æï¼‰
        if assets:
            asset_ids_list = [a["id"] for a in assets]
            supabase.table("clips").delete().in_("asset_id", asset_ids_list).execute()
            logger.info(f"[Defiller V2] æ¸…ç†å·²æœ‰ clips")
        
        # åˆ›å»º clipsï¼ˆæ¯ä¸ª segment å¯¹åº”ä¸€ä¸ªè§†é¢‘ clip + ä¸€ä¸ªå­—å¹• clipï¼‰
        created_clips = []
        subtitle_clips = []  # â˜…â˜…â˜… æ–°å¢ï¼šå­—å¹• clips â˜…â˜…â˜…
        clip_infos = []
        clip_start_time = 0  # æ—¶é—´è½´ä¸Šçš„ç´¯ç§¯ä½ç½®
        filler_clips_count = 0
        
        for idx, seg in enumerate(all_segments):
            clip_id = str(uuid4())
            subtitle_clip_id = str(uuid4())  # â˜… å­—å¹• clip ID
            seg_start = seg.get("start", 0)
            seg_end = seg.get("end", 0)
            seg_text = seg.get("text", "")
            seg_asset_id = seg.get("asset_id", assets[0]["id"] if assets else None)
            duration_ms = seg_end - seg_start
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºå£ç™–ç‰‡æ®µ
            seg_id = seg.get("id", f"seg-{idx}")
            filler_info = filler_lookup.get(seg_id)
            is_filler = filler_info is not None
            filler_type = filler_info["filler_type"] if filler_info else None
            filler_reason = filler_info["reason"] if filler_info else None
            confidence = filler_info["confidence"] if filler_info else 1.0
            
            if is_filler:
                filler_clips_count += 1
            
            # æ„å»º clip metadata
            metadata = {
                "is_filler": is_filler,
                "filler_type": filler_type,
                "filler_reason": filler_reason,
                "confidence": confidence,
                "segment_index": idx,
                "hidden": False,  # ç”¨äº apply-trimming è½¯åˆ é™¤
            }
            
            # â˜… è§†é¢‘ clip
            clip_data = {
                "id": clip_id,
                "track_id": track_id,
                "asset_id": seg_asset_id,
                "clip_type": "video",
                "start_time": clip_start_time,
                "end_time": clip_start_time + duration_ms,
                "source_start": seg_start,
                "source_end": seg_end,
                "content_text": seg_text or None,
                "metadata": metadata,
                "created_at": now,
                "updated_at": now,
            }
            created_clips.append(clip_data)
            
            # â˜…â˜…â˜… å­—å¹• clipï¼ˆæœ‰æ–‡æœ¬å†…å®¹æ‰åˆ›å»ºï¼‰â˜…â˜…â˜…
            if seg_text and seg_text.strip():
                subtitle_clip_data = {
                    "id": subtitle_clip_id,
                    "track_id": subtitle_track_id,
                    "asset_id": seg_asset_id,
                    "clip_type": "subtitle",
                    "start_time": clip_start_time,
                    "end_time": clip_start_time + duration_ms,
                    "source_start": seg_start,
                    "source_end": seg_end,
                    "content_text": seg_text,
                    "metadata": {
                        "video_clip_id": clip_id,  # å…³è”åˆ°è§†é¢‘ clip
                        "is_filler": is_filler,
                        "segment_index": idx,
                        "hidden": False,
                    },
                    "created_at": now,
                    "updated_at": now,
                }
                subtitle_clips.append(subtitle_clip_data)
            
            # æ„å»º ClipInfo å“åº”
            clip_infos.append(ClipInfo(
                id=clip_id,
                text=seg_text,
                start_time=clip_start_time,
                end_time=clip_start_time + duration_ms,
                source_start=seg_start,
                source_end=seg_end,
                asset_id=seg_asset_id,
                is_filler=is_filler,
                filler_type=filler_type,
                filler_reason=filler_reason,
                confidence=confidence,
            ))
            
            clip_start_time += duration_ms
        
        # æ‰¹é‡æ’å…¥ clips
        if created_clips:
            supabase.table("clips").insert(created_clips).execute()
            logger.info(f"[Defiller V2] âœ… åˆ›å»º {len(created_clips)} ä¸ªè§†é¢‘ clipsï¼Œå…¶ä¸­ {filler_clips_count} ä¸ªä¸ºå£ç™–")
        
        # â˜…â˜…â˜… æ‰¹é‡æ’å…¥å­—å¹• clips â˜…â˜…â˜…
        if subtitle_clips:
            supabase.table("clips").insert(subtitle_clips).execute()
            logger.info(f"[Defiller V2] âœ… åˆ›å»º {len(subtitle_clips)} ä¸ªå­—å¹• clips")
        
        # â˜… æ€»è€—æ—¶ç»Ÿè®¡
        total_elapsed = time.time() - start_time
        logger.info(f"[Defiller] â±ï¸ æ€»è€—æ—¶: {total_elapsed:.1f}s (ASR: {asr_elapsed:.1f}s)")
        
        return DetectFillersResponse(
            status="completed",
            session_id=session_id,
            project_id=project_id,
            filler_words=filler_words,
            silence_segments=silence_segments,
            transcript_segments=all_segments,
            total_filler_duration_ms=total_filler_duration,
            original_duration_ms=total_duration_ms,
            estimated_savings_percent=round(savings_percent, 1),
            # V2 æ–°å¢
            clips=clip_infos,
            clips_created=len(created_clips),
            filler_clips_count=filler_clips_count,
        )
        
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        logger.error(f"[Defiller] âŒ æ£€æµ‹å¤±è´¥: {e}")
        logger.error(f"[Defiller] âŒ å®Œæ•´å †æ ˆ:\n{traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# â˜… å£æ’­è§†é¢‘ç²¾ä¿®: åº”ç”¨ä¿®å‰ª (Apply Trimming) - V2
# ============================================

class TrimSegment(BaseModel):
    """éœ€è¦åˆ é™¤çš„ç‰‡æ®µ"""
    start: int                # å¼€å§‹æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
    end: int                  # ç»“æŸæ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
    asset_id: Optional[str] = None  # æ‰€å±èµ„æº ID
    reason: Optional[str] = None    # åˆ é™¤åŸå› ï¼ˆå¦‚ "filler_word:å—¯"ï¼‰


class TranscriptSegmentInput(BaseModel):
    """è½¬å†™ç‰‡æ®µè¾“å…¥"""
    id: Optional[str] = None
    text: str
    start: int  # æ¯«ç§’
    end: int    # æ¯«ç§’
    asset_id: Optional[str] = None


class ApplyTrimmingRequest(BaseModel):
    """åº”ç”¨ä¿®å‰ªè¯·æ±‚"""
    removed_fillers: List[str]        # ç”¨æˆ·é€‰æ‹©åˆ é™¤çš„å£ç™–è¯æ±‡
    trim_segments: Optional[List[TrimSegment]] = None  # å¯é€‰ï¼šå…·ä½“è¦åˆ é™¤çš„ç‰‡æ®µ
    transcript_segments: Optional[List[TranscriptSegmentInput]] = None  # â˜… å‰ç«¯ä¼ å…¥çš„è½¬å†™ç»“æœ
    create_clips_from_segments: bool = True  # æ˜¯å¦æ ¹æ®ä¿ç•™ç‰‡æ®µåˆ›å»º clips
    # â˜… æ–°å¢ï¼šç”¨æˆ·é€‰ä¸­çš„ç‰‡æ®µ IDï¼ˆç”¨äºæŒ‰ ID åˆ é™¤ï¼‰
    segment_ids_to_remove: Optional[List[str]] = None


class ApplyTrimmingResponse(BaseModel):
    """åº”ç”¨ä¿®å‰ªå“åº”"""
    status: str
    session_id: str
    project_id: str
    clips_created: int                # åˆ›å»ºçš„ clip æ•°é‡
    total_duration_ms: int            # ä¿®å‰ªåçš„æ€»æ—¶é•¿
    removed_duration_ms: int          # è¢«åˆ é™¤çš„æ—¶é•¿
    clips: List[dict]                 # åˆ›å»ºçš„ clips åˆ—è¡¨


# â˜… V2: ç®€åŒ–çš„åº”ç”¨ä¿®å‰ªè¯·æ±‚ï¼ˆç›´æ¥æ“ä½œ clip IDsï¼‰
class ApplyTrimmingRequestV2(BaseModel):
    """V2 åº”ç”¨ä¿®å‰ªè¯·æ±‚ - ç›´æ¥æŒ‡å®šè¦åˆ é™¤/ä¿ç•™çš„ clip IDs"""
    clip_ids_to_hide: List[str]              # è¦éšè—ï¼ˆè½¯åˆ é™¤ï¼‰çš„ clip IDs
    clip_ids_to_show: Optional[List[str]] = None  # è¦æ¢å¤æ˜¾ç¤ºçš„ clip IDsï¼ˆç”¨æˆ·æ‰‹åŠ¨æ¢å¤ï¼‰


class ApplyTrimmingResponseV2(BaseModel):
    """V2 åº”ç”¨ä¿®å‰ªå“åº”"""
    status: str
    session_id: str
    project_id: str
    hidden_clips_count: int           # éšè—çš„ clip æ•°é‡
    visible_clips_count: int          # å¯è§çš„ clip æ•°é‡
    removed_duration_ms: int          # è¢«éšè—çš„æ€»æ—¶é•¿
    remaining_duration_ms: int        # ä¿ç•™çš„æ€»æ—¶é•¿


@router.post("/sessions/{session_id}/apply-trimming-v2", response_model=ApplyTrimmingResponseV2)
async def apply_trimming_v2(
    session_id: str,
    request: ApplyTrimmingRequestV2,
    current_user: dict = Depends(get_current_user)
):
    """
    V2 åº”ç”¨å£ç™–ä¿®å‰ª - ç®€åŒ–ç‰ˆæœ¬
    
    â˜… ç›´æ¥æ“ä½œ clips çš„ metadata.hidden å­—æ®µ
    â˜… ä¸é‡æ–°åˆ›å»º clipsï¼Œåªæ ‡è®°éšè—/æ˜¾ç¤º
    
    æµç¨‹:
    1. éªŒè¯ä¼šè¯æƒé™
    2. æ‰¹é‡æ›´æ–° clips çš„ metadata.hidden å­—æ®µ
    3. è¿”å›ç»Ÿè®¡ä¿¡æ¯
    """
    try:
        user_id = current_user["user_id"]
        now = datetime.utcnow().isoformat()
        
        # 1. éªŒè¯ä¼šè¯
        session = supabase.table("workspace_sessions").select("*").eq("id", session_id).single().execute()
        if not session.data:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
        
        session_data = session.data
        project_id = session_data.get("project_id")
        
        if session_data.get("user_id") != user_id:
            raise HTTPException(status_code=403, detail="æ— æƒæ“ä½œæ­¤ä¼šè¯")
        
        logger.info(f"[ApplyTrimming V2] å¼€å§‹: session={session_id}, hide={len(request.clip_ids_to_hide)}, show={len(request.clip_ids_to_show or [])}")
        
        # 2. è·å–æ‰€æœ‰ç›¸å…³ clips
        asset_ids = session_data.get("uploaded_asset_ids", [])
        if not asset_ids:
            single_asset_id = session_data.get("uploaded_asset_id")
            if single_asset_id:
                asset_ids = [single_asset_id]
        
        all_clips_result = supabase.table("clips").select("*").in_("asset_id", asset_ids).execute()
        all_clips = all_clips_result.data or []
        
        if not all_clips:
            raise HTTPException(status_code=400, detail="æœªæ‰¾åˆ° clipsï¼Œè¯·å…ˆæ‰§è¡Œæ™ºèƒ½åˆ†æ")
        
        # 3. æ‰¹é‡æ›´æ–° hidden çŠ¶æ€
        hidden_duration_ms = 0
        visible_duration_ms = 0
        hidden_count = 0
        visible_count = 0
        
        for clip in all_clips:
            clip_id = clip["id"]
            metadata = clip.get("metadata") or {}
            duration = (clip.get("end_time") or 0) - (clip.get("start_time") or 0)
            
            if clip_id in request.clip_ids_to_hide:
                # æ ‡è®°ä¸ºéšè—
                metadata["hidden"] = True
                hidden_duration_ms += duration
                hidden_count += 1
            elif request.clip_ids_to_show and clip_id in request.clip_ids_to_show:
                # æ¢å¤æ˜¾ç¤º
                metadata["hidden"] = False
                visible_duration_ms += duration
                visible_count += 1
            elif not metadata.get("hidden", False):
                # ä¿æŒå¯è§
                visible_duration_ms += duration
                visible_count += 1
            else:
                # ä¿æŒéšè—
                hidden_duration_ms += duration
                hidden_count += 1
            
            # æ›´æ–° metadata
            supabase.table("clips").update({
                "metadata": metadata,
                "updated_at": now,
            }).eq("id", clip_id).execute()
        
        # 4. æ›´æ–°ä¼šè¯çŠ¶æ€
        supabase.table("workspace_sessions").update({
            "status": "completed",
            "updated_at": now,
        }).eq("id", session_id).execute()
        
        logger.info(f"[ApplyTrimming V2] âœ… å®Œæˆ: hidden={hidden_count}, visible={visible_count}")
        
        return ApplyTrimmingResponseV2(
            status="completed",
            session_id=session_id,
            project_id=project_id,
            hidden_clips_count=hidden_count,
            visible_clips_count=visible_count,
            removed_duration_ms=hidden_duration_ms,
            remaining_duration_ms=visible_duration_ms,
        )
        
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        logger.error(f"[ApplyTrimming V2] âŒ å¤±è´¥: {e}")
        logger.error(f"[ApplyTrimming V2] âŒ å®Œæ•´å †æ ˆ:\n{traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=str(e))


# ä¿ç•™æ—§ç‰ˆæœ¬ apply-trimming å‘åå…¼å®¹
@router.post("/sessions/{session_id}/apply-trimming", response_model=ApplyTrimmingResponse)
async def apply_trimming(
    session_id: str,
    request: ApplyTrimmingRequest,
    background_tasks: BackgroundTasks,
    current_user: dict = Depends(get_current_user)
):
    """
    åº”ç”¨å£ç™–ä¿®å‰ª (å£æ’­è§†é¢‘ç²¾ä¿®æ¨¡å¼) - V1 æ—§ç‰ˆæœ¬
    
    â˜… æ ¹æ®ç”¨æˆ·åœ¨ DefillerModal ä¸­çš„é€‰æ‹©ï¼Œæ‰§è¡Œå®é™…çš„ä¿®å‰ªæ“ä½œ
    â˜… åˆ›å»ºæ–°çš„ clips å¹¶æ›´æ–° project
    
    æµç¨‹:
    1. è·å–ä¼šè¯å…³è”çš„è§†é¢‘èµ„æºå’Œè½¬å†™ç»“æœ
    2. æ ¹æ®é€‰ä¸­çš„å£ç™–è¯æ±‡è¿‡æ»¤å‡ºéœ€è¦åˆ é™¤çš„ç‰‡æ®µ
    3. è®¡ç®—ä¿ç•™ç‰‡æ®µå¹¶åˆ›å»º clips
    4. æ›´æ–°æ•°æ®åº“
    """
    try:
        user_id = current_user["user_id"]
        now = datetime.utcnow().isoformat()
        
        # 1. è·å–ä¼šè¯ä¿¡æ¯
        session = supabase.table("workspace_sessions").select("*").eq("id", session_id).single().execute()
        if not session.data:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
        
        session_data = session.data
        project_id = session_data.get("project_id")
        
        # æ ¡éªŒä¼šè¯å½’å±
        if session_data.get("user_id") != user_id:
            raise HTTPException(status_code=403, detail="æ— æƒæ“ä½œæ­¤ä¼šè¯")
        
        # 2. è·å–å…³è”çš„ assets
        asset_ids = session_data.get("uploaded_asset_ids", [])
        if not asset_ids:
            single_asset_id = session_data.get("uploaded_asset_id")
            if single_asset_id:
                asset_ids = [single_asset_id]
        
        if not asset_ids:
            raise HTTPException(status_code=400, detail="ä¼šè¯æœªå…³è”ä»»ä½•èµ„æº")
        
        assets_result = supabase.table("assets").select("*").in_("id", asset_ids).execute()
        assets = assets_result.data or []
        
        if not assets:
            raise HTTPException(status_code=400, detail="æœªæ‰¾åˆ°èµ„æºæ–‡ä»¶")
        
        # 3. è·å–å·²æœ‰çš„è½¬å†™ç»“æœï¼ˆä» clips æˆ– transcripts è¡¨ï¼‰
        # å…ˆæ£€æŸ¥æ˜¯å¦å·²æ‰§è¡Œè¿‡ detect-fillers (clips è¡¨æ²¡æœ‰ project_idï¼Œç”¨ asset_id æŸ¥è¯¢)
        existing_clips = supabase.table("clips").select("*").in_("asset_id", asset_ids).execute()
        existing_clips_data = existing_clips.data or []
        
        # å¦‚æœæœ‰ trim_segmentsï¼Œç›´æ¥ä½¿ç”¨ï¼›å¦åˆ™éœ€è¦é‡æ–°åˆ†æ
        trim_segments = request.trim_segments or []
        removed_fillers = set(request.removed_fillers)
        
        logger.info(f"[ApplyTrimming] å¼€å§‹ä¿®å‰ª: session={session_id}, project={project_id}")
        logger.info(f"[ApplyTrimming] åˆ é™¤çš„å£ç™–: {removed_fillers}")
        
        # 4. å¦‚æœæ²¡æœ‰æä¾›å…·ä½“çš„ trim_segmentsï¼Œéœ€è¦é‡æ–°æ‰§è¡Œ ASR åˆ†æ
        if not trim_segments:
            from ..tasks.transcribe import transcribe_audio
            
            all_segments = []
            total_duration_ms = 0
            
            for asset in assets:
                file_url = asset.get("file_url") or asset.get("url")
                if not file_url:
                    continue
                
                asset_duration = int((asset.get("duration") or 0) * 1000)
                total_duration_ms += asset_duration
                
                # ä½¿ç”¨ç¼“å­˜çš„è½¬å†™ç»“æœï¼ˆå¦‚æœæœ‰ï¼‰
                cached_transcript = asset.get("metadata", {}).get("transcript_segments")
                if cached_transcript:
                    segments = cached_transcript
                else:
                    result = await transcribe_audio(
                        audio_url=file_url,
                        language="zh",
                    )
                    segments = result.get("segments", [])
                
                for seg in segments:
                    seg["asset_id"] = asset["id"]
                all_segments.extend(segments)
            
            # æ ¹æ® removed_fillers æ ‡è®°éœ€è¦åˆ é™¤çš„ç‰‡æ®µ
            FILLER_PATTERNS = list(removed_fillers)
            
            for seg in all_segments:
                silence_info = seg.get("silence_info")
                text = seg.get("text", "").strip()
                should_remove = False
                reason = None
                
                # æ£€æŸ¥é™éŸ³ç‰‡æ®µ
                if silence_info:
                    classification = silence_info.get("classification")
                    filler_type = f"[{classification}]"
                    if filler_type in removed_fillers:
                        should_remove = True
                        reason = f"silence:{classification}"
                
                # æ£€æŸ¥æ–‡æœ¬ä¸­çš„å£ç™–è¯æ±‡
                if text and not should_remove:
                    for pattern in FILLER_PATTERNS:
                        if pattern in text and not pattern.startswith("["):
                            should_remove = True
                            reason = f"filler_word:{pattern}"
                            break
                
                if should_remove:
                    trim_segments.append(TrimSegment(
                        start=int(seg.get("start", 0)),
                        end=int(seg.get("end", 0)),
                        asset_id=seg.get("asset_id"),
                        reason=reason,
                    ))
        
        # 5. è®¡ç®—ä¿ç•™ç‰‡æ®µå¹¶åˆ›å»º clips
        # â˜… ç®€åŒ–é€»è¾‘ï¼šå• asset åœºæ™¯ä¸‹ï¼Œæ‰€æœ‰ trim_segments ç›´æ¥å½’å±è¯¥ asset
        logger.info(f"[ApplyTrimming] æ”¶åˆ° {len(trim_segments)} ä¸ª trim_segments, {len(assets)} ä¸ª assets")
        
        if len(assets) == 1:
            # å• asset åœºæ™¯ï¼ˆå£æ’­è§†é¢‘ç²¾ä¿®çš„ä¸»è¦åœºæ™¯ï¼‰
            asset = assets[0]
            asset_id = asset["id"]
            duration_ms = int((asset.get("duration") or 0) * 1000)
            
            # æ‰€æœ‰ trim_segments éƒ½å±äºè¿™ä¸ª asset
            all_trim_segs = [{"start": seg.start, "end": seg.end} for seg in trim_segments]
            
            asset_segments = {
                asset_id: {
                    "asset": asset,
                    "trim_segments": all_trim_segs,
                    "duration_ms": duration_ms,
                }
            }
            logger.info(f"[ApplyTrimming] å• asset æ¨¡å¼: {asset_id}, duration={duration_ms}ms, trim_segs={len(all_trim_segs)}")
        else:
            # å¤š asset åœºæ™¯ï¼ˆéœ€è¦ asset_id æ¥åŒºåˆ†ï¼‰
            asset_segments = {}
            for asset in assets:
                asset_segments[asset["id"]] = {
                    "asset": asset,
                    "trim_segments": [],
                    "duration_ms": int((asset.get("duration") or 0) * 1000),
                }
            
            for trim_seg in trim_segments:
                if trim_seg.asset_id and trim_seg.asset_id in asset_segments:
                    asset_segments[trim_seg.asset_id]["trim_segments"].append({
                        "start": trim_seg.start,
                        "end": trim_seg.end,
                    })
        
        # åˆå¹¶é‡å çš„ä¿®å‰ªç‰‡æ®µ
        def merge_overlapping_segments(segments):
            if not segments:
                return []
            sorted_segs = sorted(segments, key=lambda x: x["start"])
            merged = [sorted_segs[0]]
            for seg in sorted_segs[1:]:
                if seg["start"] <= merged[-1]["end"]:
                    merged[-1]["end"] = max(merged[-1]["end"], seg["end"])
                else:
                    merged.append(seg)
            return merged
        
        # è®¡ç®—ä¿ç•™ç‰‡æ®µ
        created_clips = []
        total_removed_duration = 0
        clip_start_time = 0  # å…¨å±€æ—¶é—´è½´ä¸Šçš„èµ·å§‹æ—¶é—´
        
        # è·å–ä¸»è½¨é“ (tracks è¡¨æ²¡æœ‰ track_typeï¼Œé€šè¿‡ order_index=0 åˆ¤æ–­ä¸»è½¨é“)
        track_result = supabase.table("tracks").select("id").eq("project_id", project_id).eq("order_index", 0).single().execute()
        if not track_result.data:
            # åˆ›å»ºé»˜è®¤ä¸»è½¨é“ (tracks è¡¨åªæœ‰ name, order_index ç­‰å­—æ®µï¼Œæ²¡æœ‰ track_type)
            track_id = str(uuid4())
            supabase.table("tracks").insert({
                "id": track_id,
                "project_id": project_id,
                "name": "ä¸»è½¨é“",
                "order_index": 0,
                "created_at": now,
            }).execute()
        else:
            track_id = track_result.data["id"]
        
        # åˆ é™¤ç°æœ‰çš„ clipsï¼ˆé€šè¿‡ asset_ids åˆ é™¤ï¼‰
        asset_ids_list = list(asset_segments.keys())
        if asset_ids_list:
            supabase.table("clips").delete().in_("asset_id", asset_ids_list).execute()
        
        for asset_id, asset_data in asset_segments.items():
            asset = asset_data["asset"]
            duration_ms = asset_data["duration_ms"]
            trim_segs = merge_overlapping_segments(asset_data["trim_segments"])
            
            logger.info(f"[ApplyTrimming] Asset {asset_id}: duration={duration_ms}ms, trim_segs={len(trim_segs)}")
            for i, seg in enumerate(trim_segs):
                logger.info(f"[ApplyTrimming]   trim[{i}]: {seg['start']}-{seg['end']}ms")
            
            # è®¡ç®—è¢«åˆ é™¤çš„æ—¶é•¿
            for seg in trim_segs:
                total_removed_duration += seg["end"] - seg["start"]
            
            # è®¡ç®—ä¿ç•™ç‰‡æ®µ
            keep_segments = []
            current_pos = 0
            
            for trim_seg in trim_segs:
                if trim_seg["start"] > current_pos:
                    keep_segments.append({
                        "start": current_pos,
                        "end": trim_seg["start"],
                    })
                current_pos = trim_seg["end"]
            
            # æœ€åä¸€ä¸ªä¿ç•™ç‰‡æ®µ
            if current_pos < duration_ms:
                keep_segments.append({
                    "start": current_pos,
                    "end": duration_ms,
                })
            
            logger.info(f"[ApplyTrimming] è®¡ç®—å‡º {len(keep_segments)} ä¸ªä¿ç•™ç‰‡æ®µ")
            for i, seg in enumerate(keep_segments):
                logger.info(f"[ApplyTrimming]   keep[{i}]: {seg['start']}-{seg['end']}ms")
            
            # â˜… ä½¿ç”¨å‰ç«¯ä¼ å…¥çš„ transcript_segmentsï¼ˆä¸å†ä»æ•°æ®åº“æŸ¥è¯¢ï¼‰
            transcript_segments = []
            if request.transcript_segments:
                transcript_segments = [
                    {"text": seg.text, "start": seg.start, "end": seg.end}
                    for seg in request.transcript_segments
                    if not seg.asset_id or seg.asset_id == asset_id
                ]
            
            logger.info(f"[ApplyTrimming] è·å–è½¬å†™ç»“æœ: {len(transcript_segments)} ä¸ªç‰‡æ®µ")
            if not transcript_segments:
                logger.warning(f"[ApplyTrimming] âš ï¸ æ— è½¬å†™ç»“æœï¼Œclips å°†æ²¡æœ‰ content_text")
            
            def get_text_for_range(start_ms: int, end_ms: int) -> str:
                """æ ¹æ®æ—¶é—´èŒƒå›´æå–è½¬å†™æ–‡æœ¬"""
                texts = []
                for seg in transcript_segments:
                    seg_start = seg.get("start", 0)
                    seg_end = seg.get("end", 0)
                    # å¦‚æœç‰‡æ®µä¸æ—¶é—´èŒƒå›´æœ‰äº¤é›†
                    if seg_end > start_ms and seg_start < end_ms:
                        text = seg.get("text", "").strip()
                        if text:
                            texts.append(text)
                return "".join(texts)
            
            # ä¸ºæ¯ä¸ªä¿ç•™ç‰‡æ®µåˆ›å»º clip
            for i, keep_seg in enumerate(keep_segments):
                clip_id = str(uuid4())  # å®Œæ•´çš„ UUIDï¼Œä¸èƒ½æˆªæ–­
                clip_duration = keep_seg["end"] - keep_seg["start"]
                
                # â˜… æå–è¯¥æ—¶é—´æ®µçš„è½¬å†™æ–‡æœ¬
                clip_text = get_text_for_range(keep_seg["start"], keep_seg["end"])
                
                clip_data = {
                    "id": clip_id,
                    "track_id": track_id,
                    "asset_id": asset_id,
                    "clip_type": "video",
                    "start_time": clip_start_time,
                    "end_time": clip_start_time + clip_duration,
                    "source_start": keep_seg["start"],
                    "source_end": keep_seg["end"],
                    "content_text": clip_text or None,  # â˜… ä¿å­˜è½¬å†™æ–‡æœ¬
                    "created_at": now,
                    "updated_at": now,
                }
                
                text_preview = (clip_text[:50] + "...") if clip_text and len(clip_text) > 50 else (clip_text or "(æ— æ–‡æœ¬)")
                logger.info(f"[ApplyTrimming] åˆ›å»º clip[{i}]: {keep_seg['start']}-{keep_seg['end']}ms, text={text_preview}")
                
                created_clips.append(clip_data)
                clip_start_time += clip_duration
        
        # 6. æ‰¹é‡æ’å…¥ clips
        if created_clips:
            supabase.table("clips").insert(created_clips).execute()
        
        # â˜…â˜…â˜… 7. åˆ›å»ºå­—å¹•è½¨é“å’Œå­—å¹• clips â˜…â˜…â˜…
        subtitle_clips = []
        text_track_id = None
        
        if request.transcript_segments:
            # åˆ›å»ºå­—å¹•è½¨é“
            text_track_id = str(uuid4())
            supabase.table("tracks").insert({
                "id": text_track_id,
                "project_id": project_id,
                "name": "å­—å¹•",
                "order_index": 1,  # å­—å¹•è½¨é“åœ¨è§†é¢‘è½¨é“ä¸‹æ–¹
                "created_at": now,
            }).execute()
            logger.info(f"[ApplyTrimming] åˆ›å»ºå­—å¹•è½¨é“: {text_track_id}")
            
            # æ”¶é›†æ‰€æœ‰è½¬å†™ç‰‡æ®µ
            all_transcript_segs = [
                {"text": seg.text, "start": seg.start, "end": seg.end, "asset_id": seg.asset_id}
                for seg in request.transcript_segments
            ]
            
            # åˆå¹¶æ‰€æœ‰ä¿®å‰ªç‰‡æ®µç”¨äºè¿‡æ»¤
            all_trim_ranges = [{"start": seg.start, "end": seg.end} for seg in trim_segments]
            merged_trim = merge_overlapping_segments(all_trim_ranges)
            
            def is_in_trim_range(start_ms: int, end_ms: int) -> bool:
                """æ£€æŸ¥æ—¶é—´èŒƒå›´æ˜¯å¦åœ¨ä¿®å‰ªèŒƒå›´å†…ï¼ˆéœ€è¦è·³è¿‡ï¼‰"""
                for trim in merged_trim:
                    # å¦‚æœç‰‡æ®µå®Œå…¨åœ¨ä¿®å‰ªèŒƒå›´å†…ï¼Œè·³è¿‡
                    if start_ms >= trim["start"] and end_ms <= trim["end"]:
                        return True
                    # å¦‚æœæœ‰å¤§éƒ¨åˆ†é‡å ï¼ˆ>50%ï¼‰ï¼Œä¹Ÿè·³è¿‡
                    overlap_start = max(start_ms, trim["start"])
                    overlap_end = min(end_ms, trim["end"])
                    if overlap_end > overlap_start:
                        overlap = overlap_end - overlap_start
                        duration = end_ms - start_ms
                        if duration > 0 and overlap / duration > 0.5:
                            return True
                return False
            
            def get_adjusted_time(source_time_ms: int) -> int:
                """æ ¹æ®ä¿®å‰ªç‰‡æ®µè°ƒæ•´æ—¶é—´è½´ä½ç½®"""
                adjusted = source_time_ms
                for trim in merged_trim:
                    if trim["end"] <= source_time_ms:
                        # åœ¨æ­¤ä¿®å‰ªç‰‡æ®µä¹‹åï¼Œéœ€è¦å‡å»ä¿®å‰ªçš„æ—¶é•¿
                        adjusted -= (trim["end"] - trim["start"])
                    elif trim["start"] < source_time_ms < trim["end"]:
                        # åœ¨ä¿®å‰ªç‰‡æ®µå†…éƒ¨ï¼Œè°ƒæ•´åˆ°ä¿®å‰ªå¼€å§‹ä½ç½®
                        adjusted -= (source_time_ms - trim["start"])
                return max(0, adjusted)
            
            # ä¸ºæ¯ä¸ªä¿ç•™çš„è½¬å†™ç‰‡æ®µåˆ›å»ºå­—å¹• clip
            for seg_idx, seg in enumerate(all_transcript_segs):
                seg_start = seg.get("start", 0)
                seg_end = seg.get("end", 0)
                seg_text = seg.get("text", "").strip()
                seg_duration = seg_end - seg_start
                
                if seg_duration <= 0 or not seg_text:
                    continue
                
                # è·³è¿‡è¢«ä¿®å‰ªçš„ç‰‡æ®µ
                if is_in_trim_range(seg_start, seg_end):
                    continue
                
                # è®¡ç®—è°ƒæ•´åçš„æ—¶é—´è½´ä½ç½®
                adjusted_start = get_adjusted_time(seg_start)
                adjusted_end = get_adjusted_time(seg_end)
                adjusted_duration = adjusted_end - adjusted_start
                
                if adjusted_duration <= 0:
                    continue
                
                subtitle_clips.append({
                    "id": str(uuid4()),
                    "track_id": text_track_id,
                    "clip_type": "subtitle",
                    "start_time": adjusted_start,
                    "end_time": adjusted_end,
                    "source_start": 0,
                    "source_end": adjusted_duration,
                    "is_muted": False,
                    "content_text": seg_text,
                    "text_style": {
                        "fontSize": 15,
                        "fontColor": "#FFFFFF",
                        "backgroundColor": "transparent",
                        "alignment": "center",
                        "maxWidth": "95%",
                    },
                    "transform": {
                        "x": 0,
                        "y": 150,
                        "scale": 1,
                    },
                    "metadata": {
                        "order_index": seg_idx,
                        "original_start": seg_start,
                        "original_end": seg_end,
                    },
                    "created_at": now,
                    "updated_at": now,
                })
            
            # æ‰¹é‡æ’å…¥å­—å¹• clips
            if subtitle_clips:
                supabase.table("clips").insert(subtitle_clips).execute()
                logger.info(f"[ApplyTrimming] âœ… åˆ›å»º {len(subtitle_clips)} ä¸ªå­—å¹• clips")
        
        # 8. è®¡ç®—æ€»æ—¶é•¿ï¼ˆç”¨äºè¿”å›ï¼Œprojects è¡¨æ²¡æœ‰ duration å­—æ®µï¼Œä¸æ›´æ–°ï¼‰
        total_duration = sum(c["end_time"] - c["start_time"] for c in created_clips)
        supabase.table("projects").update({
            "updated_at": now,
        }).eq("id", project_id).execute()
        
        # 9. æ›´æ–°ä¼šè¯çŠ¶æ€
        supabase.table("workspace_sessions").update({
            "status": "completed",
            "updated_at": now,
        }).eq("id", session_id).execute()
        
        logger.info(f"[ApplyTrimming] âœ… ä¿®å‰ªå®Œæˆ: åˆ›å»º {len(created_clips)} ä¸ªè§†é¢‘ clips, {len(subtitle_clips)} ä¸ªå­—å¹• clips")
        logger.info(f"[ApplyTrimming]    ä¿ç•™æ—¶é•¿: {total_duration}ms, åˆ é™¤æ—¶é•¿: {total_removed_duration}ms")
        
        return ApplyTrimmingResponse(
            status="completed",
            session_id=session_id,
            project_id=project_id,
            clips_created=len(created_clips),
            total_duration_ms=total_duration,
            removed_duration_ms=total_removed_duration,
            clips=[{
                "id": c["id"],
                "start": c["start_time"],
                "duration": c["end_time"] - c["start_time"],
                "source_start": c["source_start"],
                "source_end": c["source_end"],
            } for c in created_clips],
        )
        
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        logger.error(f"[ApplyTrimming] âŒ ä¿®å‰ªå¤±è´¥: {e}")
        logger.error(f"[ApplyTrimming] âŒ å®Œæ•´å †æ ˆ:\n{traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# â˜… B-Roll ç‰‡æ®µå»ºè®® API (å£æ’­è§†é¢‘ç²¾ä¿®æ¨¡å¼)
# ============================================

class BRollAsset(BaseModel):
    """B-Roll ç´ æ"""
    id: str
    thumbnail_url: str
    video_url: str
    source: str  # pexels, local, ai-generated
    duration: int  # æ¯«ç§’
    width: int
    height: int
    relevance_score: Optional[float] = None


class ClipSuggestion(BaseModel):
    """AI ç‰‡æ®µå»ºè®®"""
    clip_id: str
    clip_number: int
    text: str
    time_range: dict  # {start: int, end: int}
    suggested_assets: List[BRollAsset]
    selected_asset_id: Optional[str] = None
    
    # B-Roll Agent åˆ†æç»“æœ
    need_broll: Optional[bool] = None          # æ˜¯å¦éœ€è¦ B-Roll
    broll_type: Optional[str] = None           # video/image/none
    broll_reason: Optional[str] = None         # å†³ç­–åŸå› 
    keywords_en: Optional[List[str]] = None    # è‹±æ–‡æœç´¢å…³é”®è¯
    keywords_cn: Optional[List[str]] = None    # ä¸­æ–‡å…³é”®è¯
    suggested_duration_ms: Optional[int] = None  # å»ºè®® B-Roll æ—¶é•¿


class GetClipSuggestionsResponse(BaseModel):
    """è·å–ç‰‡æ®µå»ºè®®å“åº”"""
    status: str
    session_id: str
    project_id: str
    clips: List[ClipSuggestion]
    total_duration_ms: int
    
    # ç»Ÿè®¡ä¿¡æ¯
    broll_segments_count: Optional[int] = None      # éœ€è¦ B-Roll çš„ç‰‡æ®µæ•°
    total_broll_duration_ms: Optional[int] = None   # B-Roll æ€»æ—¶é•¿


@router.post("/sessions/{session_id}/clip-suggestions", response_model=GetClipSuggestionsResponse)
async def get_clip_suggestions(
    session_id: str,
    current_user: dict = Depends(get_current_user)
):
    """
    è·å– AI ç‰‡æ®µå»ºè®® (å£æ’­è§†é¢‘ç²¾ä¿®æ¨¡å¼)
    
    â˜… æ ¹æ® ASR è½¬å†™ç»“æœï¼Œä¸ºæ¯ä¸ªç‰‡æ®µæ¨èåˆé€‚çš„ B-Roll ç´ æ
    â˜… ä½¿ç”¨å…³é”®è¯æå– + Pexels æœç´¢å®ç°
    
    æµç¨‹:
    1. è·å–ä¼šè¯çš„è½¬å†™ç‰‡æ®µï¼ˆä» detect-fillers ç»“æœï¼‰
    2. å¯¹æ¯ä¸ªç‰‡æ®µè¿›è¡Œå…³é”®è¯æå–
    3. ä½¿ç”¨å…³é”®è¯æœç´¢ Pexels B-Roll ç´ æ
    4. è¿”å›ç‰‡æ®µ + æ¨èç´ æåˆ—è¡¨
    """
    try:
        user_id = current_user["user_id"]
        
        # 1. è·å–ä¼šè¯ä¿¡æ¯
        session = supabase.table("workspace_sessions").select("*").eq("id", session_id).single().execute()
        if not session.data:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
        
        session_data = session.data
        project_id = session_data.get("project_id")
        
        # æ ¡éªŒä¼šè¯å½’å±
        if session_data.get("user_id") != user_id:
            raise HTTPException(status_code=403, detail="æ— æƒæ“ä½œæ­¤ä¼šè¯")
        
        # 2. è·å–é¡¹ç›®çš„ clips
        tracks_result = supabase.table("tracks").select("id").eq("project_id", project_id).execute()
        track_ids = [t["id"] for t in (tracks_result.data or [])]
        
        if not track_ids:
            raise HTTPException(status_code=400, detail="é¡¹ç›®æ²¡æœ‰è½¨é“")
        
        clips_result = supabase.table("clips").select("*").in_("track_id", track_ids).order("start_time").execute()
        clips = clips_result.data or []
        
        if not clips:
            raise HTTPException(status_code=400, detail="é¡¹ç›®æ²¡æœ‰ç‰‡æ®µ")
        
        # 3. æ”¶é›†ç‰‡æ®µä¿¡æ¯ç”¨äº B-Roll åˆ†æ
        segments_for_analysis = []
        total_duration = 0
        
        for i, clip in enumerate(clips):
            clip_id = clip["id"]
            start_time = clip.get("start_time", 0)
            end_time = clip.get("end_time", 0)
            duration = end_time - start_time
            total_duration += duration
            
            # â˜… ç›´æ¥ä½¿ç”¨ clips.content_textï¼ˆç”± apply-trimming ä¿å­˜ï¼‰
            text = clip.get("content_text", "")
            if not text:
                text = f"ç‰‡æ®µ {i + 1}"
                logger.warning(f"[ClipSuggestions] clip {clip_id} æ— æ–‡æœ¬å†…å®¹ï¼Œä½¿ç”¨é»˜è®¤æ–‡æœ¬")
            
            segments_for_analysis.append({
                "id": clip_id,
                "text": text,
                "start": start_time,
                "end": end_time,
            })
        
        # â˜… ä½¿ç”¨ B-Roll Agent V2 è¿›è¡Œæ™ºèƒ½åˆ†æ (è§„åˆ™å¼•æ“ä¸ºæ ¸å¿ƒ)
        from app.services.broll_agent_v2 import BRollAgentV2
        
        agent = BRollAgentV2()
        broll_result = await agent.analyze(
            session_id=session_id,
            segments=segments_for_analysis,
            video_style="å£æ’­",
            total_duration_ms=total_duration,
            search_assets=True,  # è‡ªåŠ¨æœç´¢ç´ æ
        )
        
        # è½¬æ¢ä¸º API å“åº”æ ¼å¼
        suggestions = []
        for i, decision in enumerate(broll_result.decisions):
            try:
                clip = next((c for c in clips if c["id"] == decision.segment_id), None)
                if not clip:
                    logger.warning(f"[ClipSuggestions] âš ï¸ æ‰¾ä¸åˆ° clip: {decision.segment_id}")
                    continue
                
                # â˜… ç›´æ¥ä½¿ç”¨ clips.content_text
                text = clip.get("content_text", "")
                if not text:
                    text = f"ç‰‡æ®µ {i + 1}"
                
                # å°†åŒ¹é…çš„ç´ æè½¬æ¢ä¸º BRollAsset
                suggested_assets = []
                for asset in decision.matched_assets:
                    try:
                        suggested_assets.append(BRollAsset(
                            id=asset.get("id", ""),
                            thumbnail_url=asset.get("thumbnail_url", ""),
                            video_url=asset.get("video_url", "") or asset.get("image_url", ""),
                            source=asset.get("source", "pexels"),
                            duration=asset.get("duration_ms", 5000),
                            width=asset.get("width", 1920),
                            height=asset.get("height", 1080),
                            relevance_score=asset.get("relevance_score", 0.8),
                        ))
                    except Exception as asset_err:
                        logger.error(f"[ClipSuggestions] âŒ Asset è½¬æ¢å¤±è´¥: {asset_err}, asset={asset}")
                
                suggestions.append(ClipSuggestion(
                    clip_id=decision.segment_id,
                    clip_number=i + 1,
                    text=text[:100] if text else f"ç‰‡æ®µ {i + 1}",
                    time_range={
                        "start": clip.get("start_time", 0), 
                        "end": clip.get("end_time", 0)
                    },
                    suggested_assets=suggested_assets,
                    # æ‰©å±•å­—æ®µ
                    need_broll=decision.need_broll,
                    broll_type=decision.broll_type.value if decision.broll_type else "none",
                    broll_reason=decision.reason,
                    keywords_en=decision.keywords_en,
                    keywords_cn=decision.keywords_cn,
                    suggested_duration_ms=decision.suggested_duration_ms,
                ))
            except Exception as decision_err:
                logger.error(f"[ClipSuggestions] âŒ Decision è½¬æ¢å¤±è´¥: {decision_err}, decision={decision}")
        
        logger.info(f"[ClipSuggestions] âœ… æ™ºèƒ½åˆ†æå®Œæˆ: {broll_result.broll_segments}/{broll_result.total_segments} ç‰‡æ®µéœ€è¦ B-Roll")
        logger.info(f"[ClipSuggestions] å‡†å¤‡è¿”å›å“åº”: suggestions={len(suggestions)}, total_duration={total_duration}")
        
        response = GetClipSuggestionsResponse(
            status="completed",
            session_id=session_id,
            project_id=project_id,
            clips=suggestions,
            total_duration_ms=total_duration,
            # æ‰©å±•ç»Ÿè®¡
            broll_segments_count=broll_result.broll_segments,
            total_broll_duration_ms=broll_result.total_broll_duration_ms,
        )
        logger.info(f"[ClipSuggestions] âœ… å“åº”æ„å»ºæˆåŠŸ")
        return response
        
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        logger.error(f"[ClipSuggestions] âŒ è·å–å»ºè®®å¤±è´¥: {e}")
        logger.error(f"[ClipSuggestions] âŒ å®Œæ•´å †æ ˆ:\n{traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# â˜… V2: Remotion é…ç½®ç”Ÿæˆ API
# ============================================

class GetRemotionConfigResponse(BaseModel):
    """V2: Remotion é…ç½®å“åº”"""
    status: str
    session_id: str
    project_id: str
    total_duration_ms: int
    
    # Remotion é…ç½®
    remotion_config: Dict[str, Any]
    
    # ç»Ÿè®¡ä¿¡æ¯
    broll_count: int = 0
    text_count: int = 0
    chapter_count: int = 0
    
    # å‘åå…¼å®¹ï¼šä¿ç•™ clips æ•°ç»„
    clips: Optional[List[ClipSuggestion]] = None


@router.post("/sessions/{session_id}/remotion-config", response_model=GetRemotionConfigResponse)
async def get_remotion_config(
    session_id: str,
    current_user: dict = Depends(get_current_user)
):
    """
    V2: ç”Ÿæˆ Remotion æ¸²æŸ“é…ç½®
    
    â˜… åˆ†æå®Œæ•´æ–‡æœ¬å†…å®¹ï¼Œç”Ÿæˆæ•´ä½“çš„è§†é¢‘æ¸²æŸ“é…ç½®
    â˜… åŒ…æ‹¬æ–‡å­—åŠ¨ç”»ã€B-Roll æ’å…¥ç‚¹ã€ç« èŠ‚æ ‡é¢˜
    â˜… B-Roll åªæä¾›æœç´¢å…³é”®è¯ï¼Œå‰ç«¯è‡ªè¡Œæœç´¢ç´ æ
    
    æµç¨‹:
    1. è·å–ä¼šè¯çš„ clipsï¼ˆdetect-fillers V2 å·²åˆ›å»ºï¼‰
    2. è¿‡æ»¤æ‰éšè—çš„ clipsï¼ˆå·²è¢« apply-trimming æ ‡è®°ï¼‰
    3. LLM åˆ†æå®Œæ•´æ–‡æœ¬ï¼Œç”Ÿæˆ Remotion é…ç½®
    4. è¿”å›é…ç½®ä¾›å‰ç«¯æ¸²æŸ“
    """
    try:
        user_id = current_user["user_id"]
        
        # 1. è·å–ä¼šè¯ä¿¡æ¯
        session = supabase.table("workspace_sessions").select("*").eq("id", session_id).single().execute()
        if not session.data:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
        
        session_data = session.data
        project_id = session_data.get("project_id")
        
        if session_data.get("user_id") != user_id:
            raise HTTPException(status_code=403, detail="æ— æƒæ“ä½œæ­¤ä¼šè¯")
        
        logger.info(f"[RemotionConfig] å¼€å§‹ç”Ÿæˆé…ç½®: session={session_id}")
        
        # 2. è·å– clips
        asset_ids = session_data.get("uploaded_asset_ids", [])
        if not asset_ids:
            single_asset_id = session_data.get("uploaded_asset_id")
            if single_asset_id:
                asset_ids = [single_asset_id]
        
        if not asset_ids:
            raise HTTPException(status_code=400, detail="ä¼šè¯æœªå…³è”ä»»ä½•èµ„æº")
        
        clips_result = supabase.table("clips").select("*").in_("asset_id", asset_ids).order("start_time").execute()
        all_clips = clips_result.data or []
        
        if not all_clips:
            raise HTTPException(status_code=400, detail="æœªæ‰¾åˆ° clipsï¼Œè¯·å…ˆæ‰§è¡Œæ™ºèƒ½åˆ†æ")
        
        logger.info(f"[RemotionConfig] è·å–åˆ° {len(all_clips)} ä¸ª clips")
        
        # 3. è®¡ç®—æ€»æ—¶é•¿
        total_duration = sum(
            (c.get("end_time") or 0) - (c.get("start_time") or 0)
            for c in all_clips
            if not (c.get("metadata") or {}).get("hidden", False)
        )
        
        # 4. è°ƒç”¨ Remotion é…ç½®ç”Ÿæˆå™¨ (V2 ä¸¤é˜¶æ®µæ–¹æ¡ˆ)
        from app.services.remotion_generator_v2 import get_remotion_generator_v2
        
        generator = get_remotion_generator_v2()
        config = await generator.generate(
            clips=all_clips,
            total_duration_ms=total_duration,
        )
        
        logger.info(f"[RemotionConfig] âœ… é…ç½®ç”ŸæˆæˆåŠŸ: {config.broll_count} B-Roll, {config.text_count} æ–‡å­—")
        
        # 5. æ„å»ºå“åº”
        return GetRemotionConfigResponse(
            status="completed",
            session_id=session_id,
            project_id=project_id,
            total_duration_ms=total_duration,
            remotion_config=config.model_dump(),
            broll_count=config.broll_count,
            text_count=config.text_count,
            chapter_count=len(config.chapter_components),
        )
        
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        logger.error(f"[RemotionConfig] âŒ ç”Ÿæˆå¤±è´¥: {e}")
        logger.error(f"[RemotionConfig] âŒ å®Œæ•´å †æ ˆ:\n{traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# â˜… æ–‡æœ¬ç‰¹æ•ˆæšä¸¾ï¼ˆå‚è€ƒå‰ªæ˜ ï¼‰
# ============================================

class TextEffect(str, Enum):
    """æ–‡æœ¬ç‰¹æ•ˆç±»å‹ - å‚è€ƒå‰ªæ˜ """
    # å…¥åœºåŠ¨ç”»
    NONE = "none"                    # æ— ç‰¹æ•ˆ
    FADE_IN = "fade-in"              # æ·¡å…¥
    TYPEWRITER = "typewriter"        # æ‰“å­—æœºï¼ˆé€å­—å‡ºç°ï¼‰
    SLIDE_UP = "slide-up"            # ä»ä¸‹æ»‘å…¥
    SLIDE_DOWN = "slide-down"        # ä»ä¸Šæ»‘å…¥
    SLIDE_LEFT = "slide-left"        # ä»å³æ»‘å…¥
    SLIDE_RIGHT = "slide-right"      # ä»å·¦æ»‘å…¥
    ZOOM_IN = "zoom-in"              # æ”¾å¤§å‡ºç°
    ZOOM_OUT = "zoom-out"            # ç¼©å°å‡ºç°
    BOUNCE = "bounce"                # å¼¹è·³å‡ºç°
    SHAKE = "shake"                  # æŠ–åŠ¨
    ROTATE_IN = "rotate-in"          # æ—‹è½¬å…¥åœº
    BLUR_IN = "blur-in"              # æ¨¡ç³Šæ·¡å…¥
    
    # å¾ªç¯åŠ¨ç”»
    PULSE = "pulse"                  # è„‰å†²ï¼ˆå‘¼å¸ï¼‰
    FLOAT = "float"                  # æ¼‚æµ®
    GLOW = "glow"                    # å‘å…‰
    NEON = "neon"                    # éœ“è™¹ç¯é—ªçƒ
    
    # ç»„åˆç‰¹æ•ˆï¼ˆæŠ–éŸ³/å°çº¢ä¹¦é£æ ¼ï¼‰
    DOUYIN_SUBTITLE = "douyin-subtitle"    # æŠ–éŸ³å­—å¹•é£æ ¼
    KEYWORD_HIGHLIGHT = "keyword-highlight"  # å…³é”®è¯é«˜äº®


# é»˜è®¤æ–‡æœ¬ç‰¹æ•ˆï¼ˆä¸€é”®æˆç‰‡ä½¿ç”¨ï¼‰
DEFAULT_TEXT_EFFECT = TextEffect.FADE_IN


# ============================================
# â˜… V3: ç”Ÿæˆ B-Roll Clips å¹¶ä¿å­˜åˆ°æ•°æ®åº“
# ============================================

class TextClipInfo(BaseModel):
    """å•ä¸ªæ–‡æœ¬ clip ä¿¡æ¯"""
    clip_id: str
    start_ms: int
    end_ms: int
    text: str
    position: str = "center"  # â˜… ä½ç½®
    effect_type: str = "fade-in"  # â˜… ç‰¹æ•ˆç±»å‹
    text_style: Dict[str, Any] = {}  # â˜… æ ·å¼

class BRollClipInfo(BaseModel):
    """å•ä¸ª B-Roll clip ä¿¡æ¯"""
    clip_id: str
    task_id: str
    start_ms: int
    end_ms: int
    search_keywords: List[str]
    pexels_video_id: Optional[int] = None
    thumbnail: Optional[str] = None

class GenerateBRollClipsResponse(BaseModel):
    """ç”Ÿæˆ B-Roll Clips å“åº”ï¼ˆâ˜… åªç”Ÿæˆ B-Roll é•œå¤´ï¼Œä¸ç”Ÿæˆæ–‡æœ¬ï¼‰"""
    status: str
    session_id: str
    project_id: str
    broll_clips_created: int = 0
    broll_track_id: str = ""
    broll_clips: List[BRollClipInfo] = []
    message: str = ""
    remotion_config: Optional[dict] = None


@router.post("/sessions/{session_id}/generate-broll-clips", response_model=GenerateBRollClipsResponse)
async def generate_broll_clips(
    session_id: str,
    background_tasks: BackgroundTasks,
    current_user: dict = Depends(get_current_user)
):
    """
    â˜… ç”Ÿæˆ B-Roll clips
    
    æ ¸å¿ƒæ”¹åŠ¨ï¼šbroll æ˜¯ video clip çš„å­ç±»å‹ï¼ˆå’Œæ‰‹åŠ¨æ‹–æ‹½ Pexels ä¸€è‡´ï¼‰
    
    æµç¨‹ï¼š
    1. è·å–ä¼šè¯çš„ clipsï¼ˆä¸»è§†é¢‘ï¼‰
    2. è°ƒç”¨ LLM ç”Ÿæˆ B-Roll é…ç½®ï¼ˆæ’å…¥ç‚¹ã€æœç´¢å…³é”®è¯ã€æ—¶é•¿ï¼‰
    3. ä¸ºæ¯ä¸ª B-Roll è‡ªåŠ¨æœç´¢ Pexels
    4. å¯åŠ¨å¼‚æ­¥ä¸‹è½½ä»»åŠ¡ï¼Œæ¯ä¸ªä»»åŠ¡å®Œæˆåä¼šï¼š
       - åˆ›å»º asset
       - åˆ›å»º video ç±»å‹çš„ clipï¼ˆå…³è” asset_idï¼Œmetadata.is_broll=trueï¼‰
    5. ç«‹å³è¿”å›ï¼ˆå‰ç«¯å¯ä»¥è½®è¯¢æ£€æµ‹ clips æ˜¯å¦åˆ›å»ºå®Œæˆï¼‰
    """
    import httpx
    from app.tasks.broll_download import download_broll_video, set_download_progress
    
    PEXELS_API_KEY = os.getenv("PEXELS_API_KEY", "")
    PEXELS_API_URL = "https://api.pexels.com/videos/search"
    
    try:
        user_id = current_user["user_id"]
        
        # 1. è·å–ä¼šè¯ä¿¡æ¯
        session = supabase.table("workspace_sessions").select("*").eq("id", session_id).single().execute()
        if not session.data:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
        
        session_data = session.data
        project_id = session_data.get("project_id")
        
        if session_data.get("user_id") != user_id:
            raise HTTPException(status_code=403, detail="æ— æƒæ“ä½œæ­¤ä¼šè¯")
        
        logger.info(f"[GenerateBRollClips] å¼€å§‹ç”Ÿæˆ B-Roll clips: session={session_id}")
        
        # â˜…â˜…â˜… 2.1 è¯»å– B-Roll é…ç½® â˜…â˜…â˜…
        processing_steps = session_data.get("processing_steps") or {}
        broll_display_mode = processing_steps.get("broll_display_mode", "fullscreen")  # fullscreen | pip | mixed
        broll_pip_config = processing_steps.get("broll_pip_config") or {}
        broll_mixed_config = processing_steps.get("broll_mixed_config") or {}
        broll_face_detection = processing_steps.get("broll_face_detection", False)
        
        logger.info(f"[GenerateBRollClips] â˜… B-Roll é…ç½®: mode={broll_display_mode}, pip_config={broll_pip_config}, face_detect={broll_face_detection}")
        
        # 2. è·å–åŸå§‹ clipsï¼ˆä¸»è§†é¢‘ï¼‰
        asset_ids = session_data.get("uploaded_asset_ids", [])
        if not asset_ids:
            single_asset_id = session_data.get("uploaded_asset_id")
            if single_asset_id:
                asset_ids = [single_asset_id]
        
        if not asset_ids:
            raise HTTPException(status_code=400, detail="ä¼šè¯æœªå…³è”ä»»ä½•èµ„æº")
        
        # â˜…â˜…â˜… 2.5 è·å–ä¸»è§†é¢‘å®½é«˜æ¯” â˜…â˜…â˜…
        from app.services.video_utils import (
            get_pexels_orientation,
            AspectRatio,
            get_broll_fit_info,  # â˜… æ”¹ç”¨æ–°çš„ fit_infoï¼ˆæ”¯æŒ letterboxï¼‰
        )
        
        # ä¼˜å…ˆä½¿ç”¨é¡¹ç›®ç›®æ ‡åˆ†è¾¨ç‡ï¼ˆå¼ºåˆ¶ 9:16 / 16:9ï¼‰
        project_result = supabase.table("projects").select("resolution").eq("id", project_id).single().execute()
        project_resolution = (project_result.data or {}).get("resolution") or {}
        target_width = project_resolution.get("width")
        target_height = project_resolution.get("height")

        if target_width and target_height:
            target_aspect_ratio = AspectRatio.RATIO_16_9 if target_width >= target_height else AspectRatio.RATIO_9_16
            main_video_width = target_width
            main_video_height = target_height
            logger.info(f"[GenerateBRollClips] â˜… ä½¿ç”¨é¡¹ç›®åˆ†è¾¨ç‡ä½œä¸ºç›®æ ‡æ¯”ä¾‹: {target_width}x{target_height}")
        else:
            # å›é€€ï¼šä½¿ç”¨ä¸»è§†é¢‘ asset ä¿¡æ¯
            main_asset_result = supabase.table("assets").select("width, height").in_("id", asset_ids).limit(1).execute()
            main_asset = main_asset_result.data[0] if main_asset_result.data else {}
            main_video_width = main_asset.get("width", 1920)
            main_video_height = main_asset.get("height", 1080)
            target_aspect_ratio = AspectRatio.RATIO_16_9 if main_video_width >= main_video_height else AspectRatio.RATIO_9_16
        pexels_orientation = get_pexels_orientation(target_aspect_ratio)
        
        logger.info(f"[GenerateBRollClips] â˜… ä¸»è§†é¢‘å°ºå¯¸: {main_video_width}x{main_video_height}")
        logger.info(f"[GenerateBRollClips] â˜… ç›®æ ‡å®½é«˜æ¯”: {target_aspect_ratio.value}, Pexelsæ–¹å‘: {pexels_orientation}")
        
        clips_result = supabase.table("clips").select("*").in_("asset_id", asset_ids).order("start_time").execute()
        all_clips = clips_result.data or []
        
        if not all_clips:
            raise HTTPException(status_code=400, detail="æœªæ‰¾åˆ° clipsï¼Œè¯·å…ˆæ‰§è¡Œæ™ºèƒ½åˆ†æ")
        
        logger.info(f"[GenerateBRollClips] è·å–åˆ° {len(all_clips)} ä¸ªä¸»è§†é¢‘ clips")
        
        # 3. è®¡ç®—æ€»æ—¶é•¿
        total_duration = sum(
            (c.get("end_time") or 0) - (c.get("start_time") or 0)
            for c in all_clips
            if not (c.get("metadata") or {}).get("hidden", False)
        )
        
        # â˜…â˜…â˜… 3.5 å¦‚æœæ˜¯ PiP æ¨¡å¼ä¸”å¼€å¯äººè„¸æ£€æµ‹ï¼Œæ‰§è¡Œäººè„¸æ£€æµ‹ â˜…â˜…â˜…
        face_detection_result = None
        if broll_display_mode in ("pip", "mixed") and broll_face_detection:
            try:
                from app.services.face_detector import get_face_detector
                
                # è·å–ä¸»è§†é¢‘æ–‡ä»¶è·¯å¾„
                main_asset_full = supabase.table("assets").select("file_url, storage_path").in_("id", asset_ids).limit(1).execute()
                if main_asset_full.data:
                    asset_info = main_asset_full.data[0]
                    video_path = asset_info.get("storage_path") or asset_info.get("file_url", "")
                    
                    if video_path and os.path.exists(video_path):
                        detector = get_face_detector()
                        face_detection_result = detector.detect_from_video(
                            video_path=video_path,
                            sample_interval_ms=2000,  # æ¯ 2 ç§’é‡‡æ ·
                            max_samples=20,
                        )
                        logger.info(f"[GenerateBRollClips] â˜… äººè„¸æ£€æµ‹å®Œæˆ: dominant_region={face_detection_result.dominant_region is not None}, safe_positions={face_detection_result.safe_pip_positions}")
                    else:
                        logger.warning(f"[GenerateBRollClips] âš ï¸ è§†é¢‘è·¯å¾„ä¸å­˜åœ¨ï¼Œè·³è¿‡äººè„¸æ£€æµ‹: {video_path}")
            except Exception as face_err:
                logger.warning(f"[GenerateBRollClips] âš ï¸ äººè„¸æ£€æµ‹å¤±è´¥ï¼ˆéè‡´å‘½ï¼‰: {face_err}")
        
        # 4. è°ƒç”¨ Remotion é…ç½®ç”Ÿæˆå™¨è·å– B-Roll é…ç½® (V2 ä¸¤é˜¶æ®µæ–¹æ¡ˆ)
        from app.services.remotion_generator_v2 import get_remotion_generator_v2
        
        # â˜…â˜…â˜… æ ¹æ®ç”¨æˆ·é…ç½®ç¡®å®šé»˜è®¤æ˜¾ç¤ºæ¨¡å¼ â˜…â˜…â˜…
        # mixed æ¨¡å¼ä¸‹ï¼Œgenerator ç”Ÿæˆçš„ B-Roll ä¼šæ··åˆä½¿ç”¨ fullscreen å’Œ pip
        # è¿™é‡Œä¼ å…¥ fullscreen ä½œä¸ºé»˜è®¤ï¼Œåç»­æ ¹æ® mixed_config è°ƒæ•´
        effective_display_mode = "fullscreen" if broll_display_mode == "fullscreen" else "pip" if broll_display_mode == "pip" else "fullscreen"
        
        generator = get_remotion_generator_v2()
        config = await generator.generate(
            clips=all_clips,
            total_duration_ms=total_duration,
            target_aspect_ratio=target_aspect_ratio.value,  # â˜… ä¼ å…¥ä¸»è§†é¢‘å®½é«˜æ¯”
            default_display_mode=effective_display_mode,  # â˜… ä½¿ç”¨ç”¨æˆ·é…ç½®çš„æ¨¡å¼
        )
        
        logger.info(f"[GenerateBRollClips] é…ç½®ç”ŸæˆæˆåŠŸ: {config.broll_count} B-Roll, mode={broll_display_mode}")
        
        if config.broll_count == 0:
            return GenerateBRollClipsResponse(
                status="completed",
                session_id=session_id,
                project_id=project_id,
                broll_clips_created=0,
                message="æ²¡æœ‰ç”Ÿæˆ B-Roll å»ºè®®",
            )
        
        now = datetime.utcnow().isoformat()
        
        # 5. â˜…â˜…â˜… ç›´æ¥åˆ›å»ºæ–°çš„ B-Roll trackï¼ˆè¿™æ‰¹ clips å…±äº«ï¼‰ â˜…â˜…â˜…
        # â˜…â˜…â˜… è½¨é“å±‚çº§è®¾è®¡ â˜…â˜…â˜…
        # - 0-9: ä¸»è§†é¢‘è½¨é“
        # - 10-49: B-Roll è½¨é“ï¼ˆåœ¨ä¸»è§†é¢‘ä¹‹ä¸Šï¼Œä½†åœ¨æ–‡æœ¬/å­—å¹•ä¹‹ä¸‹ï¼‰
        # - 50-99: å›¾ç‰‡/è´´çº¸è½¨é“
        # - 100+: æ–‡æœ¬/å­—å¹•è½¨é“ï¼ˆå§‹ç»ˆåœ¨æœ€ä¸Šå±‚ï¼‰
        tracks_result = supabase.table("tracks").select("order_index, name").eq("project_id", project_id).execute()
        tracks = tracks_result.data or []
        
        # æ‰¾åˆ° B-Roll è½¨é“èŒƒå›´å†…çš„æœ€å¤§ order_index (10-49)
        broll_orders = [t.get("order_index", 0) for t in tracks if 10 <= t.get("order_index", 0) < 50]
        broll_order = max(broll_orders, default=9) + 1  # ä» 10 å¼€å§‹
        if broll_order >= 50:
            broll_order = 49  # ä¸èƒ½è¶…è¿‡ B-Roll å±‚çº§èŒƒå›´
        
        broll_track_id = str(uuid4())
        broll_track_data = {
            "id": broll_track_id,
            "project_id": project_id,
            "name": "B-Roll",
            "order_index": broll_order,  # â˜… B-Roll å›ºå®šåœ¨ 10-49 å±‚çº§èŒƒå›´
            "is_visible": True,
            "is_locked": False,
            "is_muted": False,
            "created_at": now,
            "updated_at": now,
        }
        supabase.table("tracks").insert(broll_track_data).execute()
        logger.info(f"[GenerateBRollClips] âœ¨ åˆ›å»º B-Roll track: {broll_track_id}, order_index={broll_order}")
        
        # â˜…â˜…â˜… ä¸å†åˆ›å»ºæ–‡æœ¬è½¨é“å’Œæ–‡æœ¬ clipsï¼ˆåªåš B-Roll é•œå¤´ï¼‰â˜…â˜…â˜…
        
        # 6. â˜…â˜…â˜… ä¸ºæ¯ä¸ª B-Roll æœç´¢ Pexels å¹¶å¯åŠ¨ä¸‹è½½ä»»åŠ¡ â˜…â˜…â˜…
        # ä¸‹è½½ä»»åŠ¡å®Œæˆåä¼šè‡ªåŠ¨åˆ›å»º asset + video clip
        broll_clips_info: List[BRollClipInfo] = []
        download_tasks_count = 0
        
        async with httpx.AsyncClient() as client:
            for broll in config.broll_components:
                task_id = str(uuid4())
                
                # æ„å»ºæœç´¢å…³é”®è¯ï¼ˆåˆå¹¶ä¸ºä¸€ä¸ªæœç´¢è¯ï¼‰
                search_query = " ".join(broll.search_keywords[:3])
                
                # â˜…â˜…â˜… æœç´¢ Pexels - ä½¿ç”¨ä¸»è§†é¢‘çš„æ–¹å‘å‚æ•° â˜…â˜…â˜…
                pexels_video = None
                if PEXELS_API_KEY:
                    try:
                        response = await client.get(
                            PEXELS_API_URL,
                            params={
                                "query": search_query, 
                                "per_page": 1, 
                                "orientation": pexels_orientation  # â˜… ä½¿ç”¨ä¸»è§†é¢‘çš„æ–¹å‘
                            },
                            headers={"Authorization": PEXELS_API_KEY},
                            timeout=10.0
                        )
                        
                        if response.status_code == 200:
                            data = response.json()
                            videos = data.get("videos", [])
                            if videos:
                                pexels_video = videos[0]
                                logger.info(f"[GenerateBRollClips] âœ… Pexels æ‰¾åˆ°ç´ æ ({pexels_orientation}): {pexels_video.get('id')} for '{search_query}'")
                    except Exception as e:
                        logger.warning(f"[GenerateBRollClips] Pexels æœç´¢å¤±è´¥: {e}")
                
                if not pexels_video:
                    logger.warning(f"[GenerateBRollClips] âš ï¸ æœªæ‰¾åˆ°ç´ æ: {search_query}")
                    continue
                
                # â˜…â˜…â˜… è·å–è§†é¢‘ URL - é™åˆ¶æ–‡ä»¶å¤§å°åœ¨ 30MB ä»¥å†… â˜…â˜…â˜…
                MAX_FILE_SIZE_MB = 30
                MAX_FILE_SIZE_BYTES = MAX_FILE_SIZE_MB * 1024 * 1024
                
                video_files = pexels_video.get("video_files", [])
                best_file = None
                
                # æŒ‰ä¼˜å…ˆçº§æ’åºï¼šHD è´¨é‡ + æ–‡ä»¶å¤§å°é™åˆ¶
                # Pexels çš„ video_files åŒ…å« file_type, width, height, link, size (å¯èƒ½æ²¡æœ‰ size å­—æ®µ)
                hd_files = [vf for vf in video_files if vf.get("quality") == "hd" and vf.get("width", 0) >= 1280]
                sd_files = [vf for vf in video_files if vf.get("quality") == "sd"]
                
                # ä¼˜å…ˆé€‰æ‹© HDï¼Œä½†è¦å°äº 30MB
                for vf in sorted(hd_files, key=lambda x: x.get("width", 0), reverse=True):
                    # Pexels ä¸ä¸€å®šè¿”å› size å­—æ®µï¼Œä½† HD 720p é€šå¸¸ < 30MB
                    file_size = vf.get("size", 0)
                    # å¦‚æœæœ‰ size å­—æ®µä¸”è¶…è¿‡é™åˆ¶ï¼Œè·³è¿‡
                    if file_size > 0 and file_size > MAX_FILE_SIZE_BYTES:
                        logger.info(f"[GenerateBRollClips] è·³è¿‡è¿‡å¤§æ–‡ä»¶: {file_size / 1024 / 1024:.1f}MB > {MAX_FILE_SIZE_MB}MB")
                        continue
                    # ä¼˜å…ˆé€‰æ‹© 720pï¼ˆé€šå¸¸ < 30MBï¼‰
                    if vf.get("height", 0) <= 720:
                        best_file = vf
                        break
                
                # å¦‚æœæ²¡æœ‰åˆé€‚çš„ HDï¼Œå°è¯• SD
                if not best_file:
                    for vf in sorted(sd_files, key=lambda x: x.get("width", 0), reverse=True):
                        file_size = vf.get("size", 0)
                        if file_size > 0 and file_size > MAX_FILE_SIZE_BYTES:
                            continue
                        best_file = vf
                        break
                
                # æœ€åå…œåº•ï¼šé€‰æ‹©åˆ†è¾¨ç‡æœ€å°çš„
                if not best_file and video_files:
                    best_file = min(video_files, key=lambda x: x.get("width", 0) * x.get("height", 0))
                    logger.info(f"[GenerateBRollClips] âš ï¸ å…œåº•é€‰æ‹©æœ€å°åˆ†è¾¨ç‡: {best_file.get('width')}x{best_file.get('height')}")
                
                if not best_file:
                    continue
                
                video_url = best_file.get("link")
                thumbnail = pexels_video.get("image")
                
                # è®¾ç½®åˆå§‹ä¸‹è½½çŠ¶æ€
                set_download_progress(task_id, {
                    "status": "pending",
                    "progress": 0,
                    "asset_id": "",
                    "message": "ä»»åŠ¡æ’é˜Ÿä¸­..."
                })
                
                # â˜…â˜…â˜… è®¡ç®— B-Roll é€‚é…ä¿¡æ¯ï¼ˆfullscreen ä½¿ç”¨ letterboxï¼Œä¸è£å‰ªï¼‰â˜…â˜…â˜…
                broll_width = best_file.get("width", 1920)
                broll_height = best_file.get("height", 1080)
                
                # â˜…â˜…â˜… æ ¹æ®ç”¨æˆ·é…ç½®å†³å®šæ¯ä¸ª B-Roll çš„æ˜¾ç¤ºæ¨¡å¼ â˜…â˜…â˜…
                original_display_mode = broll.display_mode.value if hasattr(broll.display_mode, 'value') else broll.display_mode
                
                if broll_display_mode == "mixed":
                    # Mixed æ¨¡å¼ï¼šæ ¹æ® pip_ratio éšæœºå†³å®š
                    import random
                    pip_ratio = broll_mixed_config.get("pip_ratio", 0.3)  # é»˜è®¤ 30% ä¸º PiP
                    final_display_mode = "pip" if random.random() < pip_ratio else "fullscreen"
                elif broll_display_mode == "pip":
                    final_display_mode = "pip"
                else:
                    final_display_mode = "fullscreen"
                
                # â˜…â˜…â˜… PiP æ¨¡å¼ä¸‹è®¡ç®—å®‰å…¨ä½ç½®ï¼ˆé¿å¼€äººè„¸ï¼‰ â˜…â˜…â˜…
                pip_position_info = None
                if final_display_mode == "pip":
                    pip_size_map = {"small": 0.2, "medium": 0.3, "large": 0.4}
                    pip_size = pip_size_map.get(broll_pip_config.get("size", "medium"), 0.3)
                    default_position = broll_pip_config.get("default_position", "bottom-right")
                    margin = broll_pip_config.get("margin", 0.02)
                    
                    if face_detection_result and face_detection_result.dominant_region:
                        # æœ‰äººè„¸æ£€æµ‹ç»“æœï¼Œè®¡ç®—å®‰å…¨ä½ç½®
                        from app.services.face_detector import get_face_detector
                        detector = get_face_detector()
                        safe_x, safe_y, safe_position = detector.get_safe_pip_position(
                            faces=[face_detection_result.dominant_region],
                            pip_size=pip_size,
                            margin=margin,
                            preferred_position=default_position,
                        )
                        pip_position_info = {
                            "size": pip_size,
                            "position": safe_position,
                            "x": safe_x,
                            "y": safe_y,
                            "face_avoided": safe_position != default_position,
                            "margin": margin,
                            "border_radius": broll_pip_config.get("border_radius", 8),
                        }
                        logger.info(f"[GenerateBRollClips] â˜… PiP ä½ç½®: {safe_position} (é¦–é€‰={default_position}, é¿è®©={safe_position != default_position})")
                    else:
                        # æ— äººè„¸æ£€æµ‹ç»“æœï¼Œä½¿ç”¨é»˜è®¤ä½ç½®
                        from app.services.face_detector import get_pip_position_coords
                        pip_x, pip_y = get_pip_position_coords(default_position, pip_size, margin)
                        pip_position_info = {
                            "size": pip_size,
                            "position": default_position,
                            "x": pip_x,
                            "y": pip_y,
                            "face_avoided": False,
                            "margin": margin,
                            "border_radius": broll_pip_config.get("border_radius", 8),
                        }
                
                fit_info = get_broll_fit_info(
                    broll_width, broll_height, target_aspect_ratio,
                    display_mode=final_display_mode,  # â˜… ä½¿ç”¨æœ€ç»ˆç¡®å®šçš„æ˜¾ç¤ºæ¨¡å¼
                )
                
                # â˜…â˜…â˜… å¯åŠ¨ä¸‹è½½ä»»åŠ¡ï¼ˆä¸‹è½½å®Œæˆåè‡ªåŠ¨åˆ›å»º asset + video clipï¼‰ â˜…â˜…â˜…
                video_data = {
                    "id": pexels_video.get("id"),
                    "url": video_url,
                    "width": best_file.get("width"),
                    "height": best_file.get("height"),
                    "duration": pexels_video.get("duration"),
                    "thumbnail": thumbnail,
                    "source": "pexels",
                    "author": pexels_video.get("user", {}).get("name", ""),
                    "author_url": pexels_video.get("user", {}).get("url", ""),
                    "original_url": pexels_video.get("url", ""),
                }
                
                # B-Roll æ—¶é—´èŒƒå›´ä¿¡æ¯ï¼ˆå¢åŠ è£å‰ªå’Œç›®æ ‡å®½é«˜æ¯”ä¿¡æ¯ï¼‰
                broll_time_info = {
                    "start_ms": broll.start_ms,
                    "end_ms": broll.end_ms,
                    "search_keywords": broll.search_keywords,
                    "display_mode": final_display_mode,  # â˜… ä½¿ç”¨æœ€ç»ˆç¡®å®šçš„æ˜¾ç¤ºæ¨¡å¼
                    # â˜…â˜…â˜… æ–°å¢ï¼šç›®æ ‡å®½é«˜æ¯”å’Œé€‚é…ä¿¡æ¯ï¼ˆletterbox/pillarboxï¼‰â˜…â˜…â˜…
                    "target_aspect_ratio": target_aspect_ratio.value,
                    "target_width": main_video_width,
                    "target_height": main_video_height,
                    "fit_info": fit_info,  # â˜… åŒ…å« letterbox_params æˆ– crop_params
                    # â˜…â˜…â˜… æ–°å¢ï¼šPiP ä½ç½®ä¿¡æ¯ï¼ˆå¦‚æœæ˜¯ PiP æ¨¡å¼ï¼‰â˜…â˜…â˜…
                    "pip_position_info": pip_position_info,
                }
                
                # â˜… å¯åŠ¨ä¸‹è½½ä»»åŠ¡ï¼Œä¼ å…¥ track_idï¼ˆè¿™æ‰¹ B-Roll å…±äº«åŒä¸€ä¸ª trackï¼‰
                download_broll_video.delay(
                    task_id=task_id,
                    user_id=user_id,
                    project_id=project_id,
                    video_data=video_data,
                    track_id=broll_track_id,
                    broll_time_info=broll_time_info,
                )
                
                download_tasks_count += 1
                pip_info = f", pip_pos={pip_position_info.get('position')}" if pip_position_info else ""
                logger.info(f"[GenerateBRollClips] ğŸš€ å¯åŠ¨ä¸‹è½½ä»»åŠ¡: {task_id}, mode={final_display_mode}, é€‚é…={fit_info.get('fit_mode')}{pip_info}")
                
                # è®°å½• clip ä¿¡æ¯ä¾›å‰ç«¯è½®è¯¢
                broll_clips_info.append(BRollClipInfo(
                    clip_id="",  # ä¸‹è½½å®Œæˆåæ‰æœ‰
                    task_id=task_id,
                    start_ms=broll.start_ms,
                    end_ms=broll.end_ms,
                    search_keywords=broll.search_keywords,
                    pexels_video_id=pexels_video.get("id"),
                    thumbnail=thumbnail,
                ))
        
        # 7. æ›´æ–°ä¼šè¯çŠ¶æ€
        supabase.table("workspace_sessions").update({
            "workflow_step": "completed",
            "updated_at": now,
        }).eq("id", session_id).execute()
        
        return GenerateBRollClipsResponse(
            status="completed",
            session_id=session_id,
            project_id=project_id,
            broll_clips_created=download_tasks_count,
            broll_track_id=broll_track_id,
            broll_clips=broll_clips_info,
            message=f"å·²å¯åŠ¨ {download_tasks_count} ä¸ª B-Roll ä¸‹è½½ä»»åŠ¡",
            remotion_config=config.model_dump(),
        )
        
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        logger.error(f"[GenerateBRollClips] âŒ ç”Ÿæˆå¤±è´¥: {e}")
        logger.error(f"[GenerateBRollClips] âŒ å®Œæ•´å †æ ˆ:\n{traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# â˜… Remotion Agent API (çŸ¥è¯†åšä¸»è§†è§‰ç¼–æ’)
# ============================================

class GenerateVisualConfigRequest(BaseModel):
    """ç”Ÿæˆè§†è§‰é…ç½®è¯·æ±‚"""
    template: Optional[str] = "whiteboard"  # whiteboard | talking-head
    pip_position: Optional[str] = "bottom-right"  # å£æ’­å°çª—ä½ç½®


class VisualConfigResponse(BaseModel):
    """è§†è§‰é…ç½®å“åº”"""
    status: str
    session_id: str
    project_id: str
    
    # è§†è§‰é…ç½®
    visual_config: Dict[str, Any]
    
    # ç»Ÿè®¡ä¿¡æ¯
    segment_count: int = 0
    canvas_count: int = 0
    overlay_count: int = 0
    
    # å…ƒä¿¡æ¯
    template_used: str = "whiteboard"
    pip_position: str = "bottom-right"


@router.post("/sessions/{session_id}/visual-config", response_model=VisualConfigResponse)
async def generate_visual_config(
    session_id: str,
    request: GenerateVisualConfigRequest = GenerateVisualConfigRequest(),
    current_user: dict = Depends(get_current_user)
):
    """
    â˜… Remotion Agent: ä¸ºçŸ¥è¯†ç±»åšä¸»ç”Ÿæˆæ™ºèƒ½è§†è§‰ç¼–æ’é…ç½®
    
    è¿™æ˜¯ä¸€ä¸ªä¸ºçŸ¥è¯†/æ•™è‚²å†…å®¹åˆ›ä½œè€…è®¾è®¡çš„é«˜çº§è§†è§‰ç¼–æ’ç³»ç»Ÿï¼š
    - è‡ªåŠ¨è¯†åˆ«å†…å®¹ç»“æ„ï¼ˆæé—®ã€è¦ç‚¹ã€æµç¨‹ã€ç»“è®ºç­‰ï¼‰
    - ç”Ÿæˆç”»å¸ƒé…ç½®ï¼ˆè¦ç‚¹åˆ—è¡¨ã€æµç¨‹å›¾ã€å¯¹æ¯”è¡¨ï¼‰
    - ç”Ÿæˆå åŠ ç»„ä»¶ï¼ˆå…³é”®è¯å¡ç‰‡ã€æ•°æ®å±•ç¤ºã€é«˜äº®æ¡†ï¼‰
    - æ”¯æŒå¤šç§æ¨¡æ¿é£æ ¼ï¼ˆç™½æ¿è®²è§£ã€å£æ’­ä¸»å¯¼ï¼‰
    
    æµç¨‹:
    1. è·å–ä¼šè¯çš„ transcript segments
    2. Stage 2: åˆ†æå†…å®¹ç»“æ„ï¼ˆè§’è‰²ã€ç±»å‹ã€è¦ç‚¹ï¼‰
    3. Stage 3: æ ¹æ®ç»“æ„ç”Ÿæˆè§†è§‰é…ç½®
    4. è¿”å›é…ç½®ä¾›å‰ç«¯ Remotion æ¸²æŸ“
    """
    try:
        user_id = current_user["user_id"]
        
        # 1. è·å–ä¼šè¯ä¿¡æ¯
        session = supabase.table("workspace_sessions").select("*").eq("id", session_id).single().execute()
        if not session.data:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
        
        session_data = session.data
        project_id = session_data.get("project_id")
        
        if session_data.get("user_id") != user_id:
            raise HTTPException(status_code=403, detail="æ— æƒæ“ä½œæ­¤ä¼šè¯")
        
        logger.info(f"[VisualConfig] å¼€å§‹ç”Ÿæˆè§†è§‰é…ç½®: session={session_id}, template={request.template}")
        
        # 2. è·å– transcript segments
        asset_ids = session_data.get("uploaded_asset_ids", [])
        if not asset_ids:
            single_asset_id = session_data.get("uploaded_asset_id")
            if single_asset_id:
                asset_ids = [single_asset_id]
        
        if not asset_ids:
            raise HTTPException(status_code=400, detail="ä¼šè¯æœªå…³è”ä»»ä½•èµ„æº")
        
        # ä» assets è¡¨è·å– transcript
        assets_result = supabase.table("assets").select("id, transcript").in_("id", asset_ids).execute()
        assets = assets_result.data or []
        
        if not assets:
            raise HTTPException(status_code=400, detail="æœªæ‰¾åˆ°èµ„æºä¿¡æ¯")
        
        # åˆå¹¶æ‰€æœ‰ segments
        all_segments = []
        for asset in assets:
            transcript = asset.get("transcript") or {}
            segments = transcript.get("segments", [])
            for seg in segments:
                all_segments.append({
                    "id": seg.get("id", str(uuid4())),
                    "text": seg.get("text", ""),
                    "start_ms": int(seg.get("start", 0) * 1000),
                    "end_ms": int(seg.get("end", 0) * 1000),
                    "asset_id": asset.get("id"),
                })
        
        if not all_segments:
            raise HTTPException(status_code=400, detail="æœªæ‰¾åˆ°å­—å¹•æ•°æ®ï¼Œè¯·å…ˆæ‰§è¡Œ ASR å¤„ç†")
        
        logger.info(f"[VisualConfig] è·å–åˆ° {len(all_segments)} ä¸ª segments")
        
        # 3. è°ƒç”¨ Remotion Agent
        from app.services.remotion_agent import analyze_content_structure, generate_visual_config as gen_visual
        from app.services.remotion_agent.templates import get_template
        
        # è·å–æ¨¡æ¿é…ç½®
        template = get_template(request.template or "whiteboard")
        
        # Stage 2: å†…å®¹ç»“æ„åˆ†æ
        structured_segments = await analyze_content_structure(all_segments)
        logger.info(f"[VisualConfig] Stage 2 å®Œæˆ: {len(structured_segments)} ä¸ªç»“æ„åŒ–ç‰‡æ®µ")
        
        # Stage 3: ç”Ÿæˆè§†è§‰é…ç½®
        visual_config = gen_visual(
            segments=structured_segments,
            template=template,
            pip_position=request.pip_position or "bottom-right",
        )
        logger.info(f"[VisualConfig] Stage 3 å®Œæˆ: canvas={len(visual_config.canvas)}, overlays={len(visual_config.overlays)}")
        
        # 4. æ„å»ºå“åº”
        return VisualConfigResponse(
            status="completed",
            session_id=session_id,
            project_id=project_id,
            visual_config=visual_config.model_dump(),
            segment_count=len(structured_segments),
            canvas_count=len(visual_config.canvas),
            overlay_count=len(visual_config.overlays),
            template_used=request.template or "whiteboard",
            pip_position=request.pip_position or "bottom-right",
        )
        
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        logger.error(f"[VisualConfig] âŒ ç”Ÿæˆå¤±è´¥: {e}")
        logger.error(f"[VisualConfig] âŒ å®Œæ•´å †æ ˆ:\n{traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# è¾…åŠ©å‡½æ•°
# ============================================

import re


class SessionCancelledException(Exception):
    """ä¼šè¯è¢«ç”¨æˆ·å–æ¶ˆçš„å¼‚å¸¸"""
    pass


def _check_session_cancelled(session_id: str) -> bool:
    """
    æ£€æŸ¥ä¼šè¯æ˜¯å¦è¢«å–æ¶ˆ
    
    Args:
        session_id: ä¼šè¯ ID
        
    Returns:
        True å¦‚æœä¼šè¯å·²è¢«å–æ¶ˆï¼ŒFalse å¦åˆ™
    """
    try:
        result = supabase.table("workspace_sessions").select("status").eq("id", session_id).single().execute()
        if result.data:
            return result.data.get("status") == "cancelled"
        return False
    except Exception as e:
        logger.warning(f"[Workspace] æ£€æŸ¥ä¼šè¯çŠ¶æ€å¤±è´¥: {e}")
        return False


def _raise_if_cancelled(session_id: str, step_name: str = ""):
    """
    å¦‚æœä¼šè¯å·²å–æ¶ˆï¼ŒæŠ›å‡ºå¼‚å¸¸ç»ˆæ­¢å¤„ç†
    
    Args:
        session_id: ä¼šè¯ ID
        step_name: å½“å‰æ­¥éª¤åç§°ï¼ˆç”¨äºæ—¥å¿—ï¼‰
    """
    if _check_session_cancelled(session_id):
        step_info = f" (æ­¥éª¤: {step_name})" if step_name else ""
        logger.info(f"[Workspace] ğŸ›‘ ä¼šè¯ {session_id} è¢«å–æ¶ˆï¼Œç»ˆæ­¢å¤„ç†{step_info}")
        raise SessionCancelledException(f"ä¼šè¯ {session_id} å·²è¢«ç”¨æˆ·å–æ¶ˆ")


def _split_by_max_length(text: str, max_length: int) -> list:
    """
    æŒ‰æœ€å¤§é•¿åº¦æ™ºèƒ½åˆ‡åˆ†æ–‡æœ¬
    
    åˆ‡åˆ†ç­–ç•¥ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰ï¼š
    1. ä¼˜å…ˆåœ¨ç©ºæ ¼å¤„åˆ‡åˆ†ï¼ˆé€‚åˆè‹±æ–‡ï¼‰
    2. å…¶æ¬¡åœ¨ä¸­æ–‡å¸¸è§åœé¡¿è¯ååˆ‡åˆ†ï¼ˆçš„ã€æ˜¯ã€åœ¨ã€äº†ã€å’Œã€ä¸ã€æˆ–ï¼‰
    3. æœ€åå¼ºåˆ¶æŒ‰é•¿åº¦åˆ‡åˆ†
    
    Args:
        text: å¾…åˆ‡åˆ†çš„æ–‡æœ¬
        max_length: æ¯æ®µæœ€å¤§å­—ç¬¦æ•°
        
    Returns:
        åˆ‡åˆ†åçš„æ–‡æœ¬åˆ—è¡¨
    """
    if len(text) <= max_length:
        return [text]
    
    result = []
    remaining = text
    
    while len(remaining) > max_length:
        # åœ¨ max_length èŒƒå›´å†…å¯»æ‰¾æœ€ä½³åˆ‡åˆ†ç‚¹
        chunk = remaining[:max_length]
        
        # ç­–ç•¥1ï¼šå¯»æ‰¾ç©ºæ ¼åˆ‡åˆ†ç‚¹ï¼ˆè‹±æ–‡ï¼‰
        space_idx = chunk.rfind(' ')
        if space_idx > max_length // 2:  # ç¡®ä¿åˆ‡åˆ†ç‚¹ä¸ä¼šå¤ªé å‰
            result.append(chunk[:space_idx].strip())
            remaining = remaining[space_idx:].strip()
            continue
        
        # ç­–ç•¥2ï¼šå¯»æ‰¾ä¸­æ–‡åœé¡¿è¯åˆ‡åˆ†ç‚¹
        stop_words = ['çš„', 'æ˜¯', 'åœ¨', 'äº†', 'å’Œ', 'ä¸', 'æˆ–', 'ä¹Ÿ', 'éƒ½', 'å°±', 'è€Œ', 'ä½†', 'å¾ˆ', 'æ›´']
        best_stop_idx = -1
        for word in stop_words:
            idx = chunk.rfind(word)
            if idx > max_length // 2 and idx > best_stop_idx:
                best_stop_idx = idx + len(word)  # åˆ‡åˆ†ç‚¹åœ¨åœé¡¿è¯ä¹‹å
        
        if best_stop_idx > 0:
            result.append(chunk[:best_stop_idx].strip())
            remaining = remaining[best_stop_idx:].strip()
            continue
        
        # ç­–ç•¥3ï¼šå¼ºåˆ¶æŒ‰é•¿åº¦åˆ‡åˆ†
        result.append(chunk.strip())
        remaining = remaining[max_length:].strip()
    
    if remaining:
        result.append(remaining.strip())
    
    return result


def _split_segments_by_punctuation(segments: list, max_chars_per_line: int = 20) -> list:
    """
    å°† ASR segments æŒ‰æ ‡ç‚¹ç¬¦å·è¿›ä¸€æ­¥åˆ‡åˆ†æˆæ›´ç»†çš„å­å¥
    
    åˆ‡åˆ†è§„åˆ™ï¼š
    1. ä¸­æ–‡æ ‡ç‚¹ï¼šï¼Œã€‚ï¼ï¼Ÿï¼›
    2. è‹±æ–‡æ ‡ç‚¹ï¼š,.!?;
    3. æ ¹æ®æ–‡æœ¬é•¿åº¦æŒ‰æ¯”ä¾‹åˆ†é…æ—¶é—´
    4. å•è¡Œæœ€å¤§å­—ç¬¦æ•°é™åˆ¶ï¼ˆé˜²æ­¢å­—å¹•è¿‡é•¿è¶…å‡ºå±å¹•ï¼‰
    
    Args:
        segments: ASR è¿”å›çš„ segments åˆ—è¡¨ï¼Œæ¯ä¸ªåŒ…å« start, end, text
        max_chars_per_line: å•è¡Œæœ€å¤§å­—ç¬¦æ•°ï¼Œ15å·å­—ä½“ä¸‹å»ºè®®20å­—ç¬¦
        
    Returns:
        ç»†åˆ†åçš„ segments åˆ—è¡¨
    """
    # æ ‡ç‚¹ç¬¦å·æ­£åˆ™ï¼šåŒ¹é…ä¸­è‹±æ–‡é€—å·ã€å¥å·ã€é—®å·ã€æ„Ÿå¹å·ã€åˆ†å·
    punctuation_pattern = re.compile(r'([ï¼Œã€‚ï¼ï¼Ÿï¼›,.!?;])')
    
    fine_segments = []
    
    for seg in segments:
        text = seg.get("text", "").strip()
        start_ms = seg.get("start", 0)
        end_ms = seg.get("end", 0)
        total_duration = end_ms - start_ms
        
        if not text or total_duration <= 0:
            continue
        
        # æŒ‰æ ‡ç‚¹åˆ‡åˆ†æ–‡æœ¬
        parts = punctuation_pattern.split(text)
        
        # é‡æ–°ç»„åˆï¼šå°†æ ‡ç‚¹ç¬¦å·ä¸å‰é¢çš„æ–‡æœ¬åˆå¹¶
        sentences = []
        buffer = ""
        for part in parts:
            buffer += part
            if punctuation_pattern.match(part):
                if buffer.strip():
                    sentences.append(buffer.strip())
                buffer = ""
        # å¤„ç†æœ€åæ²¡æœ‰æ ‡ç‚¹çš„éƒ¨åˆ†
        if buffer.strip():
            sentences.append(buffer.strip())
        
        # å¦‚æœåªæœ‰ä¸€ä¸ªå¥å­æˆ–æ²¡æœ‰åˆ‡åˆ†ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦æŒ‰é•¿åº¦åˆ‡åˆ†
        if len(sentences) <= 1:
            # æ£€æŸ¥æ˜¯å¦è¶…è¿‡æœ€å¤§é•¿åº¦
            if len(text) <= max_chars_per_line:
                fine_segments.append(seg)
                continue
            else:
                # æŒ‰æœ€å¤§é•¿åº¦åˆ‡åˆ†
                sentences = _split_by_max_length(text, max_chars_per_line)
        else:
            # å¯¹æ¯ä¸ªå¥å­æ£€æŸ¥é•¿åº¦ï¼Œè¿‡é•¿çš„è¿›ä¸€æ­¥åˆ‡åˆ†
            expanded_sentences = []
            for s in sentences:
                if len(s) > max_chars_per_line:
                    expanded_sentences.extend(_split_by_max_length(s, max_chars_per_line))
                else:
                    expanded_sentences.append(s)
            sentences = expanded_sentences
        
        # æŒ‰å­—ç¬¦æ•°æ¯”ä¾‹åˆ†é…æ—¶é—´
        total_chars = sum(len(s) for s in sentences)
        if total_chars == 0:
            fine_segments.append(seg)
            continue
        
        current_time = start_ms
        for sentence in sentences:
            char_ratio = len(sentence) / total_chars
            duration = int(total_duration * char_ratio)
            
            # ç¡®ä¿è‡³å°‘æœ‰ 100ms
            duration = max(duration, 100)
            
            fine_segments.append({
                "id": seg.get("id"),
                "text": sentence,
                "start": current_time,
                "end": current_time + duration,
                "speaker": seg.get("speaker"),
            })
            
            current_time += duration
    
    return fine_segments


def _generate_project_name(request: CreateSessionRequest) -> str:
    """ç”Ÿæˆé¡¹ç›®åç§°"""
    if request.file_name:
        name = request.file_name.rsplit(".", 1)[0]
        return name[:50]
    elif request.source_url:
        return f"YouTube è§†é¢‘ - {datetime.now().strftime('%m/%d %H:%M')}"
    else:
        return f"æ–°é¡¹ç›® - {datetime.now().strftime('%Y-%m-%d %H:%M')}"


def _create_progress_updater(session_id: str):
    """
    åˆ›å»ºè¿›åº¦æ›´æ–°å™¨å‡½æ•°
    
    å†…ç½®èŠ‚æµï¼šåªåœ¨è¿›åº¦å˜åŒ– â‰¥1% æˆ–æ­¥éª¤å˜åŒ–æ—¶æ‰çœŸæ­£æ›´æ–°æ•°æ®åº“
    é¿å…é¢‘ç¹å†™å…¥é€ æˆæ€§èƒ½é—®é¢˜
    """
    last_progress = {"step": None, "value": -1}
    
    def update_progress(step: str, progress: int):
        # èŠ‚æµï¼šåªåœ¨è¿›åº¦å˜åŒ– â‰¥1% æˆ–æ­¥éª¤å˜åŒ–æ—¶æ‰æ›´æ–°
        if step == last_progress["step"] and progress == last_progress["value"]:
            return  # å®Œå…¨ç›¸åŒï¼Œè·³è¿‡
        
        if step == last_progress["step"] and abs(progress - last_progress["value"]) < 1:
            return  # åŒä¸€æ­¥éª¤ï¼Œè¿›åº¦å˜åŒ– <1%ï¼Œè·³è¿‡
        
        last_progress["step"] = step
        last_progress["value"] = progress
        
        supabase.table("workspace_sessions").update({
            "current_step": step,
            "progress": progress,
            "updated_at": datetime.utcnow().isoformat(),
        }).eq("id", session_id).execute()
    
    return update_progress


async def _fetch_asset_metadata(asset_id: str, file_url: str) -> dict:
    """æå–èµ„æºå…ƒæ•°æ®ï¼ˆå®½é«˜ã€å¸§ç‡ã€ç¼–ç ç­‰ï¼Œduration ç”±å‰ç«¯æä¾›ï¼‰"""
    try:
        from ..tasks.asset_processing import extract_media_metadata
        logger.info(f"[Workspace] æ­£åœ¨æå–å…ƒæ•°æ®: {file_url[:80]}...")
        metadata = await extract_media_metadata(file_url)
        logger.debug(f"[Workspace] æå–åˆ°çš„å…ƒæ•°æ®: {metadata}")
        
        # â˜… æ£€æµ‹è§†é¢‘ç¼–ç ï¼Œåˆ¤æ–­æµè§ˆå™¨æ˜¯å¦æ”¯æŒ
        video_codec = metadata.get("codec", "")
        # æµè§ˆå™¨åŸç”Ÿæ”¯æŒçš„ç¼–ç æ ¼å¼
        BROWSER_SUPPORTED_CODECS = {"h264", "avc1", "vp8", "vp9", "av1", "hevc", "h265"}
        needs_transcode = video_codec and video_codec.lower() not in BROWSER_SUPPORTED_CODECS
        if needs_transcode:
            logger.warning(f"[Workspace] âš ï¸ è§†é¢‘ç¼–ç  {video_codec} éœ€è¦è½¬ç ä¸º H.264")
        
        # duration ç”±å‰ç«¯æä¾›ï¼Œè¿™é‡Œåªæ›´æ–°å®½é«˜ã€å¸§ç‡ã€ç¼–ç ç­‰ä¿¡æ¯
        supabase.table("assets").update({
            "width": metadata.get("width", 1920),
            "height": metadata.get("height", 1080),
            "fps": metadata.get("fps", 30),
            "sample_rate": metadata.get("sample_rate"),
            "channels": metadata.get("channels"),
            "status": "ready",
            "updated_at": datetime.utcnow().isoformat(),
        }).eq("id", asset_id).execute()
        
        # è¿”å›å®Œæ•´å…ƒæ•°æ®ï¼ŒåŒ…æ‹¬ç¼–ç ä¿¡æ¯
        metadata["needs_transcode"] = needs_transcode
        return metadata
    except Exception as e:
        logger.warning(f"[Workspace] âŒ æå–å…ƒæ•°æ®å¤±è´¥: {e}, ä½¿ç”¨é»˜è®¤å€¼")
        supabase.table("assets").update({
            "status": "ready",
            "updated_at": datetime.utcnow().isoformat(),
        }).eq("id", asset_id).execute()
        return {"duration": 0, "width": 1920, "height": 1080, "fps": 30, "needs_transcode": False}


async def _extract_audio_for_asr(video_url: str, asset_id: str, update_progress, current_progress: int, video_duration_sec: float = None) -> str:
    """
    ä»è§†é¢‘ä¸­æå–å‹ç¼©éŸ³é¢‘ï¼Œç”¨äº ASR è½¬å†™
    
    ä¼˜åŒ–ç­–ç•¥:
    - 16kHz é‡‡æ ·ç‡ï¼ˆè¯­éŸ³è¯†åˆ«è¶³å¤Ÿï¼‰
    - å•å£°é“
    - 64kbps ç ç‡
    - 4GB è§†é¢‘ â†’ çº¦ 20MB éŸ³é¢‘ï¼Œä¸Šä¼ é€Ÿåº¦æå‡ 99%
    - â˜… ç¼“å­˜å¤ç”¨ï¼šå¦‚æœéŸ³é¢‘å·²æå–è¿‡ï¼Œç›´æ¥è¿”å›ç¼“å­˜ URL
    - â˜… å®æ—¶è¿›åº¦ï¼šè§£æ FFmpeg è¾“å‡ºæ›´æ–°è¿›åº¦
    
    Args:
        video_url: è§†é¢‘çš„ç­¾å URL
        asset_id: èµ„äº§ IDï¼ˆç”¨äºå­˜å‚¨è·¯å¾„ï¼‰
        update_progress: è¿›åº¦å›è°ƒ
        current_progress: å½“å‰è¿›åº¦ç™¾åˆ†æ¯”
        video_duration_sec: è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œç”¨äºè®¡ç®—è¿›åº¦
        
    Returns:
        æå–åéŸ³é¢‘çš„ç­¾å URL
    """
    import tempfile
    import httpx
    import asyncio
    import os
    import re
    
    audio_storage_path = f"asr_audio/{asset_id}.mp3"
    
    # â˜…â˜…â˜… ç¼“å­˜æ£€æŸ¥ï¼šå¦‚æœéŸ³é¢‘å·²å­˜åœ¨ï¼Œç›´æ¥è¿”å› â˜…â˜…â˜…
    try:
        # å°è¯•ç›´æ¥è·å–ç­¾å URLï¼Œå¦‚æœæˆåŠŸè¯´æ˜æ–‡ä»¶å­˜åœ¨
        from ..services.supabase_client import supabase
        result = supabase.storage.from_("clips").create_signed_url(audio_storage_path, 60)
        cached_url = result.get("signedURL") or result.get("signedUrl") or result.get("signed_url")
        if cached_url:
            logger.info(f"[ASRä¼˜åŒ–] âœ… ä½¿ç”¨ç¼“å­˜éŸ³é¢‘: {audio_storage_path}")
            update_progress("extract_audio", current_progress + 15)
            return cached_url
    except Exception:
        pass  # ç¼“å­˜ä¸å­˜åœ¨æˆ–æ£€æŸ¥å¤±è´¥ï¼Œç»§ç»­æå–
    
    logger.info(f"[ASRä¼˜åŒ–] ğŸµ å¼€å§‹æå–éŸ³é¢‘ asset_id={asset_id}, duration={video_duration_sec}s")
    
    custom_temp_dir = os.getenv("ASR_TEMP_DIR")
    temp_dir = tempfile.mkdtemp(prefix="asr_", dir=custom_temp_dir)
    logger.info(f"[ASRä¼˜åŒ–] ğŸ“ ä¸´æ—¶ç›®å½•: {temp_dir}")
    
    audio_path = os.path.join(temp_dir, "audio_for_asr.mp3")
    
    try:
        update_progress("extract_audio", current_progress)
        logger.info(f"[ASRä¼˜åŒ–] ğŸ”§ FFmpeg æµå¼æå–éŸ³é¢‘...")
        logger.info(f"[ASRä¼˜åŒ–] ğŸ“ è¾“å…¥ URL: {video_url[:120]}...")
        
        # æ£€æµ‹æ˜¯å¦æ˜¯ HLS (m3u8) æµ
        is_hls = 'm3u8' in video_url.lower()
        
        # â˜… ä¼˜åŒ–ï¼šæ·»åŠ ç½‘ç»œè¶…æ—¶å’Œæ›´å¿«çš„ç¼–ç å‚æ•°
        cmd = [
            "ffmpeg", "-y",
            "-reconnect", "1",           # æ–­çº¿é‡è¿
            "-reconnect_streamed", "1",
            "-reconnect_delay_max", "5", # æœ€å¤§é‡è¿å»¶è¿Ÿ 5 ç§’
        ]
        
        # HLS éœ€è¦é¢å¤–å‚æ•°
        if is_hls:
            cmd.extend([
                "-protocol_whitelist", "file,http,https,tcp,tls,crypto",  # å…è®¸çš„åè®®
                "-allowed_extensions", "ALL",  # å…è®¸æ‰€æœ‰æ‰©å±•å
            ])
        
        cmd.extend([
            "-i", video_url,
            "-vn",                       # ä¸è¦è§†é¢‘
            "-ar", "16000",              # 16kHz é‡‡æ ·ç‡
            "-ac", "1",                  # å•å£°é“
            "-b:a", "64k",               # 64kbps ç ç‡
            "-f", "mp3",
            "-progress", "pipe:1",       # â˜… è¾“å‡ºè¿›åº¦åˆ° stdout
            audio_path
        ])
        
        logger.info(f"[ASRä¼˜åŒ–] ğŸ”§ FFmpeg å‘½ä»¤: {' '.join(cmd[:10])}...")
        
        process = await asyncio.create_subprocess_exec(
            *cmd,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )
        
        # â˜…â˜…â˜… å®æ—¶è§£æ FFmpeg è¿›åº¦ â˜…â˜…â˜…
        last_progress_update = 0
        total_duration_us = (video_duration_sec or 60) * 1_000_000  # å¾®ç§’
        
        async def read_progress():
            nonlocal last_progress_update
            while True:
                line = await process.stdout.readline()
                if not line:
                    break
                line_str = line.decode().strip()
                # FFmpeg progress æ ¼å¼: out_time_us=12345678
                if line_str.startswith("out_time_us="):
                    try:
                        current_us = int(line_str.split("=")[1])
                        if total_duration_us > 0:
                            pct = min(current_us / total_duration_us, 1.0)
                            # extract_audio å  10% è¿›åº¦ï¼ˆcurrent_progress åˆ° current_progress + 10ï¼‰
                            new_progress = current_progress + int(pct * 10)
                            # é¿å…é¢‘ç¹æ›´æ–°ï¼ˆæ¯å¢åŠ  2% æ›´æ–°ä¸€æ¬¡ï¼‰
                            if new_progress >= last_progress_update + 2:
                                update_progress("extract_audio", new_progress)
                                last_progress_update = new_progress
                    except (ValueError, IndexError):
                        pass
        
        # å¹¶è¡Œè¯»å– stdout è¿›åº¦å’Œ stderr
        async def read_stderr():
            """è¯»å– stderr è·å–é”™è¯¯ä¿¡æ¯"""
            data = await process.stderr.read()
            return data.decode() if data else ""
        
        progress_task = asyncio.create_task(read_progress())
        stderr_task = asyncio.create_task(read_stderr())
        
        # ç­‰å¾…è¿›ç¨‹å®Œæˆï¼ˆä¸ç”¨ communicateï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»åœ¨è¯» stdoutï¼‰
        await process.wait()
        
        # ç­‰å¾…è¯»å–ä»»åŠ¡å®Œæˆ
        await progress_task
        stderr_text = await stderr_task
        
        if process.returncode != 0:
            # æå–çœŸæ­£çš„é”™è¯¯ä¿¡æ¯ï¼ˆè·³è¿‡ FFmpeg ç‰ˆæœ¬ä¿¡æ¯ï¼‰
            error_lines = stderr_text.split('\n')
            real_errors = [line for line in error_lines if 
                          'error' in line.lower() or 
                          'failed' in line.lower() or 
                          'invalid' in line.lower() or
                          'unable' in line.lower() or
                          'no such' in line.lower()]
            error_summary = '\n'.join(real_errors[-5:]) if real_errors else stderr_text[-500:]
            
            logger.error(f"[ASRä¼˜åŒ–] âŒ FFmpeg å¤±è´¥ (returncode={process.returncode}):")
            logger.error(f"[ASRä¼˜åŒ–] âŒ é”™è¯¯æ‘˜è¦: {error_summary}")
            logger.error(f"[ASRä¼˜åŒ–] âŒ å®Œæ•´ stderr (æœ€å 1000 å­—ç¬¦): {stderr_text[-1000:]}")
            raise Exception(f"éŸ³é¢‘æå–å¤±è´¥: {error_summary[:300]}")
        
        audio_size_mb = os.path.getsize(audio_path) / (1024 * 1024)
        logger.info(f"[ASRä¼˜åŒ–] âœ… éŸ³é¢‘æµå¼æå–å®Œæˆ: {audio_size_mb:.1f}MB")
        
        # ä¸Šä¼ éŸ³é¢‘åˆ° Supabase
        update_progress("upload_audio", current_progress + 12)
        logger.info(f"[ASRä¼˜åŒ–] â¬†ï¸ ä¸Šä¼ éŸ³é¢‘...")
        
        audio_storage_path = f"asr_audio/{asset_id}.mp3"
        
        with open(audio_path, "rb") as f:
            audio_data = f.read()
        
        # ä½¿ç”¨ asyncio.to_thread é¿å…é˜»å¡
        await asyncio.to_thread(
            lambda: supabase.storage.from_("clips").upload(
                audio_storage_path,
                audio_data,
                {"content-type": "audio/mpeg", "upsert": "true"}
            )
        )
        
        audio_url = get_file_url("clips", audio_storage_path)
        update_progress("upload_audio", current_progress + 15)
        logger.info(f"[ASRä¼˜åŒ–] âœ… éŸ³é¢‘ä¸Šä¼ å®Œæˆ: {audio_storage_path}")
        
        return audio_url
        
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        import shutil
        try:
            shutil.rmtree(temp_dir)
            logger.info(f"[ASRä¼˜åŒ–] ğŸ§¹ ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†")
        except Exception as e:
            logger.warning(f"[ASRä¼˜åŒ–] âš ï¸ æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")


async def _run_asr(file_url: str, update_progress, current_progress: int, step_progress: int, asset_id: str = None, video_duration_sec: float = None, enable_ddc: bool = True) -> list:
    """
    æ‰§è¡Œ ASR è¯­éŸ³è½¬å†™
    
    ä¼˜åŒ–1ï¼šå¦‚æœ asset_id åœ¨ tasks è¡¨ä¸­å·²æœ‰è½¬å†™ç»“æœï¼Œç›´æ¥å¤ç”¨
    ä¼˜åŒ–2ï¼šå¦‚æœæä¾›äº† asset_id ä¸”æ˜¯å¤§æ–‡ä»¶ï¼ˆè§†é¢‘ï¼‰ï¼Œä¼šå…ˆæå–éŸ³é¢‘å†è½¬å†™
    
    Args:
        enable_ddc: æ˜¯å¦å¯ç”¨è¯­ä¹‰é¡ºæ»‘ï¼ˆDDCï¼‰ï¼Œä¼šåˆ é™¤"å—¯"ã€"å•Š"ç­‰è¯­æ°”è¯
                    â˜… å£ç™–æ£€æµ‹ï¼ˆdetect_fillersï¼‰æ—¶åº”è®¾ä¸º False
    """
    logger.info(f"[_run_asr] ğŸ¤ å¼€å§‹ ASR è½¬å†™")
    logger.info(f"[_run_asr]    file_url: {file_url[:100]}...")
    logger.info(f"[_run_asr]    current_progress: {current_progress}, step_progress: {step_progress}")
    logger.info(f"[_run_asr]    asset_id: {asset_id}, video_duration: {video_duration_sec}s")
    
    try:
        from ..tasks.transcribe import transcribe_audio
        import httpx
        import asyncio
        
        # â˜…â˜…â˜… ä¼˜åŒ–ï¼šæ£€æŸ¥æ˜¯å¦å·²æœ‰è½¬å†™ç»“æœï¼ˆå¤ç”¨ analyze-content çš„è½¬å†™ï¼‰â˜…â˜…â˜…
        # æ³¨æ„ï¼šæ’é™¤ clip çº§åˆ«çš„è½¬å†™ä»»åŠ¡ï¼ˆparams ä¸­åŒ…å« clip_id çš„æ˜¯ clip è½¬å†™ï¼‰
        # åªå¤ç”¨æ•´ä½“ asset çš„è½¬å†™ç»“æœ
        if asset_id:
            existing_tasks = supabase.table("tasks").select(
                "id, status, result, params"
            ).eq("asset_id", asset_id).eq("task_type", "transcribe").eq("status", "completed").execute()
            
            # ç­›é€‰å‡ºæ•´ä½“ asset çš„è½¬å†™ä»»åŠ¡ï¼ˆparams ä¸­æ²¡æœ‰ clip_idï¼‰
            existing_task_data = None
            if existing_tasks and existing_tasks.data:
                for task in existing_tasks.data:
                    params = task.get("params") or {}
                    if not params.get("clip_id"):  # æ•´ä½“ asset è½¬å†™ï¼Œä¸æ˜¯ clip è½¬å†™
                        existing_task_data = task
                        break
            
            if existing_task_data and existing_task_data.get("result"):
                result = existing_task_data["result"]
                segments = result.get("segments", []) if isinstance(result, dict) else result
                if segments:
                    logger.info(f"[_run_asr] âœ… å¤ç”¨å·²æœ‰è½¬å†™ç»“æœ: {len(segments)} ä¸ªç‰‡æ®µ (task_id={existing_task_data['id'][:8]})")
                    update_progress("transcribe", current_progress + step_progress)
                    return segments
        
        # â˜… Cloudflare HLS URLï¼šFFmpeg æ”¯æŒç›´æ¥è¯»å– HLSï¼Œæå–éŸ³é¢‘ç”¨äº ASR
        is_cloudflare_hls = 'videodelivery.net' in file_url and 'm3u8' in file_url
        
        actual_audio_url = file_url
        
        if is_cloudflare_hls:
            # Cloudflare HLSï¼šä» HLS æå–éŸ³é¢‘
            logger.info(f"[_run_asr] â˜ï¸ Cloudflare HLSï¼Œä½¿ç”¨ FFmpeg æå–éŸ³é¢‘")
            audio_progress = int(step_progress * 0.2)
            actual_audio_url = await _extract_audio_for_asr(
                video_url=file_url,
                asset_id=asset_id,
                update_progress=update_progress,
                current_progress=current_progress,
                video_duration_sec=video_duration_sec
            )
            current_progress += audio_progress
            step_progress -= audio_progress
            logger.info(f"[_run_asr] âœ… Cloudflare HLS éŸ³é¢‘æå–æˆåŠŸ")
        else:
            # åˆ¤æ–­æ˜¯å¦æ˜¯è§†é¢‘æ–‡ä»¶ï¼Œéœ€è¦æå–éŸ³é¢‘
            is_video = any(ext in file_url.lower() for ext in ['.mp4', '.mov', '.avi', '.mkv', '.webm', '.m4v'])
            
            # å¦‚æœæ˜¯è§†é¢‘ä¸”æœ‰ asset_idï¼Œå…ˆæå–éŸ³é¢‘ï¼ˆå¤§å¹…æå‡é€Ÿåº¦ï¼‰
            actual_audio_url = file_url
            if is_video and asset_id:
                logger.info(f"[_run_asr] ğŸ¬ æ£€æµ‹åˆ°è§†é¢‘æ–‡ä»¶ï¼Œå…ˆæå–éŸ³é¢‘ä»¥ä¼˜åŒ–ä¸Šä¼ é€Ÿåº¦")
                try:
                    # æå–éŸ³é¢‘å ç”¨ 20% è¿›åº¦
                    audio_progress = int(step_progress * 0.2)
                    actual_audio_url = await _extract_audio_for_asr(
                        video_url=file_url,
                        asset_id=asset_id,
                        update_progress=update_progress,
                        current_progress=current_progress,
                        video_duration_sec=video_duration_sec  # â˜… ä¼ å…¥è§†é¢‘æ—¶é•¿ç”¨äºè¿›åº¦è®¡ç®—
                    )
                    # è°ƒæ•´å‰©ä½™è¿›åº¦
                    current_progress += audio_progress
                    step_progress -= audio_progress
                    logger.info(f"[_run_asr] âœ… éŸ³é¢‘æå–æˆåŠŸï¼Œä½¿ç”¨å‹ç¼©éŸ³é¢‘è¿›è¡Œè½¬å†™")
                except Exception as e:
                    logger.warning(f"[_run_asr] âš ï¸ éŸ³é¢‘æå–å¤±è´¥ï¼Œå›é€€åˆ°åŸå§‹æ–‡ä»¶: {e}")
                    actual_audio_url = file_url
        
        # â˜… Cloudflare HLS URL ä¸éœ€è¦éªŒè¯ï¼ˆç›´æ¥å¯ç”¨ï¼‰
        is_cloudflare_hls = 'videodelivery.net' in actual_audio_url and 'm3u8' in actual_audio_url
        
        if not is_cloudflare_hls:
            # éªŒè¯æ–‡ä»¶æ˜¯å¦å¯è®¿é—®ï¼ˆç­‰å¾…ä¸Šä¼ å®Œæˆï¼‰
            max_retries = 30  # æœ€å¤šç­‰å¾… 30 ç§’
            for retry in range(max_retries):
                try:
                    async with httpx.AsyncClient(timeout=10.0) as client:
                        resp = await client.head(actual_audio_url)
                        if resp.status_code == 200:
                            logger.info(f"[_run_asr] âœ… æ–‡ä»¶å¯è®¿é—®ï¼Œå¼€å§‹è½¬å†™")
                            break
                        else:
                            logger.warning(f"[_run_asr] â³ æ–‡ä»¶ä¸å¯è®¿é—® (HTTP {resp.status_code})ï¼Œç­‰å¾…... ({retry+1}/{max_retries})")
                except Exception as e:
                    logger.warning(f"[_run_asr] â³ æ–‡ä»¶æ£€æŸ¥å¤±è´¥: {e}ï¼Œç­‰å¾…... ({retry+1}/{max_retries})")
                
                if retry < max_retries - 1:
                    await asyncio.sleep(1)
            else:
                logger.error(f"[_run_asr] âŒ æ–‡ä»¶åœ¨ {max_retries} ç§’åä»ä¸å¯è®¿é—®")
                return []
        else:
            logger.info(f"[_run_asr] â˜ï¸ Cloudflare HLS URLï¼Œè·³è¿‡éªŒè¯")
        
        def on_asr_progress(progress: int, step: str):
            mapped_progress = current_progress + int(progress * step_progress / 100)
            update_progress("transcribe", mapped_progress)
        
        asr_result = await transcribe_audio(
            audio_url=actual_audio_url,
            language="zh",
            enable_ddc=enable_ddc,  # â˜… ä¼ é€’è¯­ä¹‰é¡ºæ»‘å¼€å…³
            on_progress=on_asr_progress,
        )
        
        segments = asr_result.get("segments", [])
        logger.info(f"[_run_asr] âœ… ASR å®Œæˆï¼Œè¯†åˆ« {len(segments)} ä¸ªç‰‡æ®µ")
        
        # è¯¦ç»†æ—¥å¿—
        if segments:
            first_seg = segments[0]
            last_seg = segments[-1]
            logger.info(f"[_run_asr]    ç¬¬ä¸€ä¸ªç‰‡æ®µ: start={first_seg.get('start')}ms text='{first_seg.get('text', '')[:20]}...'")
            logger.info(f"[_run_asr]    æœ€åä¸€ä¸ªç‰‡æ®µ: end={last_seg.get('end')}ms text='{last_seg.get('text', '')[:20]}...'")
        else:
            logger.warning(f"[_run_asr] âš ï¸ ASR è¿”å›ç©ºç»“æœ!")
        
        # â˜…â˜…â˜… ä¿å­˜è½¬å†™ç»“æœåˆ° tasks è¡¨ï¼Œä¾›æ™ºèƒ½åˆ†æå¤ç”¨ â˜…â˜…â˜…
        if asset_id and segments:
            try:
                now = datetime.utcnow().isoformat()
                default_user_id = "00000000-0000-0000-0000-000000000000"
                task_id = str(uuid4())
                
                # å…ˆæŸ¥è¯¢ project_id
                asset_info = supabase.table("assets").select("project_id").eq("id", asset_id).single().execute()
                project_id = asset_info.data.get("project_id") if asset_info.data else None
                
                supabase.table("tasks").insert({
                    "id": task_id,
                    "project_id": project_id,
                    "user_id": default_user_id,
                    "task_type": "transcribe",
                    "asset_id": asset_id,
                    "status": "completed",
                    "progress": 100,
                    "params": {"language": "zh", "model": "base"},
                    "result": asr_result,
                    "created_at": now,
                    "completed_at": now,
                    "updated_at": now
                }).execute()
                logger.info(f"[_run_asr] ğŸ’¾ è½¬å†™ç»“æœå·²ä¿å­˜åˆ° tasks è¡¨ (task_id={task_id[:8]})")
            except Exception as save_err:
                logger.warning(f"[_run_asr] âš ï¸ ä¿å­˜è½¬å†™ç»“æœå¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {save_err}")
            
        return segments
    except Exception as e:
        logger.error(f"[_run_asr] âŒ ASR å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return []


# NOTE: _run_silence_detection å·²åˆ é™¤ (2025-01-28)
# é™éŸ³æ£€æµ‹åŠŸèƒ½å·²æ•´åˆåˆ° filler_detector.py ä¸­
# detect_fillers API ç›´æ¥è°ƒç”¨ filler_detector.detect_all_fillers


# NOTE: _create_clips_from_segments å·²åˆ é™¤ (2025-01-27)
# è¯¥å‡½æ•°ä»æœªè¢«è°ƒç”¨ï¼Œ_process_session_multi_assets å†…éƒ¨ç›´æ¥å¤„ç† clips åˆ›å»º
# ä¿ç•™ _create_clips_from_segments_with_offset ä¾› assets.py ä½¿ç”¨


# NOTE: _process_session å·²åˆ é™¤ (2025-01-27)
# è¯¥å‡½æ•°ä»æœªè¢«è°ƒç”¨ï¼Œæ‰€æœ‰å¤„ç†éƒ½ä½¿ç”¨ _process_session_multi_assets
# åˆ é™¤çº¦ 410 è¡Œå†—ä½™ä»£ç 


async def _process_session_multi_assets(
    session_id: str,
    project_id: str,
    assets: list,
    task_type: str,
):
    """
    åå°å¤„ç†ä¼šè¯ - å¤šç´ æç‰ˆæœ¬
    æŒ‰é¡ºåºå¤„ç†å¤šä¸ªç´ æï¼Œæ‹¼æ¥åˆ°åŒä¸€æ—¶é—´è½´
    """
    import asyncio
    
    # â˜… ç”± task_type å†³å®šå¤„ç†æµç¨‹
    ai_create_mode = task_type == "ai-create"
    voice_extract_mode = task_type == "voice-extract"
    enable_llm = False
    
    logger.info(f"[Workspace] ğŸš€ å¼€å§‹å¤„ç†å¤šç´ æä¼šè¯: session={session_id}, project={project_id}, task={task_type}, assets={len(assets)}")
    logger.debug(f"[Workspace]    ai_create_mode: {ai_create_mode}, voice_extract_mode: {voice_extract_mode}")
    
    try:
        # ========================================
        # â˜… Step 0: æ¸…ç©ºé¡¹ç›®çš„æ‰€æœ‰ clips å’Œ keyframesï¼ˆé¿å…é‡å¤/æ®‹ç•™ï¼‰
        # ========================================
        logger.info(f"[Workspace] ğŸ§¹ æ¸…ç©ºé¡¹ç›® {project_id} çš„æ‰€æœ‰ clips å’Œ keyframes...")
        
        # å…ˆè·å–é¡¹ç›®çš„æ‰€æœ‰ track_ids
        tracks_result = supabase.table("tracks").select("id").eq("project_id", project_id).execute()
        track_ids = [t["id"] for t in (tracks_result.data or [])]
        
        if track_ids:
            # è·å–æ‰€æœ‰ clip_idsï¼ˆç”¨äºåˆ é™¤å…³è”çš„ keyframesï¼‰
            clips_result = supabase.table("clips").select("id").in_("track_id", track_ids).execute()
            clip_ids = [c["id"] for c in (clips_result.data or [])]
            
            # å…ˆåˆ é™¤ keyframesï¼ˆæœ‰å¤–é”®çº¦æŸï¼‰
            if clip_ids:
                try:
                    supabase.table("keyframes").delete().in_("clip_id", clip_ids).execute()
                    logger.debug(f"[Workspace]    åˆ é™¤ {len(clip_ids)} ä¸ª clips å…³è”çš„ keyframes")
                except Exception as e:
                    logger.warning(f"[Workspace]    åˆ é™¤ keyframes å¤±è´¥ï¼ˆå¯èƒ½ä¸å­˜åœ¨ï¼‰: {e}")
            
            # å†åˆ é™¤æ‰€æœ‰ clips
            try:
                supabase.table("clips").delete().in_("track_id", track_ids).execute()
                logger.debug(f"[Workspace]    åˆ é™¤ {len(track_ids)} ä¸ª tracks ä¸‹çš„æ‰€æœ‰ clips")
            except Exception as e:
                logger.warning(f"[Workspace]    åˆ é™¤ clips å¤±è´¥: {e}")
        
        logger.info(f"[Workspace] âœ… é¡¹ç›®æ¸…ç†å®Œæˆï¼Œå¼€å§‹å…¨æ–°å¤„ç†")
        
        update_progress = _create_progress_updater(session_id)
        now = datetime.utcnow().isoformat()
        
        # Step 1: è·å–æ‰€æœ‰ç´ æå…ƒæ•°æ® (0% â†’ 10%)
        _raise_if_cancelled(session_id, "å¼€å§‹å¤„ç†å¤šç´ æ")
        update_progress("fetch", 5)
        
        # æ”¶é›†æ‰€æœ‰ç´ æä¿¡æ¯
        asset_infos = []
        total_duration = 0
        max_width = 0
        max_height = 0
        
        for idx_asset, asset in enumerate(assets):
            asset_id = asset["id"]
            storage_path = asset.get("storage_path")
            logger.debug(f"[Workspace] ğŸ“¦ è·å–ç´ æ {idx_asset + 1}/{len(assets)} å…ƒæ•°æ®: {asset_id}")
            logger.debug(f"[Workspace]    storage_path: {storage_path}")
            file_url = get_file_url("clips", storage_path)
            logger.debug(f"[Workspace]    file_url: {file_url[:80]}...")
            
            # è·å–å…ƒæ•°æ®ï¼ˆåŒ…æ‹¬ç¼–ç ä¿¡æ¯ï¼‰
            metadata = await _fetch_asset_metadata(asset_id, file_url)
            logger.debug(f"[Workspace]    metadata: {metadata}")
            duration = asset.get("duration") or metadata.get("duration", 0)
            width = metadata.get("width", 1920)
            height = metadata.get("height", 1080)
            codec = metadata.get("codec", "unknown")
            needs_transcode = metadata.get("needs_transcode", False)
            
            asset_infos.append({
                "asset_id": asset_id,
                "storage_path": storage_path,  # â˜… ä¿å­˜ storage_path ç”¨äºè½¬ç 
                "file_url": file_url,
                "duration": duration,
                "duration_ms": int(duration * 1000),
                "width": width,
                "height": height,
                "order": asset.get("order_index", 0),
                "name": asset.get("name", "ç´ æ"),
                "codec": codec,  # â˜… ä¿å­˜ç¼–ç ä¿¡æ¯
                "needs_transcode": needs_transcode,  # â˜… æ˜¯å¦éœ€è¦è½¬ç 
            })
            
            total_duration += duration
            max_width = max(max_width, width)
            max_height = max(max_height, height)
        
        # æŒ‰é¡ºåºæ’åº
        asset_infos.sort(key=lambda x: x["order"])
        
        update_progress("fetch", 10)
        logger.info(f"[Workspace] âœ… è·å– {len(asset_infos)} ä¸ªç´ æå…ƒæ•°æ®ï¼Œæ€»æ—¶é•¿ {total_duration:.1f}s")
        
        # ========================================
        # â˜… Cloudflare Streamï¼šæ— éœ€æœ¬åœ°å¤„ç†
        # ========================================
        # Cloudflare è‡ªåŠ¨å¤„ç†ï¼šHLS è½¬ç ã€è‡ªé€‚åº”ç ç‡ã€CDN åˆ†å‘
        logger.info(f"[Workspace] â˜ï¸ {len(asset_infos)} ä¸ªç´ æï¼ˆCloudflare è‡ªåŠ¨å¤„ç†ï¼‰")
        
        # ========================================
        # Step 2: å¤ç”¨å·²æœ‰è½¨é“ï¼ˆfinalize_upload å·²åˆ›å»ºï¼‰
        # ========================================
        logger.info(f"[Workspace] ğŸ” æŸ¥æ‰¾å·²æœ‰è½¨é“...")
        existing_tracks = supabase.table("tracks").select("*").eq("project_id", project_id).execute()
        
        video_track_id = None
        text_track_id = None
        audio_track_id = None
        
        if existing_tracks.data:
            for track in existing_tracks.data:
                if track.get("order_index") == 0:
                    video_track_id = track["id"]
                    logger.debug(f"[Workspace]    æ‰¾åˆ°è§†é¢‘è½¨é“: {video_track_id}")
                elif track.get("order_index") == 1:
                    # order_index=1 å¯èƒ½æ˜¯å­—å¹•è½¨é“æˆ–éŸ³é¢‘è½¨é“
                    if "å­—å¹•" in track.get("name", "") or "text" in track.get("name", "").lower():
                        text_track_id = track["id"]
                        logger.debug(f"[Workspace]    æ‰¾åˆ°å­—å¹•è½¨é“: {text_track_id}")
                    else:
                        audio_track_id = track["id"]
                        logger.debug(f"[Workspace]    æ‰¾åˆ°éŸ³é¢‘è½¨é“: {audio_track_id}")
                elif track.get("order_index") == 2:
                    text_track_id = track["id"]
                    logger.debug(f"[Workspace]    æ‰¾åˆ°å­—å¹•è½¨é“(order=2): {text_track_id}")
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å·²æœ‰è½¨é“ï¼Œæ‰åˆ›å»ºæ–°çš„ï¼ˆç†è®ºä¸Šä¸åº”è¯¥å‘ç”Ÿï¼‰
        if not video_track_id:
            logger.warning(f"[Workspace] âš ï¸ æœªæ‰¾åˆ°è§†é¢‘è½¨é“ï¼Œåˆ›å»ºæ–°çš„ï¼ˆä¸åº”è¯¥å‘ç”Ÿï¼ï¼‰")
            video_track_id = str(uuid4())
            supabase.table("tracks").insert({
                "id": video_track_id,
                "project_id": project_id,
                "name": "è§†é¢‘è½¨é“",
                "order_index": 0,
                "is_muted": False,
                "is_locked": False,
                "is_visible": True,
                "created_at": now,
                "updated_at": now,
            }).execute()
        
        main_track_id = video_track_id  # é»˜è®¤ä¸»è½¨é“æ˜¯è§†é¢‘è½¨
        
        # Voice Extract æ¨¡å¼å¤„ç†
        if voice_extract_mode:
            if not audio_track_id:
                audio_track_id = str(uuid4())
                supabase.table("tracks").insert({
                    "id": audio_track_id,
                    "project_id": project_id,
                    "name": "åŸå£°éŸ³é¢‘",
                    "order_index": 1,
                    "is_muted": False,
                    "is_locked": False,
                    "is_visible": True,
                    "created_at": now,
                    "updated_at": now,
                }).execute()
            main_track_id = audio_track_id
        
        if not text_track_id:
            logger.warning(f"[Workspace] âš ï¸ æœªæ‰¾åˆ°å­—å¹•è½¨é“ï¼Œåˆ›å»ºæ–°çš„ï¼ˆä¸åº”è¯¥å‘ç”Ÿï¼ï¼‰")
            text_track_id = str(uuid4())
            supabase.table("tracks").insert({
                "id": text_track_id,
                "project_id": project_id,
                "name": "å­—å¹•è½¨é“",
                "order_index": 2 if voice_extract_mode else 1,
                "is_muted": False,
                "is_locked": False,
                "is_visible": True,
                "created_at": now,
                "updated_at": now,
            }).execute()
        
        logger.info(f"[Workspace] âœ… è½¨é“å‡†å¤‡å®Œæˆ: video={video_track_id}, text={text_track_id}")
        
        # ========================================
        # â˜… AI-Create æ¨¡å¼ï¼šå…ˆ ASRï¼Œå†æŒ‰è¯­éŸ³åˆ‡ç‰‡
        # â˜… Voice-Extract æ¨¡å¼ï¼šæ•´ä½“ clip + å­—å¹•
        # ========================================
        
        all_video_clips = []
        all_subtitle_clips = []
        all_keyframes = []
        total_segments = 0
        timeline_position = 0  # æ—¶é—´è½´ä½ç½®ï¼ˆæ¯«ç§’ï¼‰
        
        progress_per_asset = 70 / len(asset_infos)  # æ¯ä¸ªç´ æå  70% è¿›åº¦
        
        for idx, info in enumerate(asset_infos):
            # æ¯ä¸ªç´ æå¤„ç†å‰æ£€æŸ¥å–æ¶ˆçŠ¶æ€
            _raise_if_cancelled(session_id, f"å¤„ç†ç´ æ {idx + 1}/{len(asset_infos)} å‰")
            
            asset_id = info["asset_id"]
            file_url = info["file_url"]
            storage_path = info.get("storage_path", "")
            asset_duration_ms = info["duration_ms"]
            
            if asset_duration_ms <= 0:
                asset_duration_ms = 10000
                logger.warning(f"[Workspace] âš ï¸ Asset {asset_id} æ— æ—¶é•¿ä¿¡æ¯ï¼Œä½¿ç”¨é»˜è®¤ 10s")
            
            base_progress = 10 + int(idx * progress_per_asset)
            logger.info(f"[Workspace] ğŸ“¹ å¤„ç†ç´ æ {idx + 1}/{len(asset_infos)}: {info['name'][:30]}...")
            logger.debug(f"[Workspace]    asset_id: {asset_id}, æ—¶é•¿: {info['duration']:.1f}s, æ¨¡å¼: {'AIæ™ºèƒ½åˆ‡ç‰‡' if ai_create_mode else 'æ•´ä½“æå–'}")
            
            # â˜… Cloudflare è§†é¢‘ï¼šæ— éœ€ç­‰å¾… MP4ï¼ŒASR ä¼šä» HLS æå–éŸ³é¢‘
            if storage_path.startswith("cloudflare:"):
                logger.info(f"[Workspace] â˜ï¸ Cloudflare è§†é¢‘ï¼ŒASR å°†ä» HLS æå–éŸ³é¢‘")
            
            # Step 1: ASR è½¬å†™ï¼ˆè·å–è¯­éŸ³ç‰‡æ®µï¼‰
            transcript_segments = []
            logger.debug(f"[Workspace] ğŸ™ï¸ å¼€å§‹ ASR è½¬å†™ç´ æ {idx + 1}...")
            update_progress("transcribe", base_progress + 5)
            
            if idx > 0:
                logger.debug(f"[Workspace]    â³ ç­‰å¾… 2 ç§’é¿å… API é™æµ...")
                await asyncio.sleep(2)
            
            try:
                transcript_segments = await _run_asr(
                    file_url, 
                    update_progress,
                    base_progress,
                    int(progress_per_asset),
                    asset_id=asset_id,
                    video_duration_sec=info['duration']
                )
                
                logger.info(f"[Workspace] âœ… ASR å®Œæˆç´ æ {idx + 1}, è¯†åˆ« {len(transcript_segments)} ä¸ªç‰‡æ®µ")
                _raise_if_cancelled(session_id, f"ç´ æ {idx + 1} ASR å")
                
                breath_count = sum(1 for seg in transcript_segments if (seg.get("silence_info") or {}).get("classification") == "breath")
                speech_count = sum(1 for seg in transcript_segments if not seg.get("silence_info"))
                logger.debug(f"[Workspace]    å…¶ä¸­: è¯­éŸ³ç‰‡æ®µ {speech_count} ä¸ª, æ¢æ°”ç‰‡æ®µ {breath_count} ä¸ª")
                total_segments += len(transcript_segments)
            except Exception as asr_err:
                logger.error(f"[Workspace] âŒ ASR è½¬å†™ç´ æ {idx + 1} å¤±è´¥: {asr_err}")
                import traceback
                traceback.print_exc()
            
            # ========================================
            # Step 2: åˆ›å»º Video Clips
            # ========================================
            
            if ai_create_mode and transcript_segments:
                # â˜…â˜…â˜… AI-Create æ¨¡å¼ï¼šå®Œæ•´ä¸€é”®æˆç‰‡æµç¨‹ â˜…â˜…â˜…
                # ä½¿ç”¨ AIVideoCreatorService å¤„ç†ï¼š
                # 1. æ™ºèƒ½åˆ‡ç‰‡ (å·²æœ‰ ASR ç»“æœ)
                # 2. è§†è§‰åˆ†æ (äººè„¸æ£€æµ‹)
                # 3. LLM è¯­ä¹‰åˆ†æ (æƒ…ç»ª/é‡è¦æ€§)
                # 4. è¿é•œè§„åˆ™å¼•æ“ (å†³ç­–)
                # 5. åºåˆ—æ„ŸçŸ¥åå¤„ç† (å¤šæ ·æ€§)
                
                logger.debug(f"[Workspace] ğŸ¬ AIæ™ºèƒ½åˆ‡ç‰‡æ¨¡å¼ï¼šè°ƒç”¨ AIVideoCreatorService...")
                
                from app.services.ai_video_creator import ai_video_creator
                from app.services.transform_rules import ZoomStrategy
                
                try:
                    # è°ƒç”¨ AI æˆç‰‡æœåŠ¡ï¼ˆå¤ç”¨å·²æœ‰ ASR ç»“æœï¼‰
                    ai_result = await ai_video_creator.process(
                        video_path=file_url,  # ä½¿ç”¨ URLï¼ˆè§†è§‰åˆ†æä¼šä¸‹è½½ï¼‰
                        audio_url=file_url,
                        options={
                            "transcript_segments": transcript_segments,
                            "enable_llm": enable_llm,  # æ ¹æ®é…ç½®å†³å®šæ˜¯å¦å¯ç”¨ LLM
                        }
                    )
                    
                    logger.info(f"[Workspace] âœ… AIVideoCreator å¤„ç†å®Œæˆ: {ai_result.clips_count} ä¸ªç‰‡æ®µ")
                    
                    # å°† AI ç»“æœè½¬æ¢ä¸º clips å’Œ keyframes
                    for seg_idx, smart_seg in enumerate(ai_result.segments):
                        seg_start = int(smart_seg.start)
                        seg_end = int(smart_seg.end)
                        seg_text = smart_seg.text.strip() if smart_seg.text else ""
                        seg_duration = seg_end - seg_start
                        
                        if seg_duration <= 0:
                            continue
                        
                        clip_id = str(uuid4())
                        
                        # â˜… æ¢æ°”ç‰‡æ®µï¼šä¿ç•™ï¼Œæ·»åŠ  silence_info è®©å‰ç«¯å‘å¯¼å¤„ç†
                        is_breath = smart_seg.is_breath
                        
                        if is_breath:
                            # æ¢æ°”ç‰‡æ®µï¼šåˆ›å»º clip ä½†æ ‡è®°ä¸ºæ¢æ°”ï¼Œä¾›å‰ç«¯å‘å¯¼å¤„ç†
                            clip_data = {
                                "id": clip_id,
                                "track_id": video_track_id,
                                "asset_id": asset_id,
                                "clip_type": "video",
                                "name": "[æ¢æ°”]",
                                "start_time": timeline_position,
                                "end_time": timeline_position + seg_duration,
                                "source_start": seg_start,
                                "source_end": seg_end,
                                "volume": 1.0,
                                "is_muted": False,
                                "transform": {
                                    "x": 0, "y": 0,
                                    "scaleX": 1, "scaleY": 1,
                                    "rotation": 0,
                                    "opacity": 1,
                                },
                                "speed": 1.0,
                                "metadata": {
                                    "segment_id": smart_seg.id,
                                    "asset_index": idx,
                                    "segment_index": seg_idx,
                                    "silence_info": {
                                        "classification": "breath",
                                        "duration_ms": seg_duration,
                                    },
                                },
                                "created_at": now,
                                "updated_at": now,
                            }
                            all_video_clips.append(clip_data)
                            
                            # æ¢æ°”ç‰‡æ®µä¸éœ€è¦å­—å¹•å’Œè¿é•œ
                            logger.debug(f"[Workspace]    Clip {seg_idx + 1} [æ¢æ°”]: {timeline_position}~{timeline_position + seg_duration}ms")
                            timeline_position += seg_duration
                            continue
                        
                        # è·³è¿‡ç©ºæ–‡æœ¬çš„éæ¢æ°”ç‰‡æ®µ
                        if not seg_text:
                            continue
                        
                        # è¯­éŸ³ç‰‡æ®µ
                        clip_data = {
                            "id": clip_id,
                            "track_id": video_track_id,
                            "asset_id": asset_id,
                            "clip_type": "video",
                            "name": seg_text[:20] + ("..." if len(seg_text) > 20 else ""),
                            "start_time": timeline_position,
                            "end_time": timeline_position + seg_duration,
                            "source_start": seg_start,
                            "source_end": seg_end,
                            "volume": 1.0,
                            "is_muted": False,
                            "transform": {
                                "x": 0, "y": 0,
                                "scaleX": 1, "scaleY": 1,
                                "rotation": 0,
                                "opacity": 1,
                            },
                            "speed": 1.0,
                            "metadata": {
                                "segment_id": smart_seg.id,
                                "asset_index": idx,
                                "segment_index": seg_idx,
                                "emotion": smart_seg.emotion.value if smart_seg.emotion else "neutral",
                                "importance": smart_seg.importance.value if smart_seg.importance else "medium",
                                "has_face": smart_seg.has_face,
                                "rule_applied": smart_seg.transform.get("_rule_applied") if smart_seg.transform else None,
                            },
                            "created_at": now,
                            "updated_at": now,
                        }
                        all_video_clips.append(clip_data)
                        
                        # å­—å¹• clipsï¼ˆç»†åˆ†ï¼‰
                        fine_subs = _split_segments_by_punctuation([{
                            "id": smart_seg.id,
                            "start": seg_start,
                            "end": seg_end,
                            "text": seg_text,
                        }])
                        for sub_idx, sub_seg in enumerate(fine_subs):
                            sub_start = sub_seg.get("start", seg_start)
                            sub_end = sub_seg.get("end", seg_end)
                            sub_text = sub_seg.get("text", "").strip()
                            sub_duration = sub_end - sub_start
                            
                            if sub_duration <= 0 or not sub_text:
                                continue
                            
                            sub_offset = sub_start - seg_start
                            
                            all_subtitle_clips.append({
                                "id": str(uuid4()),
                                "track_id": text_track_id,
                                "clip_type": "subtitle",
                                "parent_clip_id": clip_id,
                                "start_time": timeline_position + sub_offset,
                                "end_time": timeline_position + sub_offset + sub_duration,
                                "source_start": 0,
                                "source_end": sub_duration,
                                "is_muted": False,
                                "content_text": sub_text,
                                "text_style": {
                                    "fontSize": 15,
                                    "fontColor": "#FFFFFF",
                                    "backgroundColor": "transparent",
                                    "alignment": "center",
                                    "maxWidth": "95%",
                                },
                                "transform": {"x": 0, "y": 150, "scale": 1},
                                "metadata": {
                                    "segment_id": smart_seg.id,
                                    "asset_index": idx,
                                    "order_index": seg_idx * 100 + sub_idx,
                                },
                                "created_at": now,
                                "updated_at": now,
                            })
                        
                        # â˜… Keyframesï¼šæ ¹æ® AI è¿é•œå†³ç­–ç”Ÿæˆ
                        if smart_seg.transform_params:
                            params = smart_seg.transform_params
                            
                            # èµ·å§‹å…³é”®å¸§
                            all_keyframes.append({
                                "id": str(uuid4()),
                                "clip_id": clip_id,
                                "property": "scale",
                                "offset": 0.0,
                                "value": {"x": params.start_scale, "y": params.start_scale},
                                "easing": "ease_in_out",
                                "created_at": now,
                                "updated_at": now,
                            })
                            
                            # ç»“æŸå…³é”®å¸§
                            all_keyframes.append({
                                "id": str(uuid4()),
                                "clip_id": clip_id,
                                "property": "scale",
                                "offset": 1.0,
                                "value": {"x": params.end_scale, "y": params.end_scale},
                                "easing": params.easing.value if hasattr(params.easing, 'value') else str(params.easing),
                                "created_at": now,
                                "updated_at": now,
                            })
                            
                            # ä½ç§»å…³é”®å¸§ï¼ˆå¦‚æœæœ‰ä½ç§»ï¼‰
                            if abs(params.position_x) > 0.01 or abs(params.position_y) > 0.01:
                                all_keyframes.append({
                                    "id": str(uuid4()),
                                    "clip_id": clip_id,
                                    "property": "position",
                                    "offset": 0.0,
                                    "value": {"x": 0, "y": 0},
                                    "easing": "ease_in_out",
                                    "created_at": now,
                                    "updated_at": now,
                                })
                                all_keyframes.append({
                                    "id": str(uuid4()),
                                    "clip_id": clip_id,
                                    "property": "position",
                                    "offset": 1.0,
                                    "value": {"x": params.position_x, "y": params.position_y},
                                    "easing": params.easing.value if hasattr(params.easing, 'value') else str(params.easing),
                                    "created_at": now,
                                    "updated_at": now,
                                })
                            
                            logger.debug(f"[Workspace]    Clip {seg_idx + 1}: {timeline_position}~{timeline_position + seg_duration}ms, "
                                       f"rule={params.rule_applied}, scale={params.start_scale:.2f}â†’{params.end_scale:.2f}")
                        else:
                            # Fallback: ç®€å•æ…¢æ¨
                            all_keyframes.append({
                                "id": str(uuid4()),
                                "clip_id": clip_id,
                                "property": "scale",
                                "offset": 0.0,
                                "value": {"x": 1.0, "y": 1.0},
                                "easing": "ease_in_out",
                                "created_at": now,
                                "updated_at": now,
                            })
                            all_keyframes.append({
                                "id": str(uuid4()),
                                "clip_id": clip_id,
                                "property": "scale",
                                "offset": 1.0,
                                "value": {"x": 1.08, "y": 1.08},
                                "easing": "linear",
                                "created_at": now,
                                "updated_at": now,
                            })
                        
                        timeline_position += seg_duration
                    
                    logger.debug(f"[Workspace] âœ… AIåˆ‡ç‰‡å®Œæˆ: {len([c for c in all_video_clips if c.get('asset_id') == asset_id])} ä¸ª video clips")
                    
                except Exception as ai_err:
                    logger.error(f"[Workspace] âŒ AIVideoCreator å¤„ç†å¤±è´¥: {ai_err}")
                    import traceback
                    traceback.print_exc()
                    
                    # Fallback: ä½¿ç”¨ç®€å•åˆ‡ç‰‡é€»è¾‘
                    logger.debug(f"[Workspace] âš ï¸ é™çº§ä¸ºç®€å•åˆ‡ç‰‡æ¨¡å¼...")
                    speech_segments = [seg for seg in transcript_segments 
                                      if seg.get("text", "").strip() and not seg.get("silence_info")]
                    
                    for seg_idx, seg in enumerate(speech_segments):
                        seg_start = seg.get("start", 0)
                        seg_end = seg.get("end", 0)
                        seg_text = seg.get("text", "").strip()
                        seg_duration = seg_end - seg_start
                        
                        if seg_duration <= 0:
                            continue
                        
                        clip_id = str(uuid4())
                        clip_data = {
                            "id": clip_id,
                            "track_id": video_track_id,
                            "asset_id": asset_id,
                            "clip_type": "video",
                            "name": seg_text[:20] + ("..." if len(seg_text) > 20 else ""),
                            "start_time": timeline_position,
                            "end_time": timeline_position + seg_duration,
                            "source_start": seg_start,
                            "source_end": seg_end,
                            "volume": 1.0,
                            "is_muted": False,
                            "transform": {"x": 0, "y": 0, "scaleX": 1, "scaleY": 1, "rotation": 0, "opacity": 1},
                            "speed": 1.0,
                            "created_at": now,
                            "updated_at": now,
                        }
                        all_video_clips.append(clip_data)
                        
                        # ç®€å• keyframes
                        all_keyframes.append({
                            "id": str(uuid4()),
                            "clip_id": clip_id,
                            "property": "scale",
                            "offset": 0.0,
                            "value": {"x": 1.0, "y": 1.0},
                            "easing": "ease_in_out",
                            "created_at": now,
                            "updated_at": now,
                        })
                        all_keyframes.append({
                            "id": str(uuid4()),
                            "clip_id": clip_id,
                            "property": "scale",
                            "offset": 1.0,
                            "value": {"x": 1.08, "y": 1.08},
                            "easing": "linear",
                            "created_at": now,
                            "updated_at": now,
                        })
                        
                        timeline_position += seg_duration
                
            else:
                # â˜… Voice-Extract æˆ–æ—  ASR ç»“æœï¼šåˆ›å»ºæ•´ä½“ clip
                logger.debug(f"[Workspace] ğŸ¬ æ•´ä½“æ¨¡å¼ï¼šåˆ›å»ºå•ä¸ª clip...")
                
                clip_id = str(uuid4())
                clip_data = {
                    "id": clip_id,
                    "track_id": video_track_id,
                    "asset_id": asset_id,
                    "clip_type": "video",
                    "name": info.get("name", "è§†é¢‘"),
                    "start_time": timeline_position,
                    "end_time": timeline_position + asset_duration_ms,
                    "source_start": 0,
                    "source_end": asset_duration_ms,
                    "volume": 1.0,
                    "is_muted": False,
                    "transform": {
                        "x": 0, "y": 0,
                        "scaleX": 1, "scaleY": 1,
                        "rotation": 0,
                        "opacity": 1,
                    },
                    "speed": 1.0,
                    "created_at": now,
                    "updated_at": now,
                }
                all_video_clips.append(clip_data)
                
                # åˆ›å»ºå­—å¹• clipsï¼ˆå¦‚æœæœ‰ ASR ç»“æœï¼‰
                if transcript_segments:
                    subtitle_clips = await _create_subtitle_clips_only(
                        transcript_segments=transcript_segments,
                        text_track_id=text_track_id,
                        video_clip_id=clip_id,
                        timeline_offset=timeline_position,
                        asset_index=idx,
                    )
                    all_subtitle_clips.extend(subtitle_clips)
                
                logger.debug(f"[Workspace]    åˆ›å»º clip: {clip_id}, {timeline_position}~{timeline_position + asset_duration_ms}ms")
                timeline_position += asset_duration_ms
            
            logger.debug(f"[Workspace] âœ… ç´ æ {idx + 1} å¤„ç†å®Œæˆ")
        
        # ========================================
        # Step 3: æ‰¹é‡æ’å…¥ clips å’Œ keyframes
        # ========================================
        logger.debug(f"[Workspace] ğŸ“¦ æ‰¹é‡æ’å…¥æ•°æ®åº“...")
        
        if all_video_clips:
            try:
                supabase.table("clips").insert(all_video_clips).execute()
                logger.debug(f"[Workspace] âœ… åˆ›å»º {len(all_video_clips)} ä¸ª video clips")
            except Exception as e:
                logger.error(f"[Workspace] âŒ åˆ›å»º video clips å¤±è´¥: {e}")
                raise
        
        if all_keyframes:
            try:
                supabase.table("keyframes").insert(all_keyframes).execute()
                logger.debug(f"[Workspace] âœ… åˆ›å»º {len(all_keyframes)} ä¸ª keyframes")
            except Exception as e:
                logger.warning(f"[Workspace] âš ï¸ æ’å…¥ keyframes å¤±è´¥: {e}")
        
        if all_subtitle_clips:
            try:
                supabase.table("clips").insert(all_subtitle_clips).execute()
                logger.debug(f"[Workspace] âœ… åˆ›å»º {len(all_subtitle_clips)} ä¸ªå­—å¹• clips")
            except Exception as e:
                logger.warning(f"[Workspace] âš ï¸ åˆ›å»ºå­—å¹• clips å¤±è´¥: {e}")
        
        # ========================================
        # â˜… Cloudflare ç®€åŒ–ï¼šæ— éœ€ç­‰å¾… HLS ä»»åŠ¡
        # ========================================
        update_progress("prepare", 95)
        
        # æ›´æ–°é¡¹ç›®
        fps = 30
        supabase.table("projects").update({
            "status": "ready",
            "resolution": {"width": max_width, "height": max_height},
            "fps": fps,
            "updated_at": now,
        }).eq("id", project_id).execute()
        
        # æ›´æ–°æ‰€æœ‰ç´ æçŠ¶æ€
        for info in asset_infos:
            supabase.table("assets").update({
                "status": "ready",
                "updated_at": now,
            }).eq("id", info["asset_id"]).execute()
        
        update_progress("prepare", 100)
        
        # æ ‡è®°ä¼šè¯å®Œæˆ
        supabase.table("workspace_sessions").update({
            "status": "completed",
            "progress": 100,
            "current_step": "completed",
            "transcript_segments": total_segments,
            "completed_at": now,
            "updated_at": now,
        }).eq("id", session_id).execute()
        
        logger.info(f"[Workspace] âœ… å¤šç´ æä¼šè¯ {session_id} å¤„ç†å®Œæˆï¼Œå…± {len(asset_infos)} ä¸ªç´ æ")
        
    except SessionCancelledException:
        # ç”¨æˆ·ä¸»åŠ¨å–æ¶ˆï¼Œä¸éœ€è¦æ›´æ–°çŠ¶æ€ï¼ˆå·²ç»æ˜¯ cancelledï¼‰
        logger.info(f"[Workspace] ğŸ›‘ å¤šç´ æä¼šè¯ {session_id} å¤„ç†å·²è¢«ç”¨æˆ·å–æ¶ˆ")
        return
    except Exception as e:
        logger.error(f"[Workspace] âŒ å¤šç´ æå¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        
        supabase.table("workspace_sessions").update({
            "status": "failed",
            "error_message": str(e),
            "updated_at": datetime.utcnow().isoformat(),
        }).eq("id", session_id).execute()
        
        supabase.table("projects").update({
            "status": "draft",
            "updated_at": datetime.utcnow().isoformat(),
        }).eq("id", project_id).execute()


async def _create_clips_from_segments_with_offset(
    project_id: str,
    asset_id: str,
    transcript_segments: list,
    video_track_id: str,
    text_track_id: str,
    timeline_offset: int = 0,
    asset_index: int = 0,
    enable_llm: bool = False,
    enable_smart_camera: bool = True,
    enable_subtitle: bool = True,
) -> tuple:
    """
    æ ¹æ® ASR segments åˆ›å»ºè§†é¢‘å’Œå­—å¹• clipsï¼ˆå¸¦æ—¶é—´è½´åç§»ï¼‰
    ç”¨äºå¤šç´ ææ‹¼æ¥åœºæ™¯
    
    Args:
        timeline_offset: åœ¨æ—¶é—´è½´ä¸Šçš„èµ·å§‹ä½ç½®ï¼ˆæ¯«ç§’ï¼‰
        asset_index: ç´ æç´¢å¼•ï¼Œç”¨äºå‘½å
        enable_llm: æ˜¯å¦å¯ç”¨ LLM è¯­ä¹‰åˆ†æ
        enable_smart_camera: æ˜¯å¦å¯ç”¨æ™ºèƒ½è¿é•œï¼ˆå¦‚æœä¸º Falseï¼Œåˆ™ä¸è¿›è¡Œè£å‰ª/ç¼©æ”¾ï¼‰
        enable_subtitle: æ˜¯å¦ç”Ÿæˆå­—å¹• clipsï¼ˆå¦‚æœä¸º Falseï¼Œåªç”Ÿæˆè§†é¢‘ clipsï¼‰
        
    Returns:
        tuple: (video_clips, subtitle_clips, keyframes)
        - keyframes: å¾…æ’å…¥ keyframes è¡¨çš„è®°å½•åˆ—è¡¨
    """
    logger.info(f"[Workspace] ======== åˆ‡ç‰‡å‡½æ•°å¼€å§‹ ========")
    logger.info(f"[Workspace] ğŸ¬ _create_clips_from_segments_with_offset")
    logger.info(f"[Workspace]    asset_id: {asset_id}")
    logger.info(f"[Workspace]    asset_index: {asset_index}")
    logger.info(f"[Workspace]    timeline_offset: {timeline_offset}ms")
    logger.info(f"[Workspace]    enable_smart_camera: {enable_smart_camera}")
    logger.info(f"[Workspace]    enable_subtitle: {enable_subtitle}")
    logger.info(f"[Workspace]    è¾“å…¥ segments æ•°é‡: {len(transcript_segments)}")
    
    # â˜… å…³é”®æ—¥å¿—ï¼šæ‰“å°å‰å‡ ä¸ª segments çš„å†…å®¹ï¼ŒéªŒè¯ ASR ç»“æœå’Œ asset å¯¹åº”
    if transcript_segments:
        for i, seg in enumerate(transcript_segments[:3]):
            seg_text = seg.get("text", "")[:30]
            logger.info(f"[Workspace]    segment[{i}]: start={seg.get('start')} text='{seg_text}...'")
    
    now = datetime.utcnow().isoformat()
    
    # æŒ‰æ—¶é—´é¡ºåºæ’åºåŸå§‹ segments
    sorted_segments = sorted(transcript_segments, key=lambda s: s.get("start", 0))
    
    video_clips = []
    subtitle_clips = []
    all_keyframes = []  # â˜… æ”¶é›†æ‰€æœ‰å…³é”®å¸§è®°å½•
    timeline_position = timeline_offset
    
    # ç»Ÿè®¡è‡ªåŠ¨è·³è¿‡çš„é™éŸ³ç‰‡æ®µ
    auto_skipped = {"dead_air": 0, "long_pause": 0, "hesitation": 0}
    
    # ========== ç¬¬ä¸€é˜¶æ®µï¼šæ”¶é›†æœ‰æ•ˆç‰‡æ®µ ==========
    valid_segments = []  # å­˜å‚¨ (seg_idx, seg, seg_duration, clip_name, is_breath, silence_info)
    
    for seg_idx, seg in enumerate(sorted_segments):
        seg_start = seg.get("start", 0)
        seg_end = seg.get("end", 0)
        seg_text = seg.get("text", "").strip()
        seg_duration = seg_end - seg_start
        
        if seg_duration <= 0:
            continue
        
        # æ£€æŸ¥é™éŸ³ä¿¡æ¯
        silence_info = seg.get("silence_info")
        
        if silence_info:
            cls = silence_info.get("classification")
            if cls in ("dead_air", "long_pause", "hesitation"):
                logger.info(f"[Workspace]   âš ï¸ è·³è¿‡ segment[{seg_idx}]: type={cls} start={seg_start} end={seg_end}")
                auto_skipped[cls] = auto_skipped.get(cls, 0) + 1
                continue
        
        # ç¡®å®šç‰‡æ®µç±»å‹
        clip_name = f"ç´ æ{asset_index + 1}-ç‰‡æ®µ{seg_idx + 1}"
        is_breath = False
        if silence_info and silence_info.get("classification") == "breath":
            clip_name = f"ç´ æ{asset_index + 1}-æ¢æ°”"
            is_breath = True
        
        valid_segments.append((seg_idx, seg, seg_duration, clip_name, is_breath, silence_info))
    
    # ========== ç¬¬äºŒé˜¶æ®µï¼šLLM è¯­ä¹‰åˆ†æï¼ˆå¯é€‰ï¼‰==========
    # å­˜å‚¨åˆ†æç»“æœ: {segment_id: SegmentAnalysis}
    llm_results: Dict[str, Any] = {}
    if enable_llm and valid_segments:
        from ..services.llm import llm_service
        
        if llm_service.is_configured():
            logger.info(f"[Workspace] ğŸ¤– å¼€å§‹ LLM è¯­ä¹‰åˆ†æ...")
            # æ„å»ºå¾…åˆ†æçš„æ–‡æœ¬ç‰‡æ®µ
            text_segments = []
            for seg_idx, seg, seg_duration, clip_name, is_breath, silence_info in valid_segments:
                seg_text = seg.get("text", "").strip()
                if seg_text and not is_breath:
                    text_segments.append({"id": str(seg_idx), "text": seg_text})
            
            if text_segments:
                try:
                    emotion_result = await llm_service.analyze_emotions(text_segments)
                    # ç›´æ¥ä½¿ç”¨ SegmentAnalysis å¯¹è±¡
                    for seg_analysis in emotion_result.results:
                        llm_results[seg_analysis.id] = seg_analysis
                    logger.info(f"[Workspace] âœ… LLM åˆ†æå®Œæˆ: {len(llm_results)} æ¡ç»“æœ")
                except Exception as e:
                    logger.warning(f"[Workspace] âš ï¸ LLM åˆ†æå¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            else:
                logger.info(f"[Workspace]    æ— æ–‡æœ¬ç‰‡æ®µéœ€è¦åˆ†æ")
        else:
            logger.info(f"[Workspace] âš ï¸ LLM API æœªé…ç½®ï¼Œè·³è¿‡è¯­ä¹‰åˆ†æ")
    
    # ========== ç¬¬ä¸‰é˜¶æ®µï¼šæ‰¹é‡ç”Ÿæˆ transformï¼ˆå«åºåˆ—åå¤„ç†ï¼‰==========
    # é‡ç½®åºåˆ—å¤„ç†å™¨çŠ¶æ€
    sequence_processor.reset()
    
    # å£æ’­æ¨¡å¼é»˜è®¤äººè„¸ä½ç½®ï¼ˆä¸å•ç´ ææµç¨‹ä¸€è‡´ï¼‰
    DEFAULT_FACE_CENTER_X = 0.5   # å±…ä¸­
    DEFAULT_FACE_CENTER_Y = 0.35  # ç¨å¾®åä¸Šï¼ˆå£æ’­å¸¸è§æ„å›¾ï¼‰
    
    # æ„å»ºä¸Šä¸‹æ–‡åˆ—è¡¨
    contexts = []
    for seg_idx, seg, seg_duration, clip_name, is_breath, silence_info in valid_segments:
        seg_text = seg.get("text", "").strip()
        seg_id_str = str(seg_idx)
        
        # ä» LLM ç»“æœè·å–æƒ…ç»ªå’Œé‡è¦æ€§ï¼Œæˆ–ä½¿ç”¨é»˜è®¤å€¼
        seg_analysis = llm_results.get(seg_id_str)
        emotion = seg_analysis.emotion if seg_analysis else EmotionType.NEUTRAL
        importance = seg_analysis.importance if seg_analysis else ImportanceLevel.MEDIUM
        
        context = SegmentContext(
            segment_id=seg_id_str,
            duration_ms=seg_duration,
            text=seg_text,
            # å£æ’­æ¨¡å¼ï¼šé»˜è®¤æœ‰äººè„¸ï¼Œå±…ä¸­åä¸Šï¼ˆä¸å•ç´ ææµç¨‹ä¸€è‡´ï¼‰
            has_face=True,
            face_center_x=DEFAULT_FACE_CENTER_X,
            face_center_y=DEFAULT_FACE_CENTER_Y,
            # ä½¿ç”¨ LLM åˆ†æç»“æœæˆ–é»˜è®¤å€¼
            emotion=emotion,
            importance=importance,
            is_breath=is_breath,
        )
        contexts.append(context)
    
    logger.info(f"[Workspace] ğŸ¥ enable_smart_camera={enable_smart_camera}, å¾…å¤„ç† {len(contexts)} ä¸ªç‰‡æ®µ")
    
    # ä½¿ç”¨è§„åˆ™å¼•æ“æ‰¹é‡å¤„ç†
    if enable_smart_camera:
        params_list = [transform_engine.process(ctx) for ctx in contexts]
        
        # åºåˆ—æ„ŸçŸ¥åå¤„ç†ï¼šç¡®ä¿è¿é•œå¤šæ ·æ€§ï¼ˆä¸å•ç´ ææµç¨‹ä¸€è‡´ï¼‰
        params_contexts = list(zip(params_list, contexts))
        processed_params = sequence_processor.process_batch(params_contexts)
    else:
        # ç¦ç”¨æ™ºèƒ½è¿é•œï¼Œç”Ÿæˆé»˜è®¤é™æ€å‚æ•°
        processed_params = [
            TransformParams(strategy=ZoomStrategy.STATIC, rule_applied="disabled_by_user")
            for _ in contexts
        ]
    
    # ========== ç¬¬ä¸‰é˜¶æ®µï¼šæ„å»º clips ==========
    for i, (seg_idx, seg, seg_duration, clip_name, is_breath, silence_info) in enumerate(valid_segments):
        seg_start = seg.get("start", 0)
        seg_end = seg.get("end", 0)
        seg_text = seg.get("text", "").strip()
        
        video_clip_id = str(uuid4())
        
        # è·å–æ‰¹å¤„ç†åçš„ transform
        transform_params = processed_params[i]
        
        # â˜… æ–° APIï¼šç›´æ¥è·å–å…ƒä¿¡æ¯å’Œå…³é”®å¸§
        transform_meta = transform_params.get_meta()
        clip_keyframes = transform_params.get_keyframes_for_db(video_clip_id, seg_duration)
        
        logger.info(f"[Workspace]   âœ… åˆ›å»º clip[{seg_idx}]: name='{clip_name}' timeline={timeline_position}~{timeline_position + seg_duration} source={seg_start}~{seg_end} rule={transform_meta.get('_rule_applied', 'none')}")
        
        video_clips.append({
            "id": video_clip_id,
            "track_id": video_track_id,
            "asset_id": asset_id,
            "clip_type": "video",
            "start_time": timeline_position,
            "end_time": timeline_position + seg_duration,
            "source_start": seg_start,
            "source_end": seg_end,
            "is_muted": False,
            "name": clip_name,
            "transform": transform_meta,  # åªå­˜å…ƒä¿¡æ¯
            "created_at": now,
            "updated_at": now,
            "metadata": {
                "silence_info": silence_info,
                "original_text": seg_text,
                "asset_index": asset_index,
            }
        })
        
        # æ”¶é›†å…³é”®å¸§ï¼ˆç»Ÿä¸€å­˜å‚¨åˆ° keyframes è¡¨ï¼‰
        all_keyframes.extend(clip_keyframes)
        
        # åˆ›å»ºå­—å¹• clipsï¼ˆä»…å½“ enable_subtitle=True æ—¶ï¼‰
        if seg_text and enable_subtitle:
            fine_subs = _split_segments_by_punctuation([seg])
            
            for sub_idx, sub_seg in enumerate(fine_subs):
                sub_start = sub_seg.get("start", seg_start)
                sub_end = sub_seg.get("end", seg_end)
                sub_text = sub_seg.get("text", "").strip()
                sub_duration = sub_end - sub_start
                
                if sub_duration <= 0 or not sub_text:
                    continue
                
                subtitle_timeline_start = timeline_position + (sub_start - seg_start)
                
                subtitle_clips.append({
                    "id": str(uuid4()),
                    "track_id": text_track_id,
                    "clip_type": "subtitle",
                    "parent_clip_id": video_clip_id,
                    "start_time": subtitle_timeline_start,
                    "end_time": subtitle_timeline_start + sub_duration,
                    "source_start": 0,
                    "source_end": sub_duration,
                    "is_muted": False,
                    "content_text": sub_text,
                    "text_style": {
                        "fontSize": 15,
                        "fontColor": "#FFFFFF",
                        "backgroundColor": "transparent",
                        "alignment": "center",
                        "maxWidth": "95%",
                    },
                    "transform": {
                        "x": 0,
                        "y": 150,
                        "scale": 1,
                    },
                    "metadata": {
                        "segment_id": seg.get("id"),
                        "asset_index": asset_index,
                        "order_index": seg_idx * 100 + sub_idx,
                        "original_start": sub_start,
                        "original_end": sub_end,
                    },
                    "created_at": now,
                    "updated_at": now,
                })
        
        timeline_position += seg_duration
    
    logger.info(f"[Workspace] ======== åˆ‡ç‰‡å‡½æ•°ç»“æŸ ========")
    logger.info(f"[Workspace] ğŸ“Š ç´ æ {asset_index + 1} ç»Ÿè®¡:")
    logger.info(f"[Workspace]    è¾“å…¥ segments: {len(sorted_segments)}")
    logger.info(f"[Workspace]    åˆ›å»ºè§†é¢‘ clips: {len(video_clips)}")
    logger.info(f"[Workspace]    åˆ›å»ºå­—å¹• clips: {len(subtitle_clips)}")
    logger.info(f"[Workspace]    æå–å…³é”®å¸§æ•°: {len(all_keyframes)}")
    logger.info(f"[Workspace]    è·³è¿‡é™éŸ³: {auto_skipped}")
    logger.info(f"[Workspace]    æœ€ç»ˆ timeline ä½ç½®: {timeline_position}ms")
    
    return video_clips, subtitle_clips, all_keyframes


async def _create_subtitle_clips_only(
    transcript_segments: list,
    text_track_id: str,
    video_clip_id: str = None,
    timeline_offset: int = 0,
    asset_index: int = 0,
) -> list:
    """
    â˜… åªåˆ›å»ºå­—å¹• clipsï¼Œä¸åˆ›å»º video clips
    ç”¨äº confirm_upload é˜¶æ®µï¼Œvideo clips å·²ç”± finalize_upload åˆ›å»º
    
    Args:
        transcript_segments: ASR è½¬å†™ç»“æœ
        text_track_id: å­—å¹•è½¨é“ ID
        video_clip_id: å…³è”çš„è§†é¢‘ clip ID (ç”¨äº parent_clip_id)
        timeline_offset: æ—¶é—´è½´åç§»ï¼ˆæ¯«ç§’ï¼‰
        asset_index: ç´ æç´¢å¼•
    
    Returns:
        list: å­—å¹• clips åˆ—è¡¨
    """
    logger.info(f"[Workspace] ğŸ“ _create_subtitle_clips_only")
    logger.info(f"[Workspace]    text_track_id: {text_track_id}")
    logger.info(f"[Workspace]    video_clip_id: {video_clip_id}")
    logger.info(f"[Workspace]    timeline_offset: {timeline_offset}ms")
    logger.info(f"[Workspace]    segments count: {len(transcript_segments)}")
    
    now = datetime.utcnow().isoformat()
    subtitle_clips = []
    
    # è¿‡æ»¤æœ‰æ•ˆçš„è¯­éŸ³ç‰‡æ®µï¼ˆè·³è¿‡é™éŸ³ï¼‰
    sorted_segments = sorted(transcript_segments, key=lambda s: s.get("start", 0))
    
    for seg_idx, seg in enumerate(sorted_segments):
        seg_start = seg.get("start", 0)
        seg_end = seg.get("end", 0)
        seg_text = seg.get("text", "").strip()
        seg_duration = seg_end - seg_start
        
        if seg_duration <= 0 or not seg_text:
            continue
        
        # è·³è¿‡é™éŸ³ç‰‡æ®µ
        silence_info = seg.get("silence_info")
        if silence_info:
            cls = silence_info.get("classification")
            if cls in ("dead_air", "long_pause", "hesitation", "breath"):
                continue
        
        # ç»†åˆ†å­—å¹•ï¼ˆæŒ‰æ ‡ç‚¹ç¬¦å·åˆ†å‰²ï¼‰
        fine_subs = _split_segments_by_punctuation([seg])
        
        for sub_idx, sub_seg in enumerate(fine_subs):
            sub_start = sub_seg.get("start", seg_start)
            sub_end = sub_seg.get("end", seg_end)
            sub_text = sub_seg.get("text", "").strip()
            sub_duration = sub_end - sub_start
            
            if sub_duration <= 0 or not sub_text:
                continue
            
            # â˜… è®¡ç®—æ—¶é—´è½´ä½ç½®ï¼šä½¿ç”¨ source æ—¶é—´ï¼ˆç›¸å¯¹äºè§†é¢‘å¼€å§‹ï¼‰
            subtitle_timeline_start = timeline_offset + sub_start
            
            subtitle_clips.append({
                "id": str(uuid4()),
                "track_id": text_track_id,
                "clip_type": "subtitle",
                "parent_clip_id": video_clip_id,
                "start_time": subtitle_timeline_start,
                "end_time": subtitle_timeline_start + sub_duration,
                "source_start": 0,
                "source_end": sub_duration,
                "is_muted": False,
                "content_text": sub_text,
                "text_style": {
                    "fontSize": 15,
                    "fontColor": "#FFFFFF",
                    "backgroundColor": "transparent",
                    "alignment": "center",
                    "maxWidth": "95%",
                },
                "transform": {
                    "x": 0,
                    "y": 150,
                    "scale": 1,
                },
                "metadata": {
                    "segment_id": seg.get("id"),
                    "asset_index": asset_index,
                    "order_index": seg_idx * 100 + sub_idx,
                    "original_start": sub_start,
                    "original_end": sub_end,
                },
                "created_at": now,
                "updated_at": now,
            })
    
    logger.info(f"[Workspace] âœ… åˆ›å»º {len(subtitle_clips)} ä¸ªå­—å¹• clips")
    return subtitle_clips