"""
HoppingRabbit AI - å·¥ä½œå° API
å¤„ç†ä»ä¸Šä¼ åˆ°è¿›å…¥ç¼–è¾‘å™¨çš„å®Œæ•´æµç¨‹
é€‚é…æ–°è¡¨ç»“æ„ (2026-01-07)
"""
import logging
from fastapi import APIRouter, HTTPException, BackgroundTasks, Depends
from pydantic import BaseModel
from typing import Optional, Literal, List
from datetime import datetime
from uuid import uuid4
from enum import Enum

from ..services.supabase_client import supabase, get_file_url
from ..services.transform_rules import SegmentContext, transform_engine, sequence_processor, EmotionType, ImportanceLevel, TransformParams, ZoomStrategy
from .auth import get_current_user

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/workspace", tags=["Workspace"])


# ============================================
# æ•°æ®æ¨¡å‹
# ============================================

class TaskType(str, Enum):
    AI_CLIPS = "clips"      # AI æ™ºèƒ½åˆ‡ç‰‡
    SUMMARY = "summary"     # å†…å®¹æ€»ç»“
    AI_CREATE = "ai-create" # â˜… ä¸€é”®æˆç‰‡
    VOICE_EXTRACT = "voice-extract" # â˜… ä»…æå–å­—å¹•/éŸ³é¢‘


class SourceType(str, Enum):
    LOCAL = "local"         # æœ¬åœ°ä¸Šä¼ 
    YOUTUBE = "youtube"     # YouTube é“¾æ¥
    URL = "url"             # å…¶ä»– URL


# â˜… ProcessingStepsConfig å·²åˆ é™¤
# ä¸€é”®æˆç‰‡ç”± task_type == 'ai-create' å†³å®šï¼ŒASR é»˜è®¤å¼€å¯


class FileInfo(BaseModel):
    """å•ä¸ªæ–‡ä»¶ä¿¡æ¯ï¼ˆå¤šæ–‡ä»¶ä¸Šä¼ ï¼‰"""
    name: str
    size: int
    content_type: str
    duration: Optional[float] = None  # è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
    order_index: int = 0


class CreateSessionRequest(BaseModel):
    """åˆ›å»ºå¤„ç†ä¼šè¯è¯·æ±‚"""
    source_type: SourceType
    task_type: TaskType = TaskType.AI_CLIPS
    
    # === å•æ–‡ä»¶ä¸Šä¼ ï¼ˆå‘åå…¼å®¹ï¼‰===
    file_name: Optional[str] = None
    file_size: Optional[int] = None
    content_type: Optional[str] = None
    duration: Optional[float] = None  # è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œå‰ç«¯æœ¬åœ°æå–
    
    # === å¤šæ–‡ä»¶ä¸Šä¼ ï¼ˆæ–°å¢ï¼‰===
    files: Optional[List[FileInfo]] = None  # å¤šä¸ªæ–‡ä»¶ä¿¡æ¯
    
    # é“¾æ¥è§£æç›¸å…³
    source_url: Optional[str] = None
    # â˜… processing_steps å·²åˆ é™¤ï¼Œç”± task_type å†³å®šå¤„ç†æµç¨‹


class AssetUploadInfo(BaseModel):
    """å•ä¸ªèµ„æºçš„ä¸Šä¼ ä¿¡æ¯"""
    asset_id: str
    upload_url: str
    storage_path: str
    order_index: int  # ä¿æŒä¸å‰ç«¯ä¸€è‡´
    file_name: str


class CreateSessionResponse(BaseModel):
    """åˆ›å»ºä¼šè¯å“åº”"""
    session_id: str
    project_id: str
    # â˜… ç»Ÿä¸€ç”¨ assets æ•°ç»„ï¼ˆå³ä½¿å•æ–‡ä»¶ä¹Ÿæ˜¯ä¸€ä¸ªå…ƒç´ çš„æ•°ç»„ï¼‰
    assets: Optional[List[AssetUploadInfo]] = None


class SessionStatus(BaseModel):
    """ä¼šè¯çŠ¶æ€"""
    session_id: str
    project_id: str
    status: Literal["uploading", "processing", "completed", "failed", "cancelled", "expired"]
    current_step: Optional[str] = None
    progress: int = 0
    steps: List[dict] = []  # å¤„ç†æ­¥éª¤åˆ—è¡¨
    error: Optional[str] = None
    transcript_segments: Optional[int] = None
    marked_clips: Optional[int] = None
    
    # === å¤šæ–‡ä»¶ä¸Šä¼ è¿›åº¦ï¼ˆæ–°å¢ï¼‰===
    upload_progress: Optional[dict] = None  # {total_files, completed_files, ...}


# â˜… æ­¥éª¤å®šä¹‰å·²ç§»è‡³å‰ç«¯ ProcessingView.tsx
# åç«¯åªè¿”å› current_stepï¼Œå‰ç«¯æœ¬åœ°ç”Ÿæˆæ­¥éª¤åˆ—è¡¨
# è¿™æ ·é¿å…å‰åç«¯ç»´æŠ¤ä¸¤å¥—é‡å¤çš„æ­¥éª¤å®šä¹‰


def _get_file_type(content_type: str) -> str:
    """æ ¹æ® MIME ç±»å‹åˆ¤æ–­æ–‡ä»¶ç±»å‹"""
    if not content_type:
        return "video"
    if content_type.startswith("video/"):
        return "video"
    elif content_type.startswith("audio/"):
        return "audio"
    elif content_type.startswith("image/"):
        return "image"
    else:
        return "video"


# ============================================
# API ç«¯ç‚¹
# ============================================

@router.post("/sessions", response_model=CreateSessionResponse)
async def create_session(
    request: CreateSessionRequest,
    current_user: dict = Depends(get_current_user)
):
    """
    åˆ›å»ºå¤„ç†ä¼šè¯
    éœ€è¦ç”¨æˆ·ç™»å½•
    """
    try:
        session_id = str(uuid4())
        project_id = str(uuid4())
        now = datetime.utcnow().isoformat()
        user_id = current_user["user_id"]
        
        logger.info(f"[Session] å¼€å§‹åˆ›å»ºä¼šè¯, user_id={user_id}, source_type={request.source_type.value}")
        
        # 1. åˆ›å»ºé¡¹ç›®
        project_name = _generate_project_name(request)
        project_data = {
            "id": project_id,
            "user_id": user_id,
            "name": project_name,
            "status": "processing",
            "resolution": {"width": 1920, "height": 1080},
            "fps": 30,
            "created_at": now,
            "updated_at": now,
        }
        supabase.table("projects").insert(project_data).execute()
        logger.info(f"[Session] âœ… åˆ›å»ºé¡¹ç›®æˆåŠŸ, project_id={project_id}, name={project_name}")
        
        # 2. åˆ›å»ºä¼šè¯è®°å½•
        session_data = {
            "id": session_id,
            "user_id": user_id,
            "project_id": project_id,
            "status": "uploading",
            "upload_source": request.source_type.value,
            "source_url": request.source_url,
            "selected_tasks": [request.task_type.value],
            "progress": 0,
            "created_at": now,
            "updated_at": now,
        }
        supabase.table("workspace_sessions").insert(session_data).execute()
        logger.info(f"[Session] âœ… åˆ›å»ºä¼šè¯æˆåŠŸ, session_id={session_id}, task_type={request.task_type.value}")
        
        response = CreateSessionResponse(
            session_id=session_id,
            project_id=project_id,
        )
        
        # 3. æ ¹æ®æ¥æºç±»å‹å¤„ç†
        if request.source_type == SourceType.LOCAL:
            # === åˆ¤æ–­æ˜¯å¤šæ–‡ä»¶è¿˜æ˜¯å•æ–‡ä»¶ä¸Šä¼  ===
            logger.info(f"[Session] ğŸ“‚ æ£€æŸ¥ä¸Šä¼ æ¨¡å¼:")
            logger.info(f"[Session]    request.files: {request.files}")
            logger.info(f"[Session]    request.file_name: {request.file_name}")
            logger.info(f"[Session]    files æ˜¯å¦æœ‰å€¼: {bool(request.files)}")
            logger.info(f"[Session]    files é•¿åº¦: {len(request.files) if request.files else 0}")
            
            if request.files and len(request.files) > 0:
                logger.info(f"[Session] âœ… è¿›å…¥å¤šæ–‡ä»¶ä¸Šä¼ æ¨¡å¼")
                # â˜… å¤šæ–‡ä»¶ä¸Šä¼ æ¨¡å¼
                assets_info = []
                asset_ids = []
                total_bytes = sum(f.size for f in request.files)
                
                for file_info in request.files:
                    asset_id = str(uuid4())
                    asset_ids.append(asset_id)
                    file_ext = file_info.name.split(".")[-1] if "." in file_info.name else "mp4"
                    storage_path = f"uploads/{project_id}/{asset_id}.{file_ext}"
                    
                    # ç”Ÿæˆé¢„ç­¾åä¸Šä¼  URL
                    presign_result = supabase.storage.from_("clips").create_signed_upload_url(storage_path)
                    upload_url = presign_result.get("signedURL") or presign_result.get("signed_url", "")
                    
                    # åˆ›å»º asset è®°å½•
                    asset_data = {
                        "id": asset_id,
                        "project_id": project_id,
                        "user_id": user_id,
                        "name": file_info.name,
                        "original_filename": file_info.name,
                        "file_type": _get_file_type(file_info.content_type),
                        "mime_type": file_info.content_type or "video/mp4",
                        "file_size": file_info.size,
                        "storage_path": storage_path,
                        "duration": file_info.duration,
                        "status": "uploading",  # ç­‰å¾…ä¸Šä¼ ï¼ˆçº¦æŸåªå…è®¸ uploading/processing/ready/errorï¼‰
                        "order_index": file_info.order_index,  # ç´ æé¡ºåº
                        "upload_progress": {
                            "bytes_uploaded": 0,
                            "total_bytes": file_info.size,
                            "percentage": 0,
                        },
                        "created_at": now,
                        "updated_at": now,
                    }
                    supabase.table("assets").insert(asset_data).execute()
                    
                    assets_info.append(AssetUploadInfo(
                        asset_id=asset_id,
                        upload_url=upload_url,
                        storage_path=storage_path,
                        order_index=file_info.order_index,
                        file_name=file_info.name,
                    ))
                
                # æ›´æ–°ä¼šè¯è®°å½•
                supabase.table("workspace_sessions").update({
                    "uploaded_asset_ids": asset_ids,  # JSON æ•°ç»„
                    "upload_progress": {
                        "total_files": len(request.files),
                        "completed_files": 0,
                        "failed_files": 0,
                        "pending_files": len(request.files),
                        "total_bytes": total_bytes,
                        "uploaded_bytes": 0,
                    },
                    "status": "uploading",
                }).eq("id", session_id).execute()
                
                response.assets = assets_info
                logger.info(f"[Session] âœ… å¤šæ–‡ä»¶ä¸Šä¼ æ¨¡å¼ï¼Œåˆ›å»º {len(assets_info)} ä¸ªèµ„æº")
                logger.info(f"[Session]    response.assets æ•°é‡: {len(response.assets)}")
                for i, a in enumerate(response.assets):
                    logger.info(f"[Session]    asset[{i}]: {a.asset_id}, order={a.order_index}")
                
            else:
                # â˜… å•æ–‡ä»¶ä¸Šä¼ æ¨¡å¼ï¼ˆå‘åå…¼å®¹ï¼‰
                asset_id = str(uuid4())
                file_ext = request.file_name.split(".")[-1] if request.file_name and "." in request.file_name else "mp4"
                storage_path = f"uploads/{project_id}/{asset_id}.{file_ext}"
                
                logger.info(f"[Session] æ­£åœ¨ç”Ÿæˆé¢„ç­¾åä¸Šä¼ URL, storage_path={storage_path}")
                logger.debug(f"[Session] æ”¶åˆ°çš„ duration: {request.duration}")
                presign_result = supabase.storage.from_("clips").create_signed_upload_url(storage_path)
                upload_url = presign_result.get("signedURL") or presign_result.get("signed_url", "")
                logger.info(f"[Session] âœ… é¢„ç­¾åURLç”ŸæˆæˆåŠŸ, url_length={len(upload_url)}")
                
                asset_data = {
                    "id": asset_id,
                    "project_id": project_id,
                    "user_id": user_id,
                    "name": request.file_name or "æœªå‘½å",
                    "original_filename": request.file_name,
                    "file_type": _get_file_type(request.content_type),
                    "mime_type": request.content_type or "video/mp4",
                    "file_size": request.file_size,
                    "storage_path": storage_path,
                    "duration": request.duration,
                    "status": "uploading",
                    "order_index": 0,
                    "created_at": now,
                    "updated_at": now,
                }
                supabase.table("assets").insert(asset_data).execute()
                logger.info(f"[Session] âœ… åˆ›å»ºèµ„æºæˆåŠŸ, asset_id={asset_id}, file_name={request.file_name}")
                
                supabase.table("workspace_sessions").update({
                    "uploaded_asset_id": asset_id,
                    "uploaded_asset_ids": [asset_id],  # åŒæ—¶æ›´æ–°æ•°ç»„å­—æ®µ
                    "status": "uploading",
                }).eq("id", session_id).execute()
                logger.info(f"[Session] âœ… æ›´æ–°ä¼šè¯å…³è”èµ„æºæˆåŠŸ")
                
                # â˜… å•æ–‡ä»¶ä¹Ÿç»Ÿä¸€æ”¾å…¥ assets æ•°ç»„
                response.assets = [AssetUploadInfo(
                    asset_id=asset_id,
                    upload_url=upload_url,
                    storage_path=storage_path,
                    order_index=0,
                    file_name=request.file_name,
                )]
            
        elif request.source_type in (SourceType.YOUTUBE, SourceType.URL):
            supabase.table("workspace_sessions").update({
                "status": "processing",
                "current_step": "fetch",
            }).eq("id", session_id).execute()
            logger.info(f"[Session] âœ… URLç±»å‹ä¼šè¯å¼€å§‹å¤„ç†, source_url={request.source_url}")
        
        logger.info(f"[Session] âœ… ä¼šè¯åˆ›å»ºå®Œæˆ, session_id={session_id}, project_id={project_id}")
        return response
        
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        logger.error(f"[Session] âŒ åˆ›å»ºä¼šè¯å¤±è´¥: {e}")
        logger.error(f"[Session] âŒ å®Œæ•´å †æ ˆ:\n{traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/sessions/{session_id}/asset/{asset_id}/uploaded")
async def notify_asset_uploaded(session_id: str, asset_id: str):
    """
    é€šçŸ¥å•ä¸ªæ–‡ä»¶ä¸Šä¼ å®Œæˆï¼ˆå¤šæ–‡ä»¶ä¸Šä¼ æ¨¡å¼ï¼‰
    å‰ç«¯æ¯ä¸Šä¼ å®Œä¸€ä¸ªæ–‡ä»¶å°±è°ƒç”¨ä¸€æ¬¡
    """
    logger.info(f"[Upload] ğŸ“¤ æ”¶åˆ°èµ„æºä¸Šä¼ å®Œæˆé€šçŸ¥: session={session_id}, asset={asset_id}")
    try:
        now = datetime.utcnow().isoformat()
        
        # æ›´æ–°è¯¥ asset çŠ¶æ€
        logger.info(f"[Upload]    æ›´æ–° asset {asset_id} çŠ¶æ€ä¸º uploaded")
        supabase.table("assets").update({
            "status": "uploaded",
            "upload_progress": {
                "percentage": 100,
                "completed": True,
            },
            "updated_at": now,
        }).eq("id", asset_id).execute()
        
        # è·å– session ä¿¡æ¯
        session = supabase.table("workspace_sessions").select("*").eq("id", session_id).single().execute()
        if not session.data:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
        
        session_data = session.data
        asset_ids = session_data.get("uploaded_asset_ids", [])
        
        # ç»Ÿè®¡ä¸Šä¼ è¿›åº¦
        assets_result = supabase.table("assets").select("id, status, file_size").in_("id", asset_ids).execute()
        assets = assets_result.data or []
        
        completed = sum(1 for a in assets if a.get("status") == "uploaded")
        failed = sum(1 for a in assets if a.get("status") == "error")
        pending = len(assets) - completed - failed
        uploaded_bytes = sum(a.get("file_size", 0) for a in assets if a.get("status") == "uploaded")
        total_bytes = sum(a.get("file_size", 0) for a in assets)
        
        # æ›´æ–° session è¿›åº¦
        supabase.table("workspace_sessions").update({
            "upload_progress": {
                "total_files": len(assets),
                "completed_files": completed,
                "failed_files": failed,
                "pending_files": pending,
                "total_bytes": total_bytes,
                "uploaded_bytes": uploaded_bytes,
            },
            "updated_at": now,
        }).eq("id", session_id).execute()
        
        logger.info(f"[Session] ğŸ“¤ Asset {asset_id} ä¸Šä¼ å®Œæˆ, è¿›åº¦: {completed}/{len(assets)}")
        
        return {
            "status": "ok",
            "progress": {
                "completed": completed,
                "total": len(assets),
                "all_completed": completed == len(assets),
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[Session] âŒ é€šçŸ¥ä¸Šä¼ å®Œæˆå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/sessions/{session_id}/confirm-upload")
async def confirm_upload(session_id: str, background_tasks: BackgroundTasks):
    """
    ç¡®è®¤æ‰€æœ‰æ–‡ä»¶ä¸Šä¼ å®Œæˆï¼Œå¼€å§‹å¤„ç†
    æ”¯æŒå¤šæ–‡ä»¶å’Œå•æ–‡ä»¶æ¨¡å¼
    """
    try:
        session = supabase.table("workspace_sessions").select("*").eq("id", session_id).single().execute()
        if not session.data:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
        
        session_data = session.data
        project_id = session_data.get("project_id")
        now = datetime.utcnow().isoformat()
        
        # === è·å–æ‰€æœ‰å…³è”çš„ assets ===
        asset_ids = session_data.get("uploaded_asset_ids", [])
        
        # å…¼å®¹æ—§çš„å•æ–‡ä»¶æ¨¡å¼
        if not asset_ids:
            single_asset_id = session_data.get("uploaded_asset_id")
            if single_asset_id:
                asset_ids = [single_asset_id]
        
        if not asset_ids:
            raise HTTPException(status_code=400, detail="ä¼šè¯æœªå…³è”ä»»ä½•èµ„æº")
        
        # === æ£€æŸ¥æ‰€æœ‰æ–‡ä»¶æ˜¯å¦éƒ½ä¸Šä¼ å®Œæˆ ===
        assets_result = supabase.table("assets").select("*").in_("id", asset_ids).execute()
        assets = assets_result.data or []
        
        if len(assets) != len(asset_ids):
            raise HTTPException(status_code=400, detail="éƒ¨åˆ†èµ„æºè®°å½•ä¸å­˜åœ¨")
        
        # æ£€æŸ¥æœªå®Œæˆçš„ä¸Šä¼ 
        not_uploaded = [a for a in assets if a.get("status") not in ("uploaded", "uploading", "processing", "ready")]
        if not_uploaded:
            pending_names = [a.get("name", a["id"]) for a in not_uploaded[:3]]
            raise HTTPException(
                status_code=400, 
                detail=f"éƒ¨åˆ†æ–‡ä»¶æœªä¸Šä¼ å®Œæˆ: {', '.join(pending_names)}"
            )
        
        # === æ›´æ–°æ‰€æœ‰ assets çŠ¶æ€ä¸ºå¤„ç†ä¸­ ===
        for asset in assets:
            supabase.table("assets").update({
                "status": "processing",
                "updated_at": now,
            }).eq("id", asset["id"]).execute()
        
        # === æ›´æ–° session çŠ¶æ€ ===
        supabase.table("workspace_sessions").update({
            "status": "processing",
            "current_step": "fetch",
            "progress": 0,
            "updated_at": now,
        }).eq("id", session_id).execute()
        
        selected_tasks = session_data.get("selected_tasks", ["clips"])
        task_type = selected_tasks[0] if selected_tasks else "clips"
        
        # === æŒ‰é¡ºåºæ’åˆ— assets ===
        sorted_assets = sorted(assets, key=lambda a: a.get("order_index", 0))
        
        logger.info(f"[Session] ========================================")
        logger.info(f"[Session] ğŸš€ å‡†å¤‡å¯åŠ¨åå°å¤„ç†ä»»åŠ¡")
        logger.info(f"[Session]    session_id: {session_id}")
        logger.info(f"[Session]    project_id: {project_id}")
        logger.info(f"[Session]    task_type: {task_type}")
        logger.info(f"[Session]    sorted_assets count: {len(sorted_assets)}")
        for i, a in enumerate(sorted_assets):
            logger.info(f"[Session]    asset[{i}]: {a.get('name')} (order={a.get('order_index')})")
        logger.info(f"[Session] ========================================")
        
        # === å¯åŠ¨åå°å¤„ç†ä»»åŠ¡ ===
        background_tasks.add_task(
            _process_session_multi_assets,
            session_id=session_id,
            project_id=project_id,
            assets=sorted_assets,
            task_type=task_type,
        )
        
        logger.info(f"[Session] âœ… åå°ä»»åŠ¡å·²æ·»åŠ , å¼€å§‹å¤„ç† {len(assets)} ä¸ªç´ æ")
        
        return {
            "status": "processing", 
            "message": f"å¼€å§‹å¤„ç† {len(assets)} ä¸ªç´ æ",
            "asset_count": len(assets),
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[Session] âŒ ç¡®è®¤ä¸Šä¼ å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/sessions/{session_id}", response_model=SessionStatus)
async def get_session_status(session_id: str):
    """è·å–ä¼šè¯å¤„ç†çŠ¶æ€
    
    è¿”å›:
    - current_step: å½“å‰æ­¥éª¤ IDï¼ˆfetch/transcribe/segment/vision/transform/subtitle/prepareï¼‰
    - progress: 0-100 è¿›åº¦
    - status: pending/processing/completed/failed
    
    æ³¨æ„: steps å­—æ®µå·²åºŸå¼ƒï¼Œå‰ç«¯æœ¬åœ°ç”Ÿæˆæ­¥éª¤åˆ—è¡¨
    """
    try:
        session = supabase.table("workspace_sessions").select("*").eq("id", session_id).single().execute()
        if not session.data:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
        
        data = session.data
        
        return SessionStatus(
            session_id=data["id"],
            project_id=data["project_id"],
            status=data["status"],
            current_step=data.get("current_step"),
            progress=data.get("progress", 0),
            steps=[],  # â˜… åºŸå¼ƒï¼Œå‰ç«¯æœ¬åœ°ç”Ÿæˆ
            error=data.get("error_message"),
        )
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.delete("/sessions/{session_id}")
async def cancel_session(session_id: str):
    """å–æ¶ˆå¤„ç†ä¼šè¯"""
    try:
        supabase.table("workspace_sessions").update({
            "status": "cancelled",
            "updated_at": datetime.utcnow().isoformat(),
        }).eq("id", session_id).execute()
        
        return {"message": "ä¼šè¯å·²å–æ¶ˆ"}
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# è¾…åŠ©å‡½æ•°
# ============================================

import re


class SessionCancelledException(Exception):
    """ä¼šè¯è¢«ç”¨æˆ·å–æ¶ˆçš„å¼‚å¸¸"""
    pass


def _check_session_cancelled(session_id: str) -> bool:
    """
    æ£€æŸ¥ä¼šè¯æ˜¯å¦è¢«å–æ¶ˆ
    
    Args:
        session_id: ä¼šè¯ ID
        
    Returns:
        True å¦‚æœä¼šè¯å·²è¢«å–æ¶ˆï¼ŒFalse å¦åˆ™
    """
    try:
        result = supabase.table("workspace_sessions").select("status").eq("id", session_id).single().execute()
        if result.data:
            return result.data.get("status") == "cancelled"
        return False
    except Exception as e:
        logger.warning(f"[Workspace] æ£€æŸ¥ä¼šè¯çŠ¶æ€å¤±è´¥: {e}")
        return False


def _raise_if_cancelled(session_id: str, step_name: str = ""):
    """
    å¦‚æœä¼šè¯å·²å–æ¶ˆï¼ŒæŠ›å‡ºå¼‚å¸¸ç»ˆæ­¢å¤„ç†
    
    Args:
        session_id: ä¼šè¯ ID
        step_name: å½“å‰æ­¥éª¤åç§°ï¼ˆç”¨äºæ—¥å¿—ï¼‰
    """
    if _check_session_cancelled(session_id):
        step_info = f" (æ­¥éª¤: {step_name})" if step_name else ""
        logger.info(f"[Workspace] ğŸ›‘ ä¼šè¯ {session_id} è¢«å–æ¶ˆï¼Œç»ˆæ­¢å¤„ç†{step_info}")
        raise SessionCancelledException(f"ä¼šè¯ {session_id} å·²è¢«ç”¨æˆ·å–æ¶ˆ")


def _split_by_max_length(text: str, max_length: int) -> list:
    """
    æŒ‰æœ€å¤§é•¿åº¦æ™ºèƒ½åˆ‡åˆ†æ–‡æœ¬
    
    åˆ‡åˆ†ç­–ç•¥ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰ï¼š
    1. ä¼˜å…ˆåœ¨ç©ºæ ¼å¤„åˆ‡åˆ†ï¼ˆé€‚åˆè‹±æ–‡ï¼‰
    2. å…¶æ¬¡åœ¨ä¸­æ–‡å¸¸è§åœé¡¿è¯ååˆ‡åˆ†ï¼ˆçš„ã€æ˜¯ã€åœ¨ã€äº†ã€å’Œã€ä¸ã€æˆ–ï¼‰
    3. æœ€åå¼ºåˆ¶æŒ‰é•¿åº¦åˆ‡åˆ†
    
    Args:
        text: å¾…åˆ‡åˆ†çš„æ–‡æœ¬
        max_length: æ¯æ®µæœ€å¤§å­—ç¬¦æ•°
        
    Returns:
        åˆ‡åˆ†åçš„æ–‡æœ¬åˆ—è¡¨
    """
    if len(text) <= max_length:
        return [text]
    
    result = []
    remaining = text
    
    while len(remaining) > max_length:
        # åœ¨ max_length èŒƒå›´å†…å¯»æ‰¾æœ€ä½³åˆ‡åˆ†ç‚¹
        chunk = remaining[:max_length]
        
        # ç­–ç•¥1ï¼šå¯»æ‰¾ç©ºæ ¼åˆ‡åˆ†ç‚¹ï¼ˆè‹±æ–‡ï¼‰
        space_idx = chunk.rfind(' ')
        if space_idx > max_length // 2:  # ç¡®ä¿åˆ‡åˆ†ç‚¹ä¸ä¼šå¤ªé å‰
            result.append(chunk[:space_idx].strip())
            remaining = remaining[space_idx:].strip()
            continue
        
        # ç­–ç•¥2ï¼šå¯»æ‰¾ä¸­æ–‡åœé¡¿è¯åˆ‡åˆ†ç‚¹
        stop_words = ['çš„', 'æ˜¯', 'åœ¨', 'äº†', 'å’Œ', 'ä¸', 'æˆ–', 'ä¹Ÿ', 'éƒ½', 'å°±', 'è€Œ', 'ä½†', 'å¾ˆ', 'æ›´']
        best_stop_idx = -1
        for word in stop_words:
            idx = chunk.rfind(word)
            if idx > max_length // 2 and idx > best_stop_idx:
                best_stop_idx = idx + len(word)  # åˆ‡åˆ†ç‚¹åœ¨åœé¡¿è¯ä¹‹å
        
        if best_stop_idx > 0:
            result.append(chunk[:best_stop_idx].strip())
            remaining = remaining[best_stop_idx:].strip()
            continue
        
        # ç­–ç•¥3ï¼šå¼ºåˆ¶æŒ‰é•¿åº¦åˆ‡åˆ†
        result.append(chunk.strip())
        remaining = remaining[max_length:].strip()
    
    if remaining:
        result.append(remaining.strip())
    
    return result


def _split_segments_by_punctuation(segments: list, max_chars_per_line: int = 20) -> list:
    """
    å°† ASR segments æŒ‰æ ‡ç‚¹ç¬¦å·è¿›ä¸€æ­¥åˆ‡åˆ†æˆæ›´ç»†çš„å­å¥
    
    åˆ‡åˆ†è§„åˆ™ï¼š
    1. ä¸­æ–‡æ ‡ç‚¹ï¼šï¼Œã€‚ï¼ï¼Ÿï¼›
    2. è‹±æ–‡æ ‡ç‚¹ï¼š,.!?;
    3. æ ¹æ®æ–‡æœ¬é•¿åº¦æŒ‰æ¯”ä¾‹åˆ†é…æ—¶é—´
    4. å•è¡Œæœ€å¤§å­—ç¬¦æ•°é™åˆ¶ï¼ˆé˜²æ­¢å­—å¹•è¿‡é•¿è¶…å‡ºå±å¹•ï¼‰
    
    Args:
        segments: ASR è¿”å›çš„ segments åˆ—è¡¨ï¼Œæ¯ä¸ªåŒ…å« start, end, text
        max_chars_per_line: å•è¡Œæœ€å¤§å­—ç¬¦æ•°ï¼Œ15å·å­—ä½“ä¸‹å»ºè®®20å­—ç¬¦
        
    Returns:
        ç»†åˆ†åçš„ segments åˆ—è¡¨
    """
    # æ ‡ç‚¹ç¬¦å·æ­£åˆ™ï¼šåŒ¹é…ä¸­è‹±æ–‡é€—å·ã€å¥å·ã€é—®å·ã€æ„Ÿå¹å·ã€åˆ†å·
    punctuation_pattern = re.compile(r'([ï¼Œã€‚ï¼ï¼Ÿï¼›,.!?;])')
    
    fine_segments = []
    
    for seg in segments:
        text = seg.get("text", "").strip()
        start_ms = seg.get("start", 0)
        end_ms = seg.get("end", 0)
        total_duration = end_ms - start_ms
        
        if not text or total_duration <= 0:
            continue
        
        # æŒ‰æ ‡ç‚¹åˆ‡åˆ†æ–‡æœ¬
        parts = punctuation_pattern.split(text)
        
        # é‡æ–°ç»„åˆï¼šå°†æ ‡ç‚¹ç¬¦å·ä¸å‰é¢çš„æ–‡æœ¬åˆå¹¶
        sentences = []
        buffer = ""
        for part in parts:
            buffer += part
            if punctuation_pattern.match(part):
                if buffer.strip():
                    sentences.append(buffer.strip())
                buffer = ""
        # å¤„ç†æœ€åæ²¡æœ‰æ ‡ç‚¹çš„éƒ¨åˆ†
        if buffer.strip():
            sentences.append(buffer.strip())
        
        # å¦‚æœåªæœ‰ä¸€ä¸ªå¥å­æˆ–æ²¡æœ‰åˆ‡åˆ†ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦æŒ‰é•¿åº¦åˆ‡åˆ†
        if len(sentences) <= 1:
            # æ£€æŸ¥æ˜¯å¦è¶…è¿‡æœ€å¤§é•¿åº¦
            if len(text) <= max_chars_per_line:
                fine_segments.append(seg)
                continue
            else:
                # æŒ‰æœ€å¤§é•¿åº¦åˆ‡åˆ†
                sentences = _split_by_max_length(text, max_chars_per_line)
        else:
            # å¯¹æ¯ä¸ªå¥å­æ£€æŸ¥é•¿åº¦ï¼Œè¿‡é•¿çš„è¿›ä¸€æ­¥åˆ‡åˆ†
            expanded_sentences = []
            for s in sentences:
                if len(s) > max_chars_per_line:
                    expanded_sentences.extend(_split_by_max_length(s, max_chars_per_line))
                else:
                    expanded_sentences.append(s)
            sentences = expanded_sentences
        
        # æŒ‰å­—ç¬¦æ•°æ¯”ä¾‹åˆ†é…æ—¶é—´
        total_chars = sum(len(s) for s in sentences)
        if total_chars == 0:
            fine_segments.append(seg)
            continue
        
        current_time = start_ms
        for sentence in sentences:
            char_ratio = len(sentence) / total_chars
            duration = int(total_duration * char_ratio)
            
            # ç¡®ä¿è‡³å°‘æœ‰ 100ms
            duration = max(duration, 100)
            
            fine_segments.append({
                "id": seg.get("id"),
                "text": sentence,
                "start": current_time,
                "end": current_time + duration,
                "speaker": seg.get("speaker"),
            })
            
            current_time += duration
    
    return fine_segments


def _generate_project_name(request: CreateSessionRequest) -> str:
    """ç”Ÿæˆé¡¹ç›®åç§°"""
    if request.file_name:
        name = request.file_name.rsplit(".", 1)[0]
        return name[:50]
    elif request.source_url:
        return f"YouTube è§†é¢‘ - {datetime.now().strftime('%m/%d %H:%M')}"
    else:
        return f"æ–°é¡¹ç›® - {datetime.now().strftime('%Y-%m-%d %H:%M')}"


def _create_progress_updater(session_id: str):
    """
    åˆ›å»ºè¿›åº¦æ›´æ–°å™¨å‡½æ•°
    
    å†…ç½®èŠ‚æµï¼šåªåœ¨è¿›åº¦å˜åŒ– â‰¥1% æˆ–æ­¥éª¤å˜åŒ–æ—¶æ‰çœŸæ­£æ›´æ–°æ•°æ®åº“
    é¿å…é¢‘ç¹å†™å…¥é€ æˆæ€§èƒ½é—®é¢˜
    """
    last_progress = {"step": None, "value": -1}
    
    def update_progress(step: str, progress: int):
        # èŠ‚æµï¼šåªåœ¨è¿›åº¦å˜åŒ– â‰¥1% æˆ–æ­¥éª¤å˜åŒ–æ—¶æ‰æ›´æ–°
        if step == last_progress["step"] and progress == last_progress["value"]:
            return  # å®Œå…¨ç›¸åŒï¼Œè·³è¿‡
        
        if step == last_progress["step"] and abs(progress - last_progress["value"]) < 1:
            return  # åŒä¸€æ­¥éª¤ï¼Œè¿›åº¦å˜åŒ– <1%ï¼Œè·³è¿‡
        
        last_progress["step"] = step
        last_progress["value"] = progress
        
        supabase.table("workspace_sessions").update({
            "current_step": step,
            "progress": progress,
            "updated_at": datetime.utcnow().isoformat(),
        }).eq("id", session_id).execute()
    
    return update_progress


async def _fetch_asset_metadata(asset_id: str, file_url: str) -> dict:
    """æå–èµ„æºå…ƒæ•°æ®ï¼ˆå®½é«˜ã€å¸§ç‡ã€ç¼–ç ç­‰ï¼Œduration ç”±å‰ç«¯æä¾›ï¼‰"""
    try:
        from ..tasks.asset_processing import extract_media_metadata
        logger.info(f"[Workspace] æ­£åœ¨æå–å…ƒæ•°æ®: {file_url[:80]}...")
        metadata = await extract_media_metadata(file_url)
        logger.debug(f"[Workspace] æå–åˆ°çš„å…ƒæ•°æ®: {metadata}")
        
        # â˜… æ£€æµ‹è§†é¢‘ç¼–ç ï¼Œåˆ¤æ–­æµè§ˆå™¨æ˜¯å¦æ”¯æŒ
        video_codec = metadata.get("codec", "")
        # æµè§ˆå™¨åŸç”Ÿæ”¯æŒçš„ç¼–ç æ ¼å¼
        BROWSER_SUPPORTED_CODECS = {"h264", "avc1", "vp8", "vp9", "av1", "hevc", "h265"}
        needs_transcode = video_codec and video_codec.lower() not in BROWSER_SUPPORTED_CODECS
        if needs_transcode:
            logger.warning(f"[Workspace] âš ï¸ è§†é¢‘ç¼–ç  {video_codec} éœ€è¦è½¬ç ä¸º H.264")
        
        # duration ç”±å‰ç«¯æä¾›ï¼Œè¿™é‡Œåªæ›´æ–°å®½é«˜ã€å¸§ç‡ã€ç¼–ç ç­‰ä¿¡æ¯
        supabase.table("assets").update({
            "width": metadata.get("width", 1920),
            "height": metadata.get("height", 1080),
            "fps": metadata.get("fps", 30),
            "sample_rate": metadata.get("sample_rate"),
            "channels": metadata.get("channels"),
            "status": "ready",
            "updated_at": datetime.utcnow().isoformat(),
        }).eq("id", asset_id).execute()
        
        # è¿”å›å®Œæ•´å…ƒæ•°æ®ï¼ŒåŒ…æ‹¬ç¼–ç ä¿¡æ¯
        metadata["needs_transcode"] = needs_transcode
        return metadata
    except Exception as e:
        logger.warning(f"[Workspace] âŒ æå–å…ƒæ•°æ®å¤±è´¥: {e}, ä½¿ç”¨é»˜è®¤å€¼")
        supabase.table("assets").update({
            "status": "ready",
            "updated_at": datetime.utcnow().isoformat(),
        }).eq("id", asset_id).execute()
        return {"duration": 0, "width": 1920, "height": 1080, "fps": 30, "needs_transcode": False}


async def _extract_audio_for_asr(video_url: str, asset_id: str, update_progress, current_progress: int, video_duration_sec: float = None) -> str:
    """
    ä»è§†é¢‘ä¸­æå–å‹ç¼©éŸ³é¢‘ï¼Œç”¨äº ASR è½¬å†™
    
    ä¼˜åŒ–ç­–ç•¥:
    - 16kHz é‡‡æ ·ç‡ï¼ˆè¯­éŸ³è¯†åˆ«è¶³å¤Ÿï¼‰
    - å•å£°é“
    - 64kbps ç ç‡
    - 4GB è§†é¢‘ â†’ çº¦ 20MB éŸ³é¢‘ï¼Œä¸Šä¼ é€Ÿåº¦æå‡ 99%
    - â˜… ç¼“å­˜å¤ç”¨ï¼šå¦‚æœéŸ³é¢‘å·²æå–è¿‡ï¼Œç›´æ¥è¿”å›ç¼“å­˜ URL
    - â˜… å®æ—¶è¿›åº¦ï¼šè§£æ FFmpeg è¾“å‡ºæ›´æ–°è¿›åº¦
    
    Args:
        video_url: è§†é¢‘çš„ç­¾å URL
        asset_id: èµ„äº§ IDï¼ˆç”¨äºå­˜å‚¨è·¯å¾„ï¼‰
        update_progress: è¿›åº¦å›è°ƒ
        current_progress: å½“å‰è¿›åº¦ç™¾åˆ†æ¯”
        video_duration_sec: è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œç”¨äºè®¡ç®—è¿›åº¦
        
    Returns:
        æå–åéŸ³é¢‘çš„ç­¾å URL
    """
    import tempfile
    import httpx
    import asyncio
    import os
    import re
    
    audio_storage_path = f"asr_audio/{asset_id}.mp3"
    
    # â˜…â˜…â˜… ç¼“å­˜æ£€æŸ¥ï¼šå¦‚æœéŸ³é¢‘å·²å­˜åœ¨ï¼Œç›´æ¥è¿”å› â˜…â˜…â˜…
    try:
        # å°è¯•ç›´æ¥è·å–ç­¾å URLï¼Œå¦‚æœæˆåŠŸè¯´æ˜æ–‡ä»¶å­˜åœ¨
        from ..services.supabase_client import supabase
        result = supabase.storage.from_("clips").create_signed_url(audio_storage_path, 60)
        cached_url = result.get("signedURL") or result.get("signedUrl") or result.get("signed_url")
        if cached_url:
            logger.info(f"[ASRä¼˜åŒ–] âœ… ä½¿ç”¨ç¼“å­˜éŸ³é¢‘: {audio_storage_path}")
            update_progress("extract_audio", current_progress + 15)
            return cached_url
    except Exception:
        pass  # ç¼“å­˜ä¸å­˜åœ¨æˆ–æ£€æŸ¥å¤±è´¥ï¼Œç»§ç»­æå–
    
    logger.info(f"[ASRä¼˜åŒ–] ğŸµ å¼€å§‹æå–éŸ³é¢‘ asset_id={asset_id}, duration={video_duration_sec}s")
    
    custom_temp_dir = os.getenv("ASR_TEMP_DIR")
    temp_dir = tempfile.mkdtemp(prefix="asr_", dir=custom_temp_dir)
    logger.info(f"[ASRä¼˜åŒ–] ğŸ“ ä¸´æ—¶ç›®å½•: {temp_dir}")
    
    audio_path = os.path.join(temp_dir, "audio_for_asr.mp3")
    
    try:
        update_progress("extract_audio", current_progress)
        logger.info(f"[ASRä¼˜åŒ–] ğŸ”§ FFmpeg æµå¼æå–éŸ³é¢‘...")
        
        # â˜… ä¼˜åŒ–ï¼šæ·»åŠ ç½‘ç»œè¶…æ—¶å’Œæ›´å¿«çš„ç¼–ç å‚æ•°
        cmd = [
            "ffmpeg", "-y",
            "-reconnect", "1",           # æ–­çº¿é‡è¿
            "-reconnect_streamed", "1",
            "-reconnect_delay_max", "5", # æœ€å¤§é‡è¿å»¶è¿Ÿ 5 ç§’
            "-i", video_url,
            "-vn",                       # ä¸è¦è§†é¢‘
            "-ar", "16000",              # 16kHz é‡‡æ ·ç‡
            "-ac", "1",                  # å•å£°é“
            "-b:a", "64k",               # 64kbps ç ç‡
            "-f", "mp3",
            "-progress", "pipe:1",       # â˜… è¾“å‡ºè¿›åº¦åˆ° stdout
            audio_path
        ]
        
        process = await asyncio.create_subprocess_exec(
            *cmd,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )
        
        # â˜…â˜…â˜… å®æ—¶è§£æ FFmpeg è¿›åº¦ â˜…â˜…â˜…
        last_progress_update = 0
        total_duration_us = (video_duration_sec or 60) * 1_000_000  # å¾®ç§’
        
        async def read_progress():
            nonlocal last_progress_update
            while True:
                line = await process.stdout.readline()
                if not line:
                    break
                line_str = line.decode().strip()
                # FFmpeg progress æ ¼å¼: out_time_us=12345678
                if line_str.startswith("out_time_us="):
                    try:
                        current_us = int(line_str.split("=")[1])
                        if total_duration_us > 0:
                            pct = min(current_us / total_duration_us, 1.0)
                            # extract_audio å  10% è¿›åº¦ï¼ˆcurrent_progress åˆ° current_progress + 10ï¼‰
                            new_progress = current_progress + int(pct * 10)
                            # é¿å…é¢‘ç¹æ›´æ–°ï¼ˆæ¯å¢åŠ  2% æ›´æ–°ä¸€æ¬¡ï¼‰
                            if new_progress >= last_progress_update + 2:
                                update_progress("extract_audio", new_progress)
                                last_progress_update = new_progress
                    except (ValueError, IndexError):
                        pass
        
        # å¹¶è¡Œè¯»å– stdout è¿›åº¦å’Œ stderr
        async def read_stderr():
            """è¯»å– stderr è·å–é”™è¯¯ä¿¡æ¯"""
            data = await process.stderr.read()
            return data.decode() if data else ""
        
        progress_task = asyncio.create_task(read_progress())
        stderr_task = asyncio.create_task(read_stderr())
        
        # ç­‰å¾…è¿›ç¨‹å®Œæˆï¼ˆä¸ç”¨ communicateï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»åœ¨è¯» stdoutï¼‰
        await process.wait()
        
        # ç­‰å¾…è¯»å–ä»»åŠ¡å®Œæˆ
        await progress_task
        stderr_text = await stderr_task
        
        if process.returncode != 0:
            logger.error(f"[ASRä¼˜åŒ–] âŒ FFmpeg å¤±è´¥: {stderr_text[:500]}")
            raise Exception(f"éŸ³é¢‘æå–å¤±è´¥: {stderr_text[:200]}")
        
        audio_size_mb = os.path.getsize(audio_path) / (1024 * 1024)
        logger.info(f"[ASRä¼˜åŒ–] âœ… éŸ³é¢‘æµå¼æå–å®Œæˆ: {audio_size_mb:.1f}MB")
        
        # ä¸Šä¼ éŸ³é¢‘åˆ° Supabase
        update_progress("upload_audio", current_progress + 12)
        logger.info(f"[ASRä¼˜åŒ–] â¬†ï¸ ä¸Šä¼ éŸ³é¢‘...")
        
        audio_storage_path = f"asr_audio/{asset_id}.mp3"
        
        with open(audio_path, "rb") as f:
            audio_data = f.read()
        
        # ä½¿ç”¨ asyncio.to_thread é¿å…é˜»å¡
        await asyncio.to_thread(
            lambda: supabase.storage.from_("clips").upload(
                audio_storage_path,
                audio_data,
                {"content-type": "audio/mpeg", "upsert": "true"}
            )
        )
        
        audio_url = get_file_url("clips", audio_storage_path)
        update_progress("upload_audio", current_progress + 15)
        logger.info(f"[ASRä¼˜åŒ–] âœ… éŸ³é¢‘ä¸Šä¼ å®Œæˆ: {audio_storage_path}")
        
        return audio_url
        
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        import shutil
        try:
            shutil.rmtree(temp_dir)
            logger.info(f"[ASRä¼˜åŒ–] ğŸ§¹ ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†")
        except Exception as e:
            logger.warning(f"[ASRä¼˜åŒ–] âš ï¸ æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")


async def _run_asr(file_url: str, update_progress, current_progress: int, step_progress: int, asset_id: str = None, video_duration_sec: float = None) -> list:
    """
    æ‰§è¡Œ ASR è¯­éŸ³è½¬å†™
    
    ä¼˜åŒ–1ï¼šå¦‚æœ asset_id åœ¨ tasks è¡¨ä¸­å·²æœ‰è½¬å†™ç»“æœï¼Œç›´æ¥å¤ç”¨
    ä¼˜åŒ–2ï¼šå¦‚æœæä¾›äº† asset_id ä¸”æ˜¯å¤§æ–‡ä»¶ï¼ˆè§†é¢‘ï¼‰ï¼Œä¼šå…ˆæå–éŸ³é¢‘å†è½¬å†™
    """
    logger.info(f"[_run_asr] ğŸ¤ å¼€å§‹ ASR è½¬å†™")
    logger.info(f"[_run_asr]    file_url: {file_url[:100]}...")
    logger.info(f"[_run_asr]    current_progress: {current_progress}, step_progress: {step_progress}")
    logger.info(f"[_run_asr]    asset_id: {asset_id}, video_duration: {video_duration_sec}s")
    
    try:
        from ..tasks.transcribe import transcribe_audio
        import httpx
        
        # â˜…â˜…â˜… ä¼˜åŒ–ï¼šæ£€æŸ¥æ˜¯å¦å·²æœ‰è½¬å†™ç»“æœï¼ˆå¤ç”¨ analyze-content çš„è½¬å†™ï¼‰â˜…â˜…â˜…
        # æ³¨æ„ï¼šæ’é™¤ clip çº§åˆ«çš„è½¬å†™ä»»åŠ¡ï¼ˆparams ä¸­åŒ…å« clip_id çš„æ˜¯ clip è½¬å†™ï¼‰
        # åªå¤ç”¨æ•´ä½“ asset çš„è½¬å†™ç»“æœ
        if asset_id:
            existing_tasks = supabase.table("tasks").select(
                "id, status, result, params"
            ).eq("asset_id", asset_id).eq("task_type", "transcribe").eq("status", "completed").execute()
            
            # ç­›é€‰å‡ºæ•´ä½“ asset çš„è½¬å†™ä»»åŠ¡ï¼ˆparams ä¸­æ²¡æœ‰ clip_idï¼‰
            existing_task_data = None
            if existing_tasks and existing_tasks.data:
                for task in existing_tasks.data:
                    params = task.get("params") or {}
                    if not params.get("clip_id"):  # æ•´ä½“ asset è½¬å†™ï¼Œä¸æ˜¯ clip è½¬å†™
                        existing_task_data = task
                        break
            
            if existing_task_data and existing_task_data.get("result"):
                result = existing_task_data["result"]
                segments = result.get("segments", []) if isinstance(result, dict) else result
                if segments:
                    logger.info(f"[_run_asr] âœ… å¤ç”¨å·²æœ‰è½¬å†™ç»“æœ: {len(segments)} ä¸ªç‰‡æ®µ (task_id={existing_task_data['id'][:8]})")
                    update_progress("transcribe", current_progress + step_progress)
                    return segments
        
        # åˆ¤æ–­æ˜¯å¦æ˜¯è§†é¢‘æ–‡ä»¶ï¼Œéœ€è¦æå–éŸ³é¢‘
        is_video = any(ext in file_url.lower() for ext in ['.mp4', '.mov', '.avi', '.mkv', '.webm', '.m4v'])
        
        # å¦‚æœæ˜¯è§†é¢‘ä¸”æœ‰ asset_idï¼Œå…ˆæå–éŸ³é¢‘ï¼ˆå¤§å¹…æå‡é€Ÿåº¦ï¼‰
        actual_audio_url = file_url
        if is_video and asset_id:
            logger.info(f"[_run_asr] ğŸ¬ æ£€æµ‹åˆ°è§†é¢‘æ–‡ä»¶ï¼Œå…ˆæå–éŸ³é¢‘ä»¥ä¼˜åŒ–ä¸Šä¼ é€Ÿåº¦")
            try:
                # æå–éŸ³é¢‘å ç”¨ 20% è¿›åº¦
                audio_progress = int(step_progress * 0.2)
                actual_audio_url = await _extract_audio_for_asr(
                    video_url=file_url,
                    asset_id=asset_id,
                    update_progress=update_progress,
                    current_progress=current_progress,
                    video_duration_sec=video_duration_sec  # â˜… ä¼ å…¥è§†é¢‘æ—¶é•¿ç”¨äºè¿›åº¦è®¡ç®—
                )
                # è°ƒæ•´å‰©ä½™è¿›åº¦
                current_progress += audio_progress
                step_progress -= audio_progress
                logger.info(f"[_run_asr] âœ… éŸ³é¢‘æå–æˆåŠŸï¼Œä½¿ç”¨å‹ç¼©éŸ³é¢‘è¿›è¡Œè½¬å†™")
            except Exception as e:
                logger.warning(f"[_run_asr] âš ï¸ éŸ³é¢‘æå–å¤±è´¥ï¼Œå›é€€åˆ°åŸå§‹æ–‡ä»¶: {e}")
                actual_audio_url = file_url
        
        # éªŒè¯æ–‡ä»¶æ˜¯å¦å¯è®¿é—®ï¼ˆç­‰å¾…ä¸Šä¼ å®Œæˆï¼‰
        max_retries = 30  # æœ€å¤šç­‰å¾… 30 ç§’
        for retry in range(max_retries):
            try:
                async with httpx.AsyncClient(timeout=10.0) as client:
                    resp = await client.head(actual_audio_url)
                    if resp.status_code == 200:
                        logger.info(f"[_run_asr] âœ… æ–‡ä»¶å¯è®¿é—®ï¼Œå¼€å§‹è½¬å†™")
                        break
                    else:
                        logger.warning(f"[_run_asr] â³ æ–‡ä»¶ä¸å¯è®¿é—® (HTTP {resp.status_code})ï¼Œç­‰å¾…... ({retry+1}/{max_retries})")
            except Exception as e:
                logger.warning(f"[_run_asr] â³ æ–‡ä»¶æ£€æŸ¥å¤±è´¥: {e}ï¼Œç­‰å¾…... ({retry+1}/{max_retries})")
            
            if retry < max_retries - 1:
                await asyncio.sleep(1)
        else:
            logger.error(f"[_run_asr] âŒ æ–‡ä»¶åœ¨ {max_retries} ç§’åä»ä¸å¯è®¿é—®")
            return []
        
        def on_asr_progress(progress: int, step: str):
            mapped_progress = current_progress + int(progress * step_progress / 100)
            update_progress("transcribe", mapped_progress)
        
        asr_result = await transcribe_audio(
            audio_url=actual_audio_url,
            language="zh",
            on_progress=on_asr_progress,
        )
        
        segments = asr_result.get("segments", [])
        logger.info(f"[_run_asr] âœ… ASR å®Œæˆï¼Œè¯†åˆ« {len(segments)} ä¸ªç‰‡æ®µ")
        
        # è¯¦ç»†æ—¥å¿—
        if segments:
            first_seg = segments[0]
            last_seg = segments[-1]
            logger.info(f"[_run_asr]    ç¬¬ä¸€ä¸ªç‰‡æ®µ: start={first_seg.get('start')}ms text='{first_seg.get('text', '')[:20]}...'")
            logger.info(f"[_run_asr]    æœ€åä¸€ä¸ªç‰‡æ®µ: end={last_seg.get('end')}ms text='{last_seg.get('text', '')[:20]}...'")
        else:
            logger.warning(f"[_run_asr] âš ï¸ ASR è¿”å›ç©ºç»“æœ!")
        
        # â˜…â˜…â˜… ä¿å­˜è½¬å†™ç»“æœåˆ° tasks è¡¨ï¼Œä¾›æ™ºèƒ½åˆ†æå¤ç”¨ â˜…â˜…â˜…
        if asset_id and segments:
            try:
                now = datetime.utcnow().isoformat()
                default_user_id = "00000000-0000-0000-0000-000000000000"
                task_id = str(uuid4())
                
                # å…ˆæŸ¥è¯¢ project_id
                asset_info = supabase.table("assets").select("project_id").eq("id", asset_id).single().execute()
                project_id = asset_info.data.get("project_id") if asset_info.data else None
                
                supabase.table("tasks").insert({
                    "id": task_id,
                    "project_id": project_id,
                    "user_id": default_user_id,
                    "task_type": "transcribe",
                    "asset_id": asset_id,
                    "status": "completed",
                    "progress": 100,
                    "params": {"language": "zh", "model": "base"},
                    "result": asr_result,
                    "created_at": now,
                    "completed_at": now,
                    "updated_at": now
                }).execute()
                logger.info(f"[_run_asr] ğŸ’¾ è½¬å†™ç»“æœå·²ä¿å­˜åˆ° tasks è¡¨ (task_id={task_id[:8]})")
            except Exception as save_err:
                logger.warning(f"[_run_asr] âš ï¸ ä¿å­˜è½¬å†™ç»“æœå¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {save_err}")
            
        return segments
    except Exception as e:
        logger.error(f"[_run_asr] âŒ ASR å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return []


async def _run_silence_detection(file_url: str) -> list:
    """æ‰§è¡Œé™éŸ³æ£€æµ‹"""
    try:
        from ..tasks.vad import detect_silence_segments
        
        result = await detect_silence_segments(
            audio_url=file_url,
            min_silence_duration=0.5,
            silence_threshold_db=-35,
        )
        
        segments = result.get("segments", [])
        logger.info(f"[Workspace] âœ… é™éŸ³æ£€æµ‹å®Œæˆï¼Œæ£€æµ‹åˆ° {len(segments)} ä¸ªé™éŸ³ç‰‡æ®µ")
        return segments
    except Exception as e:
        logger.error(f"[Workspace] âŒ é™éŸ³æ£€æµ‹å¤±è´¥: {e}")
        return []


def _create_clips_from_segments(
    project_id: str,
    asset_id: str,
    transcript_segments: list,
    video_track_id: str,
    text_track_id: str,
) -> tuple:
    """
    æ ¹æ® ASR segments åˆ›å»ºè§†é¢‘å’Œå­—å¹• clips
    
    ç­–ç•¥ï¼š
    - è§†é¢‘ clipï¼šä½¿ç”¨åŸå§‹ ASR segmentsï¼Œä¸å—æ ‡ç‚¹åˆ‡åˆ†å½±å“
    - å­—å¹• clipï¼šä½¿ç”¨æ ‡ç‚¹åˆ‡åˆ†åçš„ç»†åˆ† segments
    - æ­»å¯‚/é•¿åœé¡¿/å¡é¡¿ï¼šè‡ªåŠ¨è·³è¿‡ï¼Œä¸åˆ›å»º clipï¼ˆç›¸å½“äºè‡ªåŠ¨åˆ‡é™¤ï¼‰
    - æ¢æ°”ï¼šä¿ç•™è®©ç”¨æˆ·é€‰æ‹©æ˜¯å¦åˆ é™¤
    
    è¿™æ ·è§†é¢‘ç‰‡æ®µä¿æŒå®Œæ•´ï¼Œè€Œå­—å¹•å¯ä»¥æŒ‰å¥å­ç²¾ç»†æ˜¾ç¤º
    """
    now = datetime.utcnow().isoformat()
    
    # æŒ‰æ—¶é—´é¡ºåºæ’åºåŸå§‹ segments
    sorted_segments = sorted(transcript_segments, key=lambda s: s.get("start", 0))
    
    video_clips = []
    subtitle_clips = []
    timeline_position = 0
    
    # ç»Ÿè®¡è‡ªåŠ¨è·³è¿‡çš„é™éŸ³ç‰‡æ®µ
    auto_skipped = {"dead_air": 0, "long_pause": 0, "hesitation": 0}
    auto_skipped_duration = 0
    
    for seg_idx, seg in enumerate(sorted_segments):
        seg_start = seg.get("start", 0)  # åŸè§†é¢‘ä¸­çš„å¼€å§‹ä½ç½®ï¼ˆæ¯«ç§’ï¼‰
        seg_end = seg.get("end", 0)      # åŸè§†é¢‘ä¸­çš„ç»“æŸä½ç½®ï¼ˆæ¯«ç§’ï¼‰
        seg_text = seg.get("text", "").strip()
        seg_duration = seg_end - seg_start
        
        if seg_duration <= 0:
            continue
        
        # ========================================
        # æ£€æŸ¥é™éŸ³ä¿¡æ¯ï¼Œå†³å®šæ˜¯å¦è‡ªåŠ¨è·³è¿‡
        # ========================================
        silence_info = seg.get("silence_info")
        
        if silence_info:
            cls = silence_info.get("classification")
            
            # æ­»å¯‚ã€é•¿åœé¡¿ã€å¡é¡¿ï¼šè‡ªåŠ¨è·³è¿‡ï¼Œä¸åˆ›å»º clip
            if cls in ("dead_air", "long_pause", "hesitation"):
                auto_skipped[cls] = auto_skipped.get(cls, 0) + 1
                auto_skipped_duration += seg_duration
                logger.debug(f"[Workspace] â­ï¸ è‡ªåŠ¨è·³è¿‡é™éŸ³: {cls}, duration={seg_duration}ms")
                continue  # ä¸åˆ›å»º clipï¼Œä¸å¢åŠ  timeline_position
        
        # ========================================
        # 1. åˆ›å»ºè§†é¢‘ clipï¼ˆä½¿ç”¨åŸå§‹ segmentï¼Œä¸åˆ‡åˆ†ï¼‰
        # ========================================
        clip_name = f"ç‰‡æ®µ {seg_idx + 1}"
        
        if silence_info:
            cls = silence_info.get("classification")
            if cls == "breath":
                clip_name = "æ¢æ°”"
            logger.debug(f"[Workspace] ğŸ”‡ ä¿ç•™é™éŸ³ç‰‡æ®µ: classification={cls}, name={clip_name}, duration={seg_duration}ms")
        
        # ç”Ÿæˆè§†é¢‘ clip IDï¼Œåç»­å­—å¹•éœ€è¦å…³è”
        video_clip_id = str(uuid4())
        
        video_clips.append({
            "id": video_clip_id,
            "track_id": video_track_id,
            "asset_id": asset_id,
            "clip_type": "video",
            "start_time": timeline_position,
            "end_time": timeline_position + seg_duration,
            "source_start": seg_start,
            "source_end": seg_end,
            "is_muted": False,
            "name": clip_name,
            "created_at": now,
            "updated_at": now,
            "metadata": {
                "silence_info": silence_info,
                "original_text": seg_text
            }
        })
        
        # ========================================
        # 2. åˆ›å»ºå­—å¹• clipsï¼ˆæŒ‰æ ‡ç‚¹åˆ‡åˆ†æˆå¤šä¸ªå­å¥ï¼‰
        # ========================================
        if seg_text:
            # å¯¹å½“å‰ segment è¿›è¡Œæ ‡ç‚¹åˆ‡åˆ†
            fine_subs = _split_segments_by_punctuation([seg])
            
            # å½“å‰ segment å†…çš„ç›¸å¯¹æ—¶é—´èµ·ç‚¹
            relative_start = 0
            
            for sub_idx, sub_seg in enumerate(fine_subs):
                sub_start = sub_seg.get("start", seg_start)
                sub_end = sub_seg.get("end", seg_end)
                sub_text = sub_seg.get("text", "").strip()
                sub_duration = sub_end - sub_start
                
                if sub_duration <= 0 or not sub_text:
                    continue
                
                # å­—å¹•åœ¨æ—¶é—´è½´ä¸Šçš„ä½ç½® = å½“å‰è§†é¢‘ clip å¼€å§‹ä½ç½® + ç›¸å¯¹åç§»
                subtitle_timeline_start = timeline_position + (sub_start - seg_start)
                
                subtitle_clips.append({
                    "id": str(uuid4()),
                    "track_id": text_track_id,
                    "clip_type": "subtitle",
                    "parent_clip_id": video_clip_id,  # å…³è”å¯¹åº”çš„è§†é¢‘ clipï¼Œæ–¹ä¾¿åç»­è¦†ç›–
                    "start_time": subtitle_timeline_start,
                    "end_time": subtitle_timeline_start + sub_duration,
                    "source_start": 0,
                    "source_end": sub_duration,
                    "is_muted": False,
                    "content_text": sub_text,
                    "text_style": {
                        "fontSize": 15,
                        "fontColor": "#FFFFFF",
                        "backgroundColor": "transparent",
                        "alignment": "center",
                        "maxWidth": "85%",  # å­—å¹•æœ€å¤§å®½åº¦ 85% ç”»å¸ƒå®½åº¦ï¼Œé€‚é…å„ç§æ¯”ä¾‹
                    },
                    "transform": {
                        "x": 0,
                        "y": 150,
                        "scale": 1,
                    },
                    "metadata": {
                        "segment_id": seg.get("id"),
                        "speaker": seg.get("speaker"),
                        "order_index": seg_idx * 100 + sub_idx,  # ç¡®ä¿é¡ºåºå”¯ä¸€
                        "original_start": sub_start,
                        "original_end": sub_end,
                    },
                    "created_at": now,
                    "updated_at": now,
                })
        
        # æ›´æ–°æ—¶é—´è½´ä½ç½®
        timeline_position += seg_duration
    
    # è¾“å‡ºç»Ÿè®¡æ—¥å¿—
    total_skipped = sum(auto_skipped.values())
    logger.info(f"[Workspace] åˆ›å»º {len(video_clips)} ä¸ªè§†é¢‘ Clipï¼Œ{len(subtitle_clips)} ä¸ªå­—å¹• Clip")
    if total_skipped > 0:
        logger.info(f"[Workspace] âœ‚ï¸ è‡ªåŠ¨åˆ‡é™¤ {total_skipped} ä¸ªé™éŸ³ç‰‡æ®µ (å…± {auto_skipped_duration/1000:.1f}s): "
              f"æ­»å¯‚={auto_skipped['dead_air']}, é•¿åœé¡¿={auto_skipped['long_pause']}, å¡é¡¿={auto_skipped['hesitation']}")
    
    return video_clips, subtitle_clips


async def _process_session(
    session_id: str,
    project_id: str,
    asset_id: str,
    task_type: str,
):
    """
    åå°å¤„ç†ä¼šè¯
    æ‰§è¡Œ ASR è½¬å†™ï¼ˆå·²é›†æˆæ™ºèƒ½é™éŸ³åˆ†çº§ï¼‰
    æ”¯æŒä¸€é”® AI æˆç‰‡æ¨¡å¼ï¼ˆtask_type == 'ai-create'ï¼‰
    """
    import asyncio
    
    # â˜… ç”± task_type å†³å®šå¤„ç†æµç¨‹
    ai_create_mode = task_type == "ai-create"
    # enable_llm æ˜¯ç‹¬ç«‹å¼€å…³ï¼Œæ§åˆ¶æ˜¯å¦è°ƒç”¨ LLM è¿›è¡Œè¯­ä¹‰åˆ†æ
    # TODO: åç»­å¯ä»è¯·æ±‚å‚æ•°æˆ–ç”¨æˆ·é…ç½®è·å–
    enable_llm = False
    
    if ai_create_mode:
        logger.info(f"[Workspace] å¼€å§‹ä¸€é”® AI æˆç‰‡æµç¨‹ {session_id}, enable_llm={enable_llm}")
    else:
        logger.info(f"[Workspace] å¼€å§‹å¤„ç†ä¼šè¯ {session_id}, task_type={task_type}, enable_llm={enable_llm}")
    
    try:
        update_progress = _create_progress_updater(session_id)
        
        # Step 1: è·å–è§†é¢‘æ•°æ® (0% â†’ 20%)
        _raise_if_cancelled(session_id, "å¼€å§‹å¤„ç†")
        update_progress("fetch", 5)
        await asyncio.sleep(0.5)
        
        asset = supabase.table("assets").select("*").eq("id", asset_id).single().execute()
        if not asset.data:
            raise Exception("èµ„æºä¸å­˜åœ¨")
        
        storage_path = asset.data.get("storage_path")
        file_url = get_file_url("clips", storage_path)
        
        # æå–è§†é¢‘å…ƒæ•°æ®ï¼ˆå®½é«˜ã€å¸§ç‡ç­‰ï¼‰
        metadata = await _fetch_asset_metadata(asset_id, file_url)
        # duration ä» asset è¡¨è·å–ï¼ˆå‰ç«¯ä¼ å…¥ï¼‰ï¼Œä¸ä¾èµ– ffprobe
        duration = asset.data.get("duration") or metadata.get("duration", 0)
        width = metadata.get("width", 1920)
        height = metadata.get("height", 1080)
        # fps å¿…é¡»æ˜¯æ•´æ•°ï¼ˆprojects è¡¨è¦æ±‚ï¼‰
        fps_value = metadata.get("fps", 30)
        fps = int(round(fps_value)) if isinstance(fps_value, (int, float)) else 30
        
        update_progress("fetch", 20)
        
        transcript_segments = []
        
        # Step 2: ASR è¯­éŸ³è½¬å†™ï¼ˆå·²åŒ…å«æ™ºèƒ½é™éŸ³åˆ†çº§ï¼‰
        _raise_if_cancelled(session_id, "ASR è½¬å†™å‰")
        update_progress("transcribe", 25)
        logger.info(f"[Workspace] å¼€å§‹ ASR è½¬å†™ï¼ˆå«æ™ºèƒ½é™éŸ³åˆ†çº§ï¼‰...")
        transcript_segments = await _run_asr(file_url, update_progress, 20, 60, asset_id=asset_id, video_duration_sec=duration)
        _raise_if_cancelled(session_id, "ASR è½¬å†™å")
        update_progress("transcribe", 80)
        
        # ==========================================
        # ä¸€é”® AI æˆç‰‡æ¨¡å¼ - è°ƒç”¨ AI æˆç‰‡æœåŠ¡
        # ==========================================
        if ai_create_mode:
            _raise_if_cancelled(session_id, "AI æˆç‰‡å‰")
            update_progress("segment", 35)
            logger.info(f"[Workspace] è¿›å…¥ä¸€é”® AI æˆç‰‡æµç¨‹...")
            
            from ..services.ai_video_creator import ai_video_creator
            
            # è·å–æœ¬åœ°è§†é¢‘è·¯å¾„ï¼ˆä» storage_path æ„é€ ï¼‰
            video_path = f"/tmp/{storage_path}" if storage_path else file_url
            
            # è°ƒç”¨ AI æˆç‰‡æœåŠ¡
            update_progress("vision", 50)
            ai_result = await ai_video_creator.process(
                video_path=file_url,  # ä½¿ç”¨ URLï¼ŒæœåŠ¡å†…éƒ¨ä¼šå¤„ç†
                audio_url=file_url,
                options={
                    "enable_llm": enable_llm,
                    "transcript_segments": transcript_segments  # ä¼ å…¥å·²æœ‰çš„ ASR ç»“æœ
                }
            )
            
            _raise_if_cancelled(session_id, "AI è§†è§‰åˆ†æå")
            update_progress("transform", 70)
            
            # å°† AI ç»“æœè½¬æ¢ä¸º Clips
            now = datetime.utcnow().isoformat()
            
            # åˆ›å»ºè§†é¢‘è½¨é“
            video_track_id = str(uuid4())
            supabase.table("tracks").insert({
                "id": video_track_id,
                "project_id": project_id,
                "name": "AI è§†é¢‘è½¨é“",
                "order_index": 0,
                "is_muted": False,
                "is_locked": False,
                "is_visible": True,
                "created_at": now,
                "updated_at": now,
            }).execute()
            
            # åˆ›å»ºå­—å¹•è½¨é“
            text_track_id = str(uuid4())
            supabase.table("tracks").insert({
                "id": text_track_id,
                "project_id": project_id,
                "name": "AI å­—å¹•è½¨é“",
                "order_index": 1,
                "is_muted": False,
                "is_locked": False,
                "is_visible": True,
                "created_at": now,
                "updated_at": now,
            }).execute()
            
            update_progress("subtitle", 85)
            
            # ä» AI ç»“æœåˆ›å»º Clips
            video_clips = []
            subtitle_clips = []
            
            timeline_position = 0
            breath_count = 0
            speech_count = 0
            
            for seg_idx, seg in enumerate(ai_result.segments):
                clip_duration = int(seg.end - seg.start)
                
                # åˆ¤æ–­æ˜¯å¦ä¸ºæ¢æ°”ç‰‡æ®µ
                is_breath = seg.is_breath if hasattr(seg, "is_breath") else False
                is_silence = seg.is_silence if hasattr(seg, "is_silence") else False
                
                # ä¸ºç‰‡æ®µå‘½å
                if is_breath:
                    clip_name = "æ¢æ°”"
                    breath_count += 1
                elif is_silence:
                    clip_name = "é™éŸ³"
                else:
                    speech_count += 1
                    clip_name = f"ç‰‡æ®µ {speech_count}"
                
                # ç”Ÿæˆè§†é¢‘ clip IDï¼Œåç»­å­—å¹•éœ€è¦å…³è”
                video_clip_id = str(uuid4())
                
                # è§†é¢‘ Clip
                video_clip = {
                    "id": video_clip_id,
                    "track_id": video_track_id,
                    "asset_id": asset_id,
                    "clip_type": "video",
                    "name": clip_name,
                    "start_time": timeline_position,
                    "end_time": timeline_position + clip_duration,
                    "source_start": int(seg.start),
                    "source_end": int(seg.end),
                    "is_muted": False,
                    "created_at": now,
                    "updated_at": now,
                }
                
                # æ·»åŠ å…ƒæ•°æ® (ä¿ç•™é™éŸ³åˆ†çº§ä¿¡æ¯)
                if hasattr(seg, "metadata") and seg.metadata:
                    video_clip["metadata"] = seg.metadata
                
                # æ·»åŠ è¿é•œå…³é”®å¸§ (å¦‚æœæœ‰)
                if hasattr(seg, "transform") and seg.transform:
                    video_clip["transform"] = seg.transform
                
                video_clips.append(video_clip)
                
                # å­—å¹• Clip (åªæœ‰è¯­éŸ³ç‰‡æ®µæ‰ç”Ÿæˆå­—å¹•ï¼ŒæŒ‰æ ‡ç‚¹åˆ‡åˆ†)
                if seg.text and not is_breath and not is_silence:
                    # å°† SmartSegment è½¬æ¢ä¸ºæ ‡å‡† segment dict ç”¨äºåˆ‡åˆ†
                    seg_dict = {
                        "id": seg.id,
                        "text": seg.text,
                        "start": int(seg.start),
                        "end": int(seg.end),
                    }
                    
                    # æŒ‰æ ‡ç‚¹åˆ‡åˆ†æˆå¤šä¸ªå­å¥
                    fine_subs = _split_segments_by_punctuation([seg_dict])
                    
                    # ä¸ºæ¯ä¸ªå­å¥åˆ›å»ºå­—å¹• clip
                    for sub_idx, sub_seg in enumerate(fine_subs):
                        sub_start = sub_seg.get("start", seg.start)
                        sub_end = sub_seg.get("end", seg.end)
                        sub_text = sub_seg.get("text", "").strip()
                        sub_duration = sub_end - sub_start
                        
                        if sub_duration <= 0 or not sub_text:
                            continue
                        
                        # å­—å¹•åœ¨æ—¶é—´è½´ä¸Šçš„ä½ç½® = å½“å‰è§†é¢‘ clip å¼€å§‹ä½ç½® + ç›¸å¯¹åç§»
                        subtitle_timeline_start = timeline_position + (sub_start - int(seg.start))
                        
                        subtitle_clip = {
                            "id": str(uuid4()),
                            "track_id": text_track_id,
                            "clip_type": "subtitle",
                            "parent_clip_id": video_clip_id,  # å…³è”å¯¹åº”çš„è§†é¢‘ clipï¼Œæ–¹ä¾¿åç»­è¦†ç›–
                            "start_time": subtitle_timeline_start,
                            "end_time": subtitle_timeline_start + sub_duration,
                            "content_text": sub_text,
                            "text_style": {
                                "fontSize": 15,
                                "fontColor": "#FFFFFF",
                                "backgroundColor": "transparent",
                                "alignment": "center",
                                "maxWidth": "85%",  # å­—å¹•æœ€å¤§å®½åº¦ 85% ç”»å¸ƒå®½åº¦
                            },
                            "transform": {
                                "x": 0,
                                "y": 150,
                                "scale": 1,
                            },
                            "is_muted": False,
                            "metadata": {
                                "segment_id": seg.id,
                                "order_index": seg_idx * 100 + sub_idx,  # ç¡®ä¿é¡ºåºå”¯ä¸€
                                "original_start": sub_start,
                                "original_end": sub_end,
                            },
                            "created_at": now,
                            "updated_at": now,
                        }
                        subtitle_clips.append(subtitle_clip)
                
                timeline_position += clip_duration
            
            logger.info(f"[Workspace] ğŸ“Š AI æˆç‰‡ç»Ÿè®¡: è¯­éŸ³ç‰‡æ®µ {speech_count}, æ¢æ°”ä¿ç•™ {breath_count}")
            
            # æ‰¹é‡æ’å…¥å‰æ£€æŸ¥å–æ¶ˆçŠ¶æ€
            _raise_if_cancelled(session_id, "æ’å…¥ Clip å‰")
            
            # æ‰¹é‡æ’å…¥
            if video_clips:
                supabase.table("clips").insert(video_clips).execute()
                logger.info(f"[Workspace] âœ… AI æˆç‰‡åˆ›å»º {len(video_clips)} ä¸ªè§†é¢‘ Clip")
            if subtitle_clips:
                supabase.table("clips").insert(subtitle_clips).execute()
                logger.info(f"[Workspace] âœ… AI æˆç‰‡åˆ›å»º {len(subtitle_clips)} ä¸ªå­—å¹• Clip")
            
            update_progress("prepare", 95)
            
            # å®Œæˆ
            now_complete = datetime.utcnow().isoformat()
            supabase.table("workspace_sessions").update({
                "status": "completed",
                "progress": 100,
                "current_step": "completed",
                "completed_at": now_complete,
                "updated_at": now_complete
            }).eq("id", session_id).execute()
            
            logger.info(f"[Workspace] âœ… ä¸€é”® AI æˆç‰‡å®Œæˆï¼")
            return
        
        # ==========================================
        # Step 3: å‡†å¤‡å·¥ä½œå° - åˆ›å»ºè½¨é“å’Œ Clip (æ™®é€šæ¨¡å¼)
        # ==========================================
        _raise_if_cancelled(session_id, "åˆ›å»ºè½¨é“å‰")
        update_progress("prepare", 90)
        
        now = datetime.utcnow().isoformat()
        
        # åˆ›å»ºè§†é¢‘è½¨é“
        video_track_id = str(uuid4())
        supabase.table("tracks").insert({
            "id": video_track_id,
            "project_id": project_id,
            "name": "è§†é¢‘è½¨é“",
            "order_index": 0,
            "is_muted": False,
            "is_locked": False,
            "is_visible": True,
            "created_at": now,
            "updated_at": now,
        }).execute()
        
        clip_duration_ms = int((duration if duration > 0 else 10) * 1000)
        
        # å¦‚æœæœ‰ ASR ç»“æœï¼Œæ ¹æ®è¯­éŸ³ç‰‡æ®µåˆ‡åˆ†è§†é¢‘
        if transcript_segments:
            # åˆ›å»ºæ–‡æœ¬è½¨é“
            text_track_id = str(uuid4())
            supabase.table("tracks").insert({
                "id": text_track_id,
                "project_id": project_id,
                "name": "è½¬å†™æ–‡æœ¬",
                "order_index": 1,
                "is_muted": False,
                "is_locked": False,
                "is_visible": True,
                "created_at": now,
                "updated_at": now,
            }).execute()
            
            # ä½¿ç”¨è¾…åŠ©å‡½æ•°åˆ›å»º clips
            video_clips, subtitle_clips = _create_clips_from_segments(
                project_id=project_id,
                asset_id=asset_id,
                transcript_segments=transcript_segments,
                video_track_id=video_track_id,
                text_track_id=text_track_id,
            )
            
            # æ‰¹é‡æ’å…¥æ‰€æœ‰ clips
            if video_clips:
                supabase.table("clips").insert(video_clips).execute()
                logger.info(f"[Workspace] âœ… åˆ›å»º {len(video_clips)} ä¸ªè§†é¢‘ Clip æˆåŠŸ")
            
            if subtitle_clips:
                supabase.table("clips").insert(subtitle_clips).execute()
                logger.info(f"[Workspace] âœ… åˆ›å»º {len(subtitle_clips)} ä¸ªå­—å¹• Clip æˆåŠŸ")
        else:
            # æ²¡æœ‰ ASR ç»“æœï¼Œåˆ›å»ºå®Œæ•´è§†é¢‘ Clip
            video_clip_id = str(uuid4())
            supabase.table("clips").insert({
                "id": video_clip_id,
                "track_id": video_track_id,
                "asset_id": asset_id,
                "clip_type": "video",
                "start_time": 0,
                "end_time": clip_duration_ms,
                "source_start": 0,
                "source_end": clip_duration_ms,
                "is_muted": False,
                "created_at": now,
                "updated_at": now,
            }).execute()
        
        # æ›´æ–°é¡¹ç›®
        supabase.table("projects").update({
            "status": "ready",
            "resolution": {"width": width, "height": height},
            "fps": fps,
            "updated_at": now,
        }).eq("id", project_id).execute()
        
        update_progress("prepare", 100)
        
        # æ ‡è®°ä¼šè¯å®Œæˆ
        # è®¡ç®—é™éŸ³ç‰‡æ®µæ•°é‡ï¼ˆé€šè¿‡ silence_info å­—æ®µåˆ¤æ–­ï¼‰
        silence_count = len([s for s in transcript_segments if s.get("silence_info")])
        
        supabase.table("workspace_sessions").update({
            "status": "completed",
            "progress": 100,
            "transcript_segments": len(transcript_segments),
            "marked_clips": silence_count,  # é™éŸ³ç‰‡æ®µæ•°é‡ï¼ˆå·²é›†æˆåˆ° ASRï¼‰
            "completed_at": now,
            "updated_at": now,
        }).eq("id", session_id).execute()
        
        logger.info(f"[Workspace] âœ… ä¼šè¯ {session_id} å¤„ç†å®Œæˆ")
        
    except SessionCancelledException:
        # ç”¨æˆ·ä¸»åŠ¨å–æ¶ˆï¼Œä¸éœ€è¦æ›´æ–°çŠ¶æ€ï¼ˆå·²ç»æ˜¯ cancelledï¼‰
        logger.info(f"[Workspace] ğŸ›‘ ä¼šè¯ {session_id} å¤„ç†å·²è¢«ç”¨æˆ·å–æ¶ˆ")
        return
    except Exception as e:
        logger.error(f"[Workspace] âŒ å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        
        supabase.table("workspace_sessions").update({
            "status": "failed",
            "error_message": str(e),
            "updated_at": datetime.utcnow().isoformat(),
        }).eq("id", session_id).execute()
        
        supabase.table("projects").update({
            "status": "draft",
            "updated_at": datetime.utcnow().isoformat(),
        }).eq("id", project_id).execute()


async def _process_session_multi_assets(
    session_id: str,
    project_id: str,
    assets: list,
    task_type: str,
):
    """
    åå°å¤„ç†ä¼šè¯ - å¤šç´ æç‰ˆæœ¬
    æŒ‰é¡ºåºå¤„ç†å¤šä¸ªç´ æï¼Œæ‹¼æ¥åˆ°åŒä¸€æ—¶é—´è½´
    """
    import asyncio
    
    # â˜… ç”± task_type å†³å®šå¤„ç†æµç¨‹
    ai_create_mode = task_type == "ai-create"
    voice_extract_mode = task_type == "voice-extract"
    # enable_llm æ˜¯ç‹¬ç«‹å¼€å…³ï¼Œæ§åˆ¶æ˜¯å¦è°ƒç”¨ LLM è¿›è¡Œè¯­ä¹‰åˆ†æ
    # TODO: åç»­å¯ä»è¯·æ±‚å‚æ•°æˆ–ç”¨æˆ·é…ç½®è·å–
    enable_llm = False
    
    logger.info(f"[Workspace] ========================================")
    logger.info(f"[Workspace] ğŸš€ å¼€å§‹å¤„ç†å¤šç´ æä¼šè¯")
    logger.info(f"[Workspace]    session_id: {session_id}")
    logger.info(f"[Workspace]    project_id: {project_id}")
    logger.info(f"[Workspace]    task_type: {task_type}")
    logger.info(f"[Workspace]    ai_create_mode: {ai_create_mode}")
    logger.info(f"[Workspace]    voice_extract_mode: {voice_extract_mode}")
    logger.info(f"[Workspace]    enable_llm: {enable_llm}")
    logger.info(f"[Workspace]    ç´ ææ•°é‡: {len(assets)}")
    logger.info(f"[Workspace] ========================================")
    
    try:
        update_progress = _create_progress_updater(session_id)
        now = datetime.utcnow().isoformat()
        
        # Step 1: è·å–æ‰€æœ‰ç´ æå…ƒæ•°æ® (0% â†’ 10%)
        _raise_if_cancelled(session_id, "å¼€å§‹å¤„ç†å¤šç´ æ")
        update_progress("fetch", 5)
        
        # æ”¶é›†æ‰€æœ‰ç´ æä¿¡æ¯
        asset_infos = []
        total_duration = 0
        max_width = 0
        max_height = 0
        
        for idx_asset, asset in enumerate(assets):
            asset_id = asset["id"]
            storage_path = asset.get("storage_path")
            logger.info(f"[Workspace] ğŸ“¦ è·å–ç´ æ {idx_asset + 1}/{len(assets)} å…ƒæ•°æ®: {asset_id}")
            logger.info(f"[Workspace]    storage_path: {storage_path}")
            file_url = get_file_url("clips", storage_path)
            logger.info(f"[Workspace]    file_url: {file_url[:80]}...")
            
            # è·å–å…ƒæ•°æ®ï¼ˆåŒ…æ‹¬ç¼–ç ä¿¡æ¯ï¼‰
            metadata = await _fetch_asset_metadata(asset_id, file_url)
            logger.info(f"[Workspace]    metadata: {metadata}")
            duration = asset.get("duration") or metadata.get("duration", 0)
            width = metadata.get("width", 1920)
            height = metadata.get("height", 1080)
            codec = metadata.get("codec", "unknown")
            needs_transcode = metadata.get("needs_transcode", False)
            
            asset_infos.append({
                "asset_id": asset_id,
                "storage_path": storage_path,  # â˜… ä¿å­˜ storage_path ç”¨äºè½¬ç 
                "file_url": file_url,
                "duration": duration,
                "duration_ms": int(duration * 1000),
                "width": width,
                "height": height,
                "order": asset.get("order_index", 0),
                "name": asset.get("name", "ç´ æ"),
                "codec": codec,  # â˜… ä¿å­˜ç¼–ç ä¿¡æ¯
                "needs_transcode": needs_transcode,  # â˜… æ˜¯å¦éœ€è¦è½¬ç 
            })
            
            total_duration += duration
            max_width = max(max_width, width)
            max_height = max(max_height, height)
        
        # æŒ‰é¡ºåºæ’åº
        asset_infos.sort(key=lambda x: x["order"])
        
        update_progress("fetch", 10)
        logger.info(f"[Workspace] âœ… è·å– {len(asset_infos)} ä¸ªç´ æå…ƒæ•°æ®ï¼Œæ€»æ—¶é•¿ {total_duration:.1f}s")
        
        # ========================================
        # ğŸš€ å¯åŠ¨ HLS åå°ç”Ÿæˆï¼ˆæ‰€æœ‰éœ€è¦è½¬ç çš„è§†é¢‘ + å¤§è§†é¢‘ï¼‰
        # ========================================
        # â˜… ç§»é™¤é˜»å¡è½¬ç ï¼HLS æµæœ¬èº«å°±æ˜¯ H.264 ç¼–ç ï¼Œå‰ç«¯ä¼˜å…ˆä½¿ç”¨ HLS æ’­æ”¾
        # â˜… ProRes ç­‰æµè§ˆå™¨ä¸æ”¯æŒçš„æ ¼å¼ä¼šé€šè¿‡ HLS è½¬ç åæ’­æ”¾
        from ..tasks.asset_processing import generate_hls_from_url
        
        # HLS ç”Ÿæˆæ¡ä»¶ï¼š
        # 1. éœ€è¦è½¬ç çš„è§†é¢‘ï¼ˆProResã€HEVC ç­‰ï¼‰- å¿…é¡»ç”Ÿæˆ HLS æ‰èƒ½æ’­æ”¾
        # 2. æ—¶é•¿ > 2åˆ†é’Ÿ æˆ– åˆ†è¾¨ç‡ > 1080p çš„è§†é¢‘ - ä¼˜åŒ–æ’­æ”¾ä½“éªŒ
        HLS_DURATION_THRESHOLD = 120  # ç§’
        HLS_RESOLUTION_THRESHOLD = 1920  # åƒç´ 
        
        assets_need_hls = [
            info for info in asset_infos
            if info.get("needs_transcode")  # â˜… ProRes ç­‰å¿…é¡»ç”Ÿæˆ HLS
               or info["duration"] > HLS_DURATION_THRESHOLD 
               or max(info["width"], info["height"]) > HLS_RESOLUTION_THRESHOLD
        ]
        
        # â˜… æ ‡è®°éœ€è¦ HLS çš„ç´ æï¼ˆå‰ç«¯ä¼šç­‰å¾… HLS å°±ç»ªåå†æ’­æ”¾ï¼‰
        for info in assets_need_hls:
            asset_id = info["asset_id"]
            needs_transcode = info.get("needs_transcode", False)
            try:
                supabase.table("assets").update({
                    "hls_status": "pending",  # pending -> processing -> ready
                    "needs_transcode": needs_transcode,
                }).eq("id", asset_id).execute()
            except Exception as e:
                logger.warning(f"[Workspace] æ›´æ–° HLS çŠ¶æ€å¤±è´¥: {e}")
        
        async def generate_all_hls():
            """é¡ºåºç”Ÿæˆ HLSï¼Œé¿å…å¤šä¸ª FFmpeg å¹¶å‘å¯¼è‡´èµ„æºç«äº‰"""
            for info in assets_need_hls:
                asset_id = info["asset_id"]
                file_url = info["file_url"]
                codec = info.get("codec", "unknown")
                logger.info(f"[Workspace] ğŸ¬ å¯åŠ¨ HLS ç”Ÿæˆ: {asset_id} (codec={codec}, duration={info['duration']:.1f}s)")
                try:
                    hls_path = await generate_hls_from_url(asset_id, file_url)
                    if hls_path:
                        # â˜… æˆåŠŸï¼šåŒæ—¶è®¾ç½® hls_status å’Œ hls_path
                        supabase.table("assets").update({
                            "hls_status": "ready",
                            "hls_path": hls_path
                        }).eq("id", asset_id).execute()
                        logger.info(f"[Workspace] âœ… HLS ç”ŸæˆæˆåŠŸ: {asset_id}, path={hls_path}")
                    else:
                        # HLS ç”Ÿæˆè¿”å› Noneï¼ˆå¤±è´¥ï¼‰
                        supabase.table("assets").update({
                            "hls_status": "failed"
                        }).eq("id", asset_id).execute()
                        logger.error(f"[Workspace] âŒ HLS ç”Ÿæˆå¤±è´¥ï¼ˆè¿”å›ç©ºï¼‰: {asset_id}")
                except Exception as e:
                    logger.error(f"[Workspace] HLS ç”Ÿæˆå¤±è´¥ {asset_id}: {e}")
                    supabase.table("assets").update({
                        "hls_status": "failed"
                    }).eq("id", asset_id).execute()
        
        # åå°å¯åŠ¨ HLS ç”Ÿæˆï¼ˆä¸é˜»å¡ä¸»æµç¨‹ï¼‰
        hls_task = None
        if assets_need_hls:
            hls_task = asyncio.create_task(generate_all_hls())
            logger.info(f"[Workspace] ğŸ“¦ å·²å¯åŠ¨ HLS ç”Ÿæˆä»»åŠ¡ï¼ˆ{len(assets_need_hls)}/{len(asset_infos)} ä¸ªç´ æéœ€è¦ HLSï¼‰")
        else:
            logger.info(f"[Workspace] â­ï¸ è·³è¿‡ HLS ç”Ÿæˆï¼ˆæ‰€æœ‰ {len(asset_infos)} ä¸ªç´ æéƒ½æ˜¯å°è§†é¢‘ï¼Œç›´æ¥æ’­æ”¾åŸæ–‡ä»¶ï¼‰")
        
        # Step 2: åˆ›å»ºè½¨é“
        # 1. è§†é¢‘è½¨é“ (å§‹ç»ˆåˆ›å»ºï¼ŒTrack 0)
        video_track_id = str(uuid4())
        supabase.table("tracks").insert({
            "id": video_track_id,
            "project_id": project_id,
            "name": "è§†é¢‘è½¨é“",
            "order_index": 0,
            "is_muted": False,
            "is_locked": False,
            "is_visible": True,
            "created_at": now,
            "updated_at": now,
        }).execute()
        
        audio_track_id = None
        main_track_id = video_track_id  # é»˜è®¤ä¸»è½¨é“æ˜¯è§†é¢‘è½¨
        
        # 2. å¦‚æœæ˜¯ Voice Extract æ¨¡å¼ï¼Œåˆ›å»ºéŸ³é¢‘è½¨é“ (Track 1)
        if voice_extract_mode:
            audio_track_id = str(uuid4())
            supabase.table("tracks").insert({
                "id": audio_track_id,
                "project_id": project_id,
                "name": "åŸå£°éŸ³é¢‘",
                "order_index": 1,
                "is_muted": False,
                "is_locked": False,
                "is_visible": True,
                "created_at": now,
                "updated_at": now,
            }).execute()
            main_track_id = audio_track_id  # ä¸»ç´ ææ”¾åœ¨éŸ³é¢‘è½¨
        
        # 3. å­—å¹•è½¨é“ (Track 2)
        text_track_id = str(uuid4())
        supabase.table("tracks").insert({
            "id": text_track_id,
            "project_id": project_id,
            "name": "å­—å¹•è½¨é“",
            "order_index": 2 if voice_extract_mode else 1,
            "is_muted": False,
            "is_locked": False,
            "is_visible": True,
            "created_at": now,
            "updated_at": now,
        }).execute()
        
        # Step 3: æŒ‰é¡ºåºå¤„ç†æ¯ä¸ªç´ æçš„ ASR (10% â†’ 80%)
        all_video_clips = []
        all_subtitle_clips = []
        all_keyframes = []  # â˜… æ”¶é›†æ‰€æœ‰å…³é”®å¸§ï¼ˆç»Ÿä¸€å­˜å‚¨åˆ° keyframes è¡¨ï¼‰
        timeline_position = 0
        total_segments = 0
        
        progress_per_asset = 70 / len(asset_infos)  # æ¯ä¸ªç´ æå  70% è¿›åº¦
        
        for idx, info in enumerate(asset_infos):
            # æ¯ä¸ªç´ æå¤„ç†å‰æ£€æŸ¥å–æ¶ˆçŠ¶æ€
            _raise_if_cancelled(session_id, f"å¤„ç†ç´ æ {idx + 1}/{len(asset_infos)} å‰")
            
            asset_id = info["asset_id"]
            file_url = info["file_url"]
            asset_duration_ms = info["duration_ms"]
            
            base_progress = 10 + int(idx * progress_per_asset)
            logger.info(f"[Workspace] ========================================")
            logger.info(f"[Workspace] ğŸ“¹ å¤„ç†ç´ æ {idx + 1}/{len(asset_infos)}")
            logger.info(f"[Workspace]    åç§°: {info['name']}")
            logger.info(f"[Workspace]    asset_id: {asset_id}")
            logger.info(f"[Workspace]    æ—¶é•¿: {info['duration']:.1f}s ({asset_duration_ms}ms)")
            logger.info(f"[Workspace]    base_progress: {base_progress}%")
            logger.info(f"[Workspace] ========================================")
            
            transcript_segments = []
            
            # ASR è½¬å†™ï¼ˆå§‹ç»ˆæ‰§è¡Œï¼‰
            logger.info(f"[Workspace] ğŸ™ï¸ å¼€å§‹ ASR è½¬å†™ç´ æ {idx + 1}...")
            logger.info(f"[Workspace]    ASR è¾“å…¥ URL: {file_url}")
            update_progress("transcribe", base_progress + 5)
            
            # å¦‚æœä¸æ˜¯ç¬¬ä¸€ä¸ªç´ æï¼Œç­‰å¾…ä¸€å°æ®µæ—¶é—´é¿å… API é™æµ
            if idx > 0:
                logger.info(f"[Workspace]    â³ ç­‰å¾… 2 ç§’é¿å… API é™æµ...")
                await asyncio.sleep(2)
            
            try:
                transcript_segments = await _run_asr(
                    file_url, 
                    update_progress,
                    base_progress,
                    int(progress_per_asset),  # step_progress: è¿™ä¸ªç´ æå çš„è¿›åº¦èŒƒå›´
                    asset_id=asset_id,
                    video_duration_sec=info['duration']  # â˜… ä¼ å…¥è§†é¢‘æ—¶é•¿
                )
                
                logger.info(f"[Workspace] âœ… ASR å®Œæˆç´ æ {idx + 1}, è¯†åˆ« {len(transcript_segments)} ä¸ªç‰‡æ®µ")
                
                # ASR å®Œæˆåæ£€æŸ¥å–æ¶ˆçŠ¶æ€
                _raise_if_cancelled(session_id, f"ç´ æ {idx + 1} ASR å")
                
                # ç»Ÿè®¡ breath ç‰‡æ®µæ•°é‡ï¼ˆæ³¨æ„ silence_info å¯èƒ½ä¸º Noneï¼‰
                breath_count = sum(1 for seg in transcript_segments if (seg.get("silence_info") or {}).get("classification") == "breath")
                speech_count = sum(1 for seg in transcript_segments if not seg.get("silence_info"))
                logger.info(f"[Workspace]    å…¶ä¸­: è¯­éŸ³ç‰‡æ®µ {speech_count} ä¸ª, æ¢æ°”ç‰‡æ®µ {breath_count} ä¸ª")
                
                total_segments += len(transcript_segments)
            except Exception as asr_err:
                logger.error(f"[Workspace] âŒ ASR è½¬å†™ç´ æ {idx + 1} å¤±è´¥: {asr_err}")
                import traceback
                traceback.print_exc()
            
            # åˆ›å»º clipsï¼ˆå¸¦æ—¶é—´è½´åç§»ï¼‰
            # æ³¨æ„ï¼šå¦‚æœ voice_extract_modeï¼Œä¼ å…¥ audio_track_id ä½œä¸º main_track_id
            # â˜… Voice Extract æ¨¡å¼ï¼šç¦ç”¨æ™ºèƒ½è¿é•œï¼ˆä¸éœ€è¦å…³é”®å¸§ï¼‰
            video_clips, subtitle_clips, keyframes = await _create_clips_from_segments_with_offset(
                project_id=project_id,
                asset_id=asset_id,
                transcript_segments=transcript_segments,
                video_track_id=main_track_id,  # ä¼ å…¥ä¸»è½¨é“ID (å¯èƒ½æ˜¯éŸ³é¢‘è½¨ID)
                text_track_id=text_track_id,
                timeline_offset=timeline_position,
                asset_index=idx,
                enable_llm=enable_llm,
                enable_smart_camera=not voice_extract_mode,  # â˜… Voice Extract ç¦ç”¨æ™ºèƒ½è¿é•œ
            )
            
            # â˜… å¦‚æœæ˜¯ Voice Extract æ¨¡å¼ï¼Œä¿®æ­£ clip_type ä¸º audio
            if voice_extract_mode and video_clips:
                for clip in video_clips:
                    clip["clip_type"] = "audio"
                    # ç§»é™¤ä¸å¿…è¦çš„è§†è§‰å±æ€§
                    if "transform" in clip:
                        del clip["transform"]
            
            all_video_clips.extend(video_clips)
            all_subtitle_clips.extend(subtitle_clips)
            all_keyframes.extend(keyframes)  # â˜… æ”¶é›†å…³é”®å¸§
            
            # è®¡ç®—å®é™…ç”¨åˆ°çš„æ—¶é•¿ï¼ˆæ’é™¤è·³è¿‡çš„é™éŸ³ï¼‰
            if video_clips:
                last_clip = max(video_clips, key=lambda c: c["end_time"])
                timeline_position = last_clip["end_time"]
            else:
                timeline_position += asset_duration_ms
            
            logger.info(f"[Workspace] âœ… ç´ æ {idx + 1} å¤„ç†å®Œæˆï¼Œæ—¶é—´è½´ä½ç½®: {timeline_position}ms")
        
        # Step 4: æ‰¹é‡æ’å…¥æ‰€æœ‰ clips (80% â†’ 95%)
        _raise_if_cancelled(session_id, "æ‰¹é‡æ’å…¥ clips å‰")
        update_progress("prepare", 85)
        
        if all_video_clips:
            supabase.table("clips").insert(all_video_clips).execute()
            logger.info(f"[Workspace] âœ… åˆ›å»º {len(all_video_clips)} ä¸ªè§†é¢‘ Clip")
        
        if all_subtitle_clips:
            supabase.table("clips").insert(all_subtitle_clips).execute()
            logger.info(f"[Workspace] âœ… åˆ›å»º {len(all_subtitle_clips)} ä¸ªå­—å¹• Clip")
        
        # â˜… æ‰¹é‡æ’å…¥å…³é”®å¸§åˆ° keyframes è¡¨ï¼ˆç»Ÿä¸€å­˜å‚¨ï¼‰
        if all_keyframes:
            supabase.table("keyframes").insert(all_keyframes).execute()
            logger.info(f"[Workspace] âœ… åˆ›å»º {len(all_keyframes)} ä¸ªå…³é”®å¸§")
        
        # ========================================
        # ğŸ¬ ç­‰å¾… HLS åå°ä»»åŠ¡å®Œæˆï¼ˆå¸¦è¶…æ—¶ï¼‰
        # ========================================
        update_progress("prepare", 90)
        
        if 'hls_task' in locals() and hls_task:
            logger.info(f"[Workspace] â³ ç­‰å¾… HLS ç”Ÿæˆä»»åŠ¡å®Œæˆï¼ˆæœ€å¤š 120 ç§’ï¼‰...")
            try:
                # è®¾ç½®è¶…æ—¶ï¼Œé¿å…æ— é™ç­‰å¾…
                await asyncio.wait_for(hls_task, timeout=120.0)
                logger.info(f"[Workspace] âœ… HLS ç”Ÿæˆä»»åŠ¡å®Œæˆ")
            except asyncio.TimeoutError:
                logger.warning(f"[Workspace] âš ï¸ HLS ä»»åŠ¡è¶…æ—¶ï¼ˆ120ç§’ï¼‰ï¼Œç»§ç»­å¤„ç†...")
                hls_task.cancel()
            except Exception as e:
                logger.warning(f"[Workspace] âš ï¸ HLS ä»»åŠ¡å¼‚å¸¸: {e}")
        
        update_progress("prepare", 95)
        
        # æ›´æ–°é¡¹ç›®
        fps = 30
        supabase.table("projects").update({
            "status": "ready",
            "resolution": {"width": max_width, "height": max_height},
            "fps": fps,
            "updated_at": now,
        }).eq("id", project_id).execute()
        
        # æ›´æ–°æ‰€æœ‰ç´ æçŠ¶æ€
        for info in asset_infos:
            supabase.table("assets").update({
                "status": "ready",
                "updated_at": now,
            }).eq("id", info["asset_id"]).execute()
        
        update_progress("prepare", 100)
        
        # æ ‡è®°ä¼šè¯å®Œæˆ
        supabase.table("workspace_sessions").update({
            "status": "completed",
            "progress": 100,
            "current_step": "completed",
            "transcript_segments": total_segments,
            "completed_at": now,
            "updated_at": now,
        }).eq("id", session_id).execute()
        
        logger.info(f"[Workspace] âœ… å¤šç´ æä¼šè¯ {session_id} å¤„ç†å®Œæˆï¼Œå…± {len(asset_infos)} ä¸ªç´ æ")
        
    except SessionCancelledException:
        # ç”¨æˆ·ä¸»åŠ¨å–æ¶ˆï¼Œä¸éœ€è¦æ›´æ–°çŠ¶æ€ï¼ˆå·²ç»æ˜¯ cancelledï¼‰
        logger.info(f"[Workspace] ğŸ›‘ å¤šç´ æä¼šè¯ {session_id} å¤„ç†å·²è¢«ç”¨æˆ·å–æ¶ˆ")
        # å–æ¶ˆæœªå®Œæˆçš„ HLS ä»»åŠ¡
        if 'hls_task' in locals() and hls_task and not hls_task.done():
            hls_task.cancel()
            logger.info(f"[Workspace] ğŸ›‘ å–æ¶ˆ HLS ä»»åŠ¡")
        return
    except Exception as e:
        logger.error(f"[Workspace] âŒ å¤šç´ æå¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        
        # å–æ¶ˆæœªå®Œæˆçš„ HLS ä»»åŠ¡
        if 'hls_task' in locals() and hls_task and not hls_task.done():
            hls_task.cancel()
            logger.info(f"[Workspace] ğŸ›‘ å–æ¶ˆ HLS ä»»åŠ¡")
        
        supabase.table("workspace_sessions").update({
            "status": "failed",
            "error_message": str(e),
            "updated_at": datetime.utcnow().isoformat(),
        }).eq("id", session_id).execute()
        
        supabase.table("projects").update({
            "status": "draft",
            "updated_at": datetime.utcnow().isoformat(),
        }).eq("id", project_id).execute()


async def _create_clips_from_segments_with_offset(
    project_id: str,
    asset_id: str,
    transcript_segments: list,
    video_track_id: str,
    text_track_id: str,
    timeline_offset: int = 0,
    asset_index: int = 0,
    enable_llm: bool = False,
    enable_smart_camera: bool = True,
    enable_subtitle: bool = True,
) -> tuple:
    """
    æ ¹æ® ASR segments åˆ›å»ºè§†é¢‘å’Œå­—å¹• clipsï¼ˆå¸¦æ—¶é—´è½´åç§»ï¼‰
    ç”¨äºå¤šç´ ææ‹¼æ¥åœºæ™¯
    
    Args:
        timeline_offset: åœ¨æ—¶é—´è½´ä¸Šçš„èµ·å§‹ä½ç½®ï¼ˆæ¯«ç§’ï¼‰
        asset_index: ç´ æç´¢å¼•ï¼Œç”¨äºå‘½å
        enable_llm: æ˜¯å¦å¯ç”¨ LLM è¯­ä¹‰åˆ†æ
        enable_smart_camera: æ˜¯å¦å¯ç”¨æ™ºèƒ½è¿é•œï¼ˆå¦‚æœä¸º Falseï¼Œåˆ™ä¸è¿›è¡Œè£å‰ª/ç¼©æ”¾ï¼‰
        enable_subtitle: æ˜¯å¦ç”Ÿæˆå­—å¹• clipsï¼ˆå¦‚æœä¸º Falseï¼Œåªç”Ÿæˆè§†é¢‘ clipsï¼‰
        
    Returns:
        tuple: (video_clips, subtitle_clips, keyframes)
        - keyframes: å¾…æ’å…¥ keyframes è¡¨çš„è®°å½•åˆ—è¡¨
    """
    logger.info(f"[Workspace] ======== åˆ‡ç‰‡å‡½æ•°å¼€å§‹ ========")
    logger.info(f"[Workspace] ğŸ¬ _create_clips_from_segments_with_offset")
    logger.info(f"[Workspace]    asset_id: {asset_id}")
    logger.info(f"[Workspace]    asset_index: {asset_index}")
    logger.info(f"[Workspace]    timeline_offset: {timeline_offset}ms")
    logger.info(f"[Workspace]    enable_smart_camera: {enable_smart_camera}")
    logger.info(f"[Workspace]    enable_subtitle: {enable_subtitle}")
    logger.info(f"[Workspace]    è¾“å…¥ segments æ•°é‡: {len(transcript_segments)}")
    
    # â˜… å…³é”®æ—¥å¿—ï¼šæ‰“å°å‰å‡ ä¸ª segments çš„å†…å®¹ï¼ŒéªŒè¯ ASR ç»“æœå’Œ asset å¯¹åº”
    if transcript_segments:
        for i, seg in enumerate(transcript_segments[:3]):
            seg_text = seg.get("text", "")[:30]
            logger.info(f"[Workspace]    segment[{i}]: start={seg.get('start')} text='{seg_text}...'")
    
    now = datetime.utcnow().isoformat()
    
    # æŒ‰æ—¶é—´é¡ºåºæ’åºåŸå§‹ segments
    sorted_segments = sorted(transcript_segments, key=lambda s: s.get("start", 0))
    
    video_clips = []
    subtitle_clips = []
    all_keyframes = []  # â˜… æ”¶é›†æ‰€æœ‰å…³é”®å¸§è®°å½•
    timeline_position = timeline_offset
    
    # ç»Ÿè®¡è‡ªåŠ¨è·³è¿‡çš„é™éŸ³ç‰‡æ®µ
    auto_skipped = {"dead_air": 0, "long_pause": 0, "hesitation": 0}
    
    # ========== ç¬¬ä¸€é˜¶æ®µï¼šæ”¶é›†æœ‰æ•ˆç‰‡æ®µ ==========
    valid_segments = []  # å­˜å‚¨ (seg_idx, seg, seg_duration, clip_name, is_breath, silence_info)
    
    for seg_idx, seg in enumerate(sorted_segments):
        seg_start = seg.get("start", 0)
        seg_end = seg.get("end", 0)
        seg_text = seg.get("text", "").strip()
        seg_duration = seg_end - seg_start
        
        if seg_duration <= 0:
            continue
        
        # æ£€æŸ¥é™éŸ³ä¿¡æ¯
        silence_info = seg.get("silence_info")
        
        if silence_info:
            cls = silence_info.get("classification")
            if cls in ("dead_air", "long_pause", "hesitation"):
                logger.info(f"[Workspace]   âš ï¸ è·³è¿‡ segment[{seg_idx}]: type={cls} start={seg_start} end={seg_end}")
                auto_skipped[cls] = auto_skipped.get(cls, 0) + 1
                continue
        
        # ç¡®å®šç‰‡æ®µç±»å‹
        clip_name = f"ç´ æ{asset_index + 1}-ç‰‡æ®µ{seg_idx + 1}"
        is_breath = False
        if silence_info and silence_info.get("classification") == "breath":
            clip_name = f"ç´ æ{asset_index + 1}-æ¢æ°”"
            is_breath = True
        
        valid_segments.append((seg_idx, seg, seg_duration, clip_name, is_breath, silence_info))
    
    # ========== ç¬¬äºŒé˜¶æ®µï¼šLLM è¯­ä¹‰åˆ†æï¼ˆå¯é€‰ï¼‰==========
    llm_results = {}
    if enable_llm and valid_segments:
        from ..services.llm_service import analyze_segments_batch, is_llm_configured
        
        if is_llm_configured():
            logger.info(f"[Workspace] ğŸ¤– å¼€å§‹ LLM è¯­ä¹‰åˆ†æ...")
            # æ„å»ºå¾…åˆ†æçš„æ–‡æœ¬ç‰‡æ®µ
            text_segments = []
            for seg_idx, seg, seg_duration, clip_name, is_breath, silence_info in valid_segments:
                seg_text = seg.get("text", "").strip()
                if seg_text and not is_breath:
                    text_segments.append({"id": str(seg_idx), "text": seg_text})
            
            if text_segments:
                try:
                    llm_results = await analyze_segments_batch(text_segments)
                    logger.info(f"[Workspace] âœ… LLM åˆ†æå®Œæˆ: {len(llm_results)} æ¡ç»“æœ")
                except Exception as e:
                    logger.warning(f"[Workspace] âš ï¸ LLM åˆ†æå¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            else:
                logger.info(f"[Workspace]    æ— æ–‡æœ¬ç‰‡æ®µéœ€è¦åˆ†æ")
        else:
            logger.info(f"[Workspace] âš ï¸ LLM API æœªé…ç½®ï¼Œè·³è¿‡è¯­ä¹‰åˆ†æ")
    
    # ========== ç¬¬ä¸‰é˜¶æ®µï¼šæ‰¹é‡ç”Ÿæˆ transformï¼ˆå«åºåˆ—åå¤„ç†ï¼‰==========
    # é‡ç½®åºåˆ—å¤„ç†å™¨çŠ¶æ€
    sequence_processor.reset()
    
    # å£æ’­æ¨¡å¼é»˜è®¤äººè„¸ä½ç½®ï¼ˆä¸å•ç´ ææµç¨‹ä¸€è‡´ï¼‰
    DEFAULT_FACE_CENTER_X = 0.5   # å±…ä¸­
    DEFAULT_FACE_CENTER_Y = 0.35  # ç¨å¾®åä¸Šï¼ˆå£æ’­å¸¸è§æ„å›¾ï¼‰
    
    # æ„å»ºä¸Šä¸‹æ–‡åˆ—è¡¨
    contexts = []
    for seg_idx, seg, seg_duration, clip_name, is_breath, silence_info in valid_segments:
        seg_text = seg.get("text", "").strip()
        
        # ä» LLM ç»“æœè·å–æƒ…ç»ªå’Œé‡è¦æ€§ï¼Œæˆ–ä½¿ç”¨é»˜è®¤å€¼
        seg_id_str = str(seg_idx)
        llm_data = llm_results.get(seg_id_str, {})
        emotion_str = llm_data.get("emotion", "neutral")
        importance_str = llm_data.get("importance", "medium")
        
        try:
            emotion = EmotionType(emotion_str)
        except ValueError:
            emotion = EmotionType.NEUTRAL
        try:
            importance = ImportanceLevel(importance_str)
        except ValueError:
            importance = ImportanceLevel.MEDIUM
        
        context = SegmentContext(
            segment_id=seg_id_str,
            duration_ms=seg_duration,
            text=seg_text,
            # å£æ’­æ¨¡å¼ï¼šé»˜è®¤æœ‰äººè„¸ï¼Œå±…ä¸­åä¸Šï¼ˆä¸å•ç´ ææµç¨‹ä¸€è‡´ï¼‰
            has_face=True,
            face_center_x=DEFAULT_FACE_CENTER_X,
            face_center_y=DEFAULT_FACE_CENTER_Y,
            # ä½¿ç”¨ LLM åˆ†æç»“æœæˆ–é»˜è®¤å€¼
            emotion=emotion,
            importance=importance,
            is_breath=is_breath,
        )
        contexts.append(context)
    
    logger.info(f"[Workspace] ğŸ¥ enable_smart_camera={enable_smart_camera}, å¾…å¤„ç† {len(contexts)} ä¸ªç‰‡æ®µ")
    
    # ä½¿ç”¨è§„åˆ™å¼•æ“æ‰¹é‡å¤„ç†
    if enable_smart_camera:
        params_list = [transform_engine.process(ctx) for ctx in contexts]
        
        # åºåˆ—æ„ŸçŸ¥åå¤„ç†ï¼šç¡®ä¿è¿é•œå¤šæ ·æ€§ï¼ˆä¸å•ç´ ææµç¨‹ä¸€è‡´ï¼‰
        params_contexts = list(zip(params_list, contexts))
        processed_params = sequence_processor.process_batch(params_contexts)
    else:
        # ç¦ç”¨æ™ºèƒ½è¿é•œï¼Œç”Ÿæˆé»˜è®¤é™æ€å‚æ•°
        processed_params = [
            TransformParams(strategy=ZoomStrategy.STATIC, rule_applied="disabled_by_user")
            for _ in contexts
        ]
    
    # ========== ç¬¬ä¸‰é˜¶æ®µï¼šæ„å»º clips ==========
    for i, (seg_idx, seg, seg_duration, clip_name, is_breath, silence_info) in enumerate(valid_segments):
        seg_start = seg.get("start", 0)
        seg_end = seg.get("end", 0)
        seg_text = seg.get("text", "").strip()
        
        video_clip_id = str(uuid4())
        
        # è·å–æ‰¹å¤„ç†åçš„ transform
        transform_params = processed_params[i]
        
        # â˜… æ–° APIï¼šç›´æ¥è·å–å…ƒä¿¡æ¯å’Œå…³é”®å¸§
        transform_meta = transform_params.get_meta()
        clip_keyframes = transform_params.get_keyframes_for_db(video_clip_id, seg_duration)
        
        logger.info(f"[Workspace]   âœ… åˆ›å»º clip[{seg_idx}]: name='{clip_name}' timeline={timeline_position}~{timeline_position + seg_duration} source={seg_start}~{seg_end} rule={transform_meta.get('_rule_applied', 'none')}")
        
        video_clips.append({
            "id": video_clip_id,
            "track_id": video_track_id,
            "asset_id": asset_id,
            "clip_type": "video",
            "start_time": timeline_position,
            "end_time": timeline_position + seg_duration,
            "source_start": seg_start,
            "source_end": seg_end,
            "is_muted": False,
            "name": clip_name,
            "transform": transform_meta,  # åªå­˜å…ƒä¿¡æ¯
            "created_at": now,
            "updated_at": now,
            "metadata": {
                "silence_info": silence_info,
                "original_text": seg_text,
                "asset_index": asset_index,
            }
        })
        
        # æ”¶é›†å…³é”®å¸§ï¼ˆç»Ÿä¸€å­˜å‚¨åˆ° keyframes è¡¨ï¼‰
        all_keyframes.extend(clip_keyframes)
        
        # åˆ›å»ºå­—å¹• clipsï¼ˆä»…å½“ enable_subtitle=True æ—¶ï¼‰
        if seg_text and enable_subtitle:
            fine_subs = _split_segments_by_punctuation([seg])
            
            for sub_idx, sub_seg in enumerate(fine_subs):
                sub_start = sub_seg.get("start", seg_start)
                sub_end = sub_seg.get("end", seg_end)
                sub_text = sub_seg.get("text", "").strip()
                sub_duration = sub_end - sub_start
                
                if sub_duration <= 0 or not sub_text:
                    continue
                
                subtitle_timeline_start = timeline_position + (sub_start - seg_start)
                
                subtitle_clips.append({
                    "id": str(uuid4()),
                    "track_id": text_track_id,
                    "clip_type": "subtitle",
                    "parent_clip_id": video_clip_id,
                    "start_time": subtitle_timeline_start,
                    "end_time": subtitle_timeline_start + sub_duration,
                    "source_start": 0,
                    "source_end": sub_duration,
                    "is_muted": False,
                    "content_text": sub_text,
                    "text_style": {
                        "fontSize": 15,
                        "fontColor": "#FFFFFF",
                        "backgroundColor": "transparent",
                        "alignment": "center",
                        "maxWidth": "95%",
                    },
                    "transform": {
                        "x": 0,
                        "y": 150,
                        "scale": 1,
                    },
                    "metadata": {
                        "segment_id": seg.get("id"),
                        "asset_index": asset_index,
                        "order_index": seg_idx * 100 + sub_idx,
                        "original_start": sub_start,
                        "original_end": sub_end,
                    },
                    "created_at": now,
                    "updated_at": now,
                })
        
        timeline_position += seg_duration
    
    logger.info(f"[Workspace] ======== åˆ‡ç‰‡å‡½æ•°ç»“æŸ ========")
    logger.info(f"[Workspace] ğŸ“Š ç´ æ {asset_index + 1} ç»Ÿè®¡:")
    logger.info(f"[Workspace]    è¾“å…¥ segments: {len(sorted_segments)}")
    logger.info(f"[Workspace]    åˆ›å»ºè§†é¢‘ clips: {len(video_clips)}")
    logger.info(f"[Workspace]    åˆ›å»ºå­—å¹• clips: {len(subtitle_clips)}")
    logger.info(f"[Workspace]    æå–å…³é”®å¸§æ•°: {len(all_keyframes)}")
    logger.info(f"[Workspace]    è·³è¿‡é™éŸ³: {auto_skipped}")
    logger.info(f"[Workspace]    æœ€ç»ˆ timeline ä½ç½®: {timeline_position}ms")
    
    return video_clips, subtitle_clips, all_keyframes
