"""
HoppingRabbit AI - å·¥ä½œå° API
å¤„ç†ä»ä¸Šä¼ åˆ°è¿›å…¥ç¼–è¾‘å™¨çš„å®Œæ•´æµç¨‹
é€‚é…æ–°è¡¨ç»“æ„ (2026-01-07)
"""
import logging
from fastapi import APIRouter, HTTPException, BackgroundTasks, Depends
from pydantic import BaseModel
from typing import Optional, Literal, List
from datetime import datetime
from uuid import uuid4
from enum import Enum

from ..services.supabase_client import supabase, get_file_url, create_signed_upload_url
from ..services.transform_rules import SegmentContext, transform_engine, sequence_processor, EmotionType, ImportanceLevel, TransformParams, ZoomStrategy
from .auth import get_current_user

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/workspace", tags=["Workspace"])


# ============================================
# æ•°æ®æ¨¡å‹
# ============================================

class TaskType(str, Enum):
    AI_CLIPS = "clips"      # AI æ™ºèƒ½åˆ‡ç‰‡
    SUMMARY = "summary"     # å†…å®¹æ€»ç»“
    AI_CREATE = "ai-create" # â˜… ä¸€é”®æˆç‰‡
    VOICE_EXTRACT = "voice-extract" # â˜… ä»…æå–å­—å¹•/éŸ³é¢‘


class SourceType(str, Enum):
    LOCAL = "local"         # æœ¬åœ°ä¸Šä¼ 
    YOUTUBE = "youtube"     # YouTube é“¾æ¥
    URL = "url"             # å…¶ä»– URL


# â˜… ProcessingStepsConfig å·²åˆ é™¤
# ä¸€é”®æˆç‰‡ç”± task_type == 'ai-create' å†³å®šï¼ŒASR é»˜è®¤å¼€å¯


class FileInfo(BaseModel):
    """å•ä¸ªæ–‡ä»¶ä¿¡æ¯ï¼ˆå¤šæ–‡ä»¶ä¸Šä¼ ï¼‰"""
    name: str
    size: int
    content_type: str
    duration: Optional[float] = None  # è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
    order_index: int = 0


class CreateSessionRequest(BaseModel):
    """åˆ›å»ºå¤„ç†ä¼šè¯è¯·æ±‚"""
    source_type: SourceType
    task_type: TaskType = TaskType.AI_CLIPS
    
    # === å•æ–‡ä»¶ä¸Šä¼ ï¼ˆå‘åå…¼å®¹ï¼‰===
    file_name: Optional[str] = None
    file_size: Optional[int] = None
    content_type: Optional[str] = None
    duration: Optional[float] = None  # è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œå‰ç«¯æœ¬åœ°æå–
    
    # === å¤šæ–‡ä»¶ä¸Šä¼ ï¼ˆæ–°å¢ï¼‰===
    files: Optional[List[FileInfo]] = None  # å¤šä¸ªæ–‡ä»¶ä¿¡æ¯
    
    # é“¾æ¥è§£æç›¸å…³
    source_url: Optional[str] = None
    # â˜… processing_steps å·²åˆ é™¤ï¼Œç”± task_type å†³å®šå¤„ç†æµç¨‹


class AssetUploadInfo(BaseModel):
    """å•ä¸ªèµ„æºçš„ä¸Šä¼ ä¿¡æ¯"""
    asset_id: str
    upload_url: str
    storage_path: str
    order_index: int  # ä¿æŒä¸å‰ç«¯ä¸€è‡´
    file_name: str


class CreateSessionResponse(BaseModel):
    """åˆ›å»ºä¼šè¯å“åº”"""
    session_id: str
    project_id: str
    # â˜… ç»Ÿä¸€ç”¨ assets æ•°ç»„ï¼ˆå³ä½¿å•æ–‡ä»¶ä¹Ÿæ˜¯ä¸€ä¸ªå…ƒç´ çš„æ•°ç»„ï¼‰
    assets: Optional[List[AssetUploadInfo]] = None


class SessionStatus(BaseModel):
    """ä¼šè¯çŠ¶æ€"""
    session_id: str
    project_id: str
    status: Literal["uploading", "processing", "completed", "failed", "cancelled", "expired"]
    current_step: Optional[str] = None
    progress: int = 0
    steps: List[dict] = []  # å¤„ç†æ­¥éª¤åˆ—è¡¨
    error: Optional[str] = None
    transcript_segments: Optional[int] = None
    marked_clips: Optional[int] = None
    
    # === å¤šæ–‡ä»¶ä¸Šä¼ è¿›åº¦ï¼ˆæ–°å¢ï¼‰===
    upload_progress: Optional[dict] = None  # {total_files, completed_files, ...}


# â˜… æ­¥éª¤å®šä¹‰å·²ç§»è‡³å‰ç«¯ ProcessingView.tsx
# åç«¯åªè¿”å› current_stepï¼Œå‰ç«¯æœ¬åœ°ç”Ÿæˆæ­¥éª¤åˆ—è¡¨
# è¿™æ ·é¿å…å‰åç«¯ç»´æŠ¤ä¸¤å¥—é‡å¤çš„æ­¥éª¤å®šä¹‰


def _get_file_type(content_type: str) -> str:
    """æ ¹æ® MIME ç±»å‹åˆ¤æ–­æ–‡ä»¶ç±»å‹"""
    if not content_type:
        return "video"
    if content_type.startswith("video/"):
        return "video"
    elif content_type.startswith("audio/"):
        return "audio"
    elif content_type.startswith("image/"):
        return "image"
    else:
        return "video"


# ============================================
# API ç«¯ç‚¹
# ============================================

@router.post("/sessions", response_model=CreateSessionResponse)
async def create_session(
    request: CreateSessionRequest,
    current_user: dict = Depends(get_current_user)
):
    """
    åˆ›å»ºå¤„ç†ä¼šè¯ (æ­¥éª¤1: ä»…ä¸Šä¼ ï¼Œä¸æ‰£ç§¯åˆ†)
    
    â˜… æ¸è¿›å¼ä¸¤æ­¥æµç¨‹:
    1. create_session - åˆ›å»ºä¼šè¯ + ä¸Šä¼ è§†é¢‘ (æœ¬æ¥å£ï¼Œä¸æ‰£ç§¯åˆ†)
    2. start-ai-processing - ç”¨æˆ·ç¡®è®¤é…ç½®åå¯åŠ¨ AI å¤„ç† (æ‰£ç§¯åˆ†)
    """
    try:
        user_id = current_user["user_id"]
        
        # â˜… ç§»é™¤ç§¯åˆ†æ£€æŸ¥ï¼ç§¯åˆ†æ£€æŸ¥ç§»åˆ° start-ai-processing æ¥å£
        # è¿™æ ·ç”¨æˆ·å¯ä»¥å…ˆä¸Šä¼ è§†é¢‘ï¼Œå†å†³å®šæ˜¯å¦ä½¿ç”¨ AI åŠŸèƒ½
        
        session_id = str(uuid4())
        project_id = str(uuid4())
        now = datetime.utcnow().isoformat()
        
        logger.info(f"[Session] å¼€å§‹åˆ›å»ºä¼šè¯, user_id={user_id}, source_type={request.source_type.value}")
        
        # 1. åˆ›å»ºé¡¹ç›®
        project_name = _generate_project_name(request)
        project_data = {
            "id": project_id,
            "user_id": user_id,
            "name": project_name,
            "status": "processing",
            "resolution": {"width": 1920, "height": 1080},
            "fps": 30,
            "created_at": now,
            "updated_at": now,
        }
        supabase.table("projects").insert(project_data).execute()
        logger.info(f"[Session] âœ… åˆ›å»ºé¡¹ç›®æˆåŠŸ, project_id={project_id}, name={project_name}")
        
        # 2. åˆ›å»ºä¼šè¯è®°å½•
        session_data = {
            "id": session_id,
            "user_id": user_id,
            "project_id": project_id,
            "status": "uploading",
            "upload_source": request.source_type.value,
            "source_url": request.source_url,
            "selected_tasks": [request.task_type.value],
            "progress": 0,
            "created_at": now,
            "updated_at": now,
        }
        supabase.table("workspace_sessions").insert(session_data).execute()
        logger.info(f"[Session] âœ… åˆ›å»ºä¼šè¯æˆåŠŸ, session_id={session_id}, task_type={request.task_type.value}")
        
        response = CreateSessionResponse(
            session_id=session_id,
            project_id=project_id,
        )
        
        # 3. æ ¹æ®æ¥æºç±»å‹å¤„ç†
        if request.source_type == SourceType.LOCAL:
            # === åˆ¤æ–­æ˜¯å¤šæ–‡ä»¶è¿˜æ˜¯å•æ–‡ä»¶ä¸Šä¼  ===
            logger.info(f"[Session] ğŸ“‚ æ£€æŸ¥ä¸Šä¼ æ¨¡å¼:")
            logger.info(f"[Session]    request.files: {request.files}")
            logger.info(f"[Session]    request.file_name: {request.file_name}")
            logger.info(f"[Session]    files æ˜¯å¦æœ‰å€¼: {bool(request.files)}")
            logger.info(f"[Session]    files é•¿åº¦: {len(request.files) if request.files else 0}")
            
            if request.files and len(request.files) > 0:
                logger.info(f"[Session] âœ… è¿›å…¥å¤šæ–‡ä»¶ä¸Šä¼ æ¨¡å¼")
                # â˜… å¤šæ–‡ä»¶ä¸Šä¼ æ¨¡å¼
                assets_info = []
                asset_ids = []
                total_bytes = sum(f.size for f in request.files)
                
                for file_info in request.files:
                    asset_id = str(uuid4())
                    asset_ids.append(asset_id)
                    file_ext = file_info.name.split(".")[-1] if "." in file_info.name else "mp4"
                    storage_path = f"uploads/{project_id}/{asset_id}.{file_ext}"
                    
                    # ç”Ÿæˆé¢„ç­¾åä¸Šä¼  URLï¼ˆå¯ç”¨ upsert é¿å…é‡è¯•å¤±è´¥ï¼‰
                    presign_result = create_signed_upload_url("clips", storage_path, upsert=True)
                    upload_url = presign_result.get("signedURL") or presign_result.get("signed_url", "")
                    
                    # åˆ›å»º asset è®°å½•
                    asset_data = {
                        "id": asset_id,
                        "project_id": project_id,
                        "user_id": user_id,
                        "name": file_info.name,
                        "original_filename": file_info.name,
                        "file_type": _get_file_type(file_info.content_type),
                        "mime_type": file_info.content_type or "video/mp4",
                        "file_size": file_info.size,
                        "storage_path": storage_path,
                        "duration": file_info.duration,
                        "status": "uploading",  # ç­‰å¾…ä¸Šä¼ ï¼ˆçº¦æŸåªå…è®¸ uploading/processing/ready/errorï¼‰
                        "order_index": file_info.order_index,  # ç´ æé¡ºåº
                        "upload_progress": {
                            "bytes_uploaded": 0,
                            "total_bytes": file_info.size,
                            "percentage": 0,
                        },
                        "created_at": now,
                        "updated_at": now,
                    }
                    supabase.table("assets").insert(asset_data).execute()
                    
                    assets_info.append(AssetUploadInfo(
                        asset_id=asset_id,
                        upload_url=upload_url,
                        storage_path=storage_path,
                        order_index=file_info.order_index,
                        file_name=file_info.name,
                    ))
                
                # æ›´æ–°ä¼šè¯è®°å½•
                supabase.table("workspace_sessions").update({
                    "uploaded_asset_ids": asset_ids,  # JSON æ•°ç»„
                    "upload_progress": {
                        "total_files": len(request.files),
                        "completed_files": 0,
                        "failed_files": 0,
                        "pending_files": len(request.files),
                        "total_bytes": total_bytes,
                        "uploaded_bytes": 0,
                    },
                    "status": "uploading",
                }).eq("id", session_id).execute()
                
                response.assets = assets_info
                logger.info(f"[Session] âœ… å¤šæ–‡ä»¶ä¸Šä¼ æ¨¡å¼ï¼Œåˆ›å»º {len(assets_info)} ä¸ªèµ„æº")
                logger.info(f"[Session]    response.assets æ•°é‡: {len(response.assets)}")
                for i, a in enumerate(response.assets):
                    logger.info(f"[Session]    asset[{i}]: {a.asset_id}, order={a.order_index}")
                
            else:
                # â˜… å•æ–‡ä»¶ä¸Šä¼ æ¨¡å¼ï¼ˆå‘åå…¼å®¹ï¼‰
                asset_id = str(uuid4())
                file_ext = request.file_name.split(".")[-1] if request.file_name and "." in request.file_name else "mp4"
                storage_path = f"uploads/{project_id}/{asset_id}.{file_ext}"
                
                logger.info(f"[Session] æ­£åœ¨ç”Ÿæˆé¢„ç­¾åä¸Šä¼ URL, storage_path={storage_path}")
                logger.debug(f"[Session] æ”¶åˆ°çš„ duration: {request.duration}")
                presign_result = create_signed_upload_url("clips", storage_path, upsert=True)
                upload_url = presign_result.get("signedURL") or presign_result.get("signed_url", "")
                logger.info(f"[Session] âœ… é¢„ç­¾åURLç”ŸæˆæˆåŠŸ, url_length={len(upload_url)}")
                
                asset_data = {
                    "id": asset_id,
                    "project_id": project_id,
                    "user_id": user_id,
                    "name": request.file_name or "æœªå‘½å",
                    "original_filename": request.file_name,
                    "file_type": _get_file_type(request.content_type),
                    "mime_type": request.content_type or "video/mp4",
                    "file_size": request.file_size,
                    "storage_path": storage_path,
                    "duration": request.duration,
                    "status": "uploading",
                    "order_index": 0,
                    "created_at": now,
                    "updated_at": now,
                }
                supabase.table("assets").insert(asset_data).execute()
                logger.info(f"[Session] âœ… åˆ›å»ºèµ„æºæˆåŠŸ, asset_id={asset_id}, file_name={request.file_name}")
                
                supabase.table("workspace_sessions").update({
                    "uploaded_asset_id": asset_id,
                    "uploaded_asset_ids": [asset_id],  # åŒæ—¶æ›´æ–°æ•°ç»„å­—æ®µ
                    "status": "uploading",
                }).eq("id", session_id).execute()
                logger.info(f"[Session] âœ… æ›´æ–°ä¼šè¯å…³è”èµ„æºæˆåŠŸ")
                
                # â˜… å•æ–‡ä»¶ä¹Ÿç»Ÿä¸€æ”¾å…¥ assets æ•°ç»„
                response.assets = [AssetUploadInfo(
                    asset_id=asset_id,
                    upload_url=upload_url,
                    storage_path=storage_path,
                    order_index=0,
                    file_name=request.file_name,
                )]
            
        elif request.source_type in (SourceType.YOUTUBE, SourceType.URL):
            supabase.table("workspace_sessions").update({
                "status": "processing",
                "current_step": "fetch",
            }).eq("id", session_id).execute()
            logger.info(f"[Session] âœ… URLç±»å‹ä¼šè¯å¼€å§‹å¤„ç†, source_url={request.source_url}")
        
        logger.info(f"[Session] âœ… ä¼šè¯åˆ›å»ºå®Œæˆ, session_id={session_id}, project_id={project_id}")
        return response
        
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        logger.error(f"[Session] âŒ åˆ›å»ºä¼šè¯å¤±è´¥: {e}")
        logger.error(f"[Session] âŒ å®Œæ•´å †æ ˆ:\n{traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/sessions/{session_id}/asset/{asset_id}/uploaded")
async def notify_asset_uploaded(session_id: str, asset_id: str):
    """
    é€šçŸ¥å•ä¸ªæ–‡ä»¶ä¸Šä¼ å®Œæˆï¼ˆå¤šæ–‡ä»¶ä¸Šä¼ æ¨¡å¼ï¼‰
    å‰ç«¯æ¯ä¸Šä¼ å®Œä¸€ä¸ªæ–‡ä»¶å°±è°ƒç”¨ä¸€æ¬¡
    """
    logger.info(f"[Upload] ğŸ“¤ æ”¶åˆ°èµ„æºä¸Šä¼ å®Œæˆé€šçŸ¥: session={session_id}, asset={asset_id}")
    try:
        now = datetime.utcnow().isoformat()
        
        # æ›´æ–°è¯¥ asset çŠ¶æ€
        logger.info(f"[Upload]    æ›´æ–° asset {asset_id} çŠ¶æ€ä¸º uploaded")
        supabase.table("assets").update({
            "status": "uploaded",
            "upload_progress": {
                "percentage": 100,
                "completed": True,
            },
            "updated_at": now,
        }).eq("id", asset_id).execute()
        
        # è·å– session ä¿¡æ¯
        session = supabase.table("workspace_sessions").select("*").eq("id", session_id).single().execute()
        if not session.data:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
        
        session_data = session.data
        asset_ids = session_data.get("uploaded_asset_ids", [])
        
        # ç»Ÿè®¡ä¸Šä¼ è¿›åº¦
        assets_result = supabase.table("assets").select("id, status, file_size").in_("id", asset_ids).execute()
        assets = assets_result.data or []
        
        completed = sum(1 for a in assets if a.get("status") == "uploaded")
        failed = sum(1 for a in assets if a.get("status") == "error")
        pending = len(assets) - completed - failed
        uploaded_bytes = sum(a.get("file_size", 0) for a in assets if a.get("status") == "uploaded")
        total_bytes = sum(a.get("file_size", 0) for a in assets)
        
        # æ›´æ–° session è¿›åº¦
        supabase.table("workspace_sessions").update({
            "upload_progress": {
                "total_files": len(assets),
                "completed_files": completed,
                "failed_files": failed,
                "pending_files": pending,
                "total_bytes": total_bytes,
                "uploaded_bytes": uploaded_bytes,
            },
            "updated_at": now,
        }).eq("id", session_id).execute()
        
        logger.info(f"[Session] ğŸ“¤ Asset {asset_id} ä¸Šä¼ å®Œæˆ, è¿›åº¦: {completed}/{len(assets)}")
        
        return {
            "status": "ok",
            "progress": {
                "completed": completed,
                "total": len(assets),
                "all_completed": completed == len(assets),
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[Session] âŒ é€šçŸ¥ä¸Šä¼ å®Œæˆå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# â˜… ä¸Šä¼ å®Œæˆååˆ›å»ºåŸºç¡€é¡¹ç›®ç»“æ„ (æ–°å¢)
# ============================================

class FinalizeUploadResponse(BaseModel):
    """å®Œæˆä¸Šä¼ å“åº”"""
    status: str
    project_id: str
    tracks: list  # åˆ›å»ºçš„è½¨é“ä¿¡æ¯
    clips: list   # åˆ›å»ºçš„ clip ä¿¡æ¯
    message: str


@router.post("/sessions/{session_id}/finalize-upload", response_model=FinalizeUploadResponse)
async def finalize_upload(
    session_id: str,
    current_user: dict = Depends(get_current_user)
):
    """
    å®Œæˆä¸Šä¼ ï¼Œåˆ›å»ºåŸºç¡€é¡¹ç›®ç»“æ„ (track + video clip)
    
    â˜… æ¸è¿›å¼æµç¨‹çš„å…³é”®æ­¥éª¤:
    1. ç”¨æˆ·ä¸Šä¼ è§†é¢‘åè°ƒç”¨æ­¤æ¥å£
    2. åˆ›å»ºåŸºç¡€çš„è§†é¢‘è½¨é“å’Œå­—å¹•è½¨é“
    3. å°†ä¸Šä¼ çš„è§†é¢‘æ”¾åˆ°æ—¶é—´è½´ä¸Šï¼ˆåˆ›å»º video clipï¼‰
    4. æ­¤æ—¶ç”¨æˆ·å¯ä»¥åœ¨ç¼–è¾‘å™¨ä¸­é¢„è§ˆå’Œç¼–è¾‘
    5. åç»­ AI å¤„ç†æ˜¯å¯é€‰çš„å¢å€¼åŠŸèƒ½
    """
    try:
        user_id = current_user["user_id"]
        now = datetime.utcnow().isoformat()
        
        # 1. è·å–ä¼šè¯ä¿¡æ¯
        session = supabase.table("workspace_sessions").select("*").eq("id", session_id).single().execute()
        if not session.data:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
        
        session_data = session.data
        project_id = session_data.get("project_id")
        
        # æ ¡éªŒä¼šè¯å½’å±
        if session_data.get("user_id") != user_id:
            raise HTTPException(status_code=403, detail="æ— æƒæ“ä½œæ­¤ä¼šè¯")
        
        # 2. è·å–æ‰€æœ‰å…³è”çš„ assets
        asset_ids = session_data.get("uploaded_asset_ids", [])
        if not asset_ids:
            single_asset_id = session_data.get("uploaded_asset_id")
            if single_asset_id:
                asset_ids = [single_asset_id]
        
        if not asset_ids:
            raise HTTPException(status_code=400, detail="ä¼šè¯æœªå…³è”ä»»ä½•èµ„æº")
        
        # æ£€æŸ¥æ‰€æœ‰æ–‡ä»¶æ˜¯å¦éƒ½ä¸Šä¼ å®Œæˆ
        assets_result = supabase.table("assets").select("*").in_("id", asset_ids).execute()
        assets = assets_result.data or []
        
        not_ready = [a for a in assets if a.get("status") not in ("uploaded", "ready")]
        if not_ready:
            pending_names = [a.get("name", a["id"]) for a in not_ready[:3]]
            raise HTTPException(
                status_code=400, 
                detail=f"éƒ¨åˆ†æ–‡ä»¶æœªä¸Šä¼ å®Œæˆ: {', '.join(pending_names)}"
            )
        
        # 3. æ£€æŸ¥æ˜¯å¦å·²åˆ›å»ºè¿‡ trackï¼ˆé¿å…é‡å¤åˆ›å»ºï¼‰
        existing_tracks = supabase.table("tracks").select("id").eq("project_id", project_id).execute()
        if existing_tracks.data and len(existing_tracks.data) > 0:
            logger.info(f"[Finalize] âš ï¸ é¡¹ç›® {project_id} å·²å­˜åœ¨è½¨é“ï¼Œè·³è¿‡åˆ›å»º")
            return FinalizeUploadResponse(
                status="ok",
                project_id=project_id,
                tracks=[{"id": t["id"]} for t in existing_tracks.data],
                clips=[],
                message="é¡¹ç›®ç»“æ„å·²å­˜åœ¨",
            )
        
        # 4. åˆ›å»ºåŸºç¡€è½¨é“
        video_track_id = str(uuid4())
        text_track_id = str(uuid4())
        
        # è§†é¢‘è½¨é“
        supabase.table("tracks").insert({
            "id": video_track_id,
            "project_id": project_id,
            "name": "è§†é¢‘è½¨é“",
            "order_index": 0,
            "is_muted": False,
            "is_locked": False,
            "is_visible": True,
            "created_at": now,
            "updated_at": now,
        }).execute()
        
        # å­—å¹•è½¨é“
        supabase.table("tracks").insert({
            "id": text_track_id,
            "project_id": project_id,
            "name": "å­—å¹•è½¨é“",
            "order_index": 1,
            "is_muted": False,
            "is_locked": False,
            "is_visible": True,
            "created_at": now,
            "updated_at": now,
        }).execute()
        
        logger.info(f"[Finalize] âœ… åˆ›å»ºåŸºç¡€è½¨é“: video={video_track_id}, text={text_track_id}")
        
        # 5. æŒ‰é¡ºåºæ’åˆ— assets å¹¶åˆ›å»º video clips
        sorted_assets = sorted(assets, key=lambda a: a.get("order_index", 0))
        
        created_clips = []
        timeline_position = 0  # æ—¶é—´è½´ä½ç½®ï¼ˆæ¯«ç§’ï¼‰
        
        for asset in sorted_assets:
            asset_id = asset["id"]
            duration_sec = asset.get("duration") or 0
            duration_ms = int(duration_sec * 1000)
            
            # å¦‚æœæ²¡æœ‰æ—¶é•¿ä¿¡æ¯ï¼Œä½¿ç”¨é»˜è®¤å€¼ï¼ˆåç»­å¯ä»¥é€šè¿‡ ffprobe è·å–ï¼‰
            if duration_ms <= 0:
                duration_ms = 10000  # é»˜è®¤ 10 ç§’
                logger.warning(f"[Finalize] âš ï¸ Asset {asset_id} æ— æ—¶é•¿ä¿¡æ¯ï¼Œä½¿ç”¨é»˜è®¤ 10s")
            
            clip_id = str(uuid4())
            
            # åˆ›å»º video clip
            clip_data = {
                "id": clip_id,
                "track_id": video_track_id,
                "asset_id": asset_id,
                "clip_type": "video",
                "name": asset.get("name", "è§†é¢‘"),
                "start_time": timeline_position,
                "end_time": timeline_position + duration_ms,
                "source_start": 0,
                "source_end": duration_ms,
                "volume": 1.0,
                "is_muted": False,
                "transform": {
                    "x": 0, "y": 0,
                    "scaleX": 1, "scaleY": 1,
                    "rotation": 0,
                    "opacity": 1,
                },
                "speed": 1.0,
                "created_at": now,
                "updated_at": now,
            }
            
            supabase.table("clips").insert(clip_data).execute()
            
            created_clips.append({
                "id": clip_id,
                "asset_id": asset_id,
                "start_time": timeline_position,
                "end_time": timeline_position + duration_ms,
            })
            
            logger.info(f"[Finalize] âœ… åˆ›å»º clip: {clip_id}, asset={asset_id}, duration={duration_ms}ms")
            
            # æ›´æ–°æ—¶é—´è½´ä½ç½®ï¼ˆä¸‹ä¸€ä¸ª clip ç´§è·Ÿç€ï¼‰
            timeline_position += duration_ms
        
        # 6. æ›´æ–°æ‰€æœ‰ assets çŠ¶æ€ä¸º ready
        for asset in assets:
            supabase.table("assets").update({
                "status": "ready",
                "updated_at": now,
            }).eq("id", asset["id"]).execute()
        
        # 7. æ›´æ–°é¡¹ç›®çŠ¶æ€ä¸º ready (æ•°æ®åº“çº¦æŸ: draft/processing/ready/exported/archived)
        supabase.table("projects").update({
            "status": "ready",
            "updated_at": now,
        }).eq("id", project_id).execute()
        
        # 8. æ›´æ–°ä¼šè¯çŠ¶æ€ä¸º completed (æ•°æ®åº“çº¦æŸ: uploading/processing/completed/failed/cancelled)
        #    è¡¨ç¤ºä¸Šä¼ é˜¶æ®µå·²å®Œæˆï¼Œåç»­ AI å¤„ç†æ˜¯å¯é€‰çš„å¢å€¼åŠŸèƒ½
        supabase.table("workspace_sessions").update({
            "status": "completed",
            "updated_at": now,
        }).eq("id", session_id).execute()
        
        logger.info(f"[Finalize] âœ… å®Œæˆä¸Šä¼ ï¼Œé¡¹ç›® {project_id} å¯ä»¥ç¼–è¾‘äº†")
        logger.info(f"[Finalize]    åˆ›å»ºäº† {len(created_clips)} ä¸ª clips")
        
        return FinalizeUploadResponse(
            status="ok",
            project_id=project_id,
            tracks=[
                {"id": video_track_id, "name": "è§†é¢‘è½¨é“", "order_index": 0},
                {"id": text_track_id, "name": "å­—å¹•è½¨é“", "order_index": 1},
            ],
            clips=created_clips,
            message=f"åŸºç¡€é¡¹ç›®ç»“æ„åˆ›å»ºæˆåŠŸï¼ŒåŒ…å« {len(created_clips)} ä¸ªè§†é¢‘ç‰‡æ®µ",
        )
        
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        logger.error(f"[Finalize] âŒ å®Œæˆä¸Šä¼ å¤±è´¥: {e}")
        logger.error(f"[Finalize] âŒ å®Œæ•´å †æ ˆ:\n{traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/sessions/{session_id}/confirm-upload")
async def confirm_upload(session_id: str, background_tasks: BackgroundTasks):
    """
    ç¡®è®¤æ‰€æœ‰æ–‡ä»¶ä¸Šä¼ å®Œæˆï¼Œå¼€å§‹å¤„ç†
    æ”¯æŒå¤šæ–‡ä»¶å’Œå•æ–‡ä»¶æ¨¡å¼
    """
    try:
        session = supabase.table("workspace_sessions").select("*").eq("id", session_id).single().execute()
        if not session.data:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
        
        session_data = session.data
        project_id = session_data.get("project_id")
        now = datetime.utcnow().isoformat()
        
        # â˜… é˜²æ­¢é‡å¤è§¦å‘ï¼šå¦‚æœå·²ç»åœ¨å¤„ç†ä¸­ï¼Œç›´æ¥è¿”å›
        current_status = session_data.get("status")
        if current_status == "processing":
            logger.info(f"[Session] âš ï¸ ä¼šè¯ {session_id} å·²åœ¨å¤„ç†ä¸­ï¼Œè·³è¿‡é‡å¤è¯·æ±‚")
            return {
                "status": "processing",
                "message": "ä»»åŠ¡å·²åœ¨å¤„ç†ä¸­ï¼Œè¯·å‹¿é‡å¤æäº¤",
                "asset_count": len(session_data.get("uploaded_asset_ids", [])),
            }
        
        # === è·å–æ‰€æœ‰å…³è”çš„ assets ===
        asset_ids = session_data.get("uploaded_asset_ids", [])
        
        # å…¼å®¹æ—§çš„å•æ–‡ä»¶æ¨¡å¼
        if not asset_ids:
            single_asset_id = session_data.get("uploaded_asset_id")
            if single_asset_id:
                asset_ids = [single_asset_id]
        
        if not asset_ids:
            raise HTTPException(status_code=400, detail="ä¼šè¯æœªå…³è”ä»»ä½•èµ„æº")
        
        # === æ£€æŸ¥æ‰€æœ‰æ–‡ä»¶æ˜¯å¦éƒ½ä¸Šä¼ å®Œæˆ ===
        assets_result = supabase.table("assets").select("*").in_("id", asset_ids).execute()
        assets = assets_result.data or []
        
        if len(assets) != len(asset_ids):
            raise HTTPException(status_code=400, detail="éƒ¨åˆ†èµ„æºè®°å½•ä¸å­˜åœ¨")
        
        # æ£€æŸ¥æœªå®Œæˆçš„ä¸Šä¼ 
        not_uploaded = [a for a in assets if a.get("status") not in ("uploaded", "uploading", "processing", "ready")]
        if not_uploaded:
            pending_names = [a.get("name", a["id"]) for a in not_uploaded[:3]]
            raise HTTPException(
                status_code=400, 
                detail=f"éƒ¨åˆ†æ–‡ä»¶æœªä¸Šä¼ å®Œæˆ: {', '.join(pending_names)}"
            )
        
        # === æ›´æ–°æ‰€æœ‰ assets çŠ¶æ€ä¸ºå¤„ç†ä¸­ ===
        for asset in assets:
            supabase.table("assets").update({
                "status": "processing",
                "updated_at": now,
            }).eq("id", asset["id"]).execute()
        
        # === æ›´æ–° session çŠ¶æ€ ===
        supabase.table("workspace_sessions").update({
            "status": "processing",
            "current_step": "fetch",
            "progress": 0,
            "updated_at": now,
        }).eq("id", session_id).execute()
        
        selected_tasks = session_data.get("selected_tasks", ["clips"])
        task_type = selected_tasks[0] if selected_tasks else "clips"
        
        # === æŒ‰é¡ºåºæ’åˆ— assets ===
        sorted_assets = sorted(assets, key=lambda a: a.get("order_index", 0))
        
        logger.info(f"[Session] ========================================")
        logger.info(f"[Session] ğŸš€ å‡†å¤‡å¯åŠ¨åå°å¤„ç†ä»»åŠ¡")
        logger.info(f"[Session]    session_id: {session_id}")
        logger.info(f"[Session]    project_id: {project_id}")
        logger.info(f"[Session]    task_type: {task_type}")
        logger.info(f"[Session]    sorted_assets count: {len(sorted_assets)}")
        for i, a in enumerate(sorted_assets):
            logger.info(f"[Session]    asset[{i}]: {a.get('name')} (order={a.get('order_index')})")
        logger.info(f"[Session] ========================================")
        
        # === å¯åŠ¨åå°å¤„ç†ä»»åŠ¡ ===
        background_tasks.add_task(
            _process_session_multi_assets,
            session_id=session_id,
            project_id=project_id,
            assets=sorted_assets,
            task_type=task_type,
        )
        
        logger.info(f"[Session] âœ… åå°ä»»åŠ¡å·²æ·»åŠ , å¼€å§‹å¤„ç† {len(assets)} ä¸ªç´ æ")
        
        return {
            "status": "processing", 
            "message": f"å¼€å§‹å¤„ç† {len(assets)} ä¸ªç´ æ",
            "asset_count": len(assets),
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[Session] âŒ ç¡®è®¤ä¸Šä¼ å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/sessions/{session_id}", response_model=SessionStatus)
async def get_session_status(session_id: str):
    """è·å–ä¼šè¯å¤„ç†çŠ¶æ€
    
    è¿”å›:
    - current_step: å½“å‰æ­¥éª¤ IDï¼ˆfetch/transcribe/segment/vision/transform/subtitle/prepareï¼‰
    - progress: 0-100 è¿›åº¦
    - status: pending/processing/completed/failed
    
    æ³¨æ„: steps å­—æ®µå·²åºŸå¼ƒï¼Œå‰ç«¯æœ¬åœ°ç”Ÿæˆæ­¥éª¤åˆ—è¡¨
    """
    try:
        session = supabase.table("workspace_sessions").select("*").eq("id", session_id).single().execute()
        if not session.data:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
        
        data = session.data
        
        return SessionStatus(
            session_id=data["id"],
            project_id=data["project_id"],
            status=data["status"],
            current_step=data.get("current_step"),
            progress=data.get("progress", 0),
            steps=[],  # â˜… åºŸå¼ƒï¼Œå‰ç«¯æœ¬åœ°ç”Ÿæˆ
            error=data.get("error_message"),
        )
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.delete("/sessions/{session_id}")
async def cancel_session(session_id: str):
    """å–æ¶ˆå¤„ç†ä¼šè¯"""
    try:
        supabase.table("workspace_sessions").update({
            "status": "cancelled",
            "updated_at": datetime.utcnow().isoformat(),
        }).eq("id", session_id).execute()
        
        return {"message": "ä¼šè¯å·²å–æ¶ˆ"}
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# â˜… æ¸è¿›å¼ä¸¤æ­¥æµç¨‹: å¯åŠ¨ AI å¤„ç† (æ­¥éª¤2)
# ============================================

class StartAIProcessingRequest(BaseModel):
    """å¯åŠ¨ AI å¤„ç†è¯·æ±‚"""
    task_type: TaskType = TaskType.AI_CREATE
    # AI é…ç½®é€‰é¡¹ (å¯é€‰)
    output_ratio: Optional[str] = None  # è¾“å‡ºæ¯”ä¾‹: "9:16", "16:9", "1:1"
    template_id: Optional[str] = None   # æ¨¡æ¿ ID
    options: Optional[dict] = None      # å…¶ä»– AI é€‰é¡¹


class StartAIProcessingResponse(BaseModel):
    """å¯åŠ¨ AI å¤„ç†å“åº”"""
    status: str
    message: str
    credits_consumed: int
    credits_remaining: int


@router.post("/sessions/{session_id}/start-ai-processing", response_model=StartAIProcessingResponse)
async def start_ai_processing(
    session_id: str,
    request: StartAIProcessingRequest,
    background_tasks: BackgroundTasks,
    current_user: dict = Depends(get_current_user)
):
    """
    å¯åŠ¨ AI å¤„ç† (æ­¥éª¤2: æ£€æŸ¥ç§¯åˆ† + æ‰£é™¤ç§¯åˆ† + å¼€å§‹å¤„ç†)
    
    â˜… æ¸è¿›å¼ä¸¤æ­¥æµç¨‹:
    1. create_session - åˆ›å»ºä¼šè¯ + ä¸Šä¼ è§†é¢‘ (ä¸æ‰£ç§¯åˆ†)
    2. start-ai-processing - ç”¨æˆ·ç¡®è®¤é…ç½®åå¯åŠ¨ AI å¤„ç† (æœ¬æ¥å£ï¼Œæ‰£ç§¯åˆ†)
    
    æµç¨‹:
    1. æ ¡éªŒä¼šè¯çŠ¶æ€ (å¿…é¡»æ˜¯ä¸Šä¼ å®ŒæˆçŠ¶æ€)
    2. æ£€æŸ¥ç§¯åˆ†ä½™é¢
    3. æ‰£é™¤ç§¯åˆ†
    4. å¯åŠ¨åå°å¤„ç†ä»»åŠ¡
    """
    try:
        user_id = current_user["user_id"]
        now = datetime.utcnow().isoformat()
        
        # 1. è·å–ä¼šè¯ä¿¡æ¯
        session = supabase.table("workspace_sessions").select("*").eq("id", session_id).single().execute()
        if not session.data:
            raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")
        
        session_data = session.data
        project_id = session_data.get("project_id")
        
        # æ ¡éªŒä¼šè¯å½’å±
        if session_data.get("user_id") != user_id:
            raise HTTPException(status_code=403, detail="æ— æƒæ“ä½œæ­¤ä¼šè¯")
        
        # æ ¡éªŒä¼šè¯çŠ¶æ€: å¿…é¡»æ˜¯ completedï¼ˆfinalize-upload åçš„çŠ¶æ€ï¼‰
        if session_data.get("status") != "completed":
            raise HTTPException(
                status_code=400, 
                detail=f"ä¼šè¯çŠ¶æ€ä¸æ­£ç¡®: {session_data.get('status')}ï¼Œé¢„æœŸä¸º completedï¼ˆè¯·å…ˆå®Œæˆä¸Šä¼ ï¼‰"
            )
        
        # 2. è·å–æ‰€æœ‰å…³è”çš„ assets
        asset_ids = session_data.get("uploaded_asset_ids", [])
        if not asset_ids:
            single_asset_id = session_data.get("uploaded_asset_id")
            if single_asset_id:
                asset_ids = [single_asset_id]
        
        if not asset_ids:
            raise HTTPException(status_code=400, detail="ä¼šè¯æœªå…³è”ä»»ä½•èµ„æºï¼Œè¯·å…ˆä¸Šä¼ è§†é¢‘")
        
        # æ£€æŸ¥æ‰€æœ‰æ–‡ä»¶æ˜¯å¦éƒ½ä¸Šä¼ å®Œæˆ
        assets_result = supabase.table("assets").select("*").in_("id", asset_ids).execute()
        assets = assets_result.data or []
        
        not_ready = [a for a in assets if a.get("status") not in ("uploaded", "ready", "processing")]
        if not_ready:
            pending_names = [a.get("name", a["id"]) for a in not_ready[:3]]
            raise HTTPException(
                status_code=400, 
                detail=f"éƒ¨åˆ†æ–‡ä»¶æœªä¸Šä¼ å®Œæˆ: {', '.join(pending_names)}"
            )
        
        # 3. æ£€æŸ¥å¹¶æ‰£é™¤ç§¯åˆ† (ä»… AI åŠŸèƒ½éœ€è¦)
        credits_consumed = 0
        credits_remaining = 0
        
        if request.task_type.value == 'ai-create':
            from app.services.credit_service import get_credit_service
            credit_service = get_credit_service()
            
            # ai_create å›ºå®š 100 ç§¯åˆ†
            credits_required = 100
            
            # æ£€æŸ¥ç§¯åˆ†
            check_result = await credit_service.quick_check_credits(user_id, credits_required)
            
            if not check_result.get("allowed"):
                logger.warning(f"[AI Processing] âŒ ç§¯åˆ†ä¸è¶³: user_id={user_id}, required={credits_required}, available={check_result.get('available')}")
                raise HTTPException(
                    status_code=402,
                    detail={
                        "error": "insufficient_credits",
                        "message": f"ç§¯åˆ†ä¸è¶³ï¼Œéœ€è¦ {credits_required} ç§¯åˆ†ï¼Œå½“å‰ä½™é¢ {check_result.get('available')}",
                        "required": credits_required,
                        "available": check_result.get("available"),
                    }
                )
            
            # â˜… æ‰£é™¤ç§¯åˆ†
            consume_result = await credit_service.consume_credits(
                user_id=user_id,
                model_key="ai_create",
                credits=credits_required,  # â˜… å¿…é¡»ä¼ å…¥æ¶ˆè€—çš„ç§¯åˆ†æ•°
                ai_task_id=session_id,  # ä½¿ç”¨ session_id ä½œä¸ºä»»åŠ¡ ID
                description=f"ä¸€é”® AI æˆç‰‡ - {session_data.get('project_id', 'unknown')[:8]}",
            )
            
            if not consume_result.get("success"):
                raise HTTPException(
                    status_code=500,
                    detail=f"ç§¯åˆ†æ‰£é™¤å¤±è´¥: {consume_result.get('error', 'æœªçŸ¥é”™è¯¯')}"
                )
            
            credits_consumed = consume_result.get("credits_consumed", credits_required)
            credits_remaining = consume_result.get("credits_after", 0)
            
            logger.info(f"[AI Processing] âœ… ç§¯åˆ†æ‰£é™¤æˆåŠŸ: user_id={user_id}, consumed={credits_consumed}, remaining={credits_remaining}")
        
        # 4. æ›´æ–°ä¼šè¯é…ç½®
        update_data = {
            "selected_tasks": [request.task_type.value],
            "status": "processing",
            "current_step": "fetch",
            "progress": 0,
            "updated_at": now,
        }
        
        # ä¿å­˜ AI é…ç½®é€‰é¡¹
        if request.output_ratio or request.template_id or request.options:
            update_data["ai_config"] = {
                "output_ratio": request.output_ratio,
                "template_id": request.template_id,
                "options": request.options or {},
            }
        
        supabase.table("workspace_sessions").update(update_data).eq("id", session_id).execute()
        
        # 5. æ›´æ–°æ‰€æœ‰ assets çŠ¶æ€ä¸ºå¤„ç†ä¸­
        for asset in assets:
            supabase.table("assets").update({
                "status": "processing",
                "updated_at": now,
            }).eq("id", asset["id"]).execute()
        
        # 6. æŒ‰é¡ºåºæ’åˆ— assets
        sorted_assets = sorted(assets, key=lambda a: a.get("order_index", 0))
        
        logger.info(f"[AI Processing] ========================================")
        logger.info(f"[AI Processing] ğŸš€ å¯åŠ¨ AI å¤„ç†ä»»åŠ¡")
        logger.info(f"[AI Processing]    session_id: {session_id}")
        logger.info(f"[AI Processing]    project_id: {project_id}")
        logger.info(f"[AI Processing]    task_type: {request.task_type.value}")
        logger.info(f"[AI Processing]    credits_consumed: {credits_consumed}")
        logger.info(f"[AI Processing]    ç´ ææ•°é‡: {len(sorted_assets)}")
        logger.info(f"[AI Processing] ========================================")
        
        # 7. å¯åŠ¨åå°å¤„ç†ä»»åŠ¡
        background_tasks.add_task(
            _process_session_multi_assets,
            session_id=session_id,
            project_id=project_id,
            assets=sorted_assets,
            task_type=request.task_type.value,
        )
        
        return StartAIProcessingResponse(
            status="processing",
            message=f"AI å¤„ç†å·²å¯åŠ¨ï¼Œæ­£åœ¨å¤„ç† {len(assets)} ä¸ªç´ æ",
            credits_consumed=credits_consumed,
            credits_remaining=credits_remaining,
        )
        
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        logger.error(f"[AI Processing] âŒ å¯åŠ¨å¤±è´¥: {e}")
        logger.error(f"[AI Processing] âŒ å®Œæ•´å †æ ˆ:\n{traceback.format_exc()}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# è¾…åŠ©å‡½æ•°
# ============================================

import re


class SessionCancelledException(Exception):
    """ä¼šè¯è¢«ç”¨æˆ·å–æ¶ˆçš„å¼‚å¸¸"""
    pass


def _check_session_cancelled(session_id: str) -> bool:
    """
    æ£€æŸ¥ä¼šè¯æ˜¯å¦è¢«å–æ¶ˆ
    
    Args:
        session_id: ä¼šè¯ ID
        
    Returns:
        True å¦‚æœä¼šè¯å·²è¢«å–æ¶ˆï¼ŒFalse å¦åˆ™
    """
    try:
        result = supabase.table("workspace_sessions").select("status").eq("id", session_id).single().execute()
        if result.data:
            return result.data.get("status") == "cancelled"
        return False
    except Exception as e:
        logger.warning(f"[Workspace] æ£€æŸ¥ä¼šè¯çŠ¶æ€å¤±è´¥: {e}")
        return False


def _raise_if_cancelled(session_id: str, step_name: str = ""):
    """
    å¦‚æœä¼šè¯å·²å–æ¶ˆï¼ŒæŠ›å‡ºå¼‚å¸¸ç»ˆæ­¢å¤„ç†
    
    Args:
        session_id: ä¼šè¯ ID
        step_name: å½“å‰æ­¥éª¤åç§°ï¼ˆç”¨äºæ—¥å¿—ï¼‰
    """
    if _check_session_cancelled(session_id):
        step_info = f" (æ­¥éª¤: {step_name})" if step_name else ""
        logger.info(f"[Workspace] ğŸ›‘ ä¼šè¯ {session_id} è¢«å–æ¶ˆï¼Œç»ˆæ­¢å¤„ç†{step_info}")
        raise SessionCancelledException(f"ä¼šè¯ {session_id} å·²è¢«ç”¨æˆ·å–æ¶ˆ")


def _split_by_max_length(text: str, max_length: int) -> list:
    """
    æŒ‰æœ€å¤§é•¿åº¦æ™ºèƒ½åˆ‡åˆ†æ–‡æœ¬
    
    åˆ‡åˆ†ç­–ç•¥ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰ï¼š
    1. ä¼˜å…ˆåœ¨ç©ºæ ¼å¤„åˆ‡åˆ†ï¼ˆé€‚åˆè‹±æ–‡ï¼‰
    2. å…¶æ¬¡åœ¨ä¸­æ–‡å¸¸è§åœé¡¿è¯ååˆ‡åˆ†ï¼ˆçš„ã€æ˜¯ã€åœ¨ã€äº†ã€å’Œã€ä¸ã€æˆ–ï¼‰
    3. æœ€åå¼ºåˆ¶æŒ‰é•¿åº¦åˆ‡åˆ†
    
    Args:
        text: å¾…åˆ‡åˆ†çš„æ–‡æœ¬
        max_length: æ¯æ®µæœ€å¤§å­—ç¬¦æ•°
        
    Returns:
        åˆ‡åˆ†åçš„æ–‡æœ¬åˆ—è¡¨
    """
    if len(text) <= max_length:
        return [text]
    
    result = []
    remaining = text
    
    while len(remaining) > max_length:
        # åœ¨ max_length èŒƒå›´å†…å¯»æ‰¾æœ€ä½³åˆ‡åˆ†ç‚¹
        chunk = remaining[:max_length]
        
        # ç­–ç•¥1ï¼šå¯»æ‰¾ç©ºæ ¼åˆ‡åˆ†ç‚¹ï¼ˆè‹±æ–‡ï¼‰
        space_idx = chunk.rfind(' ')
        if space_idx > max_length // 2:  # ç¡®ä¿åˆ‡åˆ†ç‚¹ä¸ä¼šå¤ªé å‰
            result.append(chunk[:space_idx].strip())
            remaining = remaining[space_idx:].strip()
            continue
        
        # ç­–ç•¥2ï¼šå¯»æ‰¾ä¸­æ–‡åœé¡¿è¯åˆ‡åˆ†ç‚¹
        stop_words = ['çš„', 'æ˜¯', 'åœ¨', 'äº†', 'å’Œ', 'ä¸', 'æˆ–', 'ä¹Ÿ', 'éƒ½', 'å°±', 'è€Œ', 'ä½†', 'å¾ˆ', 'æ›´']
        best_stop_idx = -1
        for word in stop_words:
            idx = chunk.rfind(word)
            if idx > max_length // 2 and idx > best_stop_idx:
                best_stop_idx = idx + len(word)  # åˆ‡åˆ†ç‚¹åœ¨åœé¡¿è¯ä¹‹å
        
        if best_stop_idx > 0:
            result.append(chunk[:best_stop_idx].strip())
            remaining = remaining[best_stop_idx:].strip()
            continue
        
        # ç­–ç•¥3ï¼šå¼ºåˆ¶æŒ‰é•¿åº¦åˆ‡åˆ†
        result.append(chunk.strip())
        remaining = remaining[max_length:].strip()
    
    if remaining:
        result.append(remaining.strip())
    
    return result


def _split_segments_by_punctuation(segments: list, max_chars_per_line: int = 20) -> list:
    """
    å°† ASR segments æŒ‰æ ‡ç‚¹ç¬¦å·è¿›ä¸€æ­¥åˆ‡åˆ†æˆæ›´ç»†çš„å­å¥
    
    åˆ‡åˆ†è§„åˆ™ï¼š
    1. ä¸­æ–‡æ ‡ç‚¹ï¼šï¼Œã€‚ï¼ï¼Ÿï¼›
    2. è‹±æ–‡æ ‡ç‚¹ï¼š,.!?;
    3. æ ¹æ®æ–‡æœ¬é•¿åº¦æŒ‰æ¯”ä¾‹åˆ†é…æ—¶é—´
    4. å•è¡Œæœ€å¤§å­—ç¬¦æ•°é™åˆ¶ï¼ˆé˜²æ­¢å­—å¹•è¿‡é•¿è¶…å‡ºå±å¹•ï¼‰
    
    Args:
        segments: ASR è¿”å›çš„ segments åˆ—è¡¨ï¼Œæ¯ä¸ªåŒ…å« start, end, text
        max_chars_per_line: å•è¡Œæœ€å¤§å­—ç¬¦æ•°ï¼Œ15å·å­—ä½“ä¸‹å»ºè®®20å­—ç¬¦
        
    Returns:
        ç»†åˆ†åçš„ segments åˆ—è¡¨
    """
    # æ ‡ç‚¹ç¬¦å·æ­£åˆ™ï¼šåŒ¹é…ä¸­è‹±æ–‡é€—å·ã€å¥å·ã€é—®å·ã€æ„Ÿå¹å·ã€åˆ†å·
    punctuation_pattern = re.compile(r'([ï¼Œã€‚ï¼ï¼Ÿï¼›,.!?;])')
    
    fine_segments = []
    
    for seg in segments:
        text = seg.get("text", "").strip()
        start_ms = seg.get("start", 0)
        end_ms = seg.get("end", 0)
        total_duration = end_ms - start_ms
        
        if not text or total_duration <= 0:
            continue
        
        # æŒ‰æ ‡ç‚¹åˆ‡åˆ†æ–‡æœ¬
        parts = punctuation_pattern.split(text)
        
        # é‡æ–°ç»„åˆï¼šå°†æ ‡ç‚¹ç¬¦å·ä¸å‰é¢çš„æ–‡æœ¬åˆå¹¶
        sentences = []
        buffer = ""
        for part in parts:
            buffer += part
            if punctuation_pattern.match(part):
                if buffer.strip():
                    sentences.append(buffer.strip())
                buffer = ""
        # å¤„ç†æœ€åæ²¡æœ‰æ ‡ç‚¹çš„éƒ¨åˆ†
        if buffer.strip():
            sentences.append(buffer.strip())
        
        # å¦‚æœåªæœ‰ä¸€ä¸ªå¥å­æˆ–æ²¡æœ‰åˆ‡åˆ†ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦æŒ‰é•¿åº¦åˆ‡åˆ†
        if len(sentences) <= 1:
            # æ£€æŸ¥æ˜¯å¦è¶…è¿‡æœ€å¤§é•¿åº¦
            if len(text) <= max_chars_per_line:
                fine_segments.append(seg)
                continue
            else:
                # æŒ‰æœ€å¤§é•¿åº¦åˆ‡åˆ†
                sentences = _split_by_max_length(text, max_chars_per_line)
        else:
            # å¯¹æ¯ä¸ªå¥å­æ£€æŸ¥é•¿åº¦ï¼Œè¿‡é•¿çš„è¿›ä¸€æ­¥åˆ‡åˆ†
            expanded_sentences = []
            for s in sentences:
                if len(s) > max_chars_per_line:
                    expanded_sentences.extend(_split_by_max_length(s, max_chars_per_line))
                else:
                    expanded_sentences.append(s)
            sentences = expanded_sentences
        
        # æŒ‰å­—ç¬¦æ•°æ¯”ä¾‹åˆ†é…æ—¶é—´
        total_chars = sum(len(s) for s in sentences)
        if total_chars == 0:
            fine_segments.append(seg)
            continue
        
        current_time = start_ms
        for sentence in sentences:
            char_ratio = len(sentence) / total_chars
            duration = int(total_duration * char_ratio)
            
            # ç¡®ä¿è‡³å°‘æœ‰ 100ms
            duration = max(duration, 100)
            
            fine_segments.append({
                "id": seg.get("id"),
                "text": sentence,
                "start": current_time,
                "end": current_time + duration,
                "speaker": seg.get("speaker"),
            })
            
            current_time += duration
    
    return fine_segments


def _generate_project_name(request: CreateSessionRequest) -> str:
    """ç”Ÿæˆé¡¹ç›®åç§°"""
    if request.file_name:
        name = request.file_name.rsplit(".", 1)[0]
        return name[:50]
    elif request.source_url:
        return f"YouTube è§†é¢‘ - {datetime.now().strftime('%m/%d %H:%M')}"
    else:
        return f"æ–°é¡¹ç›® - {datetime.now().strftime('%Y-%m-%d %H:%M')}"


def _create_progress_updater(session_id: str):
    """
    åˆ›å»ºè¿›åº¦æ›´æ–°å™¨å‡½æ•°
    
    å†…ç½®èŠ‚æµï¼šåªåœ¨è¿›åº¦å˜åŒ– â‰¥1% æˆ–æ­¥éª¤å˜åŒ–æ—¶æ‰çœŸæ­£æ›´æ–°æ•°æ®åº“
    é¿å…é¢‘ç¹å†™å…¥é€ æˆæ€§èƒ½é—®é¢˜
    """
    last_progress = {"step": None, "value": -1}
    
    def update_progress(step: str, progress: int):
        # èŠ‚æµï¼šåªåœ¨è¿›åº¦å˜åŒ– â‰¥1% æˆ–æ­¥éª¤å˜åŒ–æ—¶æ‰æ›´æ–°
        if step == last_progress["step"] and progress == last_progress["value"]:
            return  # å®Œå…¨ç›¸åŒï¼Œè·³è¿‡
        
        if step == last_progress["step"] and abs(progress - last_progress["value"]) < 1:
            return  # åŒä¸€æ­¥éª¤ï¼Œè¿›åº¦å˜åŒ– <1%ï¼Œè·³è¿‡
        
        last_progress["step"] = step
        last_progress["value"] = progress
        
        supabase.table("workspace_sessions").update({
            "current_step": step,
            "progress": progress,
            "updated_at": datetime.utcnow().isoformat(),
        }).eq("id", session_id).execute()
    
    return update_progress


async def _fetch_asset_metadata(asset_id: str, file_url: str) -> dict:
    """æå–èµ„æºå…ƒæ•°æ®ï¼ˆå®½é«˜ã€å¸§ç‡ã€ç¼–ç ç­‰ï¼Œduration ç”±å‰ç«¯æä¾›ï¼‰"""
    try:
        from ..tasks.asset_processing import extract_media_metadata
        logger.info(f"[Workspace] æ­£åœ¨æå–å…ƒæ•°æ®: {file_url[:80]}...")
        metadata = await extract_media_metadata(file_url)
        logger.debug(f"[Workspace] æå–åˆ°çš„å…ƒæ•°æ®: {metadata}")
        
        # â˜… æ£€æµ‹è§†é¢‘ç¼–ç ï¼Œåˆ¤æ–­æµè§ˆå™¨æ˜¯å¦æ”¯æŒ
        video_codec = metadata.get("codec", "")
        # æµè§ˆå™¨åŸç”Ÿæ”¯æŒçš„ç¼–ç æ ¼å¼
        BROWSER_SUPPORTED_CODECS = {"h264", "avc1", "vp8", "vp9", "av1", "hevc", "h265"}
        needs_transcode = video_codec and video_codec.lower() not in BROWSER_SUPPORTED_CODECS
        if needs_transcode:
            logger.warning(f"[Workspace] âš ï¸ è§†é¢‘ç¼–ç  {video_codec} éœ€è¦è½¬ç ä¸º H.264")
        
        # duration ç”±å‰ç«¯æä¾›ï¼Œè¿™é‡Œåªæ›´æ–°å®½é«˜ã€å¸§ç‡ã€ç¼–ç ç­‰ä¿¡æ¯
        supabase.table("assets").update({
            "width": metadata.get("width", 1920),
            "height": metadata.get("height", 1080),
            "fps": metadata.get("fps", 30),
            "sample_rate": metadata.get("sample_rate"),
            "channels": metadata.get("channels"),
            "status": "ready",
            "updated_at": datetime.utcnow().isoformat(),
        }).eq("id", asset_id).execute()
        
        # è¿”å›å®Œæ•´å…ƒæ•°æ®ï¼ŒåŒ…æ‹¬ç¼–ç ä¿¡æ¯
        metadata["needs_transcode"] = needs_transcode
        return metadata
    except Exception as e:
        logger.warning(f"[Workspace] âŒ æå–å…ƒæ•°æ®å¤±è´¥: {e}, ä½¿ç”¨é»˜è®¤å€¼")
        supabase.table("assets").update({
            "status": "ready",
            "updated_at": datetime.utcnow().isoformat(),
        }).eq("id", asset_id).execute()
        return {"duration": 0, "width": 1920, "height": 1080, "fps": 30, "needs_transcode": False}


async def _extract_audio_for_asr(video_url: str, asset_id: str, update_progress, current_progress: int, video_duration_sec: float = None) -> str:
    """
    ä»è§†é¢‘ä¸­æå–å‹ç¼©éŸ³é¢‘ï¼Œç”¨äº ASR è½¬å†™
    
    ä¼˜åŒ–ç­–ç•¥:
    - 16kHz é‡‡æ ·ç‡ï¼ˆè¯­éŸ³è¯†åˆ«è¶³å¤Ÿï¼‰
    - å•å£°é“
    - 64kbps ç ç‡
    - 4GB è§†é¢‘ â†’ çº¦ 20MB éŸ³é¢‘ï¼Œä¸Šä¼ é€Ÿåº¦æå‡ 99%
    - â˜… ç¼“å­˜å¤ç”¨ï¼šå¦‚æœéŸ³é¢‘å·²æå–è¿‡ï¼Œç›´æ¥è¿”å›ç¼“å­˜ URL
    - â˜… å®æ—¶è¿›åº¦ï¼šè§£æ FFmpeg è¾“å‡ºæ›´æ–°è¿›åº¦
    
    Args:
        video_url: è§†é¢‘çš„ç­¾å URL
        asset_id: èµ„äº§ IDï¼ˆç”¨äºå­˜å‚¨è·¯å¾„ï¼‰
        update_progress: è¿›åº¦å›è°ƒ
        current_progress: å½“å‰è¿›åº¦ç™¾åˆ†æ¯”
        video_duration_sec: è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œç”¨äºè®¡ç®—è¿›åº¦
        
    Returns:
        æå–åéŸ³é¢‘çš„ç­¾å URL
    """
    import tempfile
    import httpx
    import asyncio
    import os
    import re
    
    audio_storage_path = f"asr_audio/{asset_id}.mp3"
    
    # â˜…â˜…â˜… ç¼“å­˜æ£€æŸ¥ï¼šå¦‚æœéŸ³é¢‘å·²å­˜åœ¨ï¼Œç›´æ¥è¿”å› â˜…â˜…â˜…
    try:
        # å°è¯•ç›´æ¥è·å–ç­¾å URLï¼Œå¦‚æœæˆåŠŸè¯´æ˜æ–‡ä»¶å­˜åœ¨
        from ..services.supabase_client import supabase
        result = supabase.storage.from_("clips").create_signed_url(audio_storage_path, 60)
        cached_url = result.get("signedURL") or result.get("signedUrl") or result.get("signed_url")
        if cached_url:
            logger.info(f"[ASRä¼˜åŒ–] âœ… ä½¿ç”¨ç¼“å­˜éŸ³é¢‘: {audio_storage_path}")
            update_progress("extract_audio", current_progress + 15)
            return cached_url
    except Exception:
        pass  # ç¼“å­˜ä¸å­˜åœ¨æˆ–æ£€æŸ¥å¤±è´¥ï¼Œç»§ç»­æå–
    
    logger.info(f"[ASRä¼˜åŒ–] ğŸµ å¼€å§‹æå–éŸ³é¢‘ asset_id={asset_id}, duration={video_duration_sec}s")
    
    custom_temp_dir = os.getenv("ASR_TEMP_DIR")
    temp_dir = tempfile.mkdtemp(prefix="asr_", dir=custom_temp_dir)
    logger.info(f"[ASRä¼˜åŒ–] ğŸ“ ä¸´æ—¶ç›®å½•: {temp_dir}")
    
    audio_path = os.path.join(temp_dir, "audio_for_asr.mp3")
    
    try:
        update_progress("extract_audio", current_progress)
        logger.info(f"[ASRä¼˜åŒ–] ğŸ”§ FFmpeg æµå¼æå–éŸ³é¢‘...")
        
        # â˜… ä¼˜åŒ–ï¼šæ·»åŠ ç½‘ç»œè¶…æ—¶å’Œæ›´å¿«çš„ç¼–ç å‚æ•°
        cmd = [
            "ffmpeg", "-y",
            "-reconnect", "1",           # æ–­çº¿é‡è¿
            "-reconnect_streamed", "1",
            "-reconnect_delay_max", "5", # æœ€å¤§é‡è¿å»¶è¿Ÿ 5 ç§’
            "-i", video_url,
            "-vn",                       # ä¸è¦è§†é¢‘
            "-ar", "16000",              # 16kHz é‡‡æ ·ç‡
            "-ac", "1",                  # å•å£°é“
            "-b:a", "64k",               # 64kbps ç ç‡
            "-f", "mp3",
            "-progress", "pipe:1",       # â˜… è¾“å‡ºè¿›åº¦åˆ° stdout
            audio_path
        ]
        
        process = await asyncio.create_subprocess_exec(
            *cmd,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )
        
        # â˜…â˜…â˜… å®æ—¶è§£æ FFmpeg è¿›åº¦ â˜…â˜…â˜…
        last_progress_update = 0
        total_duration_us = (video_duration_sec or 60) * 1_000_000  # å¾®ç§’
        
        async def read_progress():
            nonlocal last_progress_update
            while True:
                line = await process.stdout.readline()
                if not line:
                    break
                line_str = line.decode().strip()
                # FFmpeg progress æ ¼å¼: out_time_us=12345678
                if line_str.startswith("out_time_us="):
                    try:
                        current_us = int(line_str.split("=")[1])
                        if total_duration_us > 0:
                            pct = min(current_us / total_duration_us, 1.0)
                            # extract_audio å  10% è¿›åº¦ï¼ˆcurrent_progress åˆ° current_progress + 10ï¼‰
                            new_progress = current_progress + int(pct * 10)
                            # é¿å…é¢‘ç¹æ›´æ–°ï¼ˆæ¯å¢åŠ  2% æ›´æ–°ä¸€æ¬¡ï¼‰
                            if new_progress >= last_progress_update + 2:
                                update_progress("extract_audio", new_progress)
                                last_progress_update = new_progress
                    except (ValueError, IndexError):
                        pass
        
        # å¹¶è¡Œè¯»å– stdout è¿›åº¦å’Œ stderr
        async def read_stderr():
            """è¯»å– stderr è·å–é”™è¯¯ä¿¡æ¯"""
            data = await process.stderr.read()
            return data.decode() if data else ""
        
        progress_task = asyncio.create_task(read_progress())
        stderr_task = asyncio.create_task(read_stderr())
        
        # ç­‰å¾…è¿›ç¨‹å®Œæˆï¼ˆä¸ç”¨ communicateï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»åœ¨è¯» stdoutï¼‰
        await process.wait()
        
        # ç­‰å¾…è¯»å–ä»»åŠ¡å®Œæˆ
        await progress_task
        stderr_text = await stderr_task
        
        if process.returncode != 0:
            logger.error(f"[ASRä¼˜åŒ–] âŒ FFmpeg å¤±è´¥: {stderr_text[:500]}")
            raise Exception(f"éŸ³é¢‘æå–å¤±è´¥: {stderr_text[:200]}")
        
        audio_size_mb = os.path.getsize(audio_path) / (1024 * 1024)
        logger.info(f"[ASRä¼˜åŒ–] âœ… éŸ³é¢‘æµå¼æå–å®Œæˆ: {audio_size_mb:.1f}MB")
        
        # ä¸Šä¼ éŸ³é¢‘åˆ° Supabase
        update_progress("upload_audio", current_progress + 12)
        logger.info(f"[ASRä¼˜åŒ–] â¬†ï¸ ä¸Šä¼ éŸ³é¢‘...")
        
        audio_storage_path = f"asr_audio/{asset_id}.mp3"
        
        with open(audio_path, "rb") as f:
            audio_data = f.read()
        
        # ä½¿ç”¨ asyncio.to_thread é¿å…é˜»å¡
        await asyncio.to_thread(
            lambda: supabase.storage.from_("clips").upload(
                audio_storage_path,
                audio_data,
                {"content-type": "audio/mpeg", "upsert": "true"}
            )
        )
        
        audio_url = get_file_url("clips", audio_storage_path)
        update_progress("upload_audio", current_progress + 15)
        logger.info(f"[ASRä¼˜åŒ–] âœ… éŸ³é¢‘ä¸Šä¼ å®Œæˆ: {audio_storage_path}")
        
        return audio_url
        
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        import shutil
        try:
            shutil.rmtree(temp_dir)
            logger.info(f"[ASRä¼˜åŒ–] ğŸ§¹ ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†")
        except Exception as e:
            logger.warning(f"[ASRä¼˜åŒ–] âš ï¸ æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")


async def _run_asr(file_url: str, update_progress, current_progress: int, step_progress: int, asset_id: str = None, video_duration_sec: float = None) -> list:
    """
    æ‰§è¡Œ ASR è¯­éŸ³è½¬å†™
    
    ä¼˜åŒ–1ï¼šå¦‚æœ asset_id åœ¨ tasks è¡¨ä¸­å·²æœ‰è½¬å†™ç»“æœï¼Œç›´æ¥å¤ç”¨
    ä¼˜åŒ–2ï¼šå¦‚æœæä¾›äº† asset_id ä¸”æ˜¯å¤§æ–‡ä»¶ï¼ˆè§†é¢‘ï¼‰ï¼Œä¼šå…ˆæå–éŸ³é¢‘å†è½¬å†™
    """
    logger.info(f"[_run_asr] ğŸ¤ å¼€å§‹ ASR è½¬å†™")
    logger.info(f"[_run_asr]    file_url: {file_url[:100]}...")
    logger.info(f"[_run_asr]    current_progress: {current_progress}, step_progress: {step_progress}")
    logger.info(f"[_run_asr]    asset_id: {asset_id}, video_duration: {video_duration_sec}s")
    
    try:
        from ..tasks.transcribe import transcribe_audio
        import httpx
        import asyncio
        
        # â˜…â˜…â˜… ä¼˜åŒ–ï¼šæ£€æŸ¥æ˜¯å¦å·²æœ‰è½¬å†™ç»“æœï¼ˆå¤ç”¨ analyze-content çš„è½¬å†™ï¼‰â˜…â˜…â˜…
        # æ³¨æ„ï¼šæ’é™¤ clip çº§åˆ«çš„è½¬å†™ä»»åŠ¡ï¼ˆparams ä¸­åŒ…å« clip_id çš„æ˜¯ clip è½¬å†™ï¼‰
        # åªå¤ç”¨æ•´ä½“ asset çš„è½¬å†™ç»“æœ
        if asset_id:
            existing_tasks = supabase.table("tasks").select(
                "id, status, result, params"
            ).eq("asset_id", asset_id).eq("task_type", "transcribe").eq("status", "completed").execute()
            
            # ç­›é€‰å‡ºæ•´ä½“ asset çš„è½¬å†™ä»»åŠ¡ï¼ˆparams ä¸­æ²¡æœ‰ clip_idï¼‰
            existing_task_data = None
            if existing_tasks and existing_tasks.data:
                for task in existing_tasks.data:
                    params = task.get("params") or {}
                    if not params.get("clip_id"):  # æ•´ä½“ asset è½¬å†™ï¼Œä¸æ˜¯ clip è½¬å†™
                        existing_task_data = task
                        break
            
            if existing_task_data and existing_task_data.get("result"):
                result = existing_task_data["result"]
                segments = result.get("segments", []) if isinstance(result, dict) else result
                if segments:
                    logger.info(f"[_run_asr] âœ… å¤ç”¨å·²æœ‰è½¬å†™ç»“æœ: {len(segments)} ä¸ªç‰‡æ®µ (task_id={existing_task_data['id'][:8]})")
                    update_progress("transcribe", current_progress + step_progress)
                    return segments
        
        # åˆ¤æ–­æ˜¯å¦æ˜¯è§†é¢‘æ–‡ä»¶ï¼Œéœ€è¦æå–éŸ³é¢‘
        is_video = any(ext in file_url.lower() for ext in ['.mp4', '.mov', '.avi', '.mkv', '.webm', '.m4v'])
        
        # å¦‚æœæ˜¯è§†é¢‘ä¸”æœ‰ asset_idï¼Œå…ˆæå–éŸ³é¢‘ï¼ˆå¤§å¹…æå‡é€Ÿåº¦ï¼‰
        actual_audio_url = file_url
        if is_video and asset_id:
            logger.info(f"[_run_asr] ğŸ¬ æ£€æµ‹åˆ°è§†é¢‘æ–‡ä»¶ï¼Œå…ˆæå–éŸ³é¢‘ä»¥ä¼˜åŒ–ä¸Šä¼ é€Ÿåº¦")
            try:
                # æå–éŸ³é¢‘å ç”¨ 20% è¿›åº¦
                audio_progress = int(step_progress * 0.2)
                actual_audio_url = await _extract_audio_for_asr(
                    video_url=file_url,
                    asset_id=asset_id,
                    update_progress=update_progress,
                    current_progress=current_progress,
                    video_duration_sec=video_duration_sec  # â˜… ä¼ å…¥è§†é¢‘æ—¶é•¿ç”¨äºè¿›åº¦è®¡ç®—
                )
                # è°ƒæ•´å‰©ä½™è¿›åº¦
                current_progress += audio_progress
                step_progress -= audio_progress
                logger.info(f"[_run_asr] âœ… éŸ³é¢‘æå–æˆåŠŸï¼Œä½¿ç”¨å‹ç¼©éŸ³é¢‘è¿›è¡Œè½¬å†™")
            except Exception as e:
                logger.warning(f"[_run_asr] âš ï¸ éŸ³é¢‘æå–å¤±è´¥ï¼Œå›é€€åˆ°åŸå§‹æ–‡ä»¶: {e}")
                actual_audio_url = file_url
        
        # éªŒè¯æ–‡ä»¶æ˜¯å¦å¯è®¿é—®ï¼ˆç­‰å¾…ä¸Šä¼ å®Œæˆï¼‰
        max_retries = 30  # æœ€å¤šç­‰å¾… 30 ç§’
        for retry in range(max_retries):
            try:
                async with httpx.AsyncClient(timeout=10.0) as client:
                    resp = await client.head(actual_audio_url)
                    if resp.status_code == 200:
                        logger.info(f"[_run_asr] âœ… æ–‡ä»¶å¯è®¿é—®ï¼Œå¼€å§‹è½¬å†™")
                        break
                    else:
                        logger.warning(f"[_run_asr] â³ æ–‡ä»¶ä¸å¯è®¿é—® (HTTP {resp.status_code})ï¼Œç­‰å¾…... ({retry+1}/{max_retries})")
            except Exception as e:
                logger.warning(f"[_run_asr] â³ æ–‡ä»¶æ£€æŸ¥å¤±è´¥: {e}ï¼Œç­‰å¾…... ({retry+1}/{max_retries})")
            
            if retry < max_retries - 1:
                await asyncio.sleep(1)
        else:
            logger.error(f"[_run_asr] âŒ æ–‡ä»¶åœ¨ {max_retries} ç§’åä»ä¸å¯è®¿é—®")
            return []
        
        def on_asr_progress(progress: int, step: str):
            mapped_progress = current_progress + int(progress * step_progress / 100)
            update_progress("transcribe", mapped_progress)
        
        asr_result = await transcribe_audio(
            audio_url=actual_audio_url,
            language="zh",
            on_progress=on_asr_progress,
        )
        
        segments = asr_result.get("segments", [])
        logger.info(f"[_run_asr] âœ… ASR å®Œæˆï¼Œè¯†åˆ« {len(segments)} ä¸ªç‰‡æ®µ")
        
        # è¯¦ç»†æ—¥å¿—
        if segments:
            first_seg = segments[0]
            last_seg = segments[-1]
            logger.info(f"[_run_asr]    ç¬¬ä¸€ä¸ªç‰‡æ®µ: start={first_seg.get('start')}ms text='{first_seg.get('text', '')[:20]}...'")
            logger.info(f"[_run_asr]    æœ€åä¸€ä¸ªç‰‡æ®µ: end={last_seg.get('end')}ms text='{last_seg.get('text', '')[:20]}...'")
        else:
            logger.warning(f"[_run_asr] âš ï¸ ASR è¿”å›ç©ºç»“æœ!")
        
        # â˜…â˜…â˜… ä¿å­˜è½¬å†™ç»“æœåˆ° tasks è¡¨ï¼Œä¾›æ™ºèƒ½åˆ†æå¤ç”¨ â˜…â˜…â˜…
        if asset_id and segments:
            try:
                now = datetime.utcnow().isoformat()
                default_user_id = "00000000-0000-0000-0000-000000000000"
                task_id = str(uuid4())
                
                # å…ˆæŸ¥è¯¢ project_id
                asset_info = supabase.table("assets").select("project_id").eq("id", asset_id).single().execute()
                project_id = asset_info.data.get("project_id") if asset_info.data else None
                
                supabase.table("tasks").insert({
                    "id": task_id,
                    "project_id": project_id,
                    "user_id": default_user_id,
                    "task_type": "transcribe",
                    "asset_id": asset_id,
                    "status": "completed",
                    "progress": 100,
                    "params": {"language": "zh", "model": "base"},
                    "result": asr_result,
                    "created_at": now,
                    "completed_at": now,
                    "updated_at": now
                }).execute()
                logger.info(f"[_run_asr] ğŸ’¾ è½¬å†™ç»“æœå·²ä¿å­˜åˆ° tasks è¡¨ (task_id={task_id[:8]})")
            except Exception as save_err:
                logger.warning(f"[_run_asr] âš ï¸ ä¿å­˜è½¬å†™ç»“æœå¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {save_err}")
            
        return segments
    except Exception as e:
        logger.error(f"[_run_asr] âŒ ASR å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return []


async def _run_silence_detection(file_url: str) -> list:
    """æ‰§è¡Œé™éŸ³æ£€æµ‹"""
    try:
        from ..tasks.vad import detect_silence_segments
        
        result = await detect_silence_segments(
            audio_url=file_url,
            min_silence_duration=0.5,
            silence_threshold_db=-35,
        )
        
        segments = result.get("segments", [])
        logger.info(f"[Workspace] âœ… é™éŸ³æ£€æµ‹å®Œæˆï¼Œæ£€æµ‹åˆ° {len(segments)} ä¸ªé™éŸ³ç‰‡æ®µ")
        return segments
    except Exception as e:
        logger.error(f"[Workspace] âŒ é™éŸ³æ£€æµ‹å¤±è´¥: {e}")
        return []


# NOTE: _create_clips_from_segments å·²åˆ é™¤ (2025-01-27)
# è¯¥å‡½æ•°ä»æœªè¢«è°ƒç”¨ï¼Œ_process_session_multi_assets å†…éƒ¨ç›´æ¥å¤„ç† clips åˆ›å»º
# ä¿ç•™ _create_clips_from_segments_with_offset ä¾› assets.py ä½¿ç”¨


# NOTE: _process_session å·²åˆ é™¤ (2025-01-27)
# è¯¥å‡½æ•°ä»æœªè¢«è°ƒç”¨ï¼Œæ‰€æœ‰å¤„ç†éƒ½ä½¿ç”¨ _process_session_multi_assets
# åˆ é™¤çº¦ 410 è¡Œå†—ä½™ä»£ç 


async def _process_session_multi_assets(
    session_id: str,
    project_id: str,
    assets: list,
    task_type: str,
):
    """
    åå°å¤„ç†ä¼šè¯ - å¤šç´ æç‰ˆæœ¬
    æŒ‰é¡ºåºå¤„ç†å¤šä¸ªç´ æï¼Œæ‹¼æ¥åˆ°åŒä¸€æ—¶é—´è½´
    """
    import asyncio
    
    # â˜… ç”± task_type å†³å®šå¤„ç†æµç¨‹
    ai_create_mode = task_type == "ai-create"
    voice_extract_mode = task_type == "voice-extract"
    enable_llm = False
    
    logger.info(f"[Workspace] ğŸš€ å¼€å§‹å¤„ç†å¤šç´ æä¼šè¯: session={session_id}, project={project_id}, task={task_type}, assets={len(assets)}")
    logger.debug(f"[Workspace]    ai_create_mode: {ai_create_mode}, voice_extract_mode: {voice_extract_mode}")
    
    try:
        # ========================================
        # â˜… Step 0: æ¸…ç©ºé¡¹ç›®çš„æ‰€æœ‰ clips å’Œ keyframesï¼ˆé¿å…é‡å¤/æ®‹ç•™ï¼‰
        # ========================================
        logger.info(f"[Workspace] ğŸ§¹ æ¸…ç©ºé¡¹ç›® {project_id} çš„æ‰€æœ‰ clips å’Œ keyframes...")
        
        # å…ˆè·å–é¡¹ç›®çš„æ‰€æœ‰ track_ids
        tracks_result = supabase.table("tracks").select("id").eq("project_id", project_id).execute()
        track_ids = [t["id"] for t in (tracks_result.data or [])]
        
        if track_ids:
            # è·å–æ‰€æœ‰ clip_idsï¼ˆç”¨äºåˆ é™¤å…³è”çš„ keyframesï¼‰
            clips_result = supabase.table("clips").select("id").in_("track_id", track_ids).execute()
            clip_ids = [c["id"] for c in (clips_result.data or [])]
            
            # å…ˆåˆ é™¤ keyframesï¼ˆæœ‰å¤–é”®çº¦æŸï¼‰
            if clip_ids:
                try:
                    supabase.table("keyframes").delete().in_("clip_id", clip_ids).execute()
                    logger.debug(f"[Workspace]    åˆ é™¤ {len(clip_ids)} ä¸ª clips å…³è”çš„ keyframes")
                except Exception as e:
                    logger.warning(f"[Workspace]    åˆ é™¤ keyframes å¤±è´¥ï¼ˆå¯èƒ½ä¸å­˜åœ¨ï¼‰: {e}")
            
            # å†åˆ é™¤æ‰€æœ‰ clips
            try:
                supabase.table("clips").delete().in_("track_id", track_ids).execute()
                logger.debug(f"[Workspace]    åˆ é™¤ {len(track_ids)} ä¸ª tracks ä¸‹çš„æ‰€æœ‰ clips")
            except Exception as e:
                logger.warning(f"[Workspace]    åˆ é™¤ clips å¤±è´¥: {e}")
        
        logger.info(f"[Workspace] âœ… é¡¹ç›®æ¸…ç†å®Œæˆï¼Œå¼€å§‹å…¨æ–°å¤„ç†")
        
        update_progress = _create_progress_updater(session_id)
        now = datetime.utcnow().isoformat()
        
        # Step 1: è·å–æ‰€æœ‰ç´ æå…ƒæ•°æ® (0% â†’ 10%)
        _raise_if_cancelled(session_id, "å¼€å§‹å¤„ç†å¤šç´ æ")
        update_progress("fetch", 5)
        
        # æ”¶é›†æ‰€æœ‰ç´ æä¿¡æ¯
        asset_infos = []
        total_duration = 0
        max_width = 0
        max_height = 0
        
        for idx_asset, asset in enumerate(assets):
            asset_id = asset["id"]
            storage_path = asset.get("storage_path")
            logger.debug(f"[Workspace] ğŸ“¦ è·å–ç´ æ {idx_asset + 1}/{len(assets)} å…ƒæ•°æ®: {asset_id}")
            logger.debug(f"[Workspace]    storage_path: {storage_path}")
            file_url = get_file_url("clips", storage_path)
            logger.debug(f"[Workspace]    file_url: {file_url[:80]}...")
            
            # è·å–å…ƒæ•°æ®ï¼ˆåŒ…æ‹¬ç¼–ç ä¿¡æ¯ï¼‰
            metadata = await _fetch_asset_metadata(asset_id, file_url)
            logger.debug(f"[Workspace]    metadata: {metadata}")
            duration = asset.get("duration") or metadata.get("duration", 0)
            width = metadata.get("width", 1920)
            height = metadata.get("height", 1080)
            codec = metadata.get("codec", "unknown")
            needs_transcode = metadata.get("needs_transcode", False)
            
            asset_infos.append({
                "asset_id": asset_id,
                "storage_path": storage_path,  # â˜… ä¿å­˜ storage_path ç”¨äºè½¬ç 
                "file_url": file_url,
                "duration": duration,
                "duration_ms": int(duration * 1000),
                "width": width,
                "height": height,
                "order": asset.get("order_index", 0),
                "name": asset.get("name", "ç´ æ"),
                "codec": codec,  # â˜… ä¿å­˜ç¼–ç ä¿¡æ¯
                "needs_transcode": needs_transcode,  # â˜… æ˜¯å¦éœ€è¦è½¬ç 
            })
            
            total_duration += duration
            max_width = max(max_width, width)
            max_height = max(max_height, height)
        
        # æŒ‰é¡ºåºæ’åº
        asset_infos.sort(key=lambda x: x["order"])
        
        update_progress("fetch", 10)
        logger.info(f"[Workspace] âœ… è·å– {len(asset_infos)} ä¸ªç´ æå…ƒæ•°æ®ï¼Œæ€»æ—¶é•¿ {total_duration:.1f}s")
        
        # ========================================
        # ğŸš€ å¯åŠ¨ HLS åå°ç”Ÿæˆï¼ˆæ‰€æœ‰éœ€è¦è½¬ç çš„è§†é¢‘ + å¤§è§†é¢‘ï¼‰
        # ========================================
        # â˜… ç§»é™¤é˜»å¡è½¬ç ï¼HLS æµæœ¬èº«å°±æ˜¯ H.264 ç¼–ç ï¼Œå‰ç«¯ä¼˜å…ˆä½¿ç”¨ HLS æ’­æ”¾
        # â˜… ProRes ç­‰æµè§ˆå™¨ä¸æ”¯æŒçš„æ ¼å¼ä¼šé€šè¿‡ HLS è½¬ç åæ’­æ”¾
        from ..tasks.asset_processing import generate_hls_from_url
        
        # HLS ç”Ÿæˆæ¡ä»¶ï¼š
        # 1. éœ€è¦è½¬ç çš„è§†é¢‘ï¼ˆProResã€HEVC ç­‰ï¼‰- å¿…é¡»ç”Ÿæˆ HLS æ‰èƒ½æ’­æ”¾
        # 2. æ—¶é•¿ > 2åˆ†é’Ÿ æˆ– åˆ†è¾¨ç‡ > 1080p çš„è§†é¢‘ - ä¼˜åŒ–æ’­æ”¾ä½“éªŒ
        HLS_DURATION_THRESHOLD = 120  # ç§’
        HLS_RESOLUTION_THRESHOLD = 1920  # åƒç´ 
        
        assets_need_hls = [
            info for info in asset_infos
            if info.get("needs_transcode")  # â˜… ProRes ç­‰å¿…é¡»ç”Ÿæˆ HLS
               or info["duration"] > HLS_DURATION_THRESHOLD 
               or max(info["width"], info["height"]) > HLS_RESOLUTION_THRESHOLD
        ]
        
        # â˜… æ ‡è®°éœ€è¦ HLS çš„ç´ æï¼ˆå‰ç«¯ä¼šç­‰å¾… HLS å°±ç»ªåå†æ’­æ”¾ï¼‰
        for info in assets_need_hls:
            asset_id = info["asset_id"]
            needs_transcode = info.get("needs_transcode", False)
            try:
                supabase.table("assets").update({
                    "hls_status": "pending",  # pending -> processing -> ready
                    "needs_transcode": needs_transcode,
                }).eq("id", asset_id).execute()
            except Exception as e:
                logger.warning(f"[Workspace] æ›´æ–° HLS çŠ¶æ€å¤±è´¥: {e}")
        
        async def generate_all_hls():
            """é¡ºåºç”Ÿæˆ HLSï¼Œé¿å…å¤šä¸ª FFmpeg å¹¶å‘å¯¼è‡´èµ„æºç«äº‰"""
            for info in assets_need_hls:
                asset_id = info["asset_id"]
                file_url = info["file_url"]
                codec = info.get("codec", "unknown")
                logger.info(f"[Workspace] ğŸ¬ å¯åŠ¨ HLS ç”Ÿæˆ: {asset_id} (codec={codec}, duration={info['duration']:.1f}s)")
                try:
                    hls_path = await generate_hls_from_url(asset_id, file_url)
                    if hls_path:
                        # â˜… æˆåŠŸï¼šåŒæ—¶è®¾ç½® hls_status å’Œ hls_path
                        supabase.table("assets").update({
                            "hls_status": "ready",
                            "hls_path": hls_path
                        }).eq("id", asset_id).execute()
                        logger.info(f"[Workspace] âœ… HLS ç”ŸæˆæˆåŠŸ: {asset_id}, path={hls_path}")
                    else:
                        # HLS ç”Ÿæˆè¿”å› Noneï¼ˆå¤±è´¥ï¼‰
                        supabase.table("assets").update({
                            "hls_status": "failed"
                        }).eq("id", asset_id).execute()
                        logger.error(f"[Workspace] âŒ HLS ç”Ÿæˆå¤±è´¥ï¼ˆè¿”å›ç©ºï¼‰: {asset_id}")
                except Exception as e:
                    logger.error(f"[Workspace] HLS ç”Ÿæˆå¤±è´¥ {asset_id}: {e}")
                    supabase.table("assets").update({
                        "hls_status": "failed"
                    }).eq("id", asset_id).execute()
        
        # åå°å¯åŠ¨ HLS ç”Ÿæˆï¼ˆä¸é˜»å¡ä¸»æµç¨‹ï¼‰
        hls_task = None
        if assets_need_hls:
            hls_task = asyncio.create_task(generate_all_hls())
            logger.info(f"[Workspace] ğŸ“¦ å·²å¯åŠ¨ HLS ç”Ÿæˆä»»åŠ¡ï¼ˆ{len(assets_need_hls)}/{len(asset_infos)} ä¸ªç´ æéœ€è¦ HLSï¼‰")
        else:
            logger.info(f"[Workspace] â­ï¸ è·³è¿‡ HLS ç”Ÿæˆï¼ˆæ‰€æœ‰ {len(asset_infos)} ä¸ªç´ æéƒ½æ˜¯å°è§†é¢‘ï¼Œç›´æ¥æ’­æ”¾åŸæ–‡ä»¶ï¼‰")
        
        # ========================================
        # Step 2: å¤ç”¨å·²æœ‰è½¨é“ï¼ˆfinalize_upload å·²åˆ›å»ºï¼‰
        # ========================================
        logger.info(f"[Workspace] ğŸ” æŸ¥æ‰¾å·²æœ‰è½¨é“...")
        existing_tracks = supabase.table("tracks").select("*").eq("project_id", project_id).execute()
        
        video_track_id = None
        text_track_id = None
        audio_track_id = None
        
        if existing_tracks.data:
            for track in existing_tracks.data:
                if track.get("order_index") == 0:
                    video_track_id = track["id"]
                    logger.debug(f"[Workspace]    æ‰¾åˆ°è§†é¢‘è½¨é“: {video_track_id}")
                elif track.get("order_index") == 1:
                    # order_index=1 å¯èƒ½æ˜¯å­—å¹•è½¨é“æˆ–éŸ³é¢‘è½¨é“
                    if "å­—å¹•" in track.get("name", "") or "text" in track.get("name", "").lower():
                        text_track_id = track["id"]
                        logger.debug(f"[Workspace]    æ‰¾åˆ°å­—å¹•è½¨é“: {text_track_id}")
                    else:
                        audio_track_id = track["id"]
                        logger.debug(f"[Workspace]    æ‰¾åˆ°éŸ³é¢‘è½¨é“: {audio_track_id}")
                elif track.get("order_index") == 2:
                    text_track_id = track["id"]
                    logger.debug(f"[Workspace]    æ‰¾åˆ°å­—å¹•è½¨é“(order=2): {text_track_id}")
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å·²æœ‰è½¨é“ï¼Œæ‰åˆ›å»ºæ–°çš„ï¼ˆç†è®ºä¸Šä¸åº”è¯¥å‘ç”Ÿï¼‰
        if not video_track_id:
            logger.warning(f"[Workspace] âš ï¸ æœªæ‰¾åˆ°è§†é¢‘è½¨é“ï¼Œåˆ›å»ºæ–°çš„ï¼ˆä¸åº”è¯¥å‘ç”Ÿï¼ï¼‰")
            video_track_id = str(uuid4())
            supabase.table("tracks").insert({
                "id": video_track_id,
                "project_id": project_id,
                "name": "è§†é¢‘è½¨é“",
                "order_index": 0,
                "is_muted": False,
                "is_locked": False,
                "is_visible": True,
                "created_at": now,
                "updated_at": now,
            }).execute()
        
        main_track_id = video_track_id  # é»˜è®¤ä¸»è½¨é“æ˜¯è§†é¢‘è½¨
        
        # Voice Extract æ¨¡å¼å¤„ç†
        if voice_extract_mode:
            if not audio_track_id:
                audio_track_id = str(uuid4())
                supabase.table("tracks").insert({
                    "id": audio_track_id,
                    "project_id": project_id,
                    "name": "åŸå£°éŸ³é¢‘",
                    "order_index": 1,
                    "is_muted": False,
                    "is_locked": False,
                    "is_visible": True,
                    "created_at": now,
                    "updated_at": now,
                }).execute()
            main_track_id = audio_track_id
        
        if not text_track_id:
            logger.warning(f"[Workspace] âš ï¸ æœªæ‰¾åˆ°å­—å¹•è½¨é“ï¼Œåˆ›å»ºæ–°çš„ï¼ˆä¸åº”è¯¥å‘ç”Ÿï¼ï¼‰")
            text_track_id = str(uuid4())
            supabase.table("tracks").insert({
                "id": text_track_id,
                "project_id": project_id,
                "name": "å­—å¹•è½¨é“",
                "order_index": 2 if voice_extract_mode else 1,
                "is_muted": False,
                "is_locked": False,
                "is_visible": True,
                "created_at": now,
                "updated_at": now,
            }).execute()
        
        logger.info(f"[Workspace] âœ… è½¨é“å‡†å¤‡å®Œæˆ: video={video_track_id}, text={text_track_id}")
        
        # ========================================
        # â˜… AI-Create æ¨¡å¼ï¼šå…ˆ ASRï¼Œå†æŒ‰è¯­éŸ³åˆ‡ç‰‡
        # â˜… Voice-Extract æ¨¡å¼ï¼šæ•´ä½“ clip + å­—å¹•
        # ========================================
        
        all_video_clips = []
        all_subtitle_clips = []
        all_keyframes = []
        total_segments = 0
        timeline_position = 0  # æ—¶é—´è½´ä½ç½®ï¼ˆæ¯«ç§’ï¼‰
        
        progress_per_asset = 70 / len(asset_infos)  # æ¯ä¸ªç´ æå  70% è¿›åº¦
        
        for idx, info in enumerate(asset_infos):
            # æ¯ä¸ªç´ æå¤„ç†å‰æ£€æŸ¥å–æ¶ˆçŠ¶æ€
            _raise_if_cancelled(session_id, f"å¤„ç†ç´ æ {idx + 1}/{len(asset_infos)} å‰")
            
            asset_id = info["asset_id"]
            file_url = info["file_url"]
            asset_duration_ms = info["duration_ms"]
            
            if asset_duration_ms <= 0:
                asset_duration_ms = 10000
                logger.warning(f"[Workspace] âš ï¸ Asset {asset_id} æ— æ—¶é•¿ä¿¡æ¯ï¼Œä½¿ç”¨é»˜è®¤ 10s")
            
            base_progress = 10 + int(idx * progress_per_asset)
            logger.info(f"[Workspace] ğŸ“¹ å¤„ç†ç´ æ {idx + 1}/{len(asset_infos)}: {info['name'][:30]}...")
            logger.debug(f"[Workspace]    asset_id: {asset_id}, æ—¶é•¿: {info['duration']:.1f}s, æ¨¡å¼: {'AIæ™ºèƒ½åˆ‡ç‰‡' if ai_create_mode else 'æ•´ä½“æå–'}")
            
            # Step 1: ASR è½¬å†™ï¼ˆè·å–è¯­éŸ³ç‰‡æ®µï¼‰
            transcript_segments = []
            logger.debug(f"[Workspace] ğŸ™ï¸ å¼€å§‹ ASR è½¬å†™ç´ æ {idx + 1}...")
            update_progress("transcribe", base_progress + 5)
            
            if idx > 0:
                logger.debug(f"[Workspace]    â³ ç­‰å¾… 2 ç§’é¿å… API é™æµ...")
                await asyncio.sleep(2)
            
            try:
                transcript_segments = await _run_asr(
                    file_url, 
                    update_progress,
                    base_progress,
                    int(progress_per_asset),
                    asset_id=asset_id,
                    video_duration_sec=info['duration']
                )
                
                logger.info(f"[Workspace] âœ… ASR å®Œæˆç´ æ {idx + 1}, è¯†åˆ« {len(transcript_segments)} ä¸ªç‰‡æ®µ")
                _raise_if_cancelled(session_id, f"ç´ æ {idx + 1} ASR å")
                
                breath_count = sum(1 for seg in transcript_segments if (seg.get("silence_info") or {}).get("classification") == "breath")
                speech_count = sum(1 for seg in transcript_segments if not seg.get("silence_info"))
                logger.debug(f"[Workspace]    å…¶ä¸­: è¯­éŸ³ç‰‡æ®µ {speech_count} ä¸ª, æ¢æ°”ç‰‡æ®µ {breath_count} ä¸ª")
                total_segments += len(transcript_segments)
            except Exception as asr_err:
                logger.error(f"[Workspace] âŒ ASR è½¬å†™ç´ æ {idx + 1} å¤±è´¥: {asr_err}")
                import traceback
                traceback.print_exc()
            
            # ========================================
            # Step 2: åˆ›å»º Video Clips
            # ========================================
            
            if ai_create_mode and transcript_segments:
                # â˜…â˜…â˜… AI-Create æ¨¡å¼ï¼šå®Œæ•´ä¸€é”®æˆç‰‡æµç¨‹ â˜…â˜…â˜…
                # ä½¿ç”¨ AIVideoCreatorService å¤„ç†ï¼š
                # 1. æ™ºèƒ½åˆ‡ç‰‡ (å·²æœ‰ ASR ç»“æœ)
                # 2. è§†è§‰åˆ†æ (äººè„¸æ£€æµ‹)
                # 3. LLM è¯­ä¹‰åˆ†æ (æƒ…ç»ª/é‡è¦æ€§)
                # 4. è¿é•œè§„åˆ™å¼•æ“ (å†³ç­–)
                # 5. åºåˆ—æ„ŸçŸ¥åå¤„ç† (å¤šæ ·æ€§)
                
                logger.debug(f"[Workspace] ğŸ¬ AIæ™ºèƒ½åˆ‡ç‰‡æ¨¡å¼ï¼šè°ƒç”¨ AIVideoCreatorService...")
                
                from app.services.ai_video_creator import ai_video_creator
                from app.services.transform_rules import ZoomStrategy
                
                try:
                    # è°ƒç”¨ AI æˆç‰‡æœåŠ¡ï¼ˆå¤ç”¨å·²æœ‰ ASR ç»“æœï¼‰
                    ai_result = await ai_video_creator.process(
                        video_path=file_url,  # ä½¿ç”¨ URLï¼ˆè§†è§‰åˆ†æä¼šä¸‹è½½ï¼‰
                        audio_url=file_url,
                        options={
                            "transcript_segments": transcript_segments,
                            "enable_llm": enable_llm,  # æ ¹æ®é…ç½®å†³å®šæ˜¯å¦å¯ç”¨ LLM
                        }
                    )
                    
                    logger.info(f"[Workspace] âœ… AIVideoCreator å¤„ç†å®Œæˆ: {ai_result.clips_count} ä¸ªç‰‡æ®µ")
                    
                    # å°† AI ç»“æœè½¬æ¢ä¸º clips å’Œ keyframes
                    for seg_idx, smart_seg in enumerate(ai_result.segments):
                        seg_start = int(smart_seg.start)
                        seg_end = int(smart_seg.end)
                        seg_text = smart_seg.text.strip() if smart_seg.text else ""
                        seg_duration = seg_end - seg_start
                        
                        if seg_duration <= 0:
                            continue
                        
                        clip_id = str(uuid4())
                        
                        # â˜… æ¢æ°”ç‰‡æ®µï¼šä¿ç•™ï¼Œæ·»åŠ  silence_info è®©å‰ç«¯å‘å¯¼å¤„ç†
                        is_breath = smart_seg.is_breath
                        
                        if is_breath:
                            # æ¢æ°”ç‰‡æ®µï¼šåˆ›å»º clip ä½†æ ‡è®°ä¸ºæ¢æ°”ï¼Œä¾›å‰ç«¯å‘å¯¼å¤„ç†
                            clip_data = {
                                "id": clip_id,
                                "track_id": video_track_id,
                                "asset_id": asset_id,
                                "clip_type": "video",
                                "name": "[æ¢æ°”]",
                                "start_time": timeline_position,
                                "end_time": timeline_position + seg_duration,
                                "source_start": seg_start,
                                "source_end": seg_end,
                                "volume": 1.0,
                                "is_muted": False,
                                "transform": {
                                    "x": 0, "y": 0,
                                    "scaleX": 1, "scaleY": 1,
                                    "rotation": 0,
                                    "opacity": 1,
                                },
                                "speed": 1.0,
                                "metadata": {
                                    "segment_id": smart_seg.id,
                                    "asset_index": idx,
                                    "segment_index": seg_idx,
                                    "silence_info": {
                                        "classification": "breath",
                                        "duration_ms": seg_duration,
                                    },
                                },
                                "created_at": now,
                                "updated_at": now,
                            }
                            all_video_clips.append(clip_data)
                            
                            # æ¢æ°”ç‰‡æ®µä¸éœ€è¦å­—å¹•å’Œè¿é•œ
                            logger.debug(f"[Workspace]    Clip {seg_idx + 1} [æ¢æ°”]: {timeline_position}~{timeline_position + seg_duration}ms")
                            timeline_position += seg_duration
                            continue
                        
                        # è·³è¿‡ç©ºæ–‡æœ¬çš„éæ¢æ°”ç‰‡æ®µ
                        if not seg_text:
                            continue
                        
                        # è¯­éŸ³ç‰‡æ®µ
                        clip_data = {
                            "id": clip_id,
                            "track_id": video_track_id,
                            "asset_id": asset_id,
                            "clip_type": "video",
                            "name": seg_text[:20] + ("..." if len(seg_text) > 20 else ""),
                            "start_time": timeline_position,
                            "end_time": timeline_position + seg_duration,
                            "source_start": seg_start,
                            "source_end": seg_end,
                            "volume": 1.0,
                            "is_muted": False,
                            "transform": {
                                "x": 0, "y": 0,
                                "scaleX": 1, "scaleY": 1,
                                "rotation": 0,
                                "opacity": 1,
                            },
                            "speed": 1.0,
                            "metadata": {
                                "segment_id": smart_seg.id,
                                "asset_index": idx,
                                "segment_index": seg_idx,
                                "emotion": smart_seg.emotion.value if smart_seg.emotion else "neutral",
                                "importance": smart_seg.importance.value if smart_seg.importance else "medium",
                                "has_face": smart_seg.has_face,
                                "rule_applied": smart_seg.transform.get("_rule_applied") if smart_seg.transform else None,
                            },
                            "created_at": now,
                            "updated_at": now,
                        }
                        all_video_clips.append(clip_data)
                        
                        # å­—å¹• clipsï¼ˆç»†åˆ†ï¼‰
                        fine_subs = _split_segments_by_punctuation([{
                            "id": smart_seg.id,
                            "start": seg_start,
                            "end": seg_end,
                            "text": seg_text,
                        }])
                        for sub_idx, sub_seg in enumerate(fine_subs):
                            sub_start = sub_seg.get("start", seg_start)
                            sub_end = sub_seg.get("end", seg_end)
                            sub_text = sub_seg.get("text", "").strip()
                            sub_duration = sub_end - sub_start
                            
                            if sub_duration <= 0 or not sub_text:
                                continue
                            
                            sub_offset = sub_start - seg_start
                            
                            all_subtitle_clips.append({
                                "id": str(uuid4()),
                                "track_id": text_track_id,
                                "clip_type": "subtitle",
                                "parent_clip_id": clip_id,
                                "start_time": timeline_position + sub_offset,
                                "end_time": timeline_position + sub_offset + sub_duration,
                                "source_start": 0,
                                "source_end": sub_duration,
                                "is_muted": False,
                                "content_text": sub_text,
                                "text_style": {
                                    "fontSize": 15,
                                    "fontColor": "#FFFFFF",
                                    "backgroundColor": "transparent",
                                    "alignment": "center",
                                    "maxWidth": "95%",
                                },
                                "transform": {"x": 0, "y": 150, "scale": 1},
                                "metadata": {
                                    "segment_id": smart_seg.id,
                                    "asset_index": idx,
                                    "order_index": seg_idx * 100 + sub_idx,
                                },
                                "created_at": now,
                                "updated_at": now,
                            })
                        
                        # â˜… Keyframesï¼šæ ¹æ® AI è¿é•œå†³ç­–ç”Ÿæˆ
                        if smart_seg.transform_params:
                            params = smart_seg.transform_params
                            
                            # èµ·å§‹å…³é”®å¸§
                            all_keyframes.append({
                                "id": str(uuid4()),
                                "clip_id": clip_id,
                                "property": "scale",
                                "offset": 0.0,
                                "value": {"x": params.start_scale, "y": params.start_scale},
                                "easing": "ease_in_out",
                                "created_at": now,
                                "updated_at": now,
                            })
                            
                            # ç»“æŸå…³é”®å¸§
                            all_keyframes.append({
                                "id": str(uuid4()),
                                "clip_id": clip_id,
                                "property": "scale",
                                "offset": 1.0,
                                "value": {"x": params.end_scale, "y": params.end_scale},
                                "easing": params.easing.value if hasattr(params.easing, 'value') else str(params.easing),
                                "created_at": now,
                                "updated_at": now,
                            })
                            
                            # ä½ç§»å…³é”®å¸§ï¼ˆå¦‚æœæœ‰ä½ç§»ï¼‰
                            if abs(params.position_x) > 0.01 or abs(params.position_y) > 0.01:
                                all_keyframes.append({
                                    "id": str(uuid4()),
                                    "clip_id": clip_id,
                                    "property": "position",
                                    "offset": 0.0,
                                    "value": {"x": 0, "y": 0},
                                    "easing": "ease_in_out",
                                    "created_at": now,
                                    "updated_at": now,
                                })
                                all_keyframes.append({
                                    "id": str(uuid4()),
                                    "clip_id": clip_id,
                                    "property": "position",
                                    "offset": 1.0,
                                    "value": {"x": params.position_x, "y": params.position_y},
                                    "easing": params.easing.value if hasattr(params.easing, 'value') else str(params.easing),
                                    "created_at": now,
                                    "updated_at": now,
                                })
                            
                            logger.debug(f"[Workspace]    Clip {seg_idx + 1}: {timeline_position}~{timeline_position + seg_duration}ms, "
                                       f"rule={params.rule_applied}, scale={params.start_scale:.2f}â†’{params.end_scale:.2f}")
                        else:
                            # Fallback: ç®€å•æ…¢æ¨
                            all_keyframes.append({
                                "id": str(uuid4()),
                                "clip_id": clip_id,
                                "property": "scale",
                                "offset": 0.0,
                                "value": {"x": 1.0, "y": 1.0},
                                "easing": "ease_in_out",
                                "created_at": now,
                                "updated_at": now,
                            })
                            all_keyframes.append({
                                "id": str(uuid4()),
                                "clip_id": clip_id,
                                "property": "scale",
                                "offset": 1.0,
                                "value": {"x": 1.08, "y": 1.08},
                                "easing": "linear",
                                "created_at": now,
                                "updated_at": now,
                            })
                        
                        timeline_position += seg_duration
                    
                    logger.debug(f"[Workspace] âœ… AIåˆ‡ç‰‡å®Œæˆ: {len([c for c in all_video_clips if c.get('asset_id') == asset_id])} ä¸ª video clips")
                    
                except Exception as ai_err:
                    logger.error(f"[Workspace] âŒ AIVideoCreator å¤„ç†å¤±è´¥: {ai_err}")
                    import traceback
                    traceback.print_exc()
                    
                    # Fallback: ä½¿ç”¨ç®€å•åˆ‡ç‰‡é€»è¾‘
                    logger.debug(f"[Workspace] âš ï¸ é™çº§ä¸ºç®€å•åˆ‡ç‰‡æ¨¡å¼...")
                    speech_segments = [seg for seg in transcript_segments 
                                      if seg.get("text", "").strip() and not seg.get("silence_info")]
                    
                    for seg_idx, seg in enumerate(speech_segments):
                        seg_start = seg.get("start", 0)
                        seg_end = seg.get("end", 0)
                        seg_text = seg.get("text", "").strip()
                        seg_duration = seg_end - seg_start
                        
                        if seg_duration <= 0:
                            continue
                        
                        clip_id = str(uuid4())
                        clip_data = {
                            "id": clip_id,
                            "track_id": video_track_id,
                            "asset_id": asset_id,
                            "clip_type": "video",
                            "name": seg_text[:20] + ("..." if len(seg_text) > 20 else ""),
                            "start_time": timeline_position,
                            "end_time": timeline_position + seg_duration,
                            "source_start": seg_start,
                            "source_end": seg_end,
                            "volume": 1.0,
                            "is_muted": False,
                            "transform": {"x": 0, "y": 0, "scaleX": 1, "scaleY": 1, "rotation": 0, "opacity": 1},
                            "speed": 1.0,
                            "created_at": now,
                            "updated_at": now,
                        }
                        all_video_clips.append(clip_data)
                        
                        # ç®€å• keyframes
                        all_keyframes.append({
                            "id": str(uuid4()),
                            "clip_id": clip_id,
                            "property": "scale",
                            "offset": 0.0,
                            "value": {"x": 1.0, "y": 1.0},
                            "easing": "ease_in_out",
                            "created_at": now,
                            "updated_at": now,
                        })
                        all_keyframes.append({
                            "id": str(uuid4()),
                            "clip_id": clip_id,
                            "property": "scale",
                            "offset": 1.0,
                            "value": {"x": 1.08, "y": 1.08},
                            "easing": "linear",
                            "created_at": now,
                            "updated_at": now,
                        })
                        
                        timeline_position += seg_duration
                
            else:
                # â˜… Voice-Extract æˆ–æ—  ASR ç»“æœï¼šåˆ›å»ºæ•´ä½“ clip
                logger.debug(f"[Workspace] ğŸ¬ æ•´ä½“æ¨¡å¼ï¼šåˆ›å»ºå•ä¸ª clip...")
                
                clip_id = str(uuid4())
                clip_data = {
                    "id": clip_id,
                    "track_id": video_track_id,
                    "asset_id": asset_id,
                    "clip_type": "video",
                    "name": info.get("name", "è§†é¢‘"),
                    "start_time": timeline_position,
                    "end_time": timeline_position + asset_duration_ms,
                    "source_start": 0,
                    "source_end": asset_duration_ms,
                    "volume": 1.0,
                    "is_muted": False,
                    "transform": {
                        "x": 0, "y": 0,
                        "scaleX": 1, "scaleY": 1,
                        "rotation": 0,
                        "opacity": 1,
                    },
                    "speed": 1.0,
                    "created_at": now,
                    "updated_at": now,
                }
                all_video_clips.append(clip_data)
                
                # åˆ›å»ºå­—å¹• clipsï¼ˆå¦‚æœæœ‰ ASR ç»“æœï¼‰
                if transcript_segments:
                    subtitle_clips = await _create_subtitle_clips_only(
                        transcript_segments=transcript_segments,
                        text_track_id=text_track_id,
                        video_clip_id=clip_id,
                        timeline_offset=timeline_position,
                        asset_index=idx,
                    )
                    all_subtitle_clips.extend(subtitle_clips)
                
                logger.debug(f"[Workspace]    åˆ›å»º clip: {clip_id}, {timeline_position}~{timeline_position + asset_duration_ms}ms")
                timeline_position += asset_duration_ms
            
            logger.debug(f"[Workspace] âœ… ç´ æ {idx + 1} å¤„ç†å®Œæˆ")
        
        # ========================================
        # Step 3: æ‰¹é‡æ’å…¥ clips å’Œ keyframes
        # ========================================
        logger.debug(f"[Workspace] ğŸ“¦ æ‰¹é‡æ’å…¥æ•°æ®åº“...")
        
        if all_video_clips:
            try:
                supabase.table("clips").insert(all_video_clips).execute()
                logger.debug(f"[Workspace] âœ… åˆ›å»º {len(all_video_clips)} ä¸ª video clips")
            except Exception as e:
                logger.error(f"[Workspace] âŒ åˆ›å»º video clips å¤±è´¥: {e}")
                raise
        
        if all_keyframes:
            try:
                supabase.table("keyframes").insert(all_keyframes).execute()
                logger.debug(f"[Workspace] âœ… åˆ›å»º {len(all_keyframes)} ä¸ª keyframes")
            except Exception as e:
                logger.warning(f"[Workspace] âš ï¸ æ’å…¥ keyframes å¤±è´¥: {e}")
        
        if all_subtitle_clips:
            try:
                supabase.table("clips").insert(all_subtitle_clips).execute()
                logger.debug(f"[Workspace] âœ… åˆ›å»º {len(all_subtitle_clips)} ä¸ªå­—å¹• clips")
            except Exception as e:
                logger.warning(f"[Workspace] âš ï¸ åˆ›å»ºå­—å¹• clips å¤±è´¥: {e}")
        
        # ========================================
        # ğŸ¬ ç­‰å¾… HLS åå°ä»»åŠ¡å®Œæˆï¼ˆå¸¦è¶…æ—¶ï¼‰
        # ========================================
        update_progress("prepare", 90)
        
        if 'hls_task' in locals() and hls_task:
            logger.debug(f"[Workspace] â³ ç­‰å¾… HLS ç”Ÿæˆä»»åŠ¡å®Œæˆï¼ˆæœ€å¤š 120 ç§’ï¼‰...")
            try:
                # è®¾ç½®è¶…æ—¶ï¼Œé¿å…æ— é™ç­‰å¾…
                await asyncio.wait_for(hls_task, timeout=120.0)
                logger.debug(f"[Workspace] âœ… HLS ç”Ÿæˆä»»åŠ¡å®Œæˆ")
            except asyncio.TimeoutError:
                logger.warning(f"[Workspace] âš ï¸ HLS ä»»åŠ¡è¶…æ—¶ï¼ˆ120ç§’ï¼‰ï¼Œç»§ç»­å¤„ç†...")
                hls_task.cancel()
            except Exception as e:
                logger.warning(f"[Workspace] âš ï¸ HLS ä»»åŠ¡å¼‚å¸¸: {e}")
        
        update_progress("prepare", 95)
        
        # æ›´æ–°é¡¹ç›®
        fps = 30
        supabase.table("projects").update({
            "status": "ready",
            "resolution": {"width": max_width, "height": max_height},
            "fps": fps,
            "updated_at": now,
        }).eq("id", project_id).execute()
        
        # æ›´æ–°æ‰€æœ‰ç´ æçŠ¶æ€
        for info in asset_infos:
            supabase.table("assets").update({
                "status": "ready",
                "updated_at": now,
            }).eq("id", info["asset_id"]).execute()
        
        update_progress("prepare", 100)
        
        # æ ‡è®°ä¼šè¯å®Œæˆ
        supabase.table("workspace_sessions").update({
            "status": "completed",
            "progress": 100,
            "current_step": "completed",
            "transcript_segments": total_segments,
            "completed_at": now,
            "updated_at": now,
        }).eq("id", session_id).execute()
        
        logger.info(f"[Workspace] âœ… å¤šç´ æä¼šè¯ {session_id} å¤„ç†å®Œæˆï¼Œå…± {len(asset_infos)} ä¸ªç´ æ")
        
    except SessionCancelledException:
        # ç”¨æˆ·ä¸»åŠ¨å–æ¶ˆï¼Œä¸éœ€è¦æ›´æ–°çŠ¶æ€ï¼ˆå·²ç»æ˜¯ cancelledï¼‰
        logger.info(f"[Workspace] ğŸ›‘ å¤šç´ æä¼šè¯ {session_id} å¤„ç†å·²è¢«ç”¨æˆ·å–æ¶ˆ")
        # å–æ¶ˆæœªå®Œæˆçš„ HLS ä»»åŠ¡
        if 'hls_task' in locals() and hls_task and not hls_task.done():
            hls_task.cancel()
            logger.info(f"[Workspace] ğŸ›‘ å–æ¶ˆ HLS ä»»åŠ¡")
        return
    except Exception as e:
        logger.error(f"[Workspace] âŒ å¤šç´ æå¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        
        # å–æ¶ˆæœªå®Œæˆçš„ HLS ä»»åŠ¡
        if 'hls_task' in locals() and hls_task and not hls_task.done():
            hls_task.cancel()
            logger.info(f"[Workspace] ğŸ›‘ å–æ¶ˆ HLS ä»»åŠ¡")
        
        supabase.table("workspace_sessions").update({
            "status": "failed",
            "error_message": str(e),
            "updated_at": datetime.utcnow().isoformat(),
        }).eq("id", session_id).execute()
        
        supabase.table("projects").update({
            "status": "draft",
            "updated_at": datetime.utcnow().isoformat(),
        }).eq("id", project_id).execute()


async def _create_clips_from_segments_with_offset(
    project_id: str,
    asset_id: str,
    transcript_segments: list,
    video_track_id: str,
    text_track_id: str,
    timeline_offset: int = 0,
    asset_index: int = 0,
    enable_llm: bool = False,
    enable_smart_camera: bool = True,
    enable_subtitle: bool = True,
) -> tuple:
    """
    æ ¹æ® ASR segments åˆ›å»ºè§†é¢‘å’Œå­—å¹• clipsï¼ˆå¸¦æ—¶é—´è½´åç§»ï¼‰
    ç”¨äºå¤šç´ ææ‹¼æ¥åœºæ™¯
    
    Args:
        timeline_offset: åœ¨æ—¶é—´è½´ä¸Šçš„èµ·å§‹ä½ç½®ï¼ˆæ¯«ç§’ï¼‰
        asset_index: ç´ æç´¢å¼•ï¼Œç”¨äºå‘½å
        enable_llm: æ˜¯å¦å¯ç”¨ LLM è¯­ä¹‰åˆ†æ
        enable_smart_camera: æ˜¯å¦å¯ç”¨æ™ºèƒ½è¿é•œï¼ˆå¦‚æœä¸º Falseï¼Œåˆ™ä¸è¿›è¡Œè£å‰ª/ç¼©æ”¾ï¼‰
        enable_subtitle: æ˜¯å¦ç”Ÿæˆå­—å¹• clipsï¼ˆå¦‚æœä¸º Falseï¼Œåªç”Ÿæˆè§†é¢‘ clipsï¼‰
        
    Returns:
        tuple: (video_clips, subtitle_clips, keyframes)
        - keyframes: å¾…æ’å…¥ keyframes è¡¨çš„è®°å½•åˆ—è¡¨
    """
    logger.info(f"[Workspace] ======== åˆ‡ç‰‡å‡½æ•°å¼€å§‹ ========")
    logger.info(f"[Workspace] ğŸ¬ _create_clips_from_segments_with_offset")
    logger.info(f"[Workspace]    asset_id: {asset_id}")
    logger.info(f"[Workspace]    asset_index: {asset_index}")
    logger.info(f"[Workspace]    timeline_offset: {timeline_offset}ms")
    logger.info(f"[Workspace]    enable_smart_camera: {enable_smart_camera}")
    logger.info(f"[Workspace]    enable_subtitle: {enable_subtitle}")
    logger.info(f"[Workspace]    è¾“å…¥ segments æ•°é‡: {len(transcript_segments)}")
    
    # â˜… å…³é”®æ—¥å¿—ï¼šæ‰“å°å‰å‡ ä¸ª segments çš„å†…å®¹ï¼ŒéªŒè¯ ASR ç»“æœå’Œ asset å¯¹åº”
    if transcript_segments:
        for i, seg in enumerate(transcript_segments[:3]):
            seg_text = seg.get("text", "")[:30]
            logger.info(f"[Workspace]    segment[{i}]: start={seg.get('start')} text='{seg_text}...'")
    
    now = datetime.utcnow().isoformat()
    
    # æŒ‰æ—¶é—´é¡ºåºæ’åºåŸå§‹ segments
    sorted_segments = sorted(transcript_segments, key=lambda s: s.get("start", 0))
    
    video_clips = []
    subtitle_clips = []
    all_keyframes = []  # â˜… æ”¶é›†æ‰€æœ‰å…³é”®å¸§è®°å½•
    timeline_position = timeline_offset
    
    # ç»Ÿè®¡è‡ªåŠ¨è·³è¿‡çš„é™éŸ³ç‰‡æ®µ
    auto_skipped = {"dead_air": 0, "long_pause": 0, "hesitation": 0}
    
    # ========== ç¬¬ä¸€é˜¶æ®µï¼šæ”¶é›†æœ‰æ•ˆç‰‡æ®µ ==========
    valid_segments = []  # å­˜å‚¨ (seg_idx, seg, seg_duration, clip_name, is_breath, silence_info)
    
    for seg_idx, seg in enumerate(sorted_segments):
        seg_start = seg.get("start", 0)
        seg_end = seg.get("end", 0)
        seg_text = seg.get("text", "").strip()
        seg_duration = seg_end - seg_start
        
        if seg_duration <= 0:
            continue
        
        # æ£€æŸ¥é™éŸ³ä¿¡æ¯
        silence_info = seg.get("silence_info")
        
        if silence_info:
            cls = silence_info.get("classification")
            if cls in ("dead_air", "long_pause", "hesitation"):
                logger.info(f"[Workspace]   âš ï¸ è·³è¿‡ segment[{seg_idx}]: type={cls} start={seg_start} end={seg_end}")
                auto_skipped[cls] = auto_skipped.get(cls, 0) + 1
                continue
        
        # ç¡®å®šç‰‡æ®µç±»å‹
        clip_name = f"ç´ æ{asset_index + 1}-ç‰‡æ®µ{seg_idx + 1}"
        is_breath = False
        if silence_info and silence_info.get("classification") == "breath":
            clip_name = f"ç´ æ{asset_index + 1}-æ¢æ°”"
            is_breath = True
        
        valid_segments.append((seg_idx, seg, seg_duration, clip_name, is_breath, silence_info))
    
    # ========== ç¬¬äºŒé˜¶æ®µï¼šLLM è¯­ä¹‰åˆ†æï¼ˆå¯é€‰ï¼‰==========
    llm_results = {}
    if enable_llm and valid_segments:
        from ..services.llm_service import analyze_segments_batch, is_llm_configured
        
        if is_llm_configured():
            logger.info(f"[Workspace] ğŸ¤– å¼€å§‹ LLM è¯­ä¹‰åˆ†æ...")
            # æ„å»ºå¾…åˆ†æçš„æ–‡æœ¬ç‰‡æ®µ
            text_segments = []
            for seg_idx, seg, seg_duration, clip_name, is_breath, silence_info in valid_segments:
                seg_text = seg.get("text", "").strip()
                if seg_text and not is_breath:
                    text_segments.append({"id": str(seg_idx), "text": seg_text})
            
            if text_segments:
                try:
                    llm_results = await analyze_segments_batch(text_segments)
                    logger.info(f"[Workspace] âœ… LLM åˆ†æå®Œæˆ: {len(llm_results)} æ¡ç»“æœ")
                except Exception as e:
                    logger.warning(f"[Workspace] âš ï¸ LLM åˆ†æå¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            else:
                logger.info(f"[Workspace]    æ— æ–‡æœ¬ç‰‡æ®µéœ€è¦åˆ†æ")
        else:
            logger.info(f"[Workspace] âš ï¸ LLM API æœªé…ç½®ï¼Œè·³è¿‡è¯­ä¹‰åˆ†æ")
    
    # ========== ç¬¬ä¸‰é˜¶æ®µï¼šæ‰¹é‡ç”Ÿæˆ transformï¼ˆå«åºåˆ—åå¤„ç†ï¼‰==========
    # é‡ç½®åºåˆ—å¤„ç†å™¨çŠ¶æ€
    sequence_processor.reset()
    
    # å£æ’­æ¨¡å¼é»˜è®¤äººè„¸ä½ç½®ï¼ˆä¸å•ç´ ææµç¨‹ä¸€è‡´ï¼‰
    DEFAULT_FACE_CENTER_X = 0.5   # å±…ä¸­
    DEFAULT_FACE_CENTER_Y = 0.35  # ç¨å¾®åä¸Šï¼ˆå£æ’­å¸¸è§æ„å›¾ï¼‰
    
    # æ„å»ºä¸Šä¸‹æ–‡åˆ—è¡¨
    contexts = []
    for seg_idx, seg, seg_duration, clip_name, is_breath, silence_info in valid_segments:
        seg_text = seg.get("text", "").strip()
        
        # ä» LLM ç»“æœè·å–æƒ…ç»ªå’Œé‡è¦æ€§ï¼Œæˆ–ä½¿ç”¨é»˜è®¤å€¼
        seg_id_str = str(seg_idx)
        llm_data = llm_results.get(seg_id_str, {})
        emotion_str = llm_data.get("emotion", "neutral")
        importance_str = llm_data.get("importance", "medium")
        
        try:
            emotion = EmotionType(emotion_str)
        except ValueError:
            emotion = EmotionType.NEUTRAL
        try:
            importance = ImportanceLevel(importance_str)
        except ValueError:
            importance = ImportanceLevel.MEDIUM
        
        context = SegmentContext(
            segment_id=seg_id_str,
            duration_ms=seg_duration,
            text=seg_text,
            # å£æ’­æ¨¡å¼ï¼šé»˜è®¤æœ‰äººè„¸ï¼Œå±…ä¸­åä¸Šï¼ˆä¸å•ç´ ææµç¨‹ä¸€è‡´ï¼‰
            has_face=True,
            face_center_x=DEFAULT_FACE_CENTER_X,
            face_center_y=DEFAULT_FACE_CENTER_Y,
            # ä½¿ç”¨ LLM åˆ†æç»“æœæˆ–é»˜è®¤å€¼
            emotion=emotion,
            importance=importance,
            is_breath=is_breath,
        )
        contexts.append(context)
    
    logger.info(f"[Workspace] ğŸ¥ enable_smart_camera={enable_smart_camera}, å¾…å¤„ç† {len(contexts)} ä¸ªç‰‡æ®µ")
    
    # ä½¿ç”¨è§„åˆ™å¼•æ“æ‰¹é‡å¤„ç†
    if enable_smart_camera:
        params_list = [transform_engine.process(ctx) for ctx in contexts]
        
        # åºåˆ—æ„ŸçŸ¥åå¤„ç†ï¼šç¡®ä¿è¿é•œå¤šæ ·æ€§ï¼ˆä¸å•ç´ ææµç¨‹ä¸€è‡´ï¼‰
        params_contexts = list(zip(params_list, contexts))
        processed_params = sequence_processor.process_batch(params_contexts)
    else:
        # ç¦ç”¨æ™ºèƒ½è¿é•œï¼Œç”Ÿæˆé»˜è®¤é™æ€å‚æ•°
        processed_params = [
            TransformParams(strategy=ZoomStrategy.STATIC, rule_applied="disabled_by_user")
            for _ in contexts
        ]
    
    # ========== ç¬¬ä¸‰é˜¶æ®µï¼šæ„å»º clips ==========
    for i, (seg_idx, seg, seg_duration, clip_name, is_breath, silence_info) in enumerate(valid_segments):
        seg_start = seg.get("start", 0)
        seg_end = seg.get("end", 0)
        seg_text = seg.get("text", "").strip()
        
        video_clip_id = str(uuid4())
        
        # è·å–æ‰¹å¤„ç†åçš„ transform
        transform_params = processed_params[i]
        
        # â˜… æ–° APIï¼šç›´æ¥è·å–å…ƒä¿¡æ¯å’Œå…³é”®å¸§
        transform_meta = transform_params.get_meta()
        clip_keyframes = transform_params.get_keyframes_for_db(video_clip_id, seg_duration)
        
        logger.info(f"[Workspace]   âœ… åˆ›å»º clip[{seg_idx}]: name='{clip_name}' timeline={timeline_position}~{timeline_position + seg_duration} source={seg_start}~{seg_end} rule={transform_meta.get('_rule_applied', 'none')}")
        
        video_clips.append({
            "id": video_clip_id,
            "track_id": video_track_id,
            "asset_id": asset_id,
            "clip_type": "video",
            "start_time": timeline_position,
            "end_time": timeline_position + seg_duration,
            "source_start": seg_start,
            "source_end": seg_end,
            "is_muted": False,
            "name": clip_name,
            "transform": transform_meta,  # åªå­˜å…ƒä¿¡æ¯
            "created_at": now,
            "updated_at": now,
            "metadata": {
                "silence_info": silence_info,
                "original_text": seg_text,
                "asset_index": asset_index,
            }
        })
        
        # æ”¶é›†å…³é”®å¸§ï¼ˆç»Ÿä¸€å­˜å‚¨åˆ° keyframes è¡¨ï¼‰
        all_keyframes.extend(clip_keyframes)
        
        # åˆ›å»ºå­—å¹• clipsï¼ˆä»…å½“ enable_subtitle=True æ—¶ï¼‰
        if seg_text and enable_subtitle:
            fine_subs = _split_segments_by_punctuation([seg])
            
            for sub_idx, sub_seg in enumerate(fine_subs):
                sub_start = sub_seg.get("start", seg_start)
                sub_end = sub_seg.get("end", seg_end)
                sub_text = sub_seg.get("text", "").strip()
                sub_duration = sub_end - sub_start
                
                if sub_duration <= 0 or not sub_text:
                    continue
                
                subtitle_timeline_start = timeline_position + (sub_start - seg_start)
                
                subtitle_clips.append({
                    "id": str(uuid4()),
                    "track_id": text_track_id,
                    "clip_type": "subtitle",
                    "parent_clip_id": video_clip_id,
                    "start_time": subtitle_timeline_start,
                    "end_time": subtitle_timeline_start + sub_duration,
                    "source_start": 0,
                    "source_end": sub_duration,
                    "is_muted": False,
                    "content_text": sub_text,
                    "text_style": {
                        "fontSize": 15,
                        "fontColor": "#FFFFFF",
                        "backgroundColor": "transparent",
                        "alignment": "center",
                        "maxWidth": "95%",
                    },
                    "transform": {
                        "x": 0,
                        "y": 150,
                        "scale": 1,
                    },
                    "metadata": {
                        "segment_id": seg.get("id"),
                        "asset_index": asset_index,
                        "order_index": seg_idx * 100 + sub_idx,
                        "original_start": sub_start,
                        "original_end": sub_end,
                    },
                    "created_at": now,
                    "updated_at": now,
                })
        
        timeline_position += seg_duration
    
    logger.info(f"[Workspace] ======== åˆ‡ç‰‡å‡½æ•°ç»“æŸ ========")
    logger.info(f"[Workspace] ğŸ“Š ç´ æ {asset_index + 1} ç»Ÿè®¡:")
    logger.info(f"[Workspace]    è¾“å…¥ segments: {len(sorted_segments)}")
    logger.info(f"[Workspace]    åˆ›å»ºè§†é¢‘ clips: {len(video_clips)}")
    logger.info(f"[Workspace]    åˆ›å»ºå­—å¹• clips: {len(subtitle_clips)}")
    logger.info(f"[Workspace]    æå–å…³é”®å¸§æ•°: {len(all_keyframes)}")
    logger.info(f"[Workspace]    è·³è¿‡é™éŸ³: {auto_skipped}")
    logger.info(f"[Workspace]    æœ€ç»ˆ timeline ä½ç½®: {timeline_position}ms")
    
    return video_clips, subtitle_clips, all_keyframes


async def _create_subtitle_clips_only(
    transcript_segments: list,
    text_track_id: str,
    video_clip_id: str = None,
    timeline_offset: int = 0,
    asset_index: int = 0,
) -> list:
    """
    â˜… åªåˆ›å»ºå­—å¹• clipsï¼Œä¸åˆ›å»º video clips
    ç”¨äº confirm_upload é˜¶æ®µï¼Œvideo clips å·²ç”± finalize_upload åˆ›å»º
    
    Args:
        transcript_segments: ASR è½¬å†™ç»“æœ
        text_track_id: å­—å¹•è½¨é“ ID
        video_clip_id: å…³è”çš„è§†é¢‘ clip ID (ç”¨äº parent_clip_id)
        timeline_offset: æ—¶é—´è½´åç§»ï¼ˆæ¯«ç§’ï¼‰
        asset_index: ç´ æç´¢å¼•
    
    Returns:
        list: å­—å¹• clips åˆ—è¡¨
    """
    logger.info(f"[Workspace] ğŸ“ _create_subtitle_clips_only")
    logger.info(f"[Workspace]    text_track_id: {text_track_id}")
    logger.info(f"[Workspace]    video_clip_id: {video_clip_id}")
    logger.info(f"[Workspace]    timeline_offset: {timeline_offset}ms")
    logger.info(f"[Workspace]    segments count: {len(transcript_segments)}")
    
    now = datetime.utcnow().isoformat()
    subtitle_clips = []
    
    # è¿‡æ»¤æœ‰æ•ˆçš„è¯­éŸ³ç‰‡æ®µï¼ˆè·³è¿‡é™éŸ³ï¼‰
    sorted_segments = sorted(transcript_segments, key=lambda s: s.get("start", 0))
    
    for seg_idx, seg in enumerate(sorted_segments):
        seg_start = seg.get("start", 0)
        seg_end = seg.get("end", 0)
        seg_text = seg.get("text", "").strip()
        seg_duration = seg_end - seg_start
        
        if seg_duration <= 0 or not seg_text:
            continue
        
        # è·³è¿‡é™éŸ³ç‰‡æ®µ
        silence_info = seg.get("silence_info")
        if silence_info:
            cls = silence_info.get("classification")
            if cls in ("dead_air", "long_pause", "hesitation", "breath"):
                continue
        
        # ç»†åˆ†å­—å¹•ï¼ˆæŒ‰æ ‡ç‚¹ç¬¦å·åˆ†å‰²ï¼‰
        fine_subs = _split_segments_by_punctuation([seg])
        
        for sub_idx, sub_seg in enumerate(fine_subs):
            sub_start = sub_seg.get("start", seg_start)
            sub_end = sub_seg.get("end", seg_end)
            sub_text = sub_seg.get("text", "").strip()
            sub_duration = sub_end - sub_start
            
            if sub_duration <= 0 or not sub_text:
                continue
            
            # â˜… è®¡ç®—æ—¶é—´è½´ä½ç½®ï¼šä½¿ç”¨ source æ—¶é—´ï¼ˆç›¸å¯¹äºè§†é¢‘å¼€å§‹ï¼‰
            subtitle_timeline_start = timeline_offset + sub_start
            
            subtitle_clips.append({
                "id": str(uuid4()),
                "track_id": text_track_id,
                "clip_type": "subtitle",
                "parent_clip_id": video_clip_id,
                "start_time": subtitle_timeline_start,
                "end_time": subtitle_timeline_start + sub_duration,
                "source_start": 0,
                "source_end": sub_duration,
                "is_muted": False,
                "content_text": sub_text,
                "text_style": {
                    "fontSize": 15,
                    "fontColor": "#FFFFFF",
                    "backgroundColor": "transparent",
                    "alignment": "center",
                    "maxWidth": "95%",
                },
                "transform": {
                    "x": 0,
                    "y": 150,
                    "scale": 1,
                },
                "metadata": {
                    "segment_id": seg.get("id"),
                    "asset_index": asset_index,
                    "order_index": seg_idx * 100 + sub_idx,
                    "original_start": sub_start,
                    "original_end": sub_end,
                },
                "created_at": now,
                "updated_at": now,
            })
    
    logger.info(f"[Workspace] âœ… åˆ›å»º {len(subtitle_clips)} ä¸ªå­—å¹• clips")
    return subtitle_clips